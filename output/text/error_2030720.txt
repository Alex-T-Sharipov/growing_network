Training with a single process on 1 device (cuda:0).
WARNING: No pretrained configuration specified for MONet_T_one model. Using a default. Please add a config to the model pretrained_cfg registry or pass explicitly.
Model MONet_T_one created, param count:876396
Data processing configuration for current model + dataset:
	input_size: (3, 32, 32)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.875
	crop_mode: center
AMP not enabled. Training in float32.
/home/sharipov/monet/venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Scheduled epochs: 300. LR stepped per epoch.
Train: 0 [   0/625 (  0%)]  Loss: 2.30 (2.30)  Time: 1.554s,   41.19/s  (1.554s,   41.19/s)  LR: 1.000e-05  Data: 1.100 (1.100)
Train: 0 [  50/625 (  8%)]  Loss: 2.28 (2.30)  Time: 0.018s, 3629.86/s  (0.057s, 1129.92/s)  LR: 1.000e-05  Data: 0.013 (0.042)
Train: 0 [ 100/625 ( 16%)]  Loss: 2.23 (2.28)  Time: 0.016s, 3933.52/s  (0.043s, 1490.60/s)  LR: 1.000e-05  Data: 0.011 (0.033)
Train: 0 [ 150/625 ( 24%)]  Loss: 2.23 (2.27)  Time: 0.015s, 4252.85/s  (0.038s, 1666.89/s)  LR: 1.000e-05  Data: 0.010 (0.030)
Train: 0 [ 200/625 ( 32%)]  Loss: 2.20 (2.26)  Time: 0.033s, 1935.02/s  (0.036s, 1766.43/s)  LR: 1.000e-05  Data: 0.028 (0.029)
Train: 0 [ 250/625 ( 40%)]  Loss: 2.26 (2.25)  Time: 0.005s, 12285.94/s  (0.035s, 1835.30/s)  LR: 1.000e-05  Data: 0.000 (0.028)
Train: 0 [ 300/625 ( 48%)]  Loss: 2.19 (2.24)  Time: 0.033s, 1936.46/s  (0.034s, 1884.70/s)  LR: 1.000e-05  Data: 0.028 (0.027)
Train: 0 [ 350/625 ( 56%)]  Loss: 2.22 (2.24)  Time: 0.005s, 12474.35/s  (0.033s, 1925.18/s)  LR: 1.000e-05  Data: 0.000 (0.027)
Train: 0 [ 400/625 ( 64%)]  Loss: 2.12 (2.23)  Time: 0.040s, 1603.07/s  (0.033s, 1952.26/s)  LR: 1.000e-05  Data: 0.035 (0.027)
Train: 0 [ 450/625 ( 72%)]  Loss: 2.20 (2.23)  Time: 0.005s, 12198.28/s  (0.032s, 1978.76/s)  LR: 1.000e-05  Data: 0.000 (0.026)
Train: 0 [ 500/625 ( 80%)]  Loss: 2.22 (2.22)  Time: 0.044s, 1457.47/s  (0.032s, 1995.17/s)  LR: 1.000e-05  Data: 0.039 (0.026)
Train: 0 [ 550/625 ( 88%)]  Loss: 2.23 (2.22)  Time: 0.005s, 12323.16/s  (0.032s, 2013.74/s)  LR: 1.000e-05  Data: 0.000 (0.026)
Train: 0 [ 600/625 ( 96%)]  Loss: 2.18 (2.21)  Time: 0.057s, 1115.10/s  (0.032s, 2025.25/s)  LR: 1.000e-05  Data: 0.053 (0.026)
Test: [   0/156]  Time: 1.137 (1.137)  Loss:   2.037 ( 2.037)  Acc@1:  26.562 ( 26.562)  Acc@5:  84.375 ( 84.375)
Test: [  50/156]  Time: 0.010 (0.032)  Loss:   2.093 ( 2.062)  Acc@1:  15.625 ( 23.100)  Acc@5:  79.688 ( 79.534)
Test: [ 100/156]  Time: 0.009 (0.021)  Loss:   1.965 ( 2.060)  Acc@1:  26.562 ( 23.205)  Acc@5:  87.500 ( 80.012)
Test: [ 150/156]  Time: 0.002 (0.017)  Loss:   2.054 ( 2.057)  Acc@1:  23.438 ( 23.510)  Acc@5:  81.250 ( 79.739)
Test: [ 156/156]  Time: 0.041 (0.017)  Loss:   2.122 ( 2.057)  Acc@1:  18.750 ( 23.600)  Acc@5:  68.750 ( 79.710)
Current checkpoints:
 ('./output/train/Upd_Exp3_CIFAR10_1_layer/checkpoint-0.pth.tar', 23.6)

Train: 1 [   0/625 (  0%)]  Loss: 2.25 (2.25)  Time: 0.117s,  546.92/s  (0.117s,  546.92/s)  LR: 1.900e-05  Data: 0.110 (0.110)
Train: 1 [  50/625 (  8%)]  Loss: 2.27 (2.17)  Time: 0.005s, 12440.81/s  (0.030s, 2118.42/s)  LR: 1.900e-05  Data: 0.000 (0.025)
Train: 1 [ 100/625 ( 16%)]  Loss: 2.21 (2.17)  Time: 0.035s, 1811.56/s  (0.030s, 2129.38/s)  LR: 1.900e-05  Data: 0.030 (0.025)
Train: 1 [ 150/625 ( 24%)]  Loss: 2.05 (2.17)  Time: 0.020s, 3230.43/s  (0.030s, 2161.81/s)  LR: 1.900e-05  Data: 0.015 (0.025)
Train: 1 [ 200/625 ( 32%)]  Loss: 2.20 (2.17)  Time: 0.057s, 1114.79/s  (0.030s, 2154.58/s)  LR: 1.900e-05  Data: 0.053 (0.025)
Train: 1 [ 250/625 ( 40%)]  Loss: 2.17 (2.17)  Time: 0.005s, 12398.29/s  (0.029s, 2176.79/s)  LR: 1.900e-05  Data: 0.000 (0.024)
Train: 1 [ 300/625 ( 48%)]  Loss: 2.26 (2.16)  Time: 0.048s, 1333.69/s  (0.029s, 2170.31/s)  LR: 1.900e-05  Data: 0.043 (0.025)
Train: 1 [ 350/625 ( 56%)]  Loss: 2.09 (2.16)  Time: 0.005s, 12282.00/s  (0.029s, 2182.09/s)  LR: 1.900e-05  Data: 0.000 (0.024)
Train: 1 [ 400/625 ( 64%)]  Loss: 2.03 (2.16)  Time: 0.055s, 1162.64/s  (0.029s, 2173.19/s)  LR: 1.900e-05  Data: 0.050 (0.025)
Train: 1 [ 450/625 ( 72%)]  Loss: 2.06 (2.16)  Time: 0.005s, 12363.46/s  (0.029s, 2183.28/s)  LR: 1.900e-05  Data: 0.000 (0.024)
Train: 1 [ 500/625 ( 80%)]  Loss: 2.16 (2.16)  Time: 0.069s,  921.68/s  (0.029s, 2174.67/s)  LR: 1.900e-05  Data: 0.065 (0.025)
Train: 1 [ 550/625 ( 88%)]  Loss: 2.25 (2.15)  Time: 0.005s, 12386.85/s  (0.029s, 2180.50/s)  LR: 1.900e-05  Data: 0.000 (0.024)
Train: 1 [ 600/625 ( 96%)]  Loss: 2.04 (2.15)  Time: 0.102s,  629.82/s  (0.029s, 2174.38/s)  LR: 1.900e-05  Data: 0.097 (0.025)
Test: [   0/156]  Time: 0.057 (0.057)  Loss:   1.909 ( 1.909)  Acc@1:  29.688 ( 29.688)  Acc@5:  85.938 ( 85.938)
Test: [  50/156]  Time: 0.010 (0.011)  Loss:   2.014 ( 1.972)  Acc@1:  20.312 ( 29.197)  Acc@5:  81.250 ( 82.230)
Test: [ 100/156]  Time: 0.010 (0.010)  Loss:   1.850 ( 1.968)  Acc@1:  34.375 ( 29.162)  Acc@5:  85.938 ( 82.333)
Test: [ 150/156]  Time: 0.002 (0.010)  Loss:   1.993 ( 1.965)  Acc@1:  26.562 ( 29.894)  Acc@5:  87.500 ( 82.419)
Test: [ 156/156]  Time: 0.001 (0.010)  Loss:   2.054 ( 1.965)  Acc@1:  18.750 ( 29.980)  Acc@5:  75.000 ( 82.490)
Current checkpoints:
 ('./output/train/Upd_Exp3_CIFAR10_1_layer/checkpoint-1.pth.tar', 29.98)
 ('./output/train/Upd_Exp3_CIFAR10_1_layer/checkpoint-0.pth.tar', 23.6)

Train: 2 [   0/625 (  0%)]  Loss: 2.04 (2.04)  Time: 0.119s,  539.93/s  (0.119s,  539.93/s)  LR: 2.800e-05  Data: 0.113 (0.113)
Train: 2 [  50/625 (  8%)]  Loss: 2.04 (2.12)  Time: 0.010s, 6390.71/s  (0.030s, 2136.47/s)  LR: 2.800e-05  Data: 0.005 (0.024)
Train: 2 [ 100/625 ( 16%)]  Loss: 2.05 (2.12)  Time: 0.016s, 3950.14/s  (0.030s, 2134.53/s)  LR: 2.800e-05  Data: 0.011 (0.025)
Train: 2 [ 150/625 ( 24%)]  Loss: 2.21 (2.13)  Time: 0.005s, 12348.67/s  (0.029s, 2175.80/s)  LR: 2.800e-05  Data: 0.000 (0.024)
Train: 2 [ 200/625 ( 32%)]  Loss: 2.18 (2.12)  Time: 0.033s, 1959.71/s  (0.030s, 2163.46/s)  LR: 2.800e-05  Data: 0.028 (0.025)
Train: 2 [ 250/625 ( 40%)]  Loss: 2.01 (2.12)  Time: 0.005s, 12383.42/s  (0.029s, 2181.50/s)  LR: 2.800e-05  Data: 0.000 (0.024)
Train: 2 [ 300/625 ( 48%)]  Loss: 1.99 (2.12)  Time: 0.026s, 2505.25/s  (0.029s, 2175.65/s)  LR: 2.800e-05  Data: 0.021 (0.024)
Train: 2 [ 350/625 ( 56%)]  Loss: 2.18 (2.12)  Time: 0.005s, 12324.29/s  (0.029s, 2189.92/s)  LR: 2.800e-05  Data: 0.000 (0.024)
Train: 2 [ 400/625 ( 64%)]  Loss: 1.93 (2.12)  Time: 0.039s, 1621.98/s  (0.029s, 2181.24/s)  LR: 2.800e-05  Data: 0.035 (0.024)
Train: 2 [ 450/625 ( 72%)]  Loss: 2.07 (2.12)  Time: 0.005s, 12431.02/s  (0.029s, 2191.01/s)  LR: 2.800e-05  Data: 0.000 (0.024)
Train: 2 [ 500/625 ( 80%)]  Loss: 2.03 (2.12)  Time: 0.054s, 1174.92/s  (0.029s, 2184.51/s)  LR: 2.800e-05  Data: 0.050 (0.024)
Train: 2 [ 550/625 ( 88%)]  Loss: 2.10 (2.12)  Time: 0.005s, 12492.92/s  (0.029s, 2190.42/s)  LR: 2.800e-05  Data: 0.000 (0.024)
Train: 2 [ 600/625 ( 96%)]  Loss: 2.16 (2.11)  Time: 0.079s,  806.68/s  (0.029s, 2185.12/s)  LR: 2.800e-05  Data: 0.074 (0.024)
Test: [   0/156]  Time: 0.066 (0.066)  Loss:   1.812 ( 1.812)  Acc@1:  31.250 ( 31.250)  Acc@5:  90.625 ( 90.625)
Test: [  50/156]  Time: 0.009 (0.011)  Loss:   1.938 ( 1.895)  Acc@1:  26.562 ( 31.863)  Acc@5:  84.375 ( 84.926)
Test: [ 100/156]  Time: 0.009 (0.010)  Loss:   1.743 ( 1.889)  Acc@1:  40.625 ( 32.209)  Acc@5:  90.625 ( 85.412)
Test: [ 150/156]  Time: 0.002 (0.010)  Loss:   1.876 ( 1.885)  Acc@1:  35.938 ( 32.988)  Acc@5:  89.062 ( 85.751)
Test: [ 156/156]  Time: 0.001 (0.010)  Loss:   1.972 ( 1.884)  Acc@1:  25.000 ( 33.030)  Acc@5:  87.500 ( 85.820)
Current checkpoints:
 ('./output/train/Upd_Exp3_CIFAR10_1_layer/checkpoint-2.pth.tar', 33.03)
 ('./output/train/Upd_Exp3_CIFAR10_1_layer/checkpoint-1.pth.tar', 29.98)
 ('./output/train/Upd_Exp3_CIFAR10_1_layer/checkpoint-0.pth.tar', 23.6)

Train: 3 [   0/625 (  0%)]  Loss: 1.94 (1.94)  Time: 0.110s,  584.47/s  (0.110s,  584.47/s)  LR: 3.700e-05  Data: 0.104 (0.104)
Train: 3 [  50/625 (  8%)]  Loss: 1.99 (2.09)  Time: 0.005s, 12390.28/s  (0.030s, 2117.84/s)  LR: 3.700e-05  Data: 0.000 (0.024)
Train: 3 [ 100/625 ( 16%)]  Loss: 2.19 (2.10)  Time: 0.021s, 3008.25/s  (0.030s, 2119.77/s)  LR: 3.700e-05  Data: 0.016 (0.025)
Train: 3 [ 150/625 ( 24%)]  Loss: 2.21 (2.10)  Time: 0.005s, 12418.94/s  (0.030s, 2154.48/s)  LR: 3.700e-05  Data: 0.000 (0.024)
Train: 3 [ 200/625 ( 32%)]  Loss: 2.07 (2.10)  Time: 0.030s, 2129.63/s  (0.030s, 2142.14/s)  LR: 3.700e-05  Data: 0.025 (0.025)
Train: 3 [ 250/625 ( 40%)]  Loss: 2.08 (2.10)  Time: 0.005s, 12472.61/s  (0.030s, 2167.41/s)  LR: 3.700e-05  Data: 0.000 (0.024)
Train: 3 [ 300/625 ( 48%)]  Loss: 1.90 (2.10)  Time: 0.051s, 1247.94/s  (0.030s, 2159.22/s)  LR: 3.700e-05  Data: 0.046 (0.025)
Train: 3 [ 350/625 ( 56%)]  Loss: 2.12 (2.10)  Time: 0.005s, 12474.35/s  (0.029s, 2174.08/s)  LR: 3.700e-05  Data: 0.000 (0.024)
Train: 3 [ 400/625 ( 64%)]  Loss: 2.22 (2.09)  Time: 0.064s, 1005.49/s  (0.030s, 2166.60/s)  LR: 3.700e-05  Data: 0.059 (0.025)
Train: 3 [ 450/625 ( 72%)]  Loss: 2.02 (2.09)  Time: 0.005s, 12323.16/s  (0.029s, 2177.50/s)  LR: 3.700e-05  Data: 0.000 (0.024)
Train: 3 [ 500/625 ( 80%)]  Loss: 2.06 (2.09)  Time: 0.072s,  891.58/s  (0.029s, 2174.30/s)  LR: 3.700e-05  Data: 0.067 (0.024)
Train: 3 [ 550/625 ( 88%)]  Loss: 2.08 (2.09)  Time: 0.005s, 12280.88/s  (0.029s, 2183.32/s)  LR: 3.700e-05  Data: 0.000 (0.024)
Train: 3 [ 600/625 ( 96%)]  Loss: 2.15 (2.09)  Time: 0.069s,  927.34/s  (0.029s, 2178.91/s)  LR: 3.700e-05  Data: 0.064 (0.024)
Test: [   0/156]  Time: 0.056 (0.056)  Loss:   1.759 ( 1.759)  Acc@1:  39.062 ( 39.062)  Acc@5:  87.500 ( 87.500)
Test: [  50/156]  Time: 0.010 (0.011)  Loss:   1.866 ( 1.838)  Acc@1:  31.250 ( 35.049)  Acc@5:  79.688 ( 86.091)
Test: [ 100/156]  Time: 0.010 (0.010)  Loss:   1.680 ( 1.832)  Acc@1:  46.875 ( 35.396)  Acc@5:  92.188 ( 86.433)
Test: [ 150/156]  Time: 0.002 (0.010)  Loss:   1.797 ( 1.829)  Acc@1:  40.625 ( 35.720)  Acc@5:  93.750 ( 86.714)
Test: [ 156/156]  Time: 0.001 (0.010)  Loss:   1.895 ( 1.829)  Acc@1:  43.750 ( 35.730)  Acc@5:  81.250 ( 86.800)
Current checkpoints:
 ('./output/train/Upd_Exp3_CIFAR10_1_layer/checkpoint-3.pth.tar', 35.73)
 ('./output/train/Upd_Exp3_CIFAR10_1_layer/checkpoint-2.pth.tar', 33.03)
 ('./output/train/Upd_Exp3_CIFAR10_1_layer/checkpoint-1.pth.tar', 29.98)
 ('./output/train/Upd_Exp3_CIFAR10_1_layer/checkpoint-0.pth.tar', 23.6)

Train: 4 [   0/625 (  0%)]  Loss: 1.89 (1.89)  Time: 0.120s,  532.01/s  (0.120s,  532.01/s)  LR: 4.600e-05  Data: 0.115 (0.115)
Train: 4 [  50/625 (  8%)]  Loss: 2.05 (2.09)  Time: 0.010s, 6620.03/s  (0.030s, 2111.74/s)  LR: 4.600e-05  Data: 0.000 (0.024)
Train: 4 [ 100/625 ( 16%)]  Loss: 2.08 (2.08)  Time: 0.005s, 12516.22/s  (0.030s, 2119.82/s)  LR: 4.600e-05  Data: 0.000 (0.024)
Train: 4 [ 150/625 ( 24%)]  Loss: 2.23 (2.08)  Time: 0.010s, 6648.39/s  (0.030s, 2164.06/s)  LR: 4.600e-05  Data: 0.000 (0.024)
Train: 4 [ 200/625 ( 32%)]  Loss: 2.22 (2.08)  Time: 0.005s, 12357.77/s  (0.030s, 2157.51/s)  LR: 4.600e-05  Data: 0.000 (0.024)
Train: 4 [ 250/625 ( 40%)]  Loss: 2.04 (2.08)  Time: 0.010s, 6623.13/s  (0.029s, 2178.55/s)  LR: 4.600e-05  Data: 0.000 (0.023)
Train: 4 [ 300/625 ( 48%)]  Loss: 1.92 (2.08)  Time: 0.005s, 12393.14/s  (0.029s, 2170.22/s)  LR: 4.600e-05  Data: 0.000 (0.023)
Train: 4 [ 350/625 ( 56%)]  Loss: 2.06 (2.08)  Time: 0.010s, 6711.39/s  (0.029s, 2183.35/s)  LR: 4.600e-05  Data: 0.000 (0.023)
slurmstepd: error: *** JOB 2030720 ON i12 CANCELLED AT 2024-04-13T21:02:26 ***
