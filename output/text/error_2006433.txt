Training with a single process on 1 device (cuda:0).
WARNING: No pretrained configuration specified for MONet_T model. Using a default. Please add a config to the model pretrained_cfg registry or pass explicitly.
Model MONet_T created, param count:10165736
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.875
	crop_mode: center
AMP not enabled. Training in float32.
Restoring model state from checkpoint...
Restoring optimizer state from checkpoint...
Loaded checkpoint '/home/sharipov/monet/output/train/Exp2_imagenet100/model_best.pth.tar' (epoch 9)
/home/sharipov/monet/venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Scheduled epochs: 90. LR stepped per epoch.
Train: 10 [   0/989 (  0%)]  Loss: 3.34 (3.34)  Time: 15.099s,    8.48/s  (15.099s,    8.48/s)  LR: 9.698e-05  Data: 4.934 (4.934)
Train: 10 [  50/989 (  5%)]  Loss: 3.49 (3.27)  Time: 0.926s,  138.20/s  (1.215s,  105.32/s)  LR: 9.698e-05  Data: 0.009 (0.110)
Train: 10 [ 100/989 ( 10%)]  Loss: 3.36 (3.32)  Time: 0.951s,  134.58/s  (1.078s,  118.75/s)  LR: 9.698e-05  Data: 0.032 (0.064)
Train: 10 [ 150/989 ( 15%)]  Loss: 3.21 (3.33)  Time: 0.931s,  137.51/s  (1.030s,  124.22/s)  LR: 9.698e-05  Data: 0.009 (0.047)
Train: 10 [ 200/989 ( 20%)]  Loss: 3.33 (3.33)  Time: 0.945s,  135.46/s  (1.007s,  127.17/s)  LR: 9.698e-05  Data: 0.025 (0.039)
Train: 10 [ 250/989 ( 25%)]  Loss: 3.24 (3.33)  Time: 0.935s,  136.96/s  (0.993s,  128.97/s)  LR: 9.698e-05  Data: 0.017 (0.034)
Train: 10 [ 300/989 ( 30%)]  Loss: 3.15 (3.33)  Time: 0.953s,  134.37/s  (0.984s,  130.15/s)  LR: 9.698e-05  Data: 0.015 (0.031)
Train: 10 [ 350/989 ( 35%)]  Loss: 3.22 (3.32)  Time: 0.938s,  136.50/s  (0.977s,  131.07/s)  LR: 9.698e-05  Data: 0.012 (0.029)
Train: 10 [ 400/989 ( 40%)]  Loss: 3.26 (3.32)  Time: 0.935s,  136.89/s  (0.971s,  131.77/s)  LR: 9.698e-05  Data: 0.016 (0.027)
Train: 10 [ 450/989 ( 46%)]  Loss: 3.29 (3.32)  Time: 0.940s,  136.14/s  (0.967s,  132.33/s)  LR: 9.698e-05  Data: 0.023 (0.026)
Train: 10 [ 500/989 ( 51%)]  Loss: 3.39 (3.31)  Time: 0.926s,  138.20/s  (0.964s,  132.80/s)  LR: 9.698e-05  Data: 0.010 (0.025)
Train: 10 [ 550/989 ( 56%)]  Loss: 3.12 (3.31)  Time: 0.927s,  138.11/s  (0.961s,  133.16/s)  LR: 9.698e-05  Data: 0.010 (0.024)
Train: 10 [ 600/989 ( 61%)]  Loss: 3.34 (3.31)  Time: 0.934s,  137.07/s  (0.959s,  133.45/s)  LR: 9.698e-05  Data: 0.012 (0.023)
Train: 10 [ 650/989 ( 66%)]  Loss: 3.21 (3.30)  Time: 0.932s,  137.33/s  (0.957s,  133.72/s)  LR: 9.698e-05  Data: 0.015 (0.023)
Train: 10 [ 700/989 ( 71%)]  Loss: 3.25 (3.30)  Time: 0.936s,  136.82/s  (0.956s,  133.93/s)  LR: 9.698e-05  Data: 0.018 (0.022)
Train: 10 [ 750/989 ( 76%)]  Loss: 3.37 (3.30)  Time: 0.935s,  136.83/s  (0.954s,  134.12/s)  LR: 9.698e-05  Data: 0.010 (0.022)
Train: 10 [ 800/989 ( 81%)]  Loss: 3.30 (3.30)  Time: 0.933s,  137.26/s  (0.953s,  134.30/s)  LR: 9.698e-05  Data: 0.015 (0.021)
Train: 10 [ 850/989 ( 86%)]  Loss: 3.26 (3.29)  Time: 0.963s,  132.89/s  (0.952s,  134.45/s)  LR: 9.698e-05  Data: 0.021 (0.021)
Train: 10 [ 900/989 ( 91%)]  Loss: 3.23 (3.29)  Time: 0.927s,  138.06/s  (0.951s,  134.58/s)  LR: 9.698e-05  Data: 0.010 (0.021)
Train: 10 [ 950/989 ( 96%)]  Loss: 3.26 (3.29)  Time: 0.938s,  136.46/s  (0.950s,  134.71/s)  LR: 9.698e-05  Data: 0.021 (0.020)
Test: [   0/39]  Time: 3.688 (3.688)  Loss:   2.799 ( 2.799)  Acc@1:  28.906 ( 28.906)  Acc@5:  58.594 ( 58.594)
Test: [  39/39]  Time: 0.349 (0.487)  Loss:   2.368 ( 2.644)  Acc@1:  12.500 ( 34.460)  Acc@5:  75.000 ( 64.920)
Current checkpoints:
 ('./output/train/Exp3_imagenet100/checkpoint-10.pth.tar', 34.46)

Train: 11 [   0/989 (  0%)]  Loss: 3.11 (3.11)  Time: 2.771s,   46.19/s  (2.771s,   46.19/s)  LR: 9.636e-05  Data: 1.396 (1.396)
Train: 11 [  50/989 (  5%)]  Loss: 3.16 (3.23)  Time: 0.936s,  136.69/s  (0.980s,  130.58/s)  LR: 9.636e-05  Data: 0.019 (0.049)
Train: 11 [ 100/989 ( 10%)]  Loss: 3.37 (3.22)  Time: 0.935s,  136.84/s  (0.960s,  133.37/s)  LR: 9.636e-05  Data: 0.019 (0.035)
Train: 11 [ 150/989 ( 15%)]  Loss: 3.03 (3.21)  Time: 0.945s,  135.48/s  (0.953s,  134.31/s)  LR: 9.636e-05  Data: 0.028 (0.031)
Train: 11 [ 200/989 ( 20%)]  Loss: 3.26 (3.20)  Time: 0.956s,  133.90/s  (0.949s,  134.81/s)  LR: 9.636e-05  Data: 0.039 (0.028)
Train: 11 [ 250/989 ( 25%)]  Loss: 3.13 (3.20)  Time: 0.939s,  136.37/s  (0.947s,  135.13/s)  LR: 9.636e-05  Data: 0.021 (0.027)
Train: 11 [ 300/989 ( 30%)]  Loss: 3.24 (3.20)  Time: 0.948s,  135.07/s  (0.946s,  135.31/s)  LR: 9.636e-05  Data: 0.024 (0.026)
Train: 11 [ 350/989 ( 35%)]  Loss: 3.20 (3.20)  Time: 0.937s,  136.62/s  (0.945s,  135.48/s)  LR: 9.636e-05  Data: 0.020 (0.025)
Train: 11 [ 400/989 ( 40%)]  Loss: 3.22 (3.20)  Time: 0.931s,  137.46/s  (0.944s,  135.58/s)  LR: 9.636e-05  Data: 0.014 (0.025)
Train: 11 [ 450/989 ( 46%)]  Loss: 3.04 (3.20)  Time: 0.939s,  136.38/s  (0.944s,  135.66/s)  LR: 9.636e-05  Data: 0.022 (0.024)
Train: 11 [ 500/989 ( 51%)]  Loss: 3.03 (3.19)  Time: 0.938s,  136.43/s  (0.943s,  135.73/s)  LR: 9.636e-05  Data: 0.022 (0.024)
Train: 11 [ 550/989 ( 56%)]  Loss: 3.31 (3.19)  Time: 0.935s,  136.91/s  (0.943s,  135.78/s)  LR: 9.636e-05  Data: 0.019 (0.024)
Train: 11 [ 600/989 ( 61%)]  Loss: 3.15 (3.19)  Time: 0.950s,  134.71/s  (0.942s,  135.84/s)  LR: 9.636e-05  Data: 0.033 (0.024)
Train: 11 [ 650/989 ( 66%)]  Loss: 2.96 (3.18)  Time: 0.942s,  135.90/s  (0.942s,  135.88/s)  LR: 9.636e-05  Data: 0.025 (0.023)
Train: 11 [ 700/989 ( 71%)]  Loss: 3.19 (3.18)  Time: 0.938s,  136.49/s  (0.942s,  135.94/s)  LR: 9.636e-05  Data: 0.021 (0.023)
Train: 11 [ 750/989 ( 76%)]  Loss: 3.34 (3.18)  Time: 0.936s,  136.71/s  (0.941s,  135.97/s)  LR: 9.636e-05  Data: 0.014 (0.023)
Train: 11 [ 800/989 ( 81%)]  Loss: 3.18 (3.18)  Time: 0.946s,  135.28/s  (0.941s,  135.98/s)  LR: 9.636e-05  Data: 0.019 (0.023)
Train: 11 [ 850/989 ( 86%)]  Loss: 3.01 (3.18)  Time: 0.937s,  136.56/s  (0.941s,  136.00/s)  LR: 9.636e-05  Data: 0.011 (0.022)
Train: 11 [ 900/989 ( 91%)]  Loss: 3.46 (3.17)  Time: 0.956s,  133.94/s  (0.941s,  136.00/s)  LR: 9.636e-05  Data: 0.036 (0.023)
Train: 11 [ 950/989 ( 96%)]  Loss: 3.16 (3.17)  Time: 0.942s,  135.92/s  (0.941s,  136.00/s)  LR: 9.636e-05  Data: 0.024 (0.022)
Test: [   0/39]  Time: 1.334 (1.334)  Loss:   2.912 ( 2.912)  Acc@1:  27.344 ( 27.344)  Acc@5:  57.031 ( 57.031)
Test: [  39/39]  Time: 0.027 (0.366)  Loss:   1.877 ( 2.529)  Acc@1:  50.000 ( 35.940)  Acc@5:  87.500 ( 67.100)
Current checkpoints:
 ('./output/train/Exp3_imagenet100/checkpoint-11.pth.tar', 35.94)
 ('./output/train/Exp3_imagenet100/checkpoint-10.pth.tar', 34.46)

Train: 12 [   0/989 (  0%)]  Loss: 3.10 (3.10)  Time: 2.755s,   46.47/s  (2.755s,   46.47/s)  LR: 9.568e-05  Data: 1.434 (1.434)
Train: 12 [  50/989 (  5%)]  Loss: 3.14 (3.08)  Time: 0.941s,  136.02/s  (0.980s,  130.68/s)  LR: 9.568e-05  Data: 0.024 (0.051)
Train: 12 [ 100/989 ( 10%)]  Loss: 2.90 (3.08)  Time: 0.938s,  136.41/s  (0.959s,  133.43/s)  LR: 9.568e-05  Data: 0.021 (0.036)
Train: 12 [ 150/989 ( 15%)]  Loss: 3.12 (3.08)  Time: 0.937s,  136.65/s  (0.953s,  134.35/s)  LR: 9.568e-05  Data: 0.020 (0.032)
Train: 12 [ 200/989 ( 20%)]  Loss: 3.11 (3.08)  Time: 0.938s,  136.42/s  (0.949s,  134.81/s)  LR: 9.568e-05  Data: 0.021 (0.030)
Train: 12 [ 250/989 ( 25%)]  Loss: 3.29 (3.08)  Time: 0.942s,  135.88/s  (0.947s,  135.11/s)  LR: 9.568e-05  Data: 0.025 (0.028)
Train: 12 [ 300/989 ( 30%)]  Loss: 2.88 (3.08)  Time: 0.938s,  136.49/s  (0.946s,  135.32/s)  LR: 9.568e-05  Data: 0.021 (0.027)
Train: 12 [ 350/989 ( 35%)]  Loss: 3.04 (3.08)  Time: 0.937s,  136.56/s  (0.945s,  135.46/s)  LR: 9.568e-05  Data: 0.020 (0.026)
Train: 12 [ 400/989 ( 40%)]  Loss: 2.94 (3.08)  Time: 0.938s,  136.49/s  (0.944s,  135.56/s)  LR: 9.568e-05  Data: 0.021 (0.026)
Train: 12 [ 450/989 ( 46%)]  Loss: 3.06 (3.08)  Time: 0.939s,  136.25/s  (0.944s,  135.66/s)  LR: 9.568e-05  Data: 0.022 (0.025)
Train: 12 [ 500/989 ( 51%)]  Loss: 3.14 (3.08)  Time: 0.943s,  135.73/s  (0.943s,  135.72/s)  LR: 9.568e-05  Data: 0.026 (0.025)
Train: 12 [ 550/989 ( 56%)]  Loss: 2.96 (3.08)  Time: 0.934s,  137.02/s  (0.943s,  135.77/s)  LR: 9.568e-05  Data: 0.017 (0.024)
Train: 12 [ 600/989 ( 61%)]  Loss: 2.95 (3.07)  Time: 0.943s,  135.74/s  (0.943s,  135.81/s)  LR: 9.568e-05  Data: 0.026 (0.024)
Train: 12 [ 650/989 ( 66%)]  Loss: 2.96 (3.07)  Time: 0.936s,  136.81/s  (0.942s,  135.85/s)  LR: 9.568e-05  Data: 0.019 (0.024)
Train: 12 [ 700/989 ( 71%)]  Loss: 3.03 (3.07)  Time: 0.937s,  136.64/s  (0.942s,  135.89/s)  LR: 9.568e-05  Data: 0.020 (0.024)
Train: 12 [ 750/989 ( 76%)]  Loss: 2.91 (3.07)  Time: 0.934s,  136.98/s  (0.942s,  135.94/s)  LR: 9.568e-05  Data: 0.017 (0.023)
Train: 12 [ 800/989 ( 81%)]  Loss: 3.03 (3.07)  Time: 0.952s,  134.47/s  (0.941s,  135.96/s)  LR: 9.568e-05  Data: 0.035 (0.023)
Train: 12 [ 850/989 ( 86%)]  Loss: 3.20 (3.07)  Time: 0.959s,  133.50/s  (0.941s,  135.97/s)  LR: 9.568e-05  Data: 0.042 (0.023)
Train: 12 [ 900/989 ( 91%)]  Loss: 2.96 (3.06)  Time: 0.941s,  136.06/s  (0.941s,  135.99/s)  LR: 9.568e-05  Data: 0.017 (0.023)
Train: 12 [ 950/989 ( 96%)]  Loss: 2.85 (3.06)  Time: 0.949s,  134.87/s  (0.941s,  135.97/s)  LR: 9.568e-05  Data: 0.031 (0.023)
Test: [   0/39]  Time: 1.330 (1.330)  Loss:   2.561 ( 2.561)  Acc@1:  39.062 ( 39.062)  Acc@5:  65.625 ( 65.625)
Test: [  39/39]  Time: 0.027 (0.369)  Loss:   2.124 ( 2.393)  Acc@1:  50.000 ( 39.440)  Acc@5:  87.500 ( 70.300)
Current checkpoints:
 ('./output/train/Exp3_imagenet100/checkpoint-12.pth.tar', 39.44)
 ('./output/train/Exp3_imagenet100/checkpoint-11.pth.tar', 35.94)
 ('./output/train/Exp3_imagenet100/checkpoint-10.pth.tar', 34.46)

Train: 13 [   0/989 (  0%)]  Loss: 2.93 (2.93)  Time: 2.688s,   47.62/s  (2.688s,   47.62/s)  LR: 9.494e-05  Data: 1.345 (1.345)
Train: 13 [  50/989 (  5%)]  Loss: 2.95 (3.00)  Time: 0.939s,  136.34/s  (0.980s,  130.62/s)  LR: 9.494e-05  Data: 0.021 (0.049)
Train: 13 [ 100/989 ( 10%)]  Loss: 2.97 (2.99)  Time: 0.957s,  133.80/s  (0.960s,  133.34/s)  LR: 9.494e-05  Data: 0.039 (0.036)
Train: 13 [ 150/989 ( 15%)]  Loss: 3.15 (2.99)  Time: 0.934s,  136.97/s  (0.953s,  134.32/s)  LR: 9.494e-05  Data: 0.018 (0.031)
Train: 13 [ 200/989 ( 20%)]  Loss: 3.24 (2.99)  Time: 0.938s,  136.45/s  (0.950s,  134.76/s)  LR: 9.494e-05  Data: 0.021 (0.029)
Train: 13 [ 250/989 ( 25%)]  Loss: 2.93 (2.99)  Time: 0.938s,  136.46/s  (0.948s,  135.04/s)  LR: 9.494e-05  Data: 0.021 (0.028)
Train: 13 [ 300/989 ( 30%)]  Loss: 3.06 (2.99)  Time: 0.941s,  136.08/s  (0.947s,  135.19/s)  LR: 9.494e-05  Data: 0.024 (0.027)
Train: 13 [ 350/989 ( 35%)]  Loss: 2.82 (2.98)  Time: 0.935s,  136.93/s  (0.946s,  135.34/s)  LR: 9.494e-05  Data: 0.018 (0.026)
Train: 13 [ 400/989 ( 40%)]  Loss: 3.14 (2.98)  Time: 0.936s,  136.72/s  (0.945s,  135.43/s)  LR: 9.494e-05  Data: 0.019 (0.026)
Train: 13 [ 450/989 ( 46%)]  Loss: 2.97 (2.98)  Time: 0.937s,  136.54/s  (0.944s,  135.52/s)  LR: 9.494e-05  Data: 0.020 (0.026)
Train: 13 [ 500/989 ( 51%)]  Loss: 2.57 (2.98)  Time: 0.939s,  136.29/s  (0.944s,  135.59/s)  LR: 9.494e-05  Data: 0.022 (0.025)
Train: 13 [ 550/989 ( 56%)]  Loss: 2.79 (2.98)  Time: 0.943s,  135.74/s  (0.944s,  135.65/s)  LR: 9.494e-05  Data: 0.021 (0.025)
Train: 13 [ 600/989 ( 61%)]  Loss: 2.76 (2.98)  Time: 0.947s,  135.18/s  (0.943s,  135.70/s)  LR: 9.494e-05  Data: 0.030 (0.025)
Train: 13 [ 650/989 ( 66%)]  Loss: 3.01 (2.98)  Time: 0.935s,  136.96/s  (0.943s,  135.75/s)  LR: 9.494e-05  Data: 0.017 (0.024)
Train: 13 [ 700/989 ( 71%)]  Loss: 3.04 (2.98)  Time: 0.945s,  135.52/s  (0.943s,  135.77/s)  LR: 9.494e-05  Data: 0.027 (0.024)
Train: 13 [ 750/989 ( 76%)]  Loss: 2.77 (2.97)  Time: 0.957s,  133.72/s  (0.943s,  135.79/s)  LR: 9.494e-05  Data: 0.040 (0.024)
Train: 13 [ 800/989 ( 81%)]  Loss: 2.92 (2.97)  Time: 0.935s,  136.93/s  (0.942s,  135.81/s)  LR: 9.494e-05  Data: 0.017 (0.024)
Train: 13 [ 850/989 ( 86%)]  Loss: 2.83 (2.97)  Time: 0.938s,  136.51/s  (0.942s,  135.85/s)  LR: 9.494e-05  Data: 0.021 (0.024)
Train: 13 [ 900/989 ( 91%)]  Loss: 2.78 (2.97)  Time: 0.944s,  135.53/s  (0.942s,  135.87/s)  LR: 9.494e-05  Data: 0.023 (0.024)
Train: 13 [ 950/989 ( 96%)]  Loss: 3.05 (2.97)  Time: 0.935s,  136.96/s  (0.942s,  135.89/s)  LR: 9.494e-05  Data: 0.015 (0.023)
Test: [   0/39]  Time: 1.467 (1.467)  Loss:   2.468 ( 2.468)  Acc@1:  34.375 ( 34.375)  Acc@5:  64.844 ( 64.844)
Test: [  39/39]  Time: 0.026 (0.370)  Loss:   1.580 ( 2.295)  Acc@1:  75.000 ( 41.840)  Acc@5: 100.000 ( 72.000)
Current checkpoints:
 ('./output/train/Exp3_imagenet100/checkpoint-13.pth.tar', 41.84)
 ('./output/train/Exp3_imagenet100/checkpoint-12.pth.tar', 39.44)
 ('./output/train/Exp3_imagenet100/checkpoint-11.pth.tar', 35.94)
 ('./output/train/Exp3_imagenet100/checkpoint-10.pth.tar', 34.46)

Train: 14 [   0/989 (  0%)]  Loss: 2.73 (2.73)  Time: 2.904s,   44.08/s  (2.904s,   44.08/s)  LR: 9.415e-05  Data: 1.592 (1.592)
Train: 14 [  50/989 (  5%)]  Loss: 2.79 (2.91)  Time: 0.938s,  136.53/s  (0.981s,  130.51/s)  LR: 9.415e-05  Data: 0.021 (0.054)
Train: 14 [ 100/989 ( 10%)]  Loss: 2.76 (2.91)  Time: 0.939s,  136.39/s  (0.960s,  133.29/s)  LR: 9.415e-05  Data: 0.022 (0.039)
Train: 14 [ 150/989 ( 15%)]  Loss: 2.83 (2.90)  Time: 0.938s,  136.46/s  (0.953s,  134.32/s)  LR: 9.415e-05  Data: 0.021 (0.033)
Train: 14 [ 200/989 ( 20%)]  Loss: 2.74 (2.91)  Time: 0.933s,  137.23/s  (0.950s,  134.79/s)  LR: 9.415e-05  Data: 0.016 (0.030)
Train: 14 [ 250/989 ( 25%)]  Loss: 3.10 (2.90)  Time: 0.943s,  135.70/s  (0.948s,  135.08/s)  LR: 9.415e-05  Data: 0.026 (0.029)
Train: 14 [ 300/989 ( 30%)]  Loss: 2.86 (2.90)  Time: 0.952s,  134.41/s  (0.946s,  135.30/s)  LR: 9.415e-05  Data: 0.036 (0.027)
Train: 14 [ 350/989 ( 35%)]  Loss: 2.92 (2.90)  Time: 0.936s,  136.80/s  (0.945s,  135.45/s)  LR: 9.415e-05  Data: 0.019 (0.027)
Train: 14 [ 400/989 ( 40%)]  Loss: 2.76 (2.90)  Time: 0.936s,  136.72/s  (0.944s,  135.55/s)  LR: 9.415e-05  Data: 0.019 (0.026)
Train: 14 [ 450/989 ( 46%)]  Loss: 2.74 (2.89)  Time: 0.942s,  135.93/s  (0.944s,  135.61/s)  LR: 9.415e-05  Data: 0.025 (0.026)
Train: 14 [ 500/989 ( 51%)]  Loss: 2.67 (2.89)  Time: 0.937s,  136.57/s  (0.943s,  135.70/s)  LR: 9.415e-05  Data: 0.020 (0.025)
Train: 14 [ 550/989 ( 56%)]  Loss: 2.91 (2.89)  Time: 0.944s,  135.60/s  (0.943s,  135.75/s)  LR: 9.415e-05  Data: 0.026 (0.025)
Train: 14 [ 600/989 ( 61%)]  Loss: 2.99 (2.89)  Time: 0.936s,  136.71/s  (0.943s,  135.79/s)  LR: 9.415e-05  Data: 0.020 (0.025)
Train: 14 [ 650/989 ( 66%)]  Loss: 2.96 (2.89)  Time: 0.938s,  136.41/s  (0.942s,  135.82/s)  LR: 9.415e-05  Data: 0.022 (0.025)
Train: 14 [ 700/989 ( 71%)]  Loss: 2.67 (2.89)  Time: 0.930s,  137.65/s  (0.942s,  135.87/s)  LR: 9.415e-05  Data: 0.013 (0.024)
Train: 14 [ 750/989 ( 76%)]  Loss: 2.86 (2.89)  Time: 0.939s,  136.28/s  (0.942s,  135.90/s)  LR: 9.415e-05  Data: 0.022 (0.024)
Train: 14 [ 800/989 ( 81%)]  Loss: 2.79 (2.88)  Time: 0.935s,  136.96/s  (0.942s,  135.92/s)  LR: 9.415e-05  Data: 0.017 (0.024)
Train: 14 [ 850/989 ( 86%)]  Loss: 2.95 (2.88)  Time: 0.934s,  137.04/s  (0.942s,  135.95/s)  LR: 9.415e-05  Data: 0.017 (0.024)
Train: 14 [ 900/989 ( 91%)]  Loss: 2.95 (2.88)  Time: 0.937s,  136.64/s  (0.941s,  135.96/s)  LR: 9.415e-05  Data: 0.020 (0.024)
Train: 14 [ 950/989 ( 96%)]  Loss: 2.82 (2.88)  Time: 0.973s,  131.53/s  (0.941s,  135.96/s)  LR: 9.415e-05  Data: 0.044 (0.024)
Test: [   0/39]  Time: 1.368 (1.368)  Loss:   2.496 ( 2.496)  Acc@1:  36.719 ( 36.719)  Acc@5:  68.750 ( 68.750)
Test: [  39/39]  Time: 0.026 (0.368)  Loss:   2.048 ( 2.182)  Acc@1:  37.500 ( 43.660)  Acc@5:  87.500 ( 74.440)
Current checkpoints:
 ('./output/train/Exp3_imagenet100/checkpoint-14.pth.tar', 43.66)
 ('./output/train/Exp3_imagenet100/checkpoint-13.pth.tar', 41.84)
 ('./output/train/Exp3_imagenet100/checkpoint-12.pth.tar', 39.44)
 ('./output/train/Exp3_imagenet100/checkpoint-11.pth.tar', 35.94)
 ('./output/train/Exp3_imagenet100/checkpoint-10.pth.tar', 34.46)

Train: 15 [   0/989 (  0%)]  Loss: 2.93 (2.93)  Time: 2.788s,   45.92/s  (2.788s,   45.92/s)  LR: 9.330e-05  Data: 1.443 (1.443)
Train: 15 [  50/989 (  5%)]  Loss: 2.70 (2.86)  Time: 0.944s,  135.64/s  (0.981s,  130.48/s)  LR: 9.330e-05  Data: 0.027 (0.052)
Train: 15 [ 100/989 ( 10%)]  Loss: 2.82 (2.83)  Time: 0.939s,  136.36/s  (0.961s,  133.24/s)  LR: 9.330e-05  Data: 0.022 (0.037)
Train: 15 [ 150/989 ( 15%)]  Loss: 2.97 (2.83)  Time: 0.938s,  136.50/s  (0.954s,  134.21/s)  LR: 9.330e-05  Data: 0.021 (0.033)
Train: 15 [ 200/989 ( 20%)]  Loss: 2.80 (2.83)  Time: 0.936s,  136.76/s  (0.950s,  134.73/s)  LR: 9.330e-05  Data: 0.019 (0.030)
Train: 15 [ 250/989 ( 25%)]  Loss: 2.76 (2.82)  Time: 0.938s,  136.43/s  (0.948s,  135.02/s)  LR: 9.330e-05  Data: 0.021 (0.029)
Train: 15 [ 300/989 ( 30%)]  Loss: 2.81 (2.83)  Time: 0.939s,  136.36/s  (0.946s,  135.24/s)  LR: 9.330e-05  Data: 0.021 (0.027)
Train: 15 [ 350/989 ( 35%)]  Loss: 2.73 (2.83)  Time: 0.939s,  136.38/s  (0.945s,  135.39/s)  LR: 9.330e-05  Data: 0.022 (0.027)
Train: 15 [ 400/989 ( 40%)]  Loss: 2.73 (2.83)  Time: 0.941s,  135.97/s  (0.945s,  135.50/s)  LR: 9.330e-05  Data: 0.024 (0.026)
Train: 15 [ 450/989 ( 46%)]  Loss: 2.71 (2.82)  Time: 0.934s,  137.05/s  (0.944s,  135.57/s)  LR: 9.330e-05  Data: 0.017 (0.026)
Train: 15 [ 500/989 ( 51%)]  Loss: 2.96 (2.83)  Time: 0.939s,  136.37/s  (0.944s,  135.65/s)  LR: 9.330e-05  Data: 0.021 (0.025)
Train: 15 [ 550/989 ( 56%)]  Loss: 2.82 (2.82)  Time: 0.954s,  134.14/s  (0.943s,  135.71/s)  LR: 9.330e-05  Data: 0.030 (0.025)
Train: 15 [ 600/989 ( 61%)]  Loss: 2.63 (2.82)  Time: 0.949s,  134.87/s  (0.943s,  135.75/s)  LR: 9.330e-05  Data: 0.032 (0.025)
Train: 15 [ 650/989 ( 66%)]  Loss: 2.93 (2.82)  Time: 0.939s,  136.34/s  (0.943s,  135.79/s)  LR: 9.330e-05  Data: 0.022 (0.025)
Train: 15 [ 700/989 ( 71%)]  Loss: 2.92 (2.82)  Time: 0.938s,  136.49/s  (0.942s,  135.82/s)  LR: 9.330e-05  Data: 0.021 (0.024)
slurmstepd: error: *** JOB 2006433 ON i67 CANCELLED AT 2024-03-02T16:00:21 DUE TO TIME LIMIT ***
