Training with a single process on 1 device (cuda:0).
WARNING: No pretrained configuration specified for MONet_T_16_double model. Using a default. Please add a config to the model pretrained_cfg registry or pass explicitly.
Model MONet_T_16_double created, param count:17509380
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.875
	crop_mode: center
AMP not enabled. Training in float32.
/home/sharipov/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Scheduled epochs: 300. LR stepped per epoch.
Train: 0 [   0/3167 (  0%)]  Loss: 4.61 (4.61)  Time: 12.160s,    3.29/s  (12.160s,    3.29/s)  LR: 1.000e-05  Data: 2.414 (2.414)
Train: 0 [  50/3167 (  2%)]  Loss: 4.58 (4.60)  Time: 0.594s,   67.35/s  (0.823s,   48.59/s)  LR: 1.000e-05  Data: 0.004 (0.052)
Train: 0 [ 100/3167 (  3%)]  Loss: 4.58 (4.59)  Time: 0.598s,   66.90/s  (0.712s,   56.22/s)  LR: 1.000e-05  Data: 0.007 (0.029)
Train: 0 [ 150/3167 (  5%)]  Loss: 4.52 (4.58)  Time: 0.594s,   67.36/s  (0.674s,   59.38/s)  LR: 1.000e-05  Data: 0.004 (0.021)
Train: 0 [ 200/3167 (  6%)]  Loss: 4.54 (4.57)  Time: 0.595s,   67.20/s  (0.655s,   61.09/s)  LR: 1.000e-05  Data: 0.004 (0.018)
Train: 0 [ 250/3167 (  8%)]  Loss: 4.52 (4.56)  Time: 0.597s,   67.02/s  (0.643s,   62.19/s)  LR: 1.000e-05  Data: 0.007 (0.015)
Train: 0 [ 300/3167 (  9%)]  Loss: 4.56 (4.55)  Time: 0.597s,   66.95/s  (0.635s,   62.95/s)  LR: 1.000e-05  Data: 0.007 (0.013)
Train: 0 [ 350/3167 ( 11%)]  Loss: 4.51 (4.55)  Time: 0.594s,   67.35/s  (0.630s,   63.50/s)  LR: 1.000e-05  Data: 0.004 (0.012)
Train: 0 [ 400/3167 ( 13%)]  Loss: 4.44 (4.54)  Time: 0.594s,   67.35/s  (0.626s,   63.92/s)  LR: 1.000e-05  Data: 0.004 (0.011)
Train: 0 [ 450/3167 ( 14%)]  Loss: 4.46 (4.53)  Time: 0.599s,   66.80/s  (0.623s,   64.25/s)  LR: 1.000e-05  Data: 0.009 (0.011)
Train: 0 [ 500/3167 ( 16%)]  Loss: 4.48 (4.53)  Time: 0.593s,   67.41/s  (0.620s,   64.52/s)  LR: 1.000e-05  Data: 0.004 (0.010)
Train: 0 [ 550/3167 ( 17%)]  Loss: 4.52 (4.52)  Time: 0.593s,   67.41/s  (0.618s,   64.74/s)  LR: 1.000e-05  Data: 0.004 (0.010)
Train: 0 [ 600/3167 ( 19%)]  Loss: 4.53 (4.52)  Time: 0.596s,   67.08/s  (0.616s,   64.93/s)  LR: 1.000e-05  Data: 0.004 (0.009)
Train: 0 [ 650/3167 ( 21%)]  Loss: 4.45 (4.52)  Time: 0.596s,   67.06/s  (0.615s,   65.08/s)  LR: 1.000e-05  Data: 0.004 (0.009)
Train: 0 [ 700/3167 ( 22%)]  Loss: 4.25 (4.51)  Time: 0.593s,   67.41/s  (0.613s,   65.23/s)  LR: 1.000e-05  Data: 0.004 (0.009)
Train: 0 [ 750/3167 ( 24%)]  Loss: 4.55 (4.51)  Time: 0.601s,   66.52/s  (0.612s,   65.34/s)  LR: 1.000e-05  Data: 0.004 (0.008)
Train: 0 [ 800/3167 ( 25%)]  Loss: 4.32 (4.51)  Time: 0.595s,   67.27/s  (0.611s,   65.45/s)  LR: 1.000e-05  Data: 0.004 (0.008)
Train: 0 [ 850/3167 ( 27%)]  Loss: 4.38 (4.50)  Time: 0.593s,   67.42/s  (0.610s,   65.54/s)  LR: 1.000e-05  Data: 0.004 (0.008)
Train: 0 [ 900/3167 ( 28%)]  Loss: 4.52 (4.50)  Time: 0.596s,   67.09/s  (0.610s,   65.63/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [ 950/3167 ( 30%)]  Loss: 4.46 (4.50)  Time: 0.593s,   67.40/s  (0.609s,   65.70/s)  LR: 1.000e-05  Data: 0.004 (0.008)
Train: 0 [1000/3167 ( 32%)]  Loss: 4.41 (4.50)  Time: 0.607s,   65.93/s  (0.608s,   65.77/s)  LR: 1.000e-05  Data: 0.004 (0.008)
Train: 0 [1050/3167 ( 33%)]  Loss: 4.46 (4.49)  Time: 0.596s,   67.09/s  (0.608s,   65.83/s)  LR: 1.000e-05  Data: 0.007 (0.007)
Train: 0 [1100/3167 ( 35%)]  Loss: 4.55 (4.49)  Time: 0.593s,   67.42/s  (0.607s,   65.89/s)  LR: 1.000e-05  Data: 0.004 (0.007)
Train: 0 [1150/3167 ( 36%)]  Loss: 4.61 (4.49)  Time: 0.593s,   67.42/s  (0.607s,   65.94/s)  LR: 1.000e-05  Data: 0.004 (0.007)
Train: 0 [1200/3167 ( 38%)]  Loss: 4.46 (4.49)  Time: 0.596s,   67.09/s  (0.606s,   65.98/s)  LR: 1.000e-05  Data: 0.004 (0.007)
Train: 0 [1250/3167 ( 39%)]  Loss: 4.48 (4.48)  Time: 0.593s,   67.45/s  (0.606s,   66.03/s)  LR: 1.000e-05  Data: 0.004 (0.007)
Train: 0 [1300/3167 ( 41%)]  Loss: 4.56 (4.48)  Time: 0.606s,   66.05/s  (0.605s,   66.07/s)  LR: 1.000e-05  Data: 0.010 (0.007)
Train: 0 [1350/3167 ( 43%)]  Loss: 4.45 (4.48)  Time: 0.601s,   66.59/s  (0.605s,   66.11/s)  LR: 1.000e-05  Data: 0.009 (0.007)
Train: 0 [1400/3167 ( 44%)]  Loss: 4.57 (4.48)  Time: 0.598s,   66.93/s  (0.605s,   66.14/s)  LR: 1.000e-05  Data: 0.004 (0.007)
Train: 0 [1450/3167 ( 46%)]  Loss: 4.47 (4.48)  Time: 0.598s,   66.89/s  (0.604s,   66.17/s)  LR: 1.000e-05  Data: 0.004 (0.007)
Train: 0 [1500/3167 ( 47%)]  Loss: 4.63 (4.48)  Time: 0.594s,   67.39/s  (0.604s,   66.20/s)  LR: 1.000e-05  Data: 0.004 (0.007)
Train: 0 [1550/3167 ( 49%)]  Loss: 4.59 (4.48)  Time: 0.594s,   67.35/s  (0.604s,   66.23/s)  LR: 1.000e-05  Data: 0.004 (0.007)
Train: 0 [1600/3167 ( 51%)]  Loss: 4.45 (4.47)  Time: 0.596s,   67.16/s  (0.604s,   66.25/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1650/3167 ( 52%)]  Loss: 4.39 (4.47)  Time: 0.596s,   67.12/s  (0.604s,   66.28/s)  LR: 1.000e-05  Data: 0.007 (0.006)
Train: 0 [1700/3167 ( 54%)]  Loss: 4.47 (4.47)  Time: 0.594s,   67.35/s  (0.603s,   66.30/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1750/3167 ( 55%)]  Loss: 4.39 (4.47)  Time: 0.593s,   67.43/s  (0.603s,   66.32/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1800/3167 ( 57%)]  Loss: 4.43 (4.47)  Time: 0.593s,   67.43/s  (0.603s,   66.34/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1850/3167 ( 58%)]  Loss: 4.31 (4.47)  Time: 0.593s,   67.43/s  (0.603s,   66.36/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1900/3167 ( 60%)]  Loss: 4.46 (4.47)  Time: 0.609s,   65.63/s  (0.603s,   66.38/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1950/3167 ( 62%)]  Loss: 4.41 (4.47)  Time: 0.601s,   66.52/s  (0.602s,   66.40/s)  LR: 1.000e-05  Data: 0.007 (0.006)
Train: 0 [2000/3167 ( 63%)]  Loss: 4.19 (4.47)  Time: 0.593s,   67.43/s  (0.602s,   66.42/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [2050/3167 ( 65%)]  Loss: 4.50 (4.47)  Time: 0.611s,   65.49/s  (0.602s,   66.44/s)  LR: 1.000e-05  Data: 0.007 (0.006)
Train: 0 [2100/3167 ( 66%)]  Loss: 4.39 (4.46)  Time: 0.593s,   67.42/s  (0.602s,   66.45/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [2150/3167 ( 68%)]  Loss: 4.48 (4.46)  Time: 0.593s,   67.40/s  (0.602s,   66.47/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [2200/3167 ( 69%)]  Loss: 4.43 (4.46)  Time: 0.596s,   67.06/s  (0.602s,   66.48/s)  LR: 1.000e-05  Data: 0.006 (0.006)
Train: 0 [2250/3167 ( 71%)]  Loss: 4.29 (4.46)  Time: 0.596s,   67.10/s  (0.602s,   66.49/s)  LR: 1.000e-05  Data: 0.007 (0.006)
Train: 0 [2300/3167 ( 73%)]  Loss: 4.40 (4.46)  Time: 0.593s,   67.42/s  (0.601s,   66.51/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [2350/3167 ( 74%)]  Loss: 4.47 (4.46)  Time: 0.612s,   65.37/s  (0.601s,   66.52/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [2400/3167 ( 76%)]  Loss: 4.53 (4.46)  Time: 0.599s,   66.78/s  (0.601s,   66.53/s)  LR: 1.000e-05  Data: 0.010 (0.006)
Train: 0 [2450/3167 ( 77%)]  Loss: 4.35 (4.46)  Time: 0.596s,   67.12/s  (0.601s,   66.54/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [2500/3167 ( 79%)]  Loss: 4.26 (4.46)  Time: 0.604s,   66.27/s  (0.601s,   66.55/s)  LR: 1.000e-05  Data: 0.012 (0.006)
Train: 0 [2550/3167 ( 81%)]  Loss: 4.30 (4.46)  Time: 0.593s,   67.44/s  (0.601s,   66.57/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [2600/3167 ( 82%)]  Loss: 4.44 (4.45)  Time: 0.594s,   67.32/s  (0.601s,   66.58/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [2650/3167 ( 84%)]  Loss: 4.39 (4.45)  Time: 0.596s,   67.07/s  (0.601s,   66.59/s)  LR: 1.000e-05  Data: 0.007 (0.006)
Train: 0 [2700/3167 ( 85%)]  Loss: 4.40 (4.45)  Time: 0.593s,   67.42/s  (0.601s,   66.59/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [2750/3167 ( 87%)]  Loss: 4.39 (4.45)  Time: 0.598s,   66.94/s  (0.601s,   66.60/s)  LR: 1.000e-05  Data: 0.007 (0.006)
Train: 0 [2800/3167 ( 88%)]  Loss: 4.42 (4.45)  Time: 0.595s,   67.20/s  (0.600s,   66.61/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [2850/3167 ( 90%)]  Loss: 4.14 (4.45)  Time: 0.593s,   67.44/s  (0.600s,   66.62/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [2900/3167 ( 92%)]  Loss: 4.46 (4.45)  Time: 0.593s,   67.42/s  (0.600s,   66.63/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [2950/3167 ( 93%)]  Loss: 4.48 (4.45)  Time: 0.595s,   67.27/s  (0.600s,   66.63/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [3000/3167 ( 95%)]  Loss: 4.32 (4.45)  Time: 0.593s,   67.42/s  (0.600s,   66.64/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [3050/3167 ( 96%)]  Loss: 4.54 (4.45)  Time: 0.593s,   67.45/s  (0.600s,   66.65/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [3100/3167 ( 98%)]  Loss: 4.58 (4.45)  Time: 0.598s,   66.87/s  (0.600s,   66.66/s)  LR: 1.000e-05  Data: 0.007 (0.006)
Train: 0 [3150/3167 ( 99%)]  Loss: 4.54 (4.45)  Time: 0.596s,   67.14/s  (0.600s,   66.67/s)  LR: 1.000e-05  Data: 0.007 (0.006)
Test: [   0/3167]  Time: 2.287 (2.287)  Loss:   4.325 ( 4.325)  Acc@1:   2.500 (  2.500)  Acc@5:  15.000 ( 15.000)
Test: [  50/3167]  Time: 0.192 (0.232)  Loss:   4.111 ( 4.132)  Acc@1:  10.000 (  5.882)  Acc@5:  40.000 ( 30.147)
Test: [ 100/3167]  Time: 0.199 (0.212)  Loss:   4.413 ( 4.159)  Acc@1:   0.000 (  5.644)  Acc@5:   2.500 ( 27.401)
Test: [ 150/3167]  Time: 0.193 (0.205)  Loss:   3.744 ( 4.164)  Acc@1:  17.500 (  5.977)  Acc@5:  70.000 ( 26.987)
Test: [ 200/3167]  Time: 0.189 (0.201)  Loss:   4.490 ( 4.210)  Acc@1:   0.000 (  5.460)  Acc@5:   0.000 ( 23.595)
Test: [ 250/3167]  Time: 0.187 (0.199)  Loss:   4.555 ( 4.263)  Acc@1:   0.000 (  4.512)  Acc@5:  10.000 ( 19.711)
Test: [ 300/3167]  Time: 0.188 (0.198)  Loss:   4.001 ( 4.273)  Acc@1:   0.000 (  3.812)  Acc@5:  52.500 ( 20.033)
Test: [ 350/3167]  Time: 0.194 (0.197)  Loss:   3.989 ( 4.246)  Acc@1:  30.000 (  4.915)  Acc@5:  55.000 ( 23.647)
Test: [ 400/3167]  Time: 0.194 (0.196)  Loss:   4.122 ( 4.127)  Acc@1:   0.000 ( 10.567)  Acc@5:  40.000 ( 29.065)
Test: [ 450/3167]  Time: 0.184 (0.195)  Loss:   4.179 ( 4.134)  Acc@1:   0.000 (  9.490)  Acc@5:  30.000 ( 28.697)
Test: [ 500/3167]  Time: 0.195 (0.195)  Loss:   4.420 ( 4.165)  Acc@1:   2.500 (  8.618)  Acc@5:  12.500 ( 26.597)
Test: [ 550/3167]  Time: 0.190 (0.194)  Loss:   4.608 ( 4.126)  Acc@1:   0.000 (  9.574)  Acc@5:   0.000 ( 28.575)
Test: [ 600/3167]  Time: 0.184 (0.194)  Loss:   3.731 ( 4.142)  Acc@1:   5.000 (  9.027)  Acc@5:  42.500 ( 27.887)
Test: [ 650/3167]  Time: 0.202 (0.194)  Loss:   4.439 ( 4.138)  Acc@1:   0.000 (  8.932)  Acc@5:   2.500 ( 28.276)
Test: [ 700/3167]  Time: 0.186 (0.193)  Loss:   4.347 ( 4.156)  Acc@1:   0.000 (  8.327)  Acc@5:   7.500 ( 26.708)
Test: [ 750/3167]  Time: 0.189 (0.193)  Loss:   3.976 ( 4.155)  Acc@1:   5.000 (  8.093)  Acc@5:  45.000 ( 26.478)
Test: [ 800/3167]  Time: 0.190 (0.193)  Loss:   4.428 ( 4.155)  Acc@1:   0.000 (  7.999)  Acc@5:  10.000 ( 26.458)
Test: [ 850/3167]  Time: 0.186 (0.193)  Loss:   4.447 ( 4.172)  Acc@1:   0.000 (  7.541)  Acc@5:   0.000 ( 25.112)
Test: [ 900/3167]  Time: 0.184 (0.193)  Loss:   4.410 ( 4.188)  Acc@1:   0.000 (  7.125)  Acc@5:   5.000 ( 23.824)
Test: [ 950/3167]  Time: 0.187 (0.193)  Loss:   4.219 ( 4.200)  Acc@1:   0.000 (  6.764)  Acc@5:  10.000 ( 22.847)
Test: [1000/3167]  Time: 0.188 (0.192)  Loss:   4.284 ( 4.210)  Acc@1:   0.000 (  6.431)  Acc@5:  15.000 ( 22.015)
Test: [1050/3167]  Time: 0.189 (0.192)  Loss:   3.953 ( 4.202)  Acc@1:   7.500 (  6.306)  Acc@5:  32.500 ( 22.186)
Test: [1100/3167]  Time: 0.196 (0.192)  Loss:   4.384 ( 4.209)  Acc@1:   0.000 (  6.069)  Acc@5:  10.000 ( 21.460)
Test: [1150/3167]  Time: 0.184 (0.192)  Loss:   3.926 ( 4.205)  Acc@1:  12.500 (  5.984)  Acc@5:  42.500 ( 21.887)
Test: [1200/3167]  Time: 0.185 (0.192)  Loss:   3.089 ( 4.190)  Acc@1:  45.000 (  6.721)  Acc@5:  82.500 ( 23.149)
Test: [1250/3167]  Time: 0.184 (0.192)  Loss:   3.513 ( 4.162)  Acc@1:  62.500 (  8.521)  Acc@5:  80.000 ( 25.026)
Test: [1300/3167]  Time: 0.200 (0.192)  Loss:   4.240 ( 4.169)  Acc@1:   0.000 (  8.257)  Acc@5:   5.000 ( 24.385)
Test: [1350/3167]  Time: 0.187 (0.192)  Loss:   4.409 ( 4.182)  Acc@1:   0.000 (  7.952)  Acc@5:   5.000 ( 23.649)
Test: [1400/3167]  Time: 0.189 (0.192)  Loss:   3.712 ( 4.194)  Acc@1:  22.500 (  7.732)  Acc@5:  62.500 ( 23.148)
Test: [1450/3167]  Time: 0.184 (0.192)  Loss:   4.489 ( 4.189)  Acc@1:   0.000 (  7.955)  Acc@5:   0.000 ( 23.780)
Test: [1500/3167]  Time: 0.186 (0.192)  Loss:   4.262 ( 4.166)  Acc@1:   2.500 (  9.071)  Acc@5:  15.000 ( 24.614)
Test: [1550/3167]  Time: 0.191 (0.192)  Loss:   4.074 ( 4.168)  Acc@1:   2.500 (  8.856)  Acc@5:  30.000 ( 24.632)
Test: [1600/3167]  Time: 0.187 (0.192)  Loss:   2.955 ( 4.160)  Acc@1:  37.500 (  8.949)  Acc@5:  77.500 ( 25.308)
Test: [1650/3167]  Time: 0.203 (0.197)  Loss:   4.028 ( 4.141)  Acc@1:   2.500 (  9.520)  Acc@5:  32.500 ( 26.137)
Test: [1700/3167]  Time: 0.188 (0.197)  Loss:   4.170 ( 4.136)  Acc@1:   2.500 (  9.299)  Acc@5:  20.000 ( 26.580)
Test: [1750/3167]  Time: 0.189 (0.197)  Loss:   4.072 ( 4.137)  Acc@1:   0.000 (  9.099)  Acc@5:  27.500 ( 26.662)
Test: [1800/3167]  Time: 0.185 (0.197)  Loss:   4.302 ( 4.138)  Acc@1:   0.000 (  9.001)  Acc@5:  12.500 ( 26.724)
Test: [1850/3167]  Time: 0.184 (0.196)  Loss:   4.554 ( 4.147)  Acc@1:   0.000 (  8.757)  Acc@5:   5.000 ( 26.076)
Test: [1900/3167]  Time: 0.196 (0.196)  Loss:   4.549 ( 4.156)  Acc@1:   0.000 (  8.532)  Acc@5:   0.000 ( 25.493)
Test: [1950/3167]  Time: 0.183 (0.196)  Loss:   4.542 ( 4.162)  Acc@1:   0.000 (  8.353)  Acc@5:   0.000 ( 25.152)
Test: [2000/3167]  Time: 0.192 (0.201)  Loss:   4.708 ( 4.175)  Acc@1:   0.000 (  8.145)  Acc@5:   0.000 ( 24.579)
Test: [2050/3167]  Time: 0.192 (0.200)  Loss:   4.545 ( 4.185)  Acc@1:   0.000 (  7.946)  Acc@5:   0.000 ( 23.981)
Test: [2100/3167]  Time: 0.189 (0.200)  Loss:   4.330 ( 4.185)  Acc@1:   5.000 (  8.112)  Acc@5:  17.500 ( 24.265)
Test: [2150/3167]  Time: 0.193 (0.200)  Loss:   2.002 ( 4.160)  Acc@1:  77.500 (  8.928)  Acc@5:  90.000 ( 24.923)
Test: [2200/3167]  Time: 0.184 (0.200)  Loss:   4.353 ( 4.157)  Acc@1:   0.000 (  9.038)  Acc@5:  15.000 ( 25.236)
Test: [2250/3167]  Time: 0.190 (0.199)  Loss:   4.018 ( 4.163)  Acc@1:   0.000 (  8.848)  Acc@5:  50.000 ( 25.080)
Test: [2300/3167]  Time: 0.190 (0.203)  Loss:   4.374 ( 4.168)  Acc@1:   0.000 (  8.678)  Acc@5:  12.500 ( 24.982)
Test: [2350/3167]  Time: 0.223 (0.203)  Loss:   4.149 ( 4.170)  Acc@1:  12.500 (  8.593)  Acc@5:  50.000 ( 24.880)
Test: [2400/3167]  Time: 0.191 (0.203)  Loss:   4.458 ( 4.169)  Acc@1:   0.000 (  8.806)  Acc@5:   5.000 ( 25.037)
Test: [2450/3167]  Time: 0.196 (0.202)  Loss:   4.084 ( 4.171)  Acc@1:   5.000 (  8.649)  Acc@5:  22.500 ( 24.790)
Test: [2500/3167]  Time: 0.194 (0.202)  Loss:   4.318 ( 4.171)  Acc@1:   7.500 (  8.637)  Acc@5:  30.000 ( 25.017)
Test: [2550/3167]  Time: 0.188 (0.202)  Loss:   4.141 ( 4.166)  Acc@1:   0.000 (  8.583)  Acc@5:  17.500 ( 25.518)
Test: [2600/3167]  Time: 0.197 (0.205)  Loss:   3.987 ( 4.166)  Acc@1:   5.000 (  8.484)  Acc@5:  32.500 ( 25.484)
Test: [2650/3167]  Time: 0.188 (0.205)  Loss:   4.319 ( 4.168)  Acc@1:   2.500 (  8.356)  Acc@5:  20.000 ( 25.275)
Test: [2700/3167]  Time: 0.201 (0.205)  Loss:   4.188 ( 4.170)  Acc@1:   2.500 (  8.246)  Acc@5:  27.500 ( 25.290)
Test: [2750/3167]  Time: 0.185 (0.204)  Loss:   3.947 ( 4.171)  Acc@1:   2.500 (  8.132)  Acc@5:  45.000 ( 25.270)
Test: [2800/3167]  Time: 0.184 (0.204)  Loss:   4.213 ( 4.171)  Acc@1:   0.000 (  8.052)  Acc@5:  27.500 ( 25.425)
Test: [2850/3167]  Time: 0.188 (0.204)  Loss:   3.957 ( 4.174)  Acc@1:   2.500 (  7.933)  Acc@5:  55.000 ( 25.275)
Test: [2900/3167]  Time: 0.184 (0.204)  Loss:   4.182 ( 4.172)  Acc@1:   2.500 (  7.848)  Acc@5:  20.000 ( 25.383)
Test: [2950/3167]  Time: 0.194 (0.206)  Loss:   4.335 ( 4.175)  Acc@1:   0.000 (  7.716)  Acc@5:   7.500 ( 25.014)
Test: [3000/3167]  Time: 0.203 (0.206)  Loss:   4.329 ( 4.178)  Acc@1:   0.000 (  7.589)  Acc@5:   0.000 ( 24.645)
Test: [3050/3167]  Time: 0.184 (0.206)  Loss:   4.416 ( 4.179)  Acc@1:   0.000 (  7.516)  Acc@5:   0.000 ( 24.486)
Test: [3100/3167]  Time: 0.191 (0.206)  Loss:   4.255 ( 4.182)  Acc@1:   0.000 (  7.399)  Acc@5:  20.000 ( 24.252)
Test: [3150/3167]  Time: 0.189 (0.205)  Loss:   4.464 ( 4.186)  Acc@1:   0.000 (  7.286)  Acc@5:   2.500 ( 23.933)
Test: [3167/3167]  Time: 0.297 (0.205)  Loss:   4.453 ( 4.187)  Acc@1:   0.000 (  7.248)  Acc@5:   0.000 ( 23.824)
Test: [   0/124]  Time: 1.931 (1.931)  Loss:   4.315 ( 4.315)  Acc@1:   0.000 (  0.000)  Acc@5:   7.500 (  7.500)
Test: [  50/124]  Time: 0.184 (0.224)  Loss:   4.366 ( 4.204)  Acc@1:   0.000 (  7.402)  Acc@5:  12.500 ( 23.725)
Test: [ 100/124]  Time: 0.188 (0.296)  Loss:   3.542 ( 4.205)  Acc@1:   5.000 (  7.550)  Acc@5:  70.000 ( 25.000)
Test: [ 124/124]  Time: 0.180 (0.275)  Loss:   4.449 ( 4.220)  Acc@1:   0.000 (  6.420)  Acc@5:   2.500 ( 23.240)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_3/checkpoint-0.pth.tar', 7.248458824365177)

Train: 1 [   0/3167 (  0%)]  Loss: 4.38 (4.38)  Time: 1.135s,   35.25/s  (1.135s,   35.25/s)  LR: 1.900e-05  Data: 0.504 (0.504)
Train: 1 [  50/3167 (  2%)]  Loss: 4.40 (4.40)  Time: 0.601s,   66.60/s  (0.613s,   65.29/s)  LR: 1.900e-05  Data: 0.012 (0.020)
Train: 1 [ 100/3167 (  3%)]  Loss: 4.21 (4.38)  Time: 0.595s,   67.18/s  (0.607s,   65.86/s)  LR: 1.900e-05  Data: 0.004 (0.015)
Train: 1 [ 150/3167 (  5%)]  Loss: 4.50 (4.39)  Time: 0.610s,   65.59/s  (0.605s,   66.08/s)  LR: 1.900e-05  Data: 0.011 (0.013)
Train: 1 [ 200/3167 (  6%)]  Loss: 4.33 (4.39)  Time: 0.593s,   67.47/s  (0.605s,   66.16/s)  LR: 1.900e-05  Data: 0.004 (0.012)
Train: 1 [ 250/3167 (  8%)]  Loss: 4.29 (4.39)  Time: 0.602s,   66.40/s  (0.604s,   66.24/s)  LR: 1.900e-05  Data: 0.011 (0.012)
Train: 1 [ 300/3167 (  9%)]  Loss: 4.44 (4.39)  Time: 0.609s,   65.73/s  (0.603s,   66.30/s)  LR: 1.900e-05  Data: 0.012 (0.011)
Train: 1 [ 350/3167 ( 11%)]  Loss: 4.23 (4.40)  Time: 0.603s,   66.36/s  (0.603s,   66.33/s)  LR: 1.900e-05  Data: 0.004 (0.011)
Train: 1 [ 400/3167 ( 13%)]  Loss: 4.11 (4.40)  Time: 0.606s,   65.97/s  (0.603s,   66.36/s)  LR: 1.900e-05  Data: 0.012 (0.011)
Train: 1 [ 450/3167 ( 14%)]  Loss: 4.59 (4.39)  Time: 0.596s,   67.07/s  (0.602s,   66.39/s)  LR: 1.900e-05  Data: 0.004 (0.011)
Train: 1 [ 500/3167 ( 16%)]  Loss: 4.33 (4.40)  Time: 0.601s,   66.56/s  (0.602s,   66.42/s)  LR: 1.900e-05  Data: 0.012 (0.011)
Train: 1 [ 550/3167 ( 17%)]  Loss: 4.24 (4.39)  Time: 0.595s,   67.20/s  (0.602s,   66.44/s)  LR: 1.900e-05  Data: 0.006 (0.010)
Train: 1 [ 600/3167 ( 19%)]  Loss: 4.23 (4.39)  Time: 0.603s,   66.35/s  (0.602s,   66.44/s)  LR: 1.900e-05  Data: 0.011 (0.010)
Train: 1 [ 650/3167 ( 21%)]  Loss: 4.39 (4.39)  Time: 0.607s,   65.89/s  (0.602s,   66.46/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [ 700/3167 ( 22%)]  Loss: 4.34 (4.39)  Time: 0.606s,   66.02/s  (0.602s,   66.46/s)  LR: 1.900e-05  Data: 0.009 (0.010)
Train: 1 [ 750/3167 ( 24%)]  Loss: 4.22 (4.39)  Time: 0.596s,   67.16/s  (0.602s,   66.48/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [ 800/3167 ( 25%)]  Loss: 4.28 (4.39)  Time: 0.601s,   66.56/s  (0.602s,   66.48/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [ 850/3167 ( 27%)]  Loss: 4.28 (4.39)  Time: 0.596s,   67.15/s  (0.602s,   66.48/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [ 900/3167 ( 28%)]  Loss: 4.31 (4.39)  Time: 0.601s,   66.61/s  (0.602s,   66.49/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [ 950/3167 ( 30%)]  Loss: 4.33 (4.39)  Time: 0.602s,   66.40/s  (0.602s,   66.50/s)  LR: 1.900e-05  Data: 0.011 (0.010)
Train: 1 [1000/3167 ( 32%)]  Loss: 4.42 (4.39)  Time: 0.599s,   66.82/s  (0.602s,   66.50/s)  LR: 1.900e-05  Data: 0.010 (0.010)
Train: 1 [1050/3167 ( 33%)]  Loss: 4.35 (4.38)  Time: 0.596s,   67.15/s  (0.601s,   66.51/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [1100/3167 ( 35%)]  Loss: 4.42 (4.38)  Time: 0.608s,   65.81/s  (0.601s,   66.51/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [1150/3167 ( 36%)]  Loss: 4.50 (4.38)  Time: 0.601s,   66.61/s  (0.601s,   66.51/s)  LR: 1.900e-05  Data: 0.011 (0.010)
Train: 1 [1200/3167 ( 38%)]  Loss: 4.52 (4.38)  Time: 0.596s,   67.13/s  (0.601s,   66.52/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [1250/3167 ( 39%)]  Loss: 4.30 (4.38)  Time: 0.595s,   67.20/s  (0.601s,   66.53/s)  LR: 1.900e-05  Data: 0.004 (0.010)
Train: 1 [1300/3167 ( 41%)]  Loss: 4.49 (4.38)  Time: 0.600s,   66.62/s  (0.601s,   66.53/s)  LR: 1.900e-05  Data: 0.011 (0.010)
Train: 1 [1350/3167 ( 43%)]  Loss: 4.15 (4.38)  Time: 0.600s,   66.64/s  (0.601s,   66.53/s)  LR: 1.900e-05  Data: 0.011 (0.010)
Train: 1 [1400/3167 ( 44%)]  Loss: 4.41 (4.38)  Time: 0.610s,   65.60/s  (0.601s,   66.54/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [1450/3167 ( 46%)]  Loss: 4.30 (4.38)  Time: 0.600s,   66.63/s  (0.601s,   66.55/s)  LR: 1.900e-05  Data: 0.011 (0.010)
Train: 1 [1500/3167 ( 47%)]  Loss: 4.41 (4.38)  Time: 0.611s,   65.49/s  (0.601s,   66.55/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [1550/3167 ( 49%)]  Loss: 4.52 (4.38)  Time: 0.603s,   66.34/s  (0.601s,   66.56/s)  LR: 1.900e-05  Data: 0.011 (0.010)
Train: 1 [1600/3167 ( 51%)]  Loss: 4.28 (4.38)  Time: 0.593s,   67.47/s  (0.601s,   66.56/s)  LR: 1.900e-05  Data: 0.004 (0.009)
Train: 1 [1650/3167 ( 52%)]  Loss: 4.40 (4.38)  Time: 0.601s,   66.56/s  (0.601s,   66.57/s)  LR: 1.900e-05  Data: 0.012 (0.009)
Train: 1 [1700/3167 ( 54%)]  Loss: 4.32 (4.38)  Time: 0.601s,   66.51/s  (0.601s,   66.58/s)  LR: 1.900e-05  Data: 0.009 (0.009)
Train: 1 [1750/3167 ( 55%)]  Loss: 4.28 (4.38)  Time: 0.601s,   66.57/s  (0.601s,   66.58/s)  LR: 1.900e-05  Data: 0.012 (0.009)
Train: 1 [1800/3167 ( 57%)]  Loss: 4.42 (4.38)  Time: 0.596s,   67.12/s  (0.601s,   66.59/s)  LR: 1.900e-05  Data: 0.007 (0.009)
Train: 1 [1850/3167 ( 58%)]  Loss: 4.25 (4.38)  Time: 0.596s,   67.08/s  (0.601s,   66.59/s)  LR: 1.900e-05  Data: 0.007 (0.009)
Train: 1 [1900/3167 ( 60%)]  Loss: 4.38 (4.38)  Time: 0.599s,   66.77/s  (0.601s,   66.60/s)  LR: 1.900e-05  Data: 0.009 (0.009)
Train: 1 [1950/3167 ( 62%)]  Loss: 4.41 (4.38)  Time: 0.599s,   66.80/s  (0.601s,   66.61/s)  LR: 1.900e-05  Data: 0.010 (0.009)
Train: 1 [2000/3167 ( 63%)]  Loss: 4.28 (4.38)  Time: 0.603s,   66.33/s  (0.601s,   66.61/s)  LR: 1.900e-05  Data: 0.012 (0.009)
Train: 1 [2050/3167 ( 65%)]  Loss: 4.38 (4.38)  Time: 0.593s,   67.46/s  (0.600s,   66.62/s)  LR: 1.900e-05  Data: 0.004 (0.009)
Train: 1 [2100/3167 ( 66%)]  Loss: 4.48 (4.38)  Time: 0.603s,   66.30/s  (0.600s,   66.62/s)  LR: 1.900e-05  Data: 0.007 (0.009)
Train: 1 [2150/3167 ( 68%)]  Loss: 4.27 (4.38)  Time: 0.603s,   66.30/s  (0.600s,   66.63/s)  LR: 1.900e-05  Data: 0.012 (0.009)
Train: 1 [2200/3167 ( 69%)]  Loss: 4.22 (4.38)  Time: 0.601s,   66.59/s  (0.600s,   66.64/s)  LR: 1.900e-05  Data: 0.011 (0.009)
Train: 1 [2250/3167 ( 71%)]  Loss: 4.38 (4.38)  Time: 0.596s,   67.14/s  (0.600s,   66.65/s)  LR: 1.900e-05  Data: 0.004 (0.009)
Train: 1 [2300/3167 ( 73%)]  Loss: 4.42 (4.37)  Time: 0.602s,   66.47/s  (0.600s,   66.65/s)  LR: 1.900e-05  Data: 0.009 (0.009)
Train: 1 [2350/3167 ( 74%)]  Loss: 4.34 (4.37)  Time: 0.593s,   67.44/s  (0.600s,   66.66/s)  LR: 1.900e-05  Data: 0.004 (0.009)
Train: 1 [2400/3167 ( 76%)]  Loss: 4.25 (4.37)  Time: 0.596s,   67.13/s  (0.600s,   66.67/s)  LR: 1.900e-05  Data: 0.004 (0.009)
Train: 1 [2450/3167 ( 77%)]  Loss: 4.54 (4.37)  Time: 0.603s,   66.29/s  (0.600s,   66.68/s)  LR: 1.900e-05  Data: 0.011 (0.009)
Train: 1 [2500/3167 ( 79%)]  Loss: 4.24 (4.37)  Time: 0.603s,   66.29/s  (0.600s,   66.68/s)  LR: 1.900e-05  Data: 0.011 (0.009)
Train: 1 [2550/3167 ( 81%)]  Loss: 4.58 (4.37)  Time: 0.599s,   66.77/s  (0.600s,   66.69/s)  LR: 1.900e-05  Data: 0.007 (0.009)
Train: 1 [2600/3167 ( 82%)]  Loss: 4.44 (4.37)  Time: 0.598s,   66.85/s  (0.600s,   66.70/s)  LR: 1.900e-05  Data: 0.007 (0.009)
Train: 1 [2650/3167 ( 84%)]  Loss: 4.23 (4.37)  Time: 0.599s,   66.72/s  (0.600s,   66.70/s)  LR: 1.900e-05  Data: 0.007 (0.009)
Train: 1 [2700/3167 ( 85%)]  Loss: 4.36 (4.37)  Time: 0.599s,   66.80/s  (0.600s,   66.71/s)  LR: 1.900e-05  Data: 0.010 (0.008)
Train: 1 [2750/3167 ( 87%)]  Loss: 4.63 (4.37)  Time: 0.596s,   67.14/s  (0.600s,   66.71/s)  LR: 1.900e-05  Data: 0.006 (0.008)
Train: 1 [2800/3167 ( 88%)]  Loss: 4.40 (4.37)  Time: 0.593s,   67.42/s  (0.600s,   66.72/s)  LR: 1.900e-05  Data: 0.004 (0.008)
Train: 1 [2850/3167 ( 90%)]  Loss: 4.39 (4.37)  Time: 0.598s,   66.90/s  (0.599s,   66.73/s)  LR: 1.900e-05  Data: 0.006 (0.008)
Train: 1 [2900/3167 ( 92%)]  Loss: 4.60 (4.37)  Time: 0.594s,   67.34/s  (0.599s,   66.73/s)  LR: 1.900e-05  Data: 0.004 (0.008)
Train: 1 [2950/3167 ( 93%)]  Loss: 4.37 (4.37)  Time: 0.593s,   67.43/s  (0.599s,   66.74/s)  LR: 1.900e-05  Data: 0.004 (0.008)
Train: 1 [3000/3167 ( 95%)]  Loss: 4.12 (4.37)  Time: 0.593s,   67.42/s  (0.599s,   66.75/s)  LR: 1.900e-05  Data: 0.004 (0.008)
Train: 1 [3050/3167 ( 96%)]  Loss: 4.41 (4.37)  Time: 0.593s,   67.45/s  (0.599s,   66.75/s)  LR: 1.900e-05  Data: 0.004 (0.008)
Train: 1 [3100/3167 ( 98%)]  Loss: 4.31 (4.36)  Time: 0.596s,   67.12/s  (0.599s,   66.76/s)  LR: 1.900e-05  Data: 0.007 (0.008)
Train: 1 [3150/3167 ( 99%)]  Loss: 4.14 (4.36)  Time: 0.598s,   66.86/s  (0.599s,   66.76/s)  LR: 1.900e-05  Data: 0.009 (0.008)
Test: [   0/3167]  Time: 0.560 (0.560)  Loss:   4.178 ( 4.178)  Acc@1:   7.500 (  7.500)  Acc@5:  20.000 ( 20.000)
Test: [  50/3167]  Time: 0.193 (0.202)  Loss:   4.143 ( 4.085)  Acc@1:  20.000 (  9.265)  Acc@5:  35.000 ( 33.284)
Test: [ 100/3167]  Time: 0.199 (0.198)  Loss:   4.436 ( 4.172)  Acc@1:   0.000 (  6.634)  Acc@5:   5.000 ( 24.579)
Test: [ 150/3167]  Time: 0.200 (0.197)  Loss:   3.446 ( 4.138)  Acc@1:  10.000 (  6.457)  Acc@5:  70.000 ( 26.540)
Test: [ 200/3167]  Time: 0.200 (0.196)  Loss:   4.281 ( 4.168)  Acc@1:   0.000 (  5.535)  Acc@5:   7.500 ( 23.831)
Test: [ 250/3167]  Time: 0.195 (0.195)  Loss:   4.434 ( 4.194)  Acc@1:   2.500 (  4.582)  Acc@5:   5.000 ( 20.259)
Test: [ 300/3167]  Time: 0.186 (0.195)  Loss:   4.009 ( 4.214)  Acc@1:   0.000 (  4.336)  Acc@5:  40.000 ( 20.473)
Test: [ 350/3167]  Time: 0.191 (0.195)  Loss:   3.278 ( 4.131)  Acc@1:  50.000 (  7.493)  Acc@5:  67.500 ( 24.900)
Test: [ 400/3167]  Time: 0.200 (0.195)  Loss:   3.802 ( 4.013)  Acc@1:  20.000 ( 12.506)  Acc@5:  52.500 ( 30.486)
Test: [ 450/3167]  Time: 0.201 (0.195)  Loss:   3.877 ( 4.002)  Acc@1:   5.000 ( 11.829)  Acc@5:  35.000 ( 30.776)
Test: [ 500/3167]  Time: 0.190 (0.195)  Loss:   4.506 ( 4.051)  Acc@1:   0.000 ( 10.664)  Acc@5:   5.000 ( 28.204)
Test: [ 550/3167]  Time: 0.190 (0.195)  Loss:   4.565 ( 4.014)  Acc@1:   0.000 ( 12.210)  Acc@5:   0.000 ( 29.682)
Test: [ 600/3167]  Time: 0.203 (0.195)  Loss:   3.387 ( 4.026)  Acc@1:   7.500 ( 11.710)  Acc@5:  60.000 ( 29.089)
Test: [ 650/3167]  Time: 0.196 (0.195)  Loss:   4.501 ( 3.990)  Acc@1:   0.000 ( 12.746)  Acc@5:   5.000 ( 30.568)
Test: [ 700/3167]  Time: 0.199 (0.195)  Loss:   3.777 ( 4.001)  Acc@1:  12.500 ( 12.097)  Acc@5:  52.500 ( 30.178)
Test: [ 750/3167]  Time: 0.196 (0.195)  Loss:   3.640 ( 3.993)  Acc@1:  17.500 ( 11.664)  Acc@5:  50.000 ( 30.203)
Test: [ 800/3167]  Time: 0.187 (0.195)  Loss:   4.549 ( 3.997)  Acc@1:   0.000 ( 11.486)  Acc@5:  10.000 ( 30.265)
Test: [ 850/3167]  Time: 0.193 (0.195)  Loss:   4.297 ( 4.018)  Acc@1:   0.000 ( 10.978)  Acc@5:   7.500 ( 29.645)
Test: [ 900/3167]  Time: 0.202 (0.194)  Loss:   4.277 ( 4.034)  Acc@1:   7.500 ( 10.516)  Acc@5:  20.000 ( 28.979)
Test: [ 950/3167]  Time: 0.187 (0.194)  Loss:   3.767 ( 4.044)  Acc@1:   2.500 ( 10.097)  Acc@5:  37.500 ( 28.231)
Test: [1000/3167]  Time: 0.191 (0.194)  Loss:   4.229 ( 4.050)  Acc@1:   0.000 (  9.705)  Acc@5:  12.500 ( 27.415)
Test: [1050/3167]  Time: 0.185 (0.194)  Loss:   3.907 ( 4.048)  Acc@1:   2.500 (  9.443)  Acc@5:  42.500 ( 27.374)
Test: [1100/3167]  Time: 0.205 (0.194)  Loss:   4.314 ( 4.050)  Acc@1:   2.500 (  9.064)  Acc@5:   7.500 ( 26.887)
Test: [1150/3167]  Time: 0.186 (0.194)  Loss:   3.646 ( 4.046)  Acc@1:  30.000 (  9.255)  Acc@5:  62.500 ( 27.394)
Test: [1200/3167]  Time: 0.193 (0.194)  Loss:   3.164 ( 4.030)  Acc@1:  40.000 (  9.517)  Acc@5:  72.500 ( 28.283)
Test: [1250/3167]  Time: 0.184 (0.194)  Loss:   3.162 ( 3.999)  Acc@1:  42.500 ( 10.653)  Acc@5:  82.500 ( 29.966)
Test: [1300/3167]  Time: 0.192 (0.194)  Loss:   3.701 ( 4.006)  Acc@1:   0.000 ( 10.317)  Acc@5:  40.000 ( 29.656)
Test: [1350/3167]  Time: 0.187 (0.194)  Loss:   4.353 ( 4.021)  Acc@1:   2.500 (  9.956)  Acc@5:  20.000 ( 29.115)
Test: [1400/3167]  Time: 0.206 (0.194)  Loss:   3.615 ( 4.039)  Acc@1:  30.000 (  9.697)  Acc@5:  55.000 ( 28.619)
Test: [1450/3167]  Time: 0.191 (0.194)  Loss:   4.435 ( 4.036)  Acc@1:   0.000 (  9.960)  Acc@5:   2.500 ( 28.961)
Test: [1500/3167]  Time: 0.191 (0.194)  Loss:   3.837 ( 4.009)  Acc@1:   7.500 ( 10.964)  Acc@5:  32.500 ( 29.745)
Test: [1550/3167]  Time: 0.196 (0.194)  Loss:   3.034 ( 3.994)  Acc@1:  35.000 ( 11.164)  Acc@5:  82.500 ( 30.543)
Test: [1600/3167]  Time: 0.191 (0.194)  Loss:   2.908 ( 3.975)  Acc@1:  40.000 ( 11.413)  Acc@5:  75.000 ( 31.590)
Test: [1650/3167]  Time: 0.184 (0.194)  Loss:   3.852 ( 3.958)  Acc@1:  17.500 ( 11.958)  Acc@5:  45.000 ( 32.430)
Test: [1700/3167]  Time: 0.184 (0.194)  Loss:   4.307 ( 3.951)  Acc@1:   0.000 ( 12.112)  Acc@5:  12.500 ( 32.895)
Test: [1750/3167]  Time: 0.204 (0.194)  Loss:   3.886 ( 3.955)  Acc@1:   7.500 ( 12.049)  Acc@5:  32.500 ( 32.875)
Test: [1800/3167]  Time: 0.187 (0.194)  Loss:   3.964 ( 3.953)  Acc@1:   5.000 ( 12.042)  Acc@5:  32.500 ( 33.123)
Test: [1850/3167]  Time: 0.198 (0.194)  Loss:   4.722 ( 3.966)  Acc@1:   0.000 ( 11.738)  Acc@5:   0.000 ( 32.518)
Test: [1900/3167]  Time: 0.194 (0.194)  Loss:   4.542 ( 3.982)  Acc@1:   0.000 ( 11.430)  Acc@5:   0.000 ( 31.673)
Test: [1950/3167]  Time: 0.189 (0.193)  Loss:   4.505 ( 3.993)  Acc@1:   5.000 ( 11.152)  Acc@5:  20.000 ( 31.097)
Test: [2000/3167]  Time: 0.194 (0.193)  Loss:   4.600 ( 4.009)  Acc@1:   0.000 ( 10.896)  Acc@5:   0.000 ( 30.505)
Test: [2050/3167]  Time: 0.189 (0.193)  Loss:   4.593 ( 4.023)  Acc@1:   0.000 ( 10.631)  Acc@5:   0.000 ( 29.785)
Test: [2100/3167]  Time: 0.188 (0.193)  Loss:   4.215 ( 4.030)  Acc@1:   7.500 ( 10.546)  Acc@5:  10.000 ( 29.604)
Test: [2150/3167]  Time: 0.197 (0.193)  Loss:   2.066 ( 4.008)  Acc@1:  72.500 ( 11.211)  Acc@5:  80.000 ( 30.064)
Test: [2200/3167]  Time: 0.187 (0.193)  Loss:   3.936 ( 4.005)  Acc@1:   2.500 ( 11.186)  Acc@5:  32.500 ( 30.131)
Test: [2250/3167]  Time: 0.195 (0.193)  Loss:   3.659 ( 4.009)  Acc@1:  30.000 ( 11.084)  Acc@5:  62.500 ( 30.100)
Test: [2300/3167]  Time: 0.184 (0.193)  Loss:   4.400 ( 4.016)  Acc@1:   0.000 ( 11.041)  Acc@5:  12.500 ( 29.941)
Test: [2350/3167]  Time: 0.191 (0.193)  Loss:   4.018 ( 4.020)  Acc@1:  12.500 ( 10.871)  Acc@5:  37.500 ( 29.756)
Test: [2400/3167]  Time: 0.203 (0.193)  Loss:   4.368 ( 4.025)  Acc@1:   0.000 ( 10.807)  Acc@5:  12.500 ( 29.596)
Test: [2450/3167]  Time: 0.184 (0.193)  Loss:   3.682 ( 4.024)  Acc@1:   7.500 ( 10.654)  Acc@5:  42.500 ( 29.554)
Test: [2500/3167]  Time: 0.194 (0.193)  Loss:   4.485 ( 4.027)  Acc@1:  10.000 ( 10.630)  Acc@5:  17.500 ( 29.501)
Test: [2550/3167]  Time: 0.201 (0.193)  Loss:   4.192 ( 4.022)  Acc@1:   0.000 ( 10.572)  Acc@5:   7.500 ( 29.818)
Test: [2600/3167]  Time: 0.191 (0.193)  Loss:   3.890 ( 4.025)  Acc@1:  15.000 ( 10.414)  Acc@5:  40.000 ( 29.545)
Test: [2650/3167]  Time: 0.184 (0.193)  Loss:   3.933 ( 4.029)  Acc@1:  10.000 ( 10.273)  Acc@5:  37.500 ( 29.342)
Test: [2700/3167]  Time: 0.184 (0.193)  Loss:   3.925 ( 4.027)  Acc@1:   2.500 ( 10.202)  Acc@5:  30.000 ( 29.459)
Test: [2750/3167]  Time: 0.211 (0.193)  Loss:   2.965 ( 4.027)  Acc@1:  62.500 ( 10.184)  Acc@5:  85.000 ( 29.403)
Test: [2800/3167]  Time: 0.194 (0.193)  Loss:   4.235 ( 4.019)  Acc@1:   7.500 ( 10.561)  Acc@5:  27.500 ( 29.863)
Test: [2850/3167]  Time: 0.189 (0.193)  Loss:   3.920 ( 4.024)  Acc@1:  10.000 ( 10.424)  Acc@5:  35.000 ( 29.590)
Test: [2900/3167]  Time: 0.184 (0.193)  Loss:   4.045 ( 4.022)  Acc@1:  12.500 ( 10.410)  Acc@5:  32.500 ( 29.742)
Test: [2950/3167]  Time: 0.188 (0.193)  Loss:   3.926 ( 4.024)  Acc@1:   0.000 ( 10.274)  Acc@5:  17.500 ( 29.387)
Test: [3000/3167]  Time: 0.184 (0.192)  Loss:   4.175 ( 4.025)  Acc@1:   0.000 ( 10.107)  Acc@5:   7.500 ( 29.028)
Test: [3050/3167]  Time: 0.191 (0.192)  Loss:   4.538 ( 4.028)  Acc@1:   2.500 (  9.975)  Acc@5:   7.500 ( 28.875)
Test: [3100/3167]  Time: 0.188 (0.192)  Loss:   4.235 ( 4.032)  Acc@1:   0.000 (  9.822)  Acc@5:   5.000 ( 28.580)
Test: [3150/3167]  Time: 0.184 (0.192)  Loss:   4.600 ( 4.038)  Acc@1:   0.000 (  9.667)  Acc@5:   0.000 ( 28.189)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   4.583 ( 4.041)  Acc@1:   0.000 (  9.618)  Acc@5:   0.000 ( 28.051)
Test: [   0/124]  Time: 0.806 (0.806)  Loss:   4.218 ( 4.218)  Acc@1:   5.000 (  5.000)  Acc@5:  27.500 ( 27.500)
Test: [  50/124]  Time: 0.192 (0.203)  Loss:   3.904 ( 4.052)  Acc@1:   0.000 (  8.971)  Acc@5:  35.000 ( 28.676)
Test: [ 100/124]  Time: 0.197 (0.197)  Loss:   3.257 ( 4.072)  Acc@1:  10.000 (  9.257)  Acc@5:  67.500 ( 28.762)
Test: [ 124/124]  Time: 0.180 (0.195)  Loss:   4.584 ( 4.085)  Acc@1:   0.000 (  8.560)  Acc@5:   0.000 ( 26.940)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_3/checkpoint-1.pth.tar', 9.618041029607937)

Train: 2 [   0/3167 (  0%)]  Loss: 4.27 (4.27)  Time: 1.065s,   37.55/s  (1.065s,   37.55/s)  LR: 2.800e-05  Data: 0.463 (0.463)
Train: 2 [  50/3167 (  2%)]  Loss: 4.23 (4.34)  Time: 0.603s,   66.32/s  (0.612s,   65.40/s)  LR: 2.800e-05  Data: 0.012 (0.019)
Train: 2 [ 100/3167 (  3%)]  Loss: 4.27 (4.34)  Time: 0.601s,   66.50/s  (0.607s,   65.91/s)  LR: 2.800e-05  Data: 0.009 (0.014)
Train: 2 [ 150/3167 (  5%)]  Loss: 4.50 (4.33)  Time: 0.596s,   67.13/s  (0.605s,   66.11/s)  LR: 2.800e-05  Data: 0.007 (0.013)
Train: 2 [ 200/3167 (  6%)]  Loss: 4.52 (4.34)  Time: 0.600s,   66.61/s  (0.604s,   66.20/s)  LR: 2.800e-05  Data: 0.011 (0.012)
Train: 2 [ 250/3167 (  8%)]  Loss: 4.31 (4.34)  Time: 0.600s,   66.65/s  (0.604s,   66.26/s)  LR: 2.800e-05  Data: 0.011 (0.011)
Train: 2 [ 300/3167 (  9%)]  Loss: 4.26 (4.34)  Time: 0.604s,   66.28/s  (0.603s,   66.30/s)  LR: 2.800e-05  Data: 0.009 (0.011)
Train: 2 [ 350/3167 ( 11%)]  Loss: 4.26 (4.34)  Time: 0.598s,   66.87/s  (0.603s,   66.31/s)  LR: 2.800e-05  Data: 0.009 (0.011)
Train: 2 [ 400/3167 ( 13%)]  Loss: 4.14 (4.34)  Time: 0.607s,   65.91/s  (0.603s,   66.33/s)  LR: 2.800e-05  Data: 0.012 (0.011)
Train: 2 [ 450/3167 ( 14%)]  Loss: 4.27 (4.34)  Time: 0.600s,   66.64/s  (0.603s,   66.34/s)  LR: 2.800e-05  Data: 0.011 (0.011)
Train: 2 [ 500/3167 ( 16%)]  Loss: 4.41 (4.33)  Time: 0.601s,   66.58/s  (0.603s,   66.36/s)  LR: 2.800e-05  Data: 0.012 (0.011)
Train: 2 [ 550/3167 ( 17%)]  Loss: 4.20 (4.33)  Time: 0.604s,   66.22/s  (0.604s,   66.23/s)  LR: 2.800e-05  Data: 0.012 (0.011)
Train: 2 [ 600/3167 ( 19%)]  Loss: 4.25 (4.33)  Time: 0.605s,   66.15/s  (0.604s,   66.26/s)  LR: 2.800e-05  Data: 0.012 (0.011)
Train: 2 [ 650/3167 ( 21%)]  Loss: 4.26 (4.33)  Time: 0.601s,   66.59/s  (0.603s,   66.30/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [ 700/3167 ( 22%)]  Loss: 4.39 (4.33)  Time: 0.601s,   66.55/s  (0.603s,   66.32/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [ 750/3167 ( 24%)]  Loss: 4.15 (4.33)  Time: 0.601s,   66.53/s  (0.603s,   66.33/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [ 800/3167 ( 25%)]  Loss: 4.30 (4.33)  Time: 0.604s,   66.21/s  (0.603s,   66.36/s)  LR: 2.800e-05  Data: 0.011 (0.010)
Train: 2 [ 850/3167 ( 27%)]  Loss: 4.16 (4.33)  Time: 0.601s,   66.53/s  (0.603s,   66.38/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [ 900/3167 ( 28%)]  Loss: 4.47 (4.33)  Time: 0.601s,   66.54/s  (0.602s,   66.40/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [ 950/3167 ( 30%)]  Loss: 4.14 (4.32)  Time: 0.598s,   66.87/s  (0.602s,   66.41/s)  LR: 2.800e-05  Data: 0.009 (0.010)
Train: 2 [1000/3167 ( 32%)]  Loss: 4.53 (4.32)  Time: 0.599s,   66.78/s  (0.602s,   66.43/s)  LR: 2.800e-05  Data: 0.009 (0.010)
Train: 2 [1050/3167 ( 33%)]  Loss: 4.45 (4.32)  Time: 0.599s,   66.83/s  (0.602s,   66.44/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1100/3167 ( 35%)]  Loss: 4.27 (4.32)  Time: 0.608s,   65.74/s  (0.602s,   66.45/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [1150/3167 ( 36%)]  Loss: 4.40 (4.32)  Time: 0.602s,   66.43/s  (0.602s,   66.46/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [1200/3167 ( 38%)]  Loss: 4.41 (4.32)  Time: 0.598s,   66.88/s  (0.602s,   66.47/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1250/3167 ( 39%)]  Loss: 4.20 (4.32)  Time: 0.601s,   66.57/s  (0.602s,   66.48/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [1300/3167 ( 41%)]  Loss: 4.53 (4.32)  Time: 0.604s,   66.27/s  (0.602s,   66.49/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [1350/3167 ( 43%)]  Loss: 4.29 (4.32)  Time: 0.598s,   66.92/s  (0.602s,   66.50/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1400/3167 ( 44%)]  Loss: 4.20 (4.32)  Time: 0.593s,   67.45/s  (0.601s,   66.51/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1450/3167 ( 46%)]  Loss: 4.44 (4.32)  Time: 0.593s,   67.47/s  (0.601s,   66.52/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1500/3167 ( 47%)]  Loss: 4.34 (4.32)  Time: 0.600s,   66.65/s  (0.601s,   66.52/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1550/3167 ( 49%)]  Loss: 4.29 (4.32)  Time: 0.601s,   66.59/s  (0.601s,   66.53/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [1600/3167 ( 51%)]  Loss: 4.51 (4.32)  Time: 0.602s,   66.50/s  (0.601s,   66.54/s)  LR: 2.800e-05  Data: 0.009 (0.010)
Train: 2 [1650/3167 ( 52%)]  Loss: 4.44 (4.32)  Time: 0.593s,   67.45/s  (0.601s,   66.55/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1700/3167 ( 54%)]  Loss: 4.12 (4.31)  Time: 0.596s,   67.10/s  (0.601s,   66.56/s)  LR: 2.800e-05  Data: 0.007 (0.010)
Train: 2 [1750/3167 ( 55%)]  Loss: 4.41 (4.31)  Time: 0.593s,   67.45/s  (0.601s,   66.57/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1800/3167 ( 57%)]  Loss: 4.02 (4.31)  Time: 0.593s,   67.46/s  (0.601s,   66.58/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [1850/3167 ( 58%)]  Loss: 4.13 (4.31)  Time: 0.596s,   67.10/s  (0.601s,   66.59/s)  LR: 2.800e-05  Data: 0.007 (0.009)
Train: 2 [1900/3167 ( 60%)]  Loss: 4.14 (4.31)  Time: 0.593s,   67.43/s  (0.601s,   66.59/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [1950/3167 ( 62%)]  Loss: 4.23 (4.31)  Time: 0.596s,   67.15/s  (0.601s,   66.60/s)  LR: 2.800e-05  Data: 0.007 (0.009)
Train: 2 [2000/3167 ( 63%)]  Loss: 4.24 (4.31)  Time: 0.596s,   67.16/s  (0.601s,   66.61/s)  LR: 2.800e-05  Data: 0.007 (0.009)
Train: 2 [2050/3167 ( 65%)]  Loss: 4.38 (4.31)  Time: 0.601s,   66.51/s  (0.600s,   66.62/s)  LR: 2.800e-05  Data: 0.012 (0.009)
Train: 2 [2100/3167 ( 66%)]  Loss: 4.42 (4.31)  Time: 0.596s,   67.12/s  (0.600s,   66.62/s)  LR: 2.800e-05  Data: 0.007 (0.009)
Train: 2 [2150/3167 ( 68%)]  Loss: 4.31 (4.31)  Time: 0.596s,   67.10/s  (0.600s,   66.63/s)  LR: 2.800e-05  Data: 0.007 (0.009)
Train: 2 [2200/3167 ( 69%)]  Loss: 4.00 (4.31)  Time: 0.593s,   67.41/s  (0.600s,   66.64/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [2250/3167 ( 71%)]  Loss: 4.48 (4.30)  Time: 0.593s,   67.46/s  (0.600s,   66.65/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [2300/3167 ( 73%)]  Loss: 4.45 (4.30)  Time: 0.593s,   67.44/s  (0.600s,   66.65/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [2350/3167 ( 74%)]  Loss: 4.48 (4.30)  Time: 0.601s,   66.55/s  (0.600s,   66.66/s)  LR: 2.800e-05  Data: 0.012 (0.009)
Train: 2 [2400/3167 ( 76%)]  Loss: 4.25 (4.30)  Time: 0.599s,   66.78/s  (0.600s,   66.67/s)  LR: 2.800e-05  Data: 0.010 (0.009)
Train: 2 [2450/3167 ( 77%)]  Loss: 4.23 (4.30)  Time: 0.596s,   67.10/s  (0.600s,   66.68/s)  LR: 2.800e-05  Data: 0.007 (0.009)
Train: 2 [2500/3167 ( 79%)]  Loss: 4.17 (4.30)  Time: 0.596s,   67.17/s  (0.600s,   66.68/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [2550/3167 ( 81%)]  Loss: 4.66 (4.30)  Time: 0.601s,   66.54/s  (0.600s,   66.69/s)  LR: 2.800e-05  Data: 0.012 (0.009)
Train: 2 [2600/3167 ( 82%)]  Loss: 4.41 (4.30)  Time: 0.593s,   67.40/s  (0.600s,   66.69/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [2650/3167 ( 84%)]  Loss: 4.05 (4.30)  Time: 0.600s,   66.65/s  (0.600s,   66.70/s)  LR: 2.800e-05  Data: 0.007 (0.009)
Train: 2 [2700/3167 ( 85%)]  Loss: 4.37 (4.30)  Time: 0.596s,   67.11/s  (0.600s,   66.71/s)  LR: 2.800e-05  Data: 0.006 (0.009)
Train: 2 [2750/3167 ( 87%)]  Loss: 4.30 (4.30)  Time: 0.607s,   65.89/s  (0.600s,   66.71/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [2800/3167 ( 88%)]  Loss: 4.17 (4.30)  Time: 0.598s,   66.89/s  (0.600s,   66.72/s)  LR: 2.800e-05  Data: 0.007 (0.009)
Train: 2 [2850/3167 ( 90%)]  Loss: 4.42 (4.30)  Time: 0.609s,   65.69/s  (0.599s,   66.72/s)  LR: 2.800e-05  Data: 0.020 (0.008)
Train: 2 [2900/3167 ( 92%)]  Loss: 4.32 (4.29)  Time: 0.597s,   66.95/s  (0.599s,   66.73/s)  LR: 2.800e-05  Data: 0.004 (0.008)
Train: 2 [2950/3167 ( 93%)]  Loss: 3.93 (4.29)  Time: 0.595s,   67.23/s  (0.599s,   66.74/s)  LR: 2.800e-05  Data: 0.004 (0.008)
Train: 2 [3000/3167 ( 95%)]  Loss: 4.39 (4.29)  Time: 0.600s,   66.63/s  (0.599s,   66.74/s)  LR: 2.800e-05  Data: 0.007 (0.008)
Train: 2 [3050/3167 ( 96%)]  Loss: 4.30 (4.29)  Time: 0.593s,   67.43/s  (0.599s,   66.75/s)  LR: 2.800e-05  Data: 0.004 (0.008)
Train: 2 [3100/3167 ( 98%)]  Loss: 4.33 (4.29)  Time: 0.597s,   66.96/s  (0.599s,   66.75/s)  LR: 2.800e-05  Data: 0.007 (0.008)
Train: 2 [3150/3167 ( 99%)]  Loss: 4.33 (4.29)  Time: 0.595s,   67.23/s  (0.599s,   66.76/s)  LR: 2.800e-05  Data: 0.004 (0.008)
Test: [   0/3167]  Time: 0.491 (0.491)  Loss:   4.207 ( 4.207)  Acc@1:  10.000 ( 10.000)  Acc@5:  22.500 ( 22.500)
Test: [  50/3167]  Time: 0.186 (0.199)  Loss:   3.913 ( 3.996)  Acc@1:  25.000 ( 13.039)  Acc@5:  45.000 ( 35.735)
Test: [ 100/3167]  Time: 0.206 (0.197)  Loss:   4.161 ( 3.980)  Acc@1:   2.500 ( 10.050)  Acc@5:  12.500 ( 33.193)
Test: [ 150/3167]  Time: 0.194 (0.196)  Loss:   3.045 ( 3.916)  Acc@1:  40.000 ( 12.632)  Acc@5:  80.000 ( 34.338)
Test: [ 200/3167]  Time: 0.184 (0.196)  Loss:   4.095 ( 3.949)  Acc@1:   7.500 ( 11.642)  Acc@5:  25.000 ( 31.007)
Test: [ 250/3167]  Time: 0.193 (0.195)  Loss:   3.542 ( 3.911)  Acc@1:  20.000 ( 12.112)  Acc@5:  50.000 ( 32.371)
Test: [ 300/3167]  Time: 0.196 (0.195)  Loss:   3.887 ( 3.903)  Acc@1:   0.000 ( 12.392)  Acc@5:  35.000 ( 33.547)
Test: [ 350/3167]  Time: 0.184 (0.195)  Loss:   3.387 ( 3.862)  Acc@1:  42.500 ( 13.298)  Acc@5:  65.000 ( 35.520)
Test: [ 400/3167]  Time: 0.190 (0.195)  Loss:   3.725 ( 3.745)  Acc@1:  10.000 ( 17.774)  Acc@5:  47.500 ( 39.682)
Test: [ 450/3167]  Time: 0.196 (0.195)  Loss:   3.790 ( 3.757)  Acc@1:   0.000 ( 16.452)  Acc@5:  17.500 ( 38.520)
Test: [ 500/3167]  Time: 0.203 (0.195)  Loss:   3.974 ( 3.785)  Acc@1:   5.000 ( 15.409)  Acc@5:  22.500 ( 37.809)
Test: [ 550/3167]  Time: 0.197 (0.195)  Loss:   4.083 ( 3.763)  Acc@1:   0.000 ( 16.593)  Acc@5:  20.000 ( 38.875)
Test: [ 600/3167]  Time: 0.187 (0.195)  Loss:   3.385 ( 3.779)  Acc@1:   5.000 ( 15.453)  Acc@5:  45.000 ( 37.870)
Test: [ 650/3167]  Time: 0.197 (0.195)  Loss:   4.203 ( 3.763)  Acc@1:   0.000 ( 15.764)  Acc@5:  20.000 ( 38.283)
Test: [ 700/3167]  Time: 0.186 (0.194)  Loss:   3.254 ( 3.760)  Acc@1:  45.000 ( 15.756)  Acc@5:  70.000 ( 38.884)
Test: [ 750/3167]  Time: 0.192 (0.194)  Loss:   3.757 ( 3.753)  Acc@1:  15.000 ( 15.559)  Acc@5:  45.000 ( 39.348)
Test: [ 800/3167]  Time: 0.193 (0.194)  Loss:   4.329 ( 3.767)  Acc@1:   0.000 ( 15.328)  Acc@5:  20.000 ( 38.820)
Test: [ 850/3167]  Time: 0.193 (0.194)  Loss:   4.142 ( 3.793)  Acc@1:   0.000 ( 14.618)  Acc@5:   5.000 ( 37.761)
Test: [ 900/3167]  Time: 0.187 (0.194)  Loss:   4.010 ( 3.812)  Acc@1:  10.000 ( 13.993)  Acc@5:  27.500 ( 36.523)
Test: [ 950/3167]  Time: 0.196 (0.194)  Loss:   3.170 ( 3.816)  Acc@1:  27.500 ( 13.975)  Acc@5:  75.000 ( 36.506)
Test: [1000/3167]  Time: 0.191 (0.194)  Loss:   4.139 ( 3.828)  Acc@1:   0.000 ( 13.791)  Acc@5:  17.500 ( 35.849)
Test: [1050/3167]  Time: 0.187 (0.194)  Loss:   3.627 ( 3.826)  Acc@1:  10.000 ( 13.506)  Acc@5:  42.500 ( 36.063)
Test: [1100/3167]  Time: 0.190 (0.194)  Loss:   4.204 ( 3.832)  Acc@1:   2.500 ( 12.997)  Acc@5:   5.000 ( 35.486)
Test: [1150/3167]  Time: 0.186 (0.194)  Loss:   3.597 ( 3.832)  Acc@1:  22.500 ( 13.149)  Acc@5:  62.500 ( 35.712)
Test: [1200/3167]  Time: 0.185 (0.194)  Loss:   2.877 ( 3.810)  Acc@1:  47.500 ( 13.805)  Acc@5:  75.000 ( 36.782)
Test: [1250/3167]  Time: 0.198 (0.194)  Loss:   3.455 ( 3.791)  Acc@1:  42.500 ( 14.894)  Acc@5:  60.000 ( 37.806)
Test: [1300/3167]  Time: 0.203 (0.194)  Loss:   3.710 ( 3.800)  Acc@1:  20.000 ( 14.497)  Acc@5:  40.000 ( 37.298)
Test: [1350/3167]  Time: 0.197 (0.194)  Loss:   4.031 ( 3.816)  Acc@1:   2.500 ( 14.056)  Acc@5:  30.000 ( 36.501)
Test: [1400/3167]  Time: 0.188 (0.194)  Loss:   3.441 ( 3.832)  Acc@1:  45.000 ( 13.708)  Acc@5:  62.500 ( 35.894)
Test: [1450/3167]  Time: 0.191 (0.194)  Loss:   4.114 ( 3.827)  Acc@1:   0.000 ( 14.140)  Acc@5:  17.500 ( 36.370)
Test: [1500/3167]  Time: 0.191 (0.194)  Loss:   3.785 ( 3.807)  Acc@1:  10.000 ( 14.161)  Acc@5:  32.500 ( 36.985)
Test: [1550/3167]  Time: 0.190 (0.194)  Loss:   2.727 ( 3.791)  Acc@1:  72.500 ( 14.737)  Acc@5:  90.000 ( 37.661)
Test: [1600/3167]  Time: 0.189 (0.194)  Loss:   2.660 ( 3.780)  Acc@1:  45.000 ( 15.122)  Acc@5:  72.500 ( 38.201)
Test: [1650/3167]  Time: 0.190 (0.194)  Loss:   3.638 ( 3.761)  Acc@1:  20.000 ( 15.669)  Acc@5:  52.500 ( 38.913)
Test: [1700/3167]  Time: 0.194 (0.194)  Loss:   4.226 ( 3.754)  Acc@1:   2.500 ( 15.725)  Acc@5:  17.500 ( 39.292)
Test: [1750/3167]  Time: 0.196 (0.194)  Loss:   3.820 ( 3.761)  Acc@1:  10.000 ( 15.577)  Acc@5:  35.000 ( 39.063)
Test: [1800/3167]  Time: 0.193 (0.194)  Loss:   3.534 ( 3.759)  Acc@1:  27.500 ( 15.745)  Acc@5:  57.500 ( 39.409)
Test: [1850/3167]  Time: 0.197 (0.194)  Loss:   4.206 ( 3.766)  Acc@1:   7.500 ( 15.558)  Acc@5:  20.000 ( 38.988)
Test: [1900/3167]  Time: 0.194 (0.193)  Loss:   4.200 ( 3.774)  Acc@1:   2.500 ( 15.395)  Acc@5:  15.000 ( 38.811)
Test: [1950/3167]  Time: 0.194 (0.193)  Loss:   4.526 ( 3.780)  Acc@1:   0.000 ( 15.350)  Acc@5:   7.500 ( 38.652)
Test: [2000/3167]  Time: 0.208 (0.193)  Loss:   4.077 ( 3.795)  Acc@1:  12.500 ( 15.016)  Acc@5:  25.000 ( 37.899)
Test: [2050/3167]  Time: 0.204 (0.193)  Loss:   4.368 ( 3.805)  Acc@1:   0.000 ( 14.811)  Acc@5:   0.000 ( 37.346)
Test: [2100/3167]  Time: 0.184 (0.193)  Loss:   4.028 ( 3.811)  Acc@1:   2.500 ( 14.685)  Acc@5:  12.500 ( 37.131)
Test: [2150/3167]  Time: 0.193 (0.193)  Loss:   2.333 ( 3.796)  Acc@1:  62.500 ( 15.120)  Acc@5:  70.000 ( 37.462)
Test: [2200/3167]  Time: 0.195 (0.193)  Loss:   3.631 ( 3.789)  Acc@1:   2.500 ( 15.131)  Acc@5:  47.500 ( 37.729)
Test: [2250/3167]  Time: 0.195 (0.193)  Loss:   3.698 ( 3.793)  Acc@1:  25.000 ( 14.956)  Acc@5:  55.000 ( 37.648)
Test: [2300/3167]  Time: 0.190 (0.193)  Loss:   4.208 ( 3.800)  Acc@1:   2.500 ( 14.826)  Acc@5:  22.500 ( 37.355)
Test: [2350/3167]  Time: 0.190 (0.193)  Loss:   3.379 ( 3.801)  Acc@1:  52.500 ( 14.834)  Acc@5:  65.000 ( 37.312)
Test: [2400/3167]  Time: 0.189 (0.193)  Loss:   4.354 ( 3.797)  Acc@1:   0.000 ( 15.066)  Acc@5:   5.000 ( 37.498)
Test: [2450/3167]  Time: 0.196 (0.193)  Loss:   3.235 ( 3.794)  Acc@1:  30.000 ( 14.948)  Acc@5:  72.500 ( 37.673)
Test: [2500/3167]  Time: 0.184 (0.193)  Loss:   4.170 ( 3.796)  Acc@1:  10.000 ( 14.929)  Acc@5:  30.000 ( 37.678)
Test: [2550/3167]  Time: 0.192 (0.193)  Loss:   3.987 ( 3.785)  Acc@1:   5.000 ( 15.448)  Acc@5:  17.500 ( 38.123)
Test: [2600/3167]  Time: 0.208 (0.193)  Loss:   3.818 ( 3.790)  Acc@1:  12.500 ( 15.270)  Acc@5:  37.500 ( 37.837)
Test: [2650/3167]  Time: 0.210 (0.193)  Loss:   3.861 ( 3.795)  Acc@1:   2.500 ( 15.085)  Acc@5:  37.500 ( 37.679)
Test: [2700/3167]  Time: 0.191 (0.193)  Loss:   3.499 ( 3.794)  Acc@1:  15.000 ( 14.996)  Acc@5:  47.500 ( 37.719)
Test: [2750/3167]  Time: 0.189 (0.193)  Loss:   2.916 ( 3.796)  Acc@1:  27.500 ( 14.867)  Acc@5:  85.000 ( 37.564)
Test: [2800/3167]  Time: 0.184 (0.193)  Loss:   3.980 ( 3.790)  Acc@1:   2.500 ( 14.844)  Acc@5:  32.500 ( 37.875)
Test: [2850/3167]  Time: 0.184 (0.193)  Loss:   3.985 ( 3.795)  Acc@1:  15.000 ( 14.688)  Acc@5:  37.500 ( 37.700)
Test: [2900/3167]  Time: 0.193 (0.193)  Loss:   3.971 ( 3.797)  Acc@1:  10.000 ( 14.695)  Acc@5:  30.000 ( 37.709)
Test: [2950/3167]  Time: 0.189 (0.193)  Loss:   4.031 ( 3.799)  Acc@1:   0.000 ( 14.492)  Acc@5:   2.500 ( 37.342)
Test: [3000/3167]  Time: 0.184 (0.193)  Loss:   4.177 ( 3.805)  Acc@1:   0.000 ( 14.252)  Acc@5:   2.500 ( 36.823)
Test: [3050/3167]  Time: 0.184 (0.193)  Loss:   4.288 ( 3.809)  Acc@1:   2.500 ( 14.085)  Acc@5:  15.000 ( 36.622)
Test: [3100/3167]  Time: 0.185 (0.193)  Loss:   4.175 ( 3.815)  Acc@1:   0.000 ( 13.889)  Acc@5:   7.500 ( 36.281)
Test: [3150/3167]  Time: 0.187 (0.193)  Loss:   4.185 ( 3.820)  Acc@1:   0.000 ( 13.681)  Acc@5:  17.500 ( 35.941)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   4.014 ( 3.822)  Acc@1:   0.000 ( 13.624)  Acc@5:  11.111 ( 35.867)
Test: [   0/124]  Time: 0.686 (0.686)  Loss:   4.309 ( 4.309)  Acc@1:   2.500 (  2.500)  Acc@5:  20.000 ( 20.000)
Test: [  50/124]  Time: 0.186 (0.200)  Loss:   3.905 ( 3.862)  Acc@1:   7.500 ( 13.186)  Acc@5:  27.500 ( 34.216)
Test: [ 100/124]  Time: 0.185 (0.194)  Loss:   2.595 ( 3.844)  Acc@1:  67.500 ( 13.787)  Acc@5:  80.000 ( 35.545)
Test: [ 124/124]  Time: 0.180 (0.193)  Loss:   4.079 ( 3.873)  Acc@1:   0.000 ( 12.280)  Acc@5:  32.500 ( 33.860)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_3/checkpoint-2.pth.tar', 13.62391367837776)

Train: 3 [   0/3167 (  0%)]  Loss: 4.42 (4.42)  Time: 1.137s,   35.18/s  (1.137s,   35.18/s)  LR: 3.700e-05  Data: 0.518 (0.518)
Train: 3 [  50/3167 (  2%)]  Loss: 4.31 (4.25)  Time: 0.604s,   66.26/s  (0.613s,   65.28/s)  LR: 3.700e-05  Data: 0.012 (0.020)
Train: 3 [ 100/3167 (  3%)]  Loss: 4.21 (4.22)  Time: 0.604s,   66.23/s  (0.608s,   65.83/s)  LR: 3.700e-05  Data: 0.012 (0.015)
Train: 3 [ 150/3167 (  5%)]  Loss: 4.16 (4.24)  Time: 0.593s,   67.46/s  (0.606s,   66.04/s)  LR: 3.700e-05  Data: 0.004 (0.013)
Train: 3 [ 200/3167 (  6%)]  Loss: 4.15 (4.24)  Time: 0.611s,   65.44/s  (0.605s,   66.13/s)  LR: 3.700e-05  Data: 0.012 (0.012)
Train: 3 [ 250/3167 (  8%)]  Loss: 4.37 (4.25)  Time: 0.604s,   66.27/s  (0.604s,   66.17/s)  LR: 3.700e-05  Data: 0.012 (0.012)
Train: 3 [ 300/3167 (  9%)]  Loss: 4.17 (4.24)  Time: 0.610s,   65.61/s  (0.604s,   66.23/s)  LR: 3.700e-05  Data: 0.011 (0.011)
Train: 3 [ 350/3167 ( 11%)]  Loss: 4.13 (4.24)  Time: 0.593s,   67.43/s  (0.604s,   66.26/s)  LR: 3.700e-05  Data: 0.004 (0.011)
Train: 3 [ 400/3167 ( 13%)]  Loss: 4.30 (4.24)  Time: 0.603s,   66.30/s  (0.603s,   66.29/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [ 450/3167 ( 14%)]  Loss: 4.35 (4.24)  Time: 0.604s,   66.17/s  (0.603s,   66.32/s)  LR: 3.700e-05  Data: 0.007 (0.011)
Train: 3 [ 500/3167 ( 16%)]  Loss: 3.99 (4.24)  Time: 0.604s,   66.28/s  (0.603s,   66.35/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [ 550/3167 ( 17%)]  Loss: 4.28 (4.24)  Time: 0.605s,   66.15/s  (0.603s,   66.36/s)  LR: 3.700e-05  Data: 0.009 (0.011)
Train: 3 [ 600/3167 ( 19%)]  Loss: 3.87 (4.24)  Time: 0.603s,   66.28/s  (0.603s,   66.37/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [ 650/3167 ( 21%)]  Loss: 4.03 (4.24)  Time: 0.610s,   65.61/s  (0.603s,   66.38/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [ 700/3167 ( 22%)]  Loss: 4.09 (4.24)  Time: 0.604s,   66.28/s  (0.603s,   66.39/s)  LR: 3.700e-05  Data: 0.011 (0.010)
Train: 3 [ 750/3167 ( 24%)]  Loss: 4.26 (4.24)  Time: 0.598s,   66.91/s  (0.602s,   66.40/s)  LR: 3.700e-05  Data: 0.004 (0.010)
Train: 3 [ 800/3167 ( 25%)]  Loss: 3.91 (4.24)  Time: 0.603s,   66.35/s  (0.602s,   66.41/s)  LR: 3.700e-05  Data: 0.004 (0.010)
Train: 3 [ 850/3167 ( 27%)]  Loss: 4.50 (4.23)  Time: 0.604s,   66.26/s  (0.602s,   66.42/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [ 900/3167 ( 28%)]  Loss: 4.01 (4.23)  Time: 0.601s,   66.54/s  (0.602s,   66.43/s)  LR: 3.700e-05  Data: 0.004 (0.010)
Train: 3 [ 950/3167 ( 30%)]  Loss: 4.23 (4.23)  Time: 0.604s,   66.27/s  (0.602s,   66.44/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1000/3167 ( 32%)]  Loss: 4.00 (4.23)  Time: 0.598s,   66.89/s  (0.602s,   66.44/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [1050/3167 ( 33%)]  Loss: 4.31 (4.23)  Time: 0.601s,   66.60/s  (0.602s,   66.45/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1100/3167 ( 35%)]  Loss: 4.32 (4.23)  Time: 0.593s,   67.47/s  (0.602s,   66.46/s)  LR: 3.700e-05  Data: 0.004 (0.010)
Train: 3 [1150/3167 ( 36%)]  Loss: 4.25 (4.23)  Time: 0.595s,   67.18/s  (0.602s,   66.46/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [1200/3167 ( 38%)]  Loss: 4.19 (4.23)  Time: 0.596s,   67.16/s  (0.602s,   66.47/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [1250/3167 ( 39%)]  Loss: 4.25 (4.23)  Time: 0.609s,   65.65/s  (0.602s,   66.47/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1300/3167 ( 41%)]  Loss: 4.34 (4.23)  Time: 0.596s,   67.10/s  (0.602s,   66.48/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [1350/3167 ( 43%)]  Loss: 4.27 (4.23)  Time: 0.596s,   67.15/s  (0.602s,   66.49/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [1400/3167 ( 44%)]  Loss: 4.25 (4.23)  Time: 0.604s,   66.24/s  (0.602s,   66.49/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1450/3167 ( 46%)]  Loss: 4.40 (4.23)  Time: 0.600s,   66.63/s  (0.602s,   66.50/s)  LR: 3.700e-05  Data: 0.011 (0.010)
Train: 3 [1500/3167 ( 47%)]  Loss: 3.84 (4.22)  Time: 0.598s,   66.86/s  (0.601s,   66.51/s)  LR: 3.700e-05  Data: 0.009 (0.010)
Train: 3 [1550/3167 ( 49%)]  Loss: 4.28 (4.22)  Time: 0.596s,   67.14/s  (0.601s,   66.51/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [1600/3167 ( 51%)]  Loss: 3.92 (4.22)  Time: 0.609s,   65.72/s  (0.601s,   66.52/s)  LR: 3.700e-05  Data: 0.015 (0.010)
Train: 3 [1650/3167 ( 52%)]  Loss: 4.09 (4.22)  Time: 0.597s,   67.02/s  (0.601s,   66.52/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [1700/3167 ( 54%)]  Loss: 4.28 (4.22)  Time: 0.596s,   67.14/s  (0.601s,   66.53/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [1750/3167 ( 55%)]  Loss: 3.97 (4.22)  Time: 0.596s,   67.12/s  (0.601s,   66.54/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [1800/3167 ( 57%)]  Loss: 4.20 (4.22)  Time: 0.600s,   66.62/s  (0.601s,   66.55/s)  LR: 3.700e-05  Data: 0.011 (0.009)
Train: 3 [1850/3167 ( 58%)]  Loss: 3.98 (4.22)  Time: 0.600s,   66.63/s  (0.601s,   66.56/s)  LR: 3.700e-05  Data: 0.011 (0.009)
Train: 3 [1900/3167 ( 60%)]  Loss: 4.45 (4.22)  Time: 0.596s,   67.11/s  (0.601s,   66.57/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [1950/3167 ( 62%)]  Loss: 4.36 (4.22)  Time: 0.596s,   67.12/s  (0.601s,   66.57/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [2000/3167 ( 63%)]  Loss: 4.15 (4.22)  Time: 0.608s,   65.79/s  (0.601s,   66.58/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [2050/3167 ( 65%)]  Loss: 4.25 (4.22)  Time: 0.601s,   66.61/s  (0.601s,   66.58/s)  LR: 3.700e-05  Data: 0.011 (0.009)
Train: 3 [2100/3167 ( 66%)]  Loss: 4.22 (4.21)  Time: 0.596s,   67.13/s  (0.601s,   66.59/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [2150/3167 ( 68%)]  Loss: 4.17 (4.21)  Time: 0.596s,   67.15/s  (0.601s,   66.60/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [2200/3167 ( 69%)]  Loss: 4.37 (4.21)  Time: 0.599s,   66.80/s  (0.601s,   66.61/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [2250/3167 ( 71%)]  Loss: 4.41 (4.21)  Time: 0.602s,   66.45/s  (0.600s,   66.62/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [2300/3167 ( 73%)]  Loss: 3.92 (4.21)  Time: 0.593s,   67.41/s  (0.600s,   66.63/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [2350/3167 ( 74%)]  Loss: 4.46 (4.21)  Time: 0.596s,   67.08/s  (0.600s,   66.63/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [2400/3167 ( 76%)]  Loss: 4.22 (4.21)  Time: 0.602s,   66.46/s  (0.600s,   66.64/s)  LR: 3.700e-05  Data: 0.012 (0.009)
Train: 3 [2450/3167 ( 77%)]  Loss: 4.40 (4.21)  Time: 0.593s,   67.43/s  (0.600s,   66.65/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [2500/3167 ( 79%)]  Loss: 4.27 (4.21)  Time: 0.593s,   67.41/s  (0.600s,   66.66/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [2550/3167 ( 81%)]  Loss: 4.34 (4.21)  Time: 0.596s,   67.15/s  (0.600s,   66.67/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [2600/3167 ( 82%)]  Loss: 3.84 (4.21)  Time: 0.609s,   65.66/s  (0.600s,   66.67/s)  LR: 3.700e-05  Data: 0.020 (0.009)
Train: 3 [2650/3167 ( 84%)]  Loss: 3.93 (4.21)  Time: 0.598s,   66.85/s  (0.600s,   66.68/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [2700/3167 ( 85%)]  Loss: 4.56 (4.21)  Time: 0.598s,   66.92/s  (0.600s,   66.69/s)  LR: 3.700e-05  Data: 0.006 (0.008)
Train: 3 [2750/3167 ( 87%)]  Loss: 4.09 (4.20)  Time: 0.593s,   67.42/s  (0.600s,   66.69/s)  LR: 3.700e-05  Data: 0.004 (0.008)
Train: 3 [2800/3167 ( 88%)]  Loss: 3.83 (4.20)  Time: 0.593s,   67.42/s  (0.600s,   66.70/s)  LR: 3.700e-05  Data: 0.004 (0.008)
Train: 3 [2850/3167 ( 90%)]  Loss: 4.31 (4.20)  Time: 0.593s,   67.46/s  (0.600s,   66.71/s)  LR: 3.700e-05  Data: 0.004 (0.008)
Train: 3 [2900/3167 ( 92%)]  Loss: 3.84 (4.20)  Time: 0.593s,   67.44/s  (0.600s,   66.72/s)  LR: 3.700e-05  Data: 0.004 (0.008)
Train: 3 [2950/3167 ( 93%)]  Loss: 4.08 (4.20)  Time: 0.601s,   66.59/s  (0.600s,   66.72/s)  LR: 3.700e-05  Data: 0.010 (0.008)
Train: 3 [3000/3167 ( 95%)]  Loss: 4.15 (4.20)  Time: 0.598s,   66.84/s  (0.599s,   66.73/s)  LR: 3.700e-05  Data: 0.004 (0.008)
Train: 3 [3050/3167 ( 96%)]  Loss: 3.89 (4.20)  Time: 0.597s,   66.95/s  (0.599s,   66.73/s)  LR: 3.700e-05  Data: 0.004 (0.008)
Train: 3 [3100/3167 ( 98%)]  Loss: 4.16 (4.20)  Time: 0.593s,   67.44/s  (0.599s,   66.73/s)  LR: 3.700e-05  Data: 0.004 (0.008)
Train: 3 [3150/3167 ( 99%)]  Loss: 4.00 (4.20)  Time: 0.593s,   67.45/s  (0.599s,   66.74/s)  LR: 3.700e-05  Data: 0.004 (0.008)
Test: [   0/3167]  Time: 0.503 (0.503)  Loss:   4.076 ( 4.076)  Acc@1:  10.000 ( 10.000)  Acc@5:  30.000 ( 30.000)
Test: [  50/3167]  Time: 0.191 (0.200)  Loss:   3.883 ( 3.903)  Acc@1:  25.000 (  9.559)  Acc@5:  45.000 ( 36.422)
Test: [ 100/3167]  Time: 0.199 (0.197)  Loss:   3.982 ( 3.897)  Acc@1:   2.500 (  6.832)  Acc@5:  22.500 ( 33.218)
Test: [ 150/3167]  Time: 0.190 (0.196)  Loss:   2.515 ( 3.742)  Acc@1:  52.500 ( 12.632)  Acc@5:  80.000 ( 38.659)
Test: [ 200/3167]  Time: 0.189 (0.195)  Loss:   4.259 ( 3.761)  Acc@1:   0.000 ( 12.562)  Acc@5:   7.500 ( 36.443)
Test: [ 250/3167]  Time: 0.190 (0.195)  Loss:   3.040 ( 3.739)  Acc@1:  35.000 ( 14.054)  Acc@5:  50.000 ( 35.299)
Test: [ 300/3167]  Time: 0.191 (0.195)  Loss:   3.764 ( 3.743)  Acc@1:   0.000 ( 13.522)  Acc@5:  37.500 ( 35.855)
Test: [ 350/3167]  Time: 0.190 (0.194)  Loss:   3.044 ( 3.691)  Acc@1:  25.000 ( 13.519)  Acc@5:  70.000 ( 38.312)
Test: [ 400/3167]  Time: 0.191 (0.194)  Loss:   3.132 ( 3.523)  Acc@1:  25.000 ( 18.709)  Acc@5:  70.000 ( 43.186)
Test: [ 450/3167]  Time: 0.192 (0.194)  Loss:   3.927 ( 3.555)  Acc@1:   0.000 ( 17.622)  Acc@5:  17.500 ( 42.134)
Test: [ 500/3167]  Time: 0.191 (0.194)  Loss:   3.789 ( 3.606)  Acc@1:  22.500 ( 16.801)  Acc@5:  32.500 ( 40.559)
Test: [ 550/3167]  Time: 0.198 (0.194)  Loss:   4.014 ( 3.554)  Acc@1:  12.500 ( 18.961)  Acc@5:  20.000 ( 42.264)
Test: [ 600/3167]  Time: 0.195 (0.194)  Loss:   2.904 ( 3.559)  Acc@1:  12.500 ( 18.045)  Acc@5:  67.500 ( 42.176)
Test: [ 650/3167]  Time: 0.191 (0.194)  Loss:   3.824 ( 3.511)  Acc@1:  20.000 ( 19.647)  Acc@5:  45.000 ( 43.829)
Test: [ 700/3167]  Time: 0.184 (0.194)  Loss:   3.333 ( 3.512)  Acc@1:  12.500 ( 19.593)  Acc@5:  62.500 ( 44.861)
Test: [ 750/3167]  Time: 0.194 (0.194)  Loss:   3.589 ( 3.502)  Acc@1:  32.500 ( 19.281)  Acc@5:  45.000 ( 45.276)
Test: [ 800/3167]  Time: 0.195 (0.194)  Loss:   4.393 ( 3.526)  Acc@1:   0.000 ( 18.880)  Acc@5:   7.500 ( 44.354)
Test: [ 850/3167]  Time: 0.192 (0.194)  Loss:   3.733 ( 3.552)  Acc@1:   2.500 ( 18.146)  Acc@5:  22.500 ( 43.461)
Test: [ 900/3167]  Time: 0.203 (0.194)  Loss:   4.242 ( 3.586)  Acc@1:   5.000 ( 17.267)  Acc@5:  15.000 ( 42.109)
Test: [ 950/3167]  Time: 0.191 (0.194)  Loss:   3.064 ( 3.599)  Acc@1:  25.000 ( 16.882)  Acc@5:  65.000 ( 41.740)
Test: [1000/3167]  Time: 0.189 (0.194)  Loss:   3.438 ( 3.605)  Acc@1:  12.500 ( 16.528)  Acc@5:  57.500 ( 41.596)
Test: [1050/3167]  Time: 0.196 (0.194)  Loss:   3.421 ( 3.590)  Acc@1:  15.000 ( 16.637)  Acc@5:  47.500 ( 42.498)
Test: [1100/3167]  Time: 0.192 (0.194)  Loss:   3.874 ( 3.583)  Acc@1:  12.500 ( 16.574)  Acc@5:  37.500 ( 43.136)
Test: [1150/3167]  Time: 0.187 (0.194)  Loss:   3.044 ( 3.574)  Acc@1:  45.000 ( 17.305)  Acc@5:  80.000 ( 43.831)
Test: [1200/3167]  Time: 0.207 (0.194)  Loss:   2.797 ( 3.547)  Acc@1:  52.500 ( 18.170)  Acc@5:  75.000 ( 45.062)
Test: [1250/3167]  Time: 0.205 (0.194)  Loss:   3.216 ( 3.535)  Acc@1:  37.500 ( 18.893)  Acc@5:  65.000 ( 45.731)
Test: [1300/3167]  Time: 0.184 (0.194)  Loss:   3.495 ( 3.547)  Acc@1:  12.500 ( 18.432)  Acc@5:  45.000 ( 45.163)
Test: [1350/3167]  Time: 0.194 (0.194)  Loss:   4.019 ( 3.571)  Acc@1:   7.500 ( 18.007)  Acc@5:  35.000 ( 44.258)
Test: [1400/3167]  Time: 0.205 (0.194)  Loss:   3.639 ( 3.597)  Acc@1:  17.500 ( 17.573)  Acc@5:  50.000 ( 43.419)
Test: [1450/3167]  Time: 0.194 (0.194)  Loss:   3.682 ( 3.596)  Acc@1:   7.500 ( 17.636)  Acc@5:  40.000 ( 43.663)
Test: [1500/3167]  Time: 0.191 (0.194)  Loss:   3.415 ( 3.567)  Acc@1:  15.000 ( 18.619)  Acc@5:  55.000 ( 44.537)
Test: [1550/3167]  Time: 0.184 (0.194)  Loss:   2.514 ( 3.550)  Acc@1:  67.500 ( 19.320)  Acc@5:  85.000 ( 45.327)
Test: [1600/3167]  Time: 0.189 (0.194)  Loss:   2.585 ( 3.538)  Acc@1:  50.000 ( 19.805)  Acc@5:  72.500 ( 45.889)
Test: [1650/3167]  Time: 0.191 (0.194)  Loss:   3.346 ( 3.519)  Acc@1:  25.000 ( 20.415)  Acc@5:  60.000 ( 46.481)
Test: [1700/3167]  Time: 0.202 (0.194)  Loss:   4.199 ( 3.511)  Acc@1:   2.500 ( 20.654)  Acc@5:  20.000 ( 46.909)
Test: [1750/3167]  Time: 0.187 (0.194)  Loss:   3.584 ( 3.521)  Acc@1:  10.000 ( 20.341)  Acc@5:  37.500 ( 46.529)
Test: [1800/3167]  Time: 0.189 (0.194)  Loss:   3.355 ( 3.527)  Acc@1:  12.500 ( 20.068)  Acc@5:  45.000 ( 46.295)
Test: [1850/3167]  Time: 0.184 (0.194)  Loss:   4.175 ( 3.540)  Acc@1:  12.500 ( 19.575)  Acc@5:  20.000 ( 45.511)
Test: [1900/3167]  Time: 0.196 (0.194)  Loss:   3.901 ( 3.549)  Acc@1:   0.000 ( 19.316)  Acc@5:  30.000 ( 45.293)
Test: [1950/3167]  Time: 0.185 (0.194)  Loss:   4.595 ( 3.556)  Acc@1:   0.000 ( 19.204)  Acc@5:  10.000 ( 45.110)
Test: [2000/3167]  Time: 0.186 (0.193)  Loss:   3.900 ( 3.575)  Acc@1:   5.000 ( 18.759)  Acc@5:  35.000 ( 44.324)
Test: [2050/3167]  Time: 0.184 (0.193)  Loss:   4.120 ( 3.584)  Acc@1:   0.000 ( 18.461)  Acc@5:  25.000 ( 43.909)
Test: [2100/3167]  Time: 0.189 (0.193)  Loss:   3.805 ( 3.594)  Acc@1:   7.500 ( 18.277)  Acc@5:  27.500 ( 43.598)
Test: [2150/3167]  Time: 0.198 (0.193)  Loss:   2.019 ( 3.575)  Acc@1:  65.000 ( 18.763)  Acc@5:  80.000 ( 43.985)
Test: [2200/3167]  Time: 0.186 (0.193)  Loss:   3.288 ( 3.564)  Acc@1:   5.000 ( 18.835)  Acc@5:  57.500 ( 44.283)
Test: [2250/3167]  Time: 0.192 (0.193)  Loss:   3.712 ( 3.568)  Acc@1:  20.000 ( 18.555)  Acc@5:  52.500 ( 44.183)
Test: [2300/3167]  Time: 0.193 (0.193)  Loss:   4.160 ( 3.580)  Acc@1:   0.000 ( 18.289)  Acc@5:  12.500 ( 43.699)
Test: [2350/3167]  Time: 0.191 (0.193)  Loss:   3.996 ( 3.589)  Acc@1:   5.000 ( 17.950)  Acc@5:  42.500 ( 43.148)
Test: [2400/3167]  Time: 0.184 (0.193)  Loss:   4.348 ( 3.590)  Acc@1:   0.000 ( 18.040)  Acc@5:   7.500 ( 43.117)
Test: [2450/3167]  Time: 0.190 (0.193)  Loss:   2.769 ( 3.586)  Acc@1:  35.000 ( 18.155)  Acc@5:  82.500 ( 43.337)
Test: [2500/3167]  Time: 0.190 (0.193)  Loss:   4.246 ( 3.589)  Acc@1:  10.000 ( 18.145)  Acc@5:  20.000 ( 43.313)
Test: [2550/3167]  Time: 0.192 (0.193)  Loss:   4.123 ( 3.578)  Acc@1:   5.000 ( 18.636)  Acc@5:  22.500 ( 43.706)
Test: [2600/3167]  Time: 0.191 (0.193)  Loss:   3.299 ( 3.585)  Acc@1:  27.500 ( 18.482)  Acc@5:  55.000 ( 43.380)
Test: [2650/3167]  Time: 0.189 (0.193)  Loss:   4.110 ( 3.594)  Acc@1:   0.000 ( 18.287)  Acc@5:  12.500 ( 43.089)
Test: [2700/3167]  Time: 0.186 (0.193)  Loss:   3.262 ( 3.597)  Acc@1:  27.500 ( 18.150)  Acc@5:  52.500 ( 42.861)
Test: [2750/3167]  Time: 0.191 (0.193)  Loss:   2.846 ( 3.601)  Acc@1:  30.000 ( 18.070)  Acc@5:  77.500 ( 42.736)
Test: [2800/3167]  Time: 0.185 (0.193)  Loss:   4.293 ( 3.600)  Acc@1:   0.000 ( 18.019)  Acc@5:   5.000 ( 42.792)
Test: [2850/3167]  Time: 0.197 (0.193)  Loss:   3.913 ( 3.607)  Acc@1:  12.500 ( 17.822)  Acc@5:  40.000 ( 42.512)
Test: [2900/3167]  Time: 0.184 (0.193)  Loss:   3.800 ( 3.609)  Acc@1:  10.000 ( 17.801)  Acc@5:  40.000 ( 42.544)
Test: [2950/3167]  Time: 0.186 (0.193)  Loss:   3.940 ( 3.614)  Acc@1:   0.000 ( 17.562)  Acc@5:  15.000 ( 42.199)
Test: [3000/3167]  Time: 0.200 (0.193)  Loss:   4.097 ( 3.622)  Acc@1:   0.000 ( 17.278)  Acc@5:  15.000 ( 41.723)
Test: [3050/3167]  Time: 0.184 (0.193)  Loss:   4.305 ( 3.625)  Acc@1:   0.000 ( 17.114)  Acc@5:   5.000 ( 41.553)
Test: [3100/3167]  Time: 0.184 (0.193)  Loss:   4.130 ( 3.634)  Acc@1:   0.000 ( 16.873)  Acc@5:  17.500 ( 41.163)
Test: [3150/3167]  Time: 0.186 (0.193)  Loss:   4.131 ( 3.637)  Acc@1:   0.000 ( 16.723)  Acc@5:  20.000 ( 41.089)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   3.855 ( 3.639)  Acc@1:   0.000 ( 16.654)  Acc@5:  33.333 ( 40.995)
Test: [   0/124]  Time: 0.755 (0.755)  Loss:   4.169 ( 4.169)  Acc@1:   0.000 (  0.000)  Acc@5:  15.000 ( 15.000)
Test: [  50/124]  Time: 0.190 (0.202)  Loss:   3.819 ( 3.598)  Acc@1:  15.000 ( 16.765)  Acc@5:  32.500 ( 43.627)
Test: [ 100/124]  Time: 0.187 (0.196)  Loss:   2.424 ( 3.642)  Acc@1:  62.500 ( 16.980)  Acc@5:  87.500 ( 41.609)
Test: [ 124/124]  Time: 0.180 (0.194)  Loss:   4.066 ( 3.697)  Acc@1:   2.500 ( 15.340)  Acc@5:  32.500 ( 39.200)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_3/checkpoint-3.pth.tar', 16.65416887022551)

Train: 4 [   0/3167 (  0%)]  Loss: 3.98 (3.98)  Time: 1.106s,   36.16/s  (1.106s,   36.16/s)  LR: 4.600e-05  Data: 0.493 (0.493)
Train: 4 [  50/3167 (  2%)]  Loss: 3.83 (4.15)  Time: 0.600s,   66.61/s  (0.612s,   65.31/s)  LR: 4.600e-05  Data: 0.011 (0.020)
Train: 4 [ 100/3167 (  3%)]  Loss: 4.45 (4.19)  Time: 0.606s,   65.97/s  (0.607s,   65.89/s)  LR: 4.600e-05  Data: 0.012 (0.015)
Train: 4 [ 150/3167 (  5%)]  Loss: 4.22 (4.18)  Time: 0.605s,   66.16/s  (0.605s,   66.10/s)  LR: 4.600e-05  Data: 0.012 (0.013)
Train: 4 [ 200/3167 (  6%)]  Loss: 4.04 (4.19)  Time: 0.593s,   67.47/s  (0.604s,   66.20/s)  LR: 4.600e-05  Data: 0.004 (0.012)
Train: 4 [ 250/3167 (  8%)]  Loss: 4.28 (4.18)  Time: 0.604s,   66.23/s  (0.604s,   66.25/s)  LR: 4.600e-05  Data: 0.007 (0.012)
Train: 4 [ 300/3167 (  9%)]  Loss: 4.31 (4.17)  Time: 0.603s,   66.35/s  (0.603s,   66.29/s)  LR: 4.600e-05  Data: 0.011 (0.011)
Train: 4 [ 350/3167 ( 11%)]  Loss: 4.03 (4.17)  Time: 0.605s,   66.07/s  (0.603s,   66.32/s)  LR: 4.600e-05  Data: 0.007 (0.011)
Train: 4 [ 400/3167 ( 13%)]  Loss: 4.11 (4.17)  Time: 0.603s,   66.31/s  (0.603s,   66.34/s)  LR: 4.600e-05  Data: 0.012 (0.011)
Train: 4 [ 450/3167 ( 14%)]  Loss: 4.24 (4.17)  Time: 0.602s,   66.50/s  (0.603s,   66.37/s)  LR: 4.600e-05  Data: 0.009 (0.011)
Train: 4 [ 500/3167 ( 16%)]  Loss: 4.33 (4.16)  Time: 0.600s,   66.69/s  (0.603s,   66.38/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [ 550/3167 ( 17%)]  Loss: 4.34 (4.17)  Time: 0.600s,   66.65/s  (0.602s,   66.40/s)  LR: 4.600e-05  Data: 0.011 (0.010)
Train: 4 [ 600/3167 ( 19%)]  Loss: 4.18 (4.16)  Time: 0.595s,   67.17/s  (0.602s,   66.40/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [ 650/3167 ( 21%)]  Loss: 4.06 (4.16)  Time: 0.601s,   66.58/s  (0.602s,   66.42/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [ 700/3167 ( 22%)]  Loss: 4.21 (4.17)  Time: 0.600s,   66.62/s  (0.602s,   66.43/s)  LR: 4.600e-05  Data: 0.011 (0.010)
Train: 4 [ 750/3167 ( 24%)]  Loss: 4.13 (4.16)  Time: 0.601s,   66.59/s  (0.602s,   66.44/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [ 800/3167 ( 25%)]  Loss: 4.05 (4.16)  Time: 0.598s,   66.88/s  (0.602s,   66.46/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [ 850/3167 ( 27%)]  Loss: 4.36 (4.16)  Time: 0.593s,   67.46/s  (0.602s,   66.46/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [ 900/3167 ( 28%)]  Loss: 3.87 (4.16)  Time: 0.603s,   66.34/s  (0.602s,   66.47/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [ 950/3167 ( 30%)]  Loss: 4.34 (4.15)  Time: 0.598s,   66.90/s  (0.602s,   66.47/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [1000/3167 ( 32%)]  Loss: 3.99 (4.15)  Time: 0.600s,   66.63/s  (0.602s,   66.48/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [1050/3167 ( 33%)]  Loss: 4.27 (4.15)  Time: 0.597s,   67.05/s  (0.602s,   66.49/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [1100/3167 ( 35%)]  Loss: 4.23 (4.15)  Time: 0.609s,   65.70/s  (0.602s,   66.49/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1150/3167 ( 36%)]  Loss: 3.67 (4.15)  Time: 0.596s,   67.17/s  (0.602s,   66.49/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [1200/3167 ( 38%)]  Loss: 3.94 (4.15)  Time: 0.595s,   67.18/s  (0.602s,   66.50/s)  LR: 4.600e-05  Data: 0.006 (0.010)
Train: 4 [1250/3167 ( 39%)]  Loss: 3.86 (4.14)  Time: 0.603s,   66.38/s  (0.601s,   66.50/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [1300/3167 ( 41%)]  Loss: 4.46 (4.14)  Time: 0.597s,   67.03/s  (0.601s,   66.51/s)  LR: 4.600e-05  Data: 0.006 (0.010)
Train: 4 [1350/3167 ( 43%)]  Loss: 3.99 (4.14)  Time: 0.598s,   66.91/s  (0.601s,   66.51/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [1400/3167 ( 44%)]  Loss: 4.28 (4.14)  Time: 0.593s,   67.45/s  (0.601s,   66.52/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [1450/3167 ( 46%)]  Loss: 4.22 (4.14)  Time: 0.597s,   67.04/s  (0.601s,   66.53/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [1500/3167 ( 47%)]  Loss: 4.15 (4.14)  Time: 0.596s,   67.17/s  (0.601s,   66.53/s)  LR: 4.600e-05  Data: 0.006 (0.010)
Train: 4 [1550/3167 ( 49%)]  Loss: 4.31 (4.14)  Time: 0.601s,   66.59/s  (0.601s,   66.54/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1600/3167 ( 51%)]  Loss: 3.89 (4.14)  Time: 0.598s,   66.93/s  (0.601s,   66.55/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [1650/3167 ( 52%)]  Loss: 4.32 (4.14)  Time: 0.600s,   66.62/s  (0.601s,   66.55/s)  LR: 4.600e-05  Data: 0.011 (0.009)
Train: 4 [1700/3167 ( 54%)]  Loss: 4.12 (4.14)  Time: 0.601s,   66.57/s  (0.601s,   66.56/s)  LR: 4.600e-05  Data: 0.010 (0.009)
Train: 4 [1750/3167 ( 55%)]  Loss: 4.14 (4.14)  Time: 0.593s,   67.45/s  (0.601s,   66.56/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [1800/3167 ( 57%)]  Loss: 4.15 (4.14)  Time: 0.593s,   67.45/s  (0.601s,   66.57/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [1850/3167 ( 58%)]  Loss: 4.20 (4.14)  Time: 0.605s,   66.13/s  (0.601s,   66.58/s)  LR: 4.600e-05  Data: 0.011 (0.009)
Train: 4 [1900/3167 ( 60%)]  Loss: 4.22 (4.14)  Time: 0.598s,   66.85/s  (0.601s,   66.58/s)  LR: 4.600e-05  Data: 0.009 (0.009)
Train: 4 [1950/3167 ( 62%)]  Loss: 3.87 (4.14)  Time: 0.599s,   66.80/s  (0.601s,   66.59/s)  LR: 4.600e-05  Data: 0.010 (0.009)
Train: 4 [2000/3167 ( 63%)]  Loss: 4.17 (4.14)  Time: 0.600s,   66.63/s  (0.601s,   66.60/s)  LR: 4.600e-05  Data: 0.011 (0.009)
Train: 4 [2050/3167 ( 65%)]  Loss: 3.99 (4.14)  Time: 0.598s,   66.84/s  (0.601s,   66.61/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2100/3167 ( 66%)]  Loss: 3.94 (4.14)  Time: 0.599s,   66.80/s  (0.600s,   66.61/s)  LR: 4.600e-05  Data: 0.009 (0.009)
Train: 4 [2150/3167 ( 68%)]  Loss: 4.02 (4.14)  Time: 0.596s,   67.08/s  (0.600s,   66.62/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Train: 4 [2200/3167 ( 69%)]  Loss: 4.01 (4.14)  Time: 0.599s,   66.82/s  (0.600s,   66.63/s)  LR: 4.600e-05  Data: 0.009 (0.009)
Train: 4 [2250/3167 ( 71%)]  Loss: 4.27 (4.14)  Time: 0.593s,   67.44/s  (0.600s,   66.63/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2300/3167 ( 73%)]  Loss: 4.18 (4.14)  Time: 0.598s,   66.90/s  (0.600s,   66.64/s)  LR: 4.600e-05  Data: 0.009 (0.009)
Train: 4 [2350/3167 ( 74%)]  Loss: 4.50 (4.14)  Time: 0.603s,   66.29/s  (0.600s,   66.65/s)  LR: 4.600e-05  Data: 0.012 (0.009)
Train: 4 [2400/3167 ( 76%)]  Loss: 4.18 (4.13)  Time: 0.602s,   66.44/s  (0.600s,   66.66/s)  LR: 4.600e-05  Data: 0.013 (0.009)
Train: 4 [2450/3167 ( 77%)]  Loss: 3.57 (4.13)  Time: 0.596s,   67.12/s  (0.600s,   66.66/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Train: 4 [2500/3167 ( 79%)]  Loss: 4.14 (4.13)  Time: 0.601s,   66.58/s  (0.600s,   66.67/s)  LR: 4.600e-05  Data: 0.009 (0.009)
Train: 4 [2550/3167 ( 81%)]  Loss: 4.22 (4.13)  Time: 0.594s,   67.39/s  (0.600s,   66.68/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2600/3167 ( 82%)]  Loss: 3.90 (4.13)  Time: 0.595s,   67.24/s  (0.600s,   66.68/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2650/3167 ( 84%)]  Loss: 4.42 (4.13)  Time: 0.596s,   67.09/s  (0.600s,   66.69/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Train: 4 [2700/3167 ( 85%)]  Loss: 4.32 (4.13)  Time: 0.606s,   66.04/s  (0.600s,   66.69/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2750/3167 ( 87%)]  Loss: 4.40 (4.13)  Time: 0.593s,   67.45/s  (0.600s,   66.70/s)  LR: 4.600e-05  Data: 0.004 (0.008)
Train: 4 [2800/3167 ( 88%)]  Loss: 4.09 (4.13)  Time: 0.598s,   66.86/s  (0.600s,   66.71/s)  LR: 4.600e-05  Data: 0.009 (0.008)
Train: 4 [2850/3167 ( 90%)]  Loss: 4.31 (4.13)  Time: 0.593s,   67.42/s  (0.600s,   66.71/s)  LR: 4.600e-05  Data: 0.004 (0.008)
Train: 4 [2900/3167 ( 92%)]  Loss: 3.94 (4.13)  Time: 0.600s,   66.67/s  (0.600s,   66.72/s)  LR: 4.600e-05  Data: 0.007 (0.008)
Train: 4 [2950/3167 ( 93%)]  Loss: 4.43 (4.13)  Time: 0.596s,   67.15/s  (0.599s,   66.73/s)  LR: 4.600e-05  Data: 0.007 (0.008)
Train: 4 [3000/3167 ( 95%)]  Loss: 4.04 (4.13)  Time: 0.596s,   67.15/s  (0.599s,   66.73/s)  LR: 4.600e-05  Data: 0.007 (0.008)
Train: 4 [3050/3167 ( 96%)]  Loss: 4.28 (4.13)  Time: 0.597s,   66.95/s  (0.599s,   66.74/s)  LR: 4.600e-05  Data: 0.006 (0.008)
Train: 4 [3100/3167 ( 98%)]  Loss: 3.87 (4.13)  Time: 0.599s,   66.82/s  (0.599s,   66.74/s)  LR: 4.600e-05  Data: 0.009 (0.008)
Train: 4 [3150/3167 ( 99%)]  Loss: 4.15 (4.13)  Time: 0.593s,   67.40/s  (0.599s,   66.75/s)  LR: 4.600e-05  Data: 0.004 (0.008)
Test: [   0/3167]  Time: 0.541 (0.541)  Loss:   4.182 ( 4.182)  Acc@1:   5.000 (  5.000)  Acc@5:  17.500 ( 17.500)
Test: [  50/3167]  Time: 0.191 (0.200)  Loss:   3.762 ( 3.886)  Acc@1:  32.500 ( 11.324)  Acc@5:  50.000 ( 34.461)
Test: [ 100/3167]  Time: 0.209 (0.197)  Loss:   3.628 ( 3.652)  Acc@1:   7.500 ( 12.698)  Acc@5:  37.500 ( 44.059)
Test: [ 150/3167]  Time: 0.203 (0.196)  Loss:   2.292 ( 3.481)  Acc@1:  62.500 ( 19.354)  Acc@5:  82.500 ( 49.553)
Test: [ 200/3167]  Time: 0.197 (0.195)  Loss:   4.070 ( 3.543)  Acc@1:   2.500 ( 17.886)  Acc@5:  15.000 ( 43.694)
Test: [ 250/3167]  Time: 0.191 (0.195)  Loss:   2.651 ( 3.522)  Acc@1:  45.000 ( 18.785)  Acc@5:  65.000 ( 42.291)
Test: [ 300/3167]  Time: 0.196 (0.195)  Loss:   3.746 ( 3.528)  Acc@1:   5.000 ( 18.679)  Acc@5:  32.500 ( 42.674)
Test: [ 350/3167]  Time: 0.191 (0.194)  Loss:   2.969 ( 3.508)  Acc@1:  47.500 ( 19.010)  Acc@5:  75.000 ( 44.024)
Test: [ 400/3167]  Time: 0.190 (0.195)  Loss:   3.288 ( 3.404)  Acc@1:  22.500 ( 22.488)  Acc@5:  57.500 ( 47.594)
Test: [ 450/3167]  Time: 0.186 (0.195)  Loss:   3.695 ( 3.439)  Acc@1:   5.000 ( 20.859)  Acc@5:  35.000 ( 46.153)
Test: [ 500/3167]  Time: 0.186 (0.195)  Loss:   3.204 ( 3.460)  Acc@1:  35.000 ( 21.098)  Acc@5:  52.500 ( 45.973)
Test: [ 550/3167]  Time: 0.195 (0.194)  Loss:   3.951 ( 3.416)  Acc@1:   7.500 ( 22.868)  Acc@5:  27.500 ( 47.246)
Test: [ 600/3167]  Time: 0.193 (0.194)  Loss:   3.154 ( 3.440)  Acc@1:  17.500 ( 21.851)  Acc@5:  55.000 ( 46.373)
Test: [ 650/3167]  Time: 0.191 (0.194)  Loss:   3.529 ( 3.411)  Acc@1:  17.500 ( 22.761)  Acc@5:  52.500 ( 47.270)
Test: [ 700/3167]  Time: 0.190 (0.194)  Loss:   3.249 ( 3.408)  Acc@1:  12.500 ( 22.240)  Acc@5:  67.500 ( 48.163)
Test: [ 750/3167]  Time: 0.198 (0.194)  Loss:   3.417 ( 3.397)  Acc@1:  37.500 ( 22.121)  Acc@5:  50.000 ( 48.931)
Test: [ 800/3167]  Time: 0.195 (0.194)  Loss:   4.232 ( 3.413)  Acc@1:   0.000 ( 21.969)  Acc@5:  25.000 ( 48.237)
Test: [ 850/3167]  Time: 0.192 (0.194)  Loss:   4.003 ( 3.441)  Acc@1:   0.000 ( 21.140)  Acc@5:  15.000 ( 47.139)
Test: [ 900/3167]  Time: 0.193 (0.194)  Loss:   3.957 ( 3.479)  Acc@1:   5.000 ( 20.139)  Acc@5:  30.000 ( 45.560)
Test: [ 950/3167]  Time: 0.191 (0.194)  Loss:   3.313 ( 3.489)  Acc@1:  15.000 ( 19.732)  Acc@5:  50.000 ( 45.237)
Test: [1000/3167]  Time: 0.192 (0.194)  Loss:   3.436 ( 3.514)  Acc@1:  17.500 ( 19.098)  Acc@5:  57.500 ( 44.291)
Test: [1050/3167]  Time: 0.200 (0.194)  Loss:   2.896 ( 3.487)  Acc@1:  32.500 ( 19.812)  Acc@5:  80.000 ( 45.573)
Test: [1100/3167]  Time: 0.187 (0.194)  Loss:   3.424 ( 3.488)  Acc@1:  30.000 ( 19.478)  Acc@5:  60.000 ( 45.309)
Test: [1150/3167]  Time: 0.189 (0.194)  Loss:   2.943 ( 3.473)  Acc@1:  55.000 ( 20.387)  Acc@5:  70.000 ( 46.188)
Test: [1200/3167]  Time: 0.192 (0.194)  Loss:   3.244 ( 3.457)  Acc@1:  20.000 ( 20.789)  Acc@5:  55.000 ( 46.971)
Test: [1250/3167]  Time: 0.198 (0.194)  Loss:   2.822 ( 3.441)  Acc@1:  50.000 ( 21.623)  Acc@5:  67.500 ( 47.736)
Test: [1300/3167]  Time: 0.195 (0.194)  Loss:   3.215 ( 3.441)  Acc@1:  25.000 ( 21.362)  Acc@5:  72.500 ( 47.930)
Test: [1350/3167]  Time: 0.200 (0.194)  Loss:   3.817 ( 3.458)  Acc@1:  12.500 ( 21.055)  Acc@5:  45.000 ( 47.365)
Test: [1400/3167]  Time: 0.201 (0.194)  Loss:   3.071 ( 3.479)  Acc@1:  42.500 ( 20.700)  Acc@5:  60.000 ( 46.638)
Test: [1450/3167]  Time: 0.194 (0.194)  Loss:   3.570 ( 3.473)  Acc@1:  12.500 ( 21.075)  Acc@5:  42.500 ( 47.014)
Test: [1500/3167]  Time: 0.186 (0.194)  Loss:   3.369 ( 3.452)  Acc@1:  17.500 ( 21.691)  Acc@5:  52.500 ( 47.708)
Test: [1550/3167]  Time: 0.189 (0.194)  Loss:   2.321 ( 3.436)  Acc@1:  75.000 ( 22.203)  Acc@5:  87.500 ( 48.366)
Test: [1600/3167]  Time: 0.190 (0.194)  Loss:   2.641 ( 3.426)  Acc@1:  55.000 ( 22.495)  Acc@5:  65.000 ( 48.826)
Test: [1650/3167]  Time: 0.202 (0.194)  Loss:   3.218 ( 3.408)  Acc@1:  22.500 ( 23.050)  Acc@5:  52.500 ( 49.328)
Test: [1700/3167]  Time: 0.190 (0.193)  Loss:   4.217 ( 3.408)  Acc@1:   5.000 ( 23.035)  Acc@5:  15.000 ( 49.540)
Test: [1750/3167]  Time: 0.192 (0.193)  Loss:   3.430 ( 3.416)  Acc@1:  22.500 ( 22.748)  Acc@5:  40.000 ( 49.193)
Test: [1800/3167]  Time: 0.195 (0.193)  Loss:   3.388 ( 3.426)  Acc@1:  10.000 ( 22.467)  Acc@5:  47.500 ( 48.863)
Test: [1850/3167]  Time: 0.192 (0.193)  Loss:   3.785 ( 3.436)  Acc@1:  12.500 ( 21.960)  Acc@5:  30.000 ( 48.147)
Test: [1900/3167]  Time: 0.186 (0.193)  Loss:   3.637 ( 3.440)  Acc@1:  10.000 ( 21.739)  Acc@5:  45.000 ( 48.156)
Test: [1950/3167]  Time: 0.191 (0.193)  Loss:   4.620 ( 3.441)  Acc@1:   5.000 ( 21.730)  Acc@5:  17.500 ( 48.178)
Test: [2000/3167]  Time: 0.191 (0.193)  Loss:   4.056 ( 3.463)  Acc@1:   0.000 ( 21.291)  Acc@5:  25.000 ( 47.340)
Test: [2050/3167]  Time: 0.189 (0.193)  Loss:   3.976 ( 3.475)  Acc@1:   0.000 ( 20.897)  Acc@5:  10.000 ( 46.686)
Test: [2100/3167]  Time: 0.184 (0.193)  Loss:   3.212 ( 3.481)  Acc@1:  17.500 ( 20.788)  Acc@5:  65.000 ( 46.540)
Test: [2150/3167]  Time: 0.199 (0.193)  Loss:   1.796 ( 3.456)  Acc@1:  67.500 ( 21.448)  Acc@5:  80.000 ( 47.220)
Test: [2200/3167]  Time: 0.189 (0.193)  Loss:   3.458 ( 3.449)  Acc@1:   7.500 ( 21.348)  Acc@5:  50.000 ( 47.518)
Test: [2250/3167]  Time: 0.191 (0.193)  Loss:   3.573 ( 3.454)  Acc@1:  20.000 ( 21.083)  Acc@5:  55.000 ( 47.353)
Test: [2300/3167]  Time: 0.186 (0.193)  Loss:   3.891 ( 3.464)  Acc@1:   0.000 ( 20.818)  Acc@5:  15.000 ( 46.845)
Test: [2350/3167]  Time: 0.192 (0.193)  Loss:   3.961 ( 3.471)  Acc@1:   7.500 ( 20.462)  Acc@5:  37.500 ( 46.379)
Test: [2400/3167]  Time: 0.189 (0.193)  Loss:   4.104 ( 3.469)  Acc@1:   2.500 ( 20.567)  Acc@5:  27.500 ( 46.483)
Test: [2450/3167]  Time: 0.198 (0.193)  Loss:   2.749 ( 3.466)  Acc@1:  40.000 ( 20.658)  Acc@5:  85.000 ( 46.711)
Test: [2500/3167]  Time: 0.195 (0.193)  Loss:   3.724 ( 3.464)  Acc@1:  25.000 ( 20.728)  Acc@5:  47.500 ( 46.886)
Test: [2550/3167]  Time: 0.185 (0.193)  Loss:   4.141 ( 3.453)  Acc@1:   2.500 ( 21.276)  Acc@5:  12.500 ( 47.321)
Test: [2600/3167]  Time: 0.184 (0.193)  Loss:   3.399 ( 3.462)  Acc@1:  30.000 ( 21.047)  Acc@5:  47.500 ( 46.891)
Test: [2650/3167]  Time: 0.190 (0.193)  Loss:   3.759 ( 3.472)  Acc@1:   5.000 ( 20.862)  Acc@5:  30.000 ( 46.614)
Test: [2700/3167]  Time: 0.189 (0.193)  Loss:   2.962 ( 3.471)  Acc@1:  35.000 ( 20.862)  Acc@5:  65.000 ( 46.616)
Test: [2750/3167]  Time: 0.185 (0.193)  Loss:   2.650 ( 3.476)  Acc@1:  40.000 ( 20.790)  Acc@5:  87.500 ( 46.480)
Test: [2800/3167]  Time: 0.185 (0.193)  Loss:   4.165 ( 3.474)  Acc@1:   0.000 ( 20.837)  Acc@5:  22.500 ( 46.601)
Test: [2850/3167]  Time: 0.197 (0.193)  Loss:   3.935 ( 3.483)  Acc@1:  12.500 ( 20.538)  Acc@5:  35.000 ( 46.193)
Test: [2900/3167]  Time: 0.186 (0.192)  Loss:   3.562 ( 3.486)  Acc@1:  10.000 ( 20.483)  Acc@5:  50.000 ( 46.166)
Test: [2950/3167]  Time: 0.187 (0.192)  Loss:   3.940 ( 3.492)  Acc@1:   0.000 ( 20.224)  Acc@5:  15.000 ( 45.842)
Test: [3000/3167]  Time: 0.201 (0.192)  Loss:   3.867 ( 3.500)  Acc@1:   7.500 ( 19.939)  Acc@5:  35.000 ( 45.468)
Test: [3050/3167]  Time: 0.187 (0.192)  Loss:   4.020 ( 3.497)  Acc@1:   5.000 ( 20.097)  Acc@5:  12.500 ( 45.689)
Test: [3100/3167]  Time: 0.184 (0.192)  Loss:   3.989 ( 3.505)  Acc@1:   2.500 ( 19.829)  Acc@5:  25.000 ( 45.360)
Test: [3150/3167]  Time: 0.188 (0.192)  Loss:   3.597 ( 3.506)  Acc@1:   0.000 ( 19.628)  Acc@5:  45.000 ( 45.429)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   3.317 ( 3.506)  Acc@1:  22.222 ( 19.578)  Acc@5:  66.667 ( 45.425)
Test: [   0/124]  Time: 0.724 (0.724)  Loss:   4.268 ( 4.268)  Acc@1:   0.000 (  0.000)  Acc@5:  15.000 ( 15.000)
Test: [  50/124]  Time: 0.200 (0.201)  Loss:   3.481 ( 3.510)  Acc@1:  27.500 ( 18.529)  Acc@5:  52.500 ( 45.049)
Test: [ 100/124]  Time: 0.184 (0.195)  Loss:   2.620 ( 3.525)  Acc@1:  62.500 ( 18.713)  Acc@5:  75.000 ( 44.109)
Test: [ 124/124]  Time: 0.180 (0.193)  Loss:   3.537 ( 3.570)  Acc@1:  12.500 ( 17.380)  Acc@5:  47.500 ( 42.780)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_3/checkpoint-4.pth.tar', 19.577863903018706)

Train: 5 [   0/3167 (  0%)]  Loss: 4.29 (4.29)  Time: 1.067s,   37.49/s  (1.067s,   37.49/s)  LR: 5.500e-05  Data: 0.464 (0.464)
Train: 5 [  50/3167 (  2%)]  Loss: 4.13 (4.20)  Time: 0.597s,   66.96/s  (0.612s,   65.38/s)  LR: 5.500e-05  Data: 0.006 (0.019)
Train: 5 [ 100/3167 (  3%)]  Loss: 4.50 (4.15)  Time: 0.605s,   66.11/s  (0.607s,   65.87/s)  LR: 5.500e-05  Data: 0.007 (0.014)
Train: 5 [ 150/3167 (  5%)]  Loss: 4.18 (4.13)  Time: 0.593s,   67.48/s  (0.605s,   66.12/s)  LR: 5.500e-05  Data: 0.004 (0.013)
Train: 5 [ 200/3167 (  6%)]  Loss: 4.22 (4.12)  Time: 0.603s,   66.34/s  (0.604s,   66.22/s)  LR: 5.500e-05  Data: 0.012 (0.012)
Train: 5 [ 250/3167 (  8%)]  Loss: 4.49 (4.11)  Time: 0.597s,   67.05/s  (0.604s,   66.27/s)  LR: 5.500e-05  Data: 0.004 (0.011)
Train: 5 [ 300/3167 (  9%)]  Loss: 3.93 (4.11)  Time: 0.598s,   66.88/s  (0.603s,   66.34/s)  LR: 5.500e-05  Data: 0.007 (0.011)
Train: 5 [ 350/3167 ( 11%)]  Loss: 3.95 (4.10)  Time: 0.602s,   66.41/s  (0.603s,   66.36/s)  LR: 5.500e-05  Data: 0.011 (0.011)
Train: 5 [ 400/3167 ( 13%)]  Loss: 4.28 (4.10)  Time: 0.607s,   65.85/s  (0.603s,   66.37/s)  LR: 5.500e-05  Data: 0.011 (0.011)
Train: 5 [ 450/3167 ( 14%)]  Loss: 4.27 (4.10)  Time: 0.600s,   66.64/s  (0.603s,   66.39/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [ 500/3167 ( 16%)]  Loss: 3.33 (4.09)  Time: 0.606s,   66.04/s  (0.602s,   66.40/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [ 550/3167 ( 17%)]  Loss: 4.48 (4.09)  Time: 0.603s,   66.35/s  (0.602s,   66.42/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [ 600/3167 ( 19%)]  Loss: 4.51 (4.10)  Time: 0.603s,   66.36/s  (0.602s,   66.42/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [ 650/3167 ( 21%)]  Loss: 4.01 (4.10)  Time: 0.601s,   66.55/s  (0.602s,   66.42/s)  LR: 5.500e-05  Data: 0.009 (0.010)
Train: 5 [ 700/3167 ( 22%)]  Loss: 4.36 (4.10)  Time: 0.601s,   66.58/s  (0.602s,   66.43/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [ 750/3167 ( 24%)]  Loss: 4.24 (4.10)  Time: 0.603s,   66.32/s  (0.602s,   66.44/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [ 800/3167 ( 25%)]  Loss: 3.66 (4.09)  Time: 0.601s,   66.58/s  (0.602s,   66.46/s)  LR: 5.500e-05  Data: 0.009 (0.010)
Train: 5 [ 850/3167 ( 27%)]  Loss: 4.08 (4.09)  Time: 0.593s,   67.46/s  (0.602s,   66.47/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [ 900/3167 ( 28%)]  Loss: 3.93 (4.09)  Time: 0.593s,   67.48/s  (0.602s,   66.48/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [ 950/3167 ( 30%)]  Loss: 4.12 (4.09)  Time: 0.604s,   66.21/s  (0.602s,   66.49/s)  LR: 5.500e-05  Data: 0.010 (0.010)
Train: 5 [1000/3167 ( 32%)]  Loss: 4.00 (4.09)  Time: 0.600s,   66.65/s  (0.602s,   66.50/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [1050/3167 ( 33%)]  Loss: 4.38 (4.09)  Time: 0.595s,   67.18/s  (0.601s,   66.50/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [1100/3167 ( 35%)]  Loss: 4.39 (4.09)  Time: 0.596s,   67.15/s  (0.601s,   66.51/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [1150/3167 ( 36%)]  Loss: 4.47 (4.09)  Time: 0.601s,   66.55/s  (0.601s,   66.52/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [1200/3167 ( 38%)]  Loss: 4.28 (4.09)  Time: 0.596s,   67.16/s  (0.601s,   66.52/s)  LR: 5.500e-05  Data: 0.006 (0.010)
Train: 5 [1250/3167 ( 39%)]  Loss: 3.94 (4.09)  Time: 0.602s,   66.42/s  (0.601s,   66.53/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1300/3167 ( 41%)]  Loss: 3.91 (4.09)  Time: 0.600s,   66.62/s  (0.601s,   66.54/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [1350/3167 ( 43%)]  Loss: 3.60 (4.09)  Time: 0.600s,   66.66/s  (0.601s,   66.54/s)  LR: 5.500e-05  Data: 0.011 (0.009)
Train: 5 [1400/3167 ( 44%)]  Loss: 4.28 (4.09)  Time: 0.606s,   66.06/s  (0.601s,   66.54/s)  LR: 5.500e-05  Data: 0.011 (0.009)
Train: 5 [1450/3167 ( 46%)]  Loss: 4.04 (4.09)  Time: 0.598s,   66.89/s  (0.601s,   66.55/s)  LR: 5.500e-05  Data: 0.009 (0.009)
Train: 5 [1500/3167 ( 47%)]  Loss: 4.06 (4.08)  Time: 0.593s,   67.45/s  (0.601s,   66.55/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [1550/3167 ( 49%)]  Loss: 4.24 (4.09)  Time: 0.596s,   67.15/s  (0.601s,   66.56/s)  LR: 5.500e-05  Data: 0.007 (0.009)
Train: 5 [1600/3167 ( 51%)]  Loss: 4.16 (4.09)  Time: 0.601s,   66.60/s  (0.601s,   66.56/s)  LR: 5.500e-05  Data: 0.012 (0.009)
Train: 5 [1650/3167 ( 52%)]  Loss: 3.74 (4.08)  Time: 0.593s,   67.48/s  (0.601s,   66.57/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [1700/3167 ( 54%)]  Loss: 3.97 (4.08)  Time: 0.596s,   67.14/s  (0.601s,   66.57/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [1750/3167 ( 55%)]  Loss: 4.17 (4.08)  Time: 0.601s,   66.56/s  (0.601s,   66.58/s)  LR: 5.500e-05  Data: 0.012 (0.009)
Train: 5 [1800/3167 ( 57%)]  Loss: 4.22 (4.08)  Time: 0.595s,   67.21/s  (0.601s,   66.58/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [1850/3167 ( 58%)]  Loss: 3.64 (4.08)  Time: 0.593s,   67.46/s  (0.601s,   66.59/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [1900/3167 ( 60%)]  Loss: 4.32 (4.08)  Time: 0.593s,   67.45/s  (0.601s,   66.59/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [1950/3167 ( 62%)]  Loss: 4.43 (4.08)  Time: 0.594s,   67.33/s  (0.601s,   66.60/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2000/3167 ( 63%)]  Loss: 3.98 (4.08)  Time: 0.601s,   66.56/s  (0.601s,   66.61/s)  LR: 5.500e-05  Data: 0.012 (0.009)
Train: 5 [2050/3167 ( 65%)]  Loss: 4.21 (4.08)  Time: 0.593s,   67.46/s  (0.600s,   66.61/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2100/3167 ( 66%)]  Loss: 4.38 (4.08)  Time: 0.601s,   66.52/s  (0.600s,   66.62/s)  LR: 5.500e-05  Data: 0.012 (0.009)
Train: 5 [2150/3167 ( 68%)]  Loss: 3.66 (4.08)  Time: 0.593s,   67.44/s  (0.600s,   66.63/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2200/3167 ( 69%)]  Loss: 4.14 (4.08)  Time: 0.599s,   66.83/s  (0.600s,   66.64/s)  LR: 5.500e-05  Data: 0.009 (0.009)
Train: 5 [2250/3167 ( 71%)]  Loss: 4.20 (4.08)  Time: 0.601s,   66.51/s  (0.600s,   66.64/s)  LR: 5.500e-05  Data: 0.012 (0.009)
Train: 5 [2300/3167 ( 73%)]  Loss: 4.23 (4.08)  Time: 0.601s,   66.51/s  (0.600s,   66.65/s)  LR: 5.500e-05  Data: 0.012 (0.009)
Train: 5 [2350/3167 ( 74%)]  Loss: 3.94 (4.08)  Time: 0.593s,   67.46/s  (0.600s,   66.66/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2400/3167 ( 76%)]  Loss: 4.38 (4.08)  Time: 0.593s,   67.45/s  (0.600s,   66.67/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2450/3167 ( 77%)]  Loss: 4.31 (4.08)  Time: 0.596s,   67.14/s  (0.600s,   66.68/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2500/3167 ( 79%)]  Loss: 3.81 (4.08)  Time: 0.593s,   67.41/s  (0.600s,   66.68/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2550/3167 ( 81%)]  Loss: 3.65 (4.08)  Time: 0.596s,   67.09/s  (0.600s,   66.69/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2600/3167 ( 82%)]  Loss: 4.29 (4.08)  Time: 0.596s,   67.16/s  (0.600s,   66.69/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2650/3167 ( 84%)]  Loss: 3.79 (4.08)  Time: 0.596s,   67.15/s  (0.600s,   66.70/s)  LR: 5.500e-05  Data: 0.007 (0.009)
Train: 5 [2700/3167 ( 85%)]  Loss: 4.04 (4.08)  Time: 0.593s,   67.46/s  (0.600s,   66.71/s)  LR: 5.500e-05  Data: 0.004 (0.008)
Train: 5 [2750/3167 ( 87%)]  Loss: 4.21 (4.08)  Time: 0.593s,   67.46/s  (0.600s,   66.71/s)  LR: 5.500e-05  Data: 0.004 (0.008)
Train: 5 [2800/3167 ( 88%)]  Loss: 4.05 (4.07)  Time: 0.603s,   66.35/s  (0.600s,   66.72/s)  LR: 5.500e-05  Data: 0.007 (0.008)
Train: 5 [2850/3167 ( 90%)]  Loss: 3.93 (4.07)  Time: 0.597s,   67.04/s  (0.599s,   66.73/s)  LR: 5.500e-05  Data: 0.004 (0.008)
Train: 5 [2900/3167 ( 92%)]  Loss: 3.90 (4.07)  Time: 0.596s,   67.16/s  (0.599s,   66.74/s)  LR: 5.500e-05  Data: 0.004 (0.008)
Train: 5 [2950/3167 ( 93%)]  Loss: 4.28 (4.07)  Time: 0.593s,   67.47/s  (0.599s,   66.74/s)  LR: 5.500e-05  Data: 0.004 (0.008)
Train: 5 [3000/3167 ( 95%)]  Loss: 4.01 (4.07)  Time: 0.597s,   66.99/s  (0.599s,   66.75/s)  LR: 5.500e-05  Data: 0.004 (0.008)
Train: 5 [3050/3167 ( 96%)]  Loss: 4.17 (4.07)  Time: 0.595s,   67.24/s  (0.599s,   66.76/s)  LR: 5.500e-05  Data: 0.004 (0.008)
Train: 5 [3100/3167 ( 98%)]  Loss: 4.11 (4.07)  Time: 0.596s,   67.13/s  (0.599s,   66.76/s)  LR: 5.500e-05  Data: 0.007 (0.008)
Train: 5 [3150/3167 ( 99%)]  Loss: 3.68 (4.07)  Time: 0.597s,   67.00/s  (0.599s,   66.77/s)  LR: 5.500e-05  Data: 0.006 (0.008)
Test: [   0/3167]  Time: 0.534 (0.534)  Loss:   3.953 ( 3.953)  Acc@1:   2.500 (  2.500)  Acc@5:  30.000 ( 30.000)
Test: [  50/3167]  Time: 0.195 (0.202)  Loss:   3.541 ( 3.677)  Acc@1:  32.500 ( 13.578)  Acc@5:  47.500 ( 40.980)
Test: [ 100/3167]  Time: 0.199 (0.198)  Loss:   3.693 ( 3.692)  Acc@1:  17.500 ( 13.342)  Acc@5:  45.000 ( 39.530)
Test: [ 150/3167]  Time: 0.202 (0.196)  Loss:   2.182 ( 3.515)  Acc@1:  62.500 ( 19.570)  Acc@5:  92.500 ( 46.474)
Test: [ 200/3167]  Time: 0.200 (0.196)  Loss:   3.609 ( 3.531)  Acc@1:  12.500 ( 19.465)  Acc@5:  42.500 ( 45.983)
Test: [ 250/3167]  Time: 0.207 (0.195)  Loss:   2.814 ( 3.477)  Acc@1:  30.000 ( 20.677)  Acc@5:  60.000 ( 46.604)
Test: [ 300/3167]  Time: 0.194 (0.195)  Loss:   3.207 ( 3.452)  Acc@1:  20.000 ( 21.811)  Acc@5:  62.500 ( 47.973)
Test: [ 350/3167]  Time: 0.196 (0.195)  Loss:   2.495 ( 3.370)  Acc@1:  60.000 ( 24.031)  Acc@5:  77.500 ( 50.840)
Test: [ 400/3167]  Time: 0.199 (0.195)  Loss:   2.676 ( 3.205)  Acc@1:  30.000 ( 28.579)  Acc@5:  72.500 ( 55.006)
Test: [ 450/3167]  Time: 0.193 (0.195)  Loss:   3.333 ( 3.215)  Acc@1:   2.500 ( 27.084)  Acc@5:  50.000 ( 54.401)
Test: [ 500/3167]  Time: 0.187 (0.194)  Loss:   2.721 ( 3.229)  Acc@1:  52.500 ( 27.056)  Acc@5:  65.000 ( 53.698)
Test: [ 550/3167]  Time: 0.191 (0.194)  Loss:   3.729 ( 3.166)  Acc@1:   2.500 ( 29.270)  Acc@5:  32.500 ( 55.168)
Test: [ 600/3167]  Time: 0.192 (0.194)  Loss:   2.606 ( 3.184)  Acc@1:  30.000 ( 28.037)  Acc@5:  75.000 ( 54.468)
Test: [ 650/3167]  Time: 0.190 (0.194)  Loss:   3.509 ( 3.171)  Acc@1:  32.500 ( 28.445)  Acc@5:  52.500 ( 55.000)
Test: [ 700/3167]  Time: 0.193 (0.194)  Loss:   3.007 ( 3.178)  Acc@1:  35.000 ( 28.659)  Acc@5:  75.000 ( 55.767)
Test: [ 750/3167]  Time: 0.198 (0.194)  Loss:   3.274 ( 3.174)  Acc@1:  42.500 ( 28.109)  Acc@5:  50.000 ( 56.265)
Test: [ 800/3167]  Time: 0.184 (0.194)  Loss:   4.384 ( 3.207)  Acc@1:   0.000 ( 27.537)  Acc@5:  17.500 ( 54.956)
Test: [ 850/3167]  Time: 0.195 (0.194)  Loss:   3.615 ( 3.257)  Acc@1:   2.500 ( 26.055)  Acc@5:  35.000 ( 52.994)
Test: [ 900/3167]  Time: 0.191 (0.194)  Loss:   3.706 ( 3.288)  Acc@1:  10.000 ( 24.828)  Acc@5:  40.000 ( 51.718)
Test: [ 950/3167]  Time: 0.195 (0.194)  Loss:   3.032 ( 3.319)  Acc@1:  22.500 ( 23.962)  Acc@5:  62.500 ( 50.465)
Test: [1000/3167]  Time: 0.200 (0.194)  Loss:   2.944 ( 3.326)  Acc@1:  40.000 ( 23.546)  Acc@5:  75.000 ( 50.367)
Test: [1050/3167]  Time: 0.207 (0.194)  Loss:   3.511 ( 3.316)  Acc@1:  20.000 ( 23.718)  Acc@5:  42.500 ( 50.971)
Test: [1100/3167]  Time: 0.204 (0.194)  Loss:   3.628 ( 3.316)  Acc@1:  22.500 ( 23.470)  Acc@5:  42.500 ( 51.219)
Test: [1150/3167]  Time: 0.196 (0.194)  Loss:   2.378 ( 3.300)  Acc@1:  65.000 ( 24.292)  Acc@5:  87.500 ( 51.872)
Test: [1200/3167]  Time: 0.207 (0.194)  Loss:   3.044 ( 3.282)  Acc@1:  37.500 ( 24.530)  Acc@5:  70.000 ( 52.739)
Test: [1250/3167]  Time: 0.198 (0.194)  Loss:   2.718 ( 3.268)  Acc@1:  50.000 ( 25.246)  Acc@5:  70.000 ( 53.301)
Test: [1300/3167]  Time: 0.193 (0.194)  Loss:   3.293 ( 3.286)  Acc@1:  20.000 ( 24.602)  Acc@5:  62.500 ( 52.414)
Test: [1350/3167]  Time: 0.196 (0.194)  Loss:   3.266 ( 3.313)  Acc@1:  17.500 ( 24.054)  Acc@5:  67.500 ( 51.471)
Test: [1400/3167]  Time: 0.184 (0.194)  Loss:   2.682 ( 3.331)  Acc@1:  50.000 ( 23.737)  Acc@5:  75.000 ( 50.910)
Test: [1450/3167]  Time: 0.195 (0.194)  Loss:   3.171 ( 3.315)  Acc@1:  20.000 ( 24.426)  Acc@5:  62.500 ( 51.606)
Test: [1500/3167]  Time: 0.196 (0.194)  Loss:   3.670 ( 3.297)  Acc@1:   7.500 ( 24.967)  Acc@5:  47.500 ( 52.179)
Test: [1550/3167]  Time: 0.193 (0.194)  Loss:   2.083 ( 3.288)  Acc@1:  80.000 ( 25.322)  Acc@5:  90.000 ( 52.571)
Test: [1600/3167]  Time: 0.189 (0.194)  Loss:   2.699 ( 3.275)  Acc@1:  45.000 ( 25.700)  Acc@5:  60.000 ( 53.059)
Test: [1650/3167]  Time: 0.187 (0.194)  Loss:   3.106 ( 3.262)  Acc@1:  15.000 ( 26.034)  Acc@5:  62.500 ( 53.471)
Test: [1700/3167]  Time: 0.191 (0.194)  Loss:   3.929 ( 3.258)  Acc@1:   2.500 ( 26.164)  Acc@5:  17.500 ( 53.686)
Test: [1750/3167]  Time: 0.190 (0.194)  Loss:   3.615 ( 3.271)  Acc@1:  17.500 ( 25.865)  Acc@5:  37.500 ( 53.207)
Test: [1800/3167]  Time: 0.191 (0.194)  Loss:   3.015 ( 3.271)  Acc@1:  20.000 ( 25.887)  Acc@5:  70.000 ( 53.315)
Test: [1850/3167]  Time: 0.187 (0.194)  Loss:   3.889 ( 3.288)  Acc@1:  15.000 ( 25.415)  Acc@5:  35.000 ( 52.622)
Test: [1900/3167]  Time: 0.197 (0.194)  Loss:   3.861 ( 3.301)  Acc@1:   0.000 ( 25.049)  Acc@5:  32.500 ( 52.305)
Test: [1950/3167]  Time: 0.188 (0.194)  Loss:   4.402 ( 3.316)  Acc@1:   0.000 ( 24.641)  Acc@5:  10.000 ( 51.758)
Test: [2000/3167]  Time: 0.187 (0.194)  Loss:   3.804 ( 3.336)  Acc@1:  10.000 ( 24.120)  Acc@5:  37.500 ( 50.956)
Test: [2050/3167]  Time: 0.184 (0.194)  Loss:   4.317 ( 3.351)  Acc@1:   0.000 ( 23.715)  Acc@5:   5.000 ( 50.227)
Test: [2100/3167]  Time: 0.197 (0.194)  Loss:   3.785 ( 3.357)  Acc@1:  12.500 ( 23.683)  Acc@5:  32.500 ( 50.106)
Test: [2150/3167]  Time: 0.184 (0.193)  Loss:   1.517 ( 3.338)  Acc@1:  75.000 ( 24.136)  Acc@5:  82.500 ( 50.350)
Test: [2200/3167]  Time: 0.184 (0.193)  Loss:   3.062 ( 3.329)  Acc@1:  15.000 ( 24.162)  Acc@5:  70.000 ( 50.675)
Test: [2250/3167]  Time: 0.184 (0.193)  Loss:   3.215 ( 3.335)  Acc@1:  40.000 ( 23.990)  Acc@5:  70.000 ( 50.518)
Test: [2300/3167]  Time: 0.200 (0.193)  Loss:   4.205 ( 3.345)  Acc@1:   0.000 ( 23.837)  Acc@5:  17.500 ( 50.251)
Test: [2350/3167]  Time: 0.202 (0.193)  Loss:   3.436 ( 3.353)  Acc@1:  27.500 ( 23.528)  Acc@5:  57.500 ( 49.957)
Test: [2400/3167]  Time: 0.194 (0.193)  Loss:   3.950 ( 3.343)  Acc@1:   0.000 ( 23.895)  Acc@5:  20.000 ( 50.170)
Test: [2450/3167]  Time: 0.184 (0.193)  Loss:   2.812 ( 3.341)  Acc@1:  40.000 ( 23.861)  Acc@5:  80.000 ( 50.297)
Test: [2500/3167]  Time: 0.195 (0.193)  Loss:   3.867 ( 3.345)  Acc@1:  10.000 ( 23.770)  Acc@5:  47.500 ( 50.312)
Test: [2550/3167]  Time: 0.194 (0.193)  Loss:   3.697 ( 3.337)  Acc@1:   5.000 ( 24.094)  Acc@5:  27.500 ( 50.645)
Test: [2600/3167]  Time: 0.202 (0.193)  Loss:   3.054 ( 3.341)  Acc@1:  32.500 ( 23.898)  Acc@5:  52.500 ( 50.366)
Test: [2650/3167]  Time: 0.186 (0.193)  Loss:   3.029 ( 3.344)  Acc@1:  35.000 ( 23.794)  Acc@5:  75.000 ( 50.342)
Test: [2700/3167]  Time: 0.190 (0.193)  Loss:   2.966 ( 3.340)  Acc@1:  32.500 ( 24.039)  Acc@5:  65.000 ( 50.604)
Test: [2750/3167]  Time: 0.202 (0.193)  Loss:   2.372 ( 3.344)  Acc@1:  52.500 ( 23.918)  Acc@5:  85.000 ( 50.339)
Test: [2800/3167]  Time: 0.186 (0.193)  Loss:   3.715 ( 3.339)  Acc@1:   0.000 ( 24.045)  Acc@5:  40.000 ( 50.534)
Test: [2850/3167]  Time: 0.188 (0.193)  Loss:   3.710 ( 3.349)  Acc@1:  12.500 ( 23.734)  Acc@5:  42.500 ( 50.157)
Test: [2900/3167]  Time: 0.186 (0.193)  Loss:   3.418 ( 3.351)  Acc@1:  27.500 ( 23.723)  Acc@5:  60.000 ( 50.197)
Test: [2950/3167]  Time: 0.186 (0.193)  Loss:   3.696 ( 3.353)  Acc@1:   2.500 ( 23.559)  Acc@5:  37.500 ( 50.175)
Test: [3000/3167]  Time: 0.189 (0.193)  Loss:   3.869 ( 3.361)  Acc@1:   5.000 ( 23.220)  Acc@5:  27.500 ( 49.790)
Test: [3050/3167]  Time: 0.189 (0.193)  Loss:   4.160 ( 3.367)  Acc@1:   0.000 ( 23.017)  Acc@5:  22.500 ( 49.509)
Test: [3100/3167]  Time: 0.187 (0.193)  Loss:   3.728 ( 3.376)  Acc@1:   7.500 ( 22.709)  Acc@5:  40.000 ( 49.166)
Test: [3150/3167]  Time: 0.187 (0.193)  Loss:   3.734 ( 3.384)  Acc@1:   0.000 ( 22.397)  Acc@5:  40.000 ( 48.905)
Test: [3167/3167]  Time: 0.043 (0.193)  Loss:   3.401 ( 3.387)  Acc@1:  11.111 ( 22.349)  Acc@5:  55.556 ( 48.878)
Test: [   0/124]  Time: 0.730 (0.730)  Loss:   4.166 ( 4.166)  Acc@1:   2.500 (  2.500)  Acc@5:  12.500 ( 12.500)
Test: [  50/124]  Time: 0.192 (0.200)  Loss:   3.455 ( 3.371)  Acc@1:  20.000 ( 22.010)  Acc@5:  57.500 ( 49.559)
Test: [ 100/124]  Time: 0.184 (0.194)  Loss:   2.609 ( 3.416)  Acc@1:  57.500 ( 21.832)  Acc@5:  75.000 ( 47.450)
Test: [ 124/124]  Time: 0.180 (0.193)  Loss:   3.642 ( 3.453)  Acc@1:  12.500 ( 20.740)  Acc@5:  45.000 ( 46.500)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_3/checkpoint-5.pth.tar', 22.349217374868918)

Train: 6 [   0/3167 (  0%)]  Loss: 4.10 (4.10)  Time: 1.052s,   38.02/s  (1.052s,   38.02/s)  LR: 6.400e-05  Data: 0.459 (0.459)
Train: 6 [  50/3167 (  2%)]  Loss: 4.27 (4.05)  Time: 0.595s,   67.19/s  (0.611s,   65.46/s)  LR: 6.400e-05  Data: 0.004 (0.019)
Train: 6 [ 100/3167 (  3%)]  Loss: 4.02 (4.05)  Time: 0.597s,   66.98/s  (0.607s,   65.95/s)  LR: 6.400e-05  Data: 0.007 (0.014)
Train: 6 [ 150/3167 (  5%)]  Loss: 3.71 (4.04)  Time: 0.595s,   67.20/s  (0.605s,   66.15/s)  LR: 6.400e-05  Data: 0.004 (0.013)
Train: 6 [ 200/3167 (  6%)]  Loss: 4.05 (4.03)  Time: 0.603s,   66.30/s  (0.604s,   66.23/s)  LR: 6.400e-05  Data: 0.012 (0.012)
Train: 6 [ 250/3167 (  8%)]  Loss: 3.78 (4.02)  Time: 0.601s,   66.52/s  (0.604s,   66.26/s)  LR: 6.400e-05  Data: 0.006 (0.012)
Train: 6 [ 300/3167 (  9%)]  Loss: 3.47 (4.02)  Time: 0.610s,   65.55/s  (0.603s,   66.31/s)  LR: 6.400e-05  Data: 0.012 (0.011)
Train: 6 [ 350/3167 ( 11%)]  Loss: 4.05 (4.03)  Time: 0.603s,   66.30/s  (0.603s,   66.34/s)  LR: 6.400e-05  Data: 0.012 (0.011)
Train: 6 [ 400/3167 ( 13%)]  Loss: 3.92 (4.03)  Time: 0.600s,   66.68/s  (0.603s,   66.37/s)  LR: 6.400e-05  Data: 0.011 (0.011)
Train: 6 [ 450/3167 ( 14%)]  Loss: 4.00 (4.03)  Time: 0.602s,   66.42/s  (0.603s,   66.39/s)  LR: 6.400e-05  Data: 0.012 (0.011)
Train: 6 [ 500/3167 ( 16%)]  Loss: 3.98 (4.02)  Time: 0.593s,   67.49/s  (0.602s,   66.39/s)  LR: 6.400e-05  Data: 0.004 (0.011)
Train: 6 [ 550/3167 ( 17%)]  Loss: 4.13 (4.03)  Time: 0.598s,   66.87/s  (0.602s,   66.40/s)  LR: 6.400e-05  Data: 0.009 (0.010)
Train: 6 [ 600/3167 ( 19%)]  Loss: 4.27 (4.03)  Time: 0.602s,   66.48/s  (0.602s,   66.42/s)  LR: 6.400e-05  Data: 0.011 (0.010)
Train: 6 [ 650/3167 ( 21%)]  Loss: 3.79 (4.03)  Time: 0.603s,   66.34/s  (0.602s,   66.43/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [ 700/3167 ( 22%)]  Loss: 4.40 (4.03)  Time: 0.596s,   67.15/s  (0.602s,   66.44/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [ 750/3167 ( 24%)]  Loss: 4.22 (4.03)  Time: 0.596s,   67.12/s  (0.602s,   66.45/s)  LR: 6.400e-05  Data: 0.007 (0.010)
Train: 6 [ 800/3167 ( 25%)]  Loss: 4.24 (4.03)  Time: 0.593s,   67.48/s  (0.602s,   66.45/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [ 850/3167 ( 27%)]  Loss: 4.37 (4.02)  Time: 0.605s,   66.17/s  (0.602s,   66.46/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [ 900/3167 ( 28%)]  Loss: 3.66 (4.02)  Time: 0.601s,   66.60/s  (0.602s,   66.46/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [ 950/3167 ( 30%)]  Loss: 3.74 (4.02)  Time: 0.595s,   67.21/s  (0.602s,   66.47/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [1000/3167 ( 32%)]  Loss: 3.92 (4.02)  Time: 0.610s,   65.55/s  (0.602s,   66.48/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1050/3167 ( 33%)]  Loss: 3.90 (4.03)  Time: 0.598s,   66.86/s  (0.602s,   66.48/s)  LR: 6.400e-05  Data: 0.009 (0.010)
Train: 6 [1100/3167 ( 35%)]  Loss: 3.88 (4.03)  Time: 0.608s,   65.77/s  (0.602s,   66.49/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1150/3167 ( 36%)]  Loss: 3.85 (4.02)  Time: 0.598s,   66.88/s  (0.602s,   66.50/s)  LR: 6.400e-05  Data: 0.009 (0.010)
Train: 6 [1200/3167 ( 38%)]  Loss: 4.01 (4.02)  Time: 0.600s,   66.63/s  (0.601s,   66.50/s)  LR: 6.400e-05  Data: 0.011 (0.010)
Train: 6 [1250/3167 ( 39%)]  Loss: 4.22 (4.02)  Time: 0.593s,   67.48/s  (0.601s,   66.51/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [1300/3167 ( 41%)]  Loss: 4.65 (4.02)  Time: 0.602s,   66.46/s  (0.601s,   66.52/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [1350/3167 ( 43%)]  Loss: 4.22 (4.02)  Time: 0.603s,   66.34/s  (0.601s,   66.52/s)  LR: 6.400e-05  Data: 0.011 (0.010)
Train: 6 [1400/3167 ( 44%)]  Loss: 4.15 (4.02)  Time: 0.598s,   66.85/s  (0.601s,   66.53/s)  LR: 6.400e-05  Data: 0.009 (0.010)
Train: 6 [1450/3167 ( 46%)]  Loss: 3.59 (4.02)  Time: 0.601s,   66.55/s  (0.601s,   66.54/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1500/3167 ( 47%)]  Loss: 4.37 (4.02)  Time: 0.599s,   66.81/s  (0.601s,   66.54/s)  LR: 6.400e-05  Data: 0.010 (0.010)
Train: 6 [1550/3167 ( 49%)]  Loss: 4.00 (4.02)  Time: 0.610s,   65.59/s  (0.601s,   66.55/s)  LR: 6.400e-05  Data: 0.011 (0.009)
Train: 6 [1600/3167 ( 51%)]  Loss: 3.68 (4.02)  Time: 0.601s,   66.59/s  (0.601s,   66.55/s)  LR: 6.400e-05  Data: 0.012 (0.009)
Train: 6 [1650/3167 ( 52%)]  Loss: 4.06 (4.02)  Time: 0.611s,   65.43/s  (0.601s,   66.55/s)  LR: 6.400e-05  Data: 0.011 (0.009)
Train: 6 [1700/3167 ( 54%)]  Loss: 4.33 (4.02)  Time: 0.601s,   66.56/s  (0.601s,   66.56/s)  LR: 6.400e-05  Data: 0.012 (0.009)
Train: 6 [1750/3167 ( 55%)]  Loss: 3.59 (4.02)  Time: 0.593s,   67.48/s  (0.601s,   66.56/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [1800/3167 ( 57%)]  Loss: 3.83 (4.02)  Time: 0.602s,   66.41/s  (0.601s,   66.57/s)  LR: 6.400e-05  Data: 0.010 (0.009)
Train: 6 [1850/3167 ( 58%)]  Loss: 3.97 (4.02)  Time: 0.601s,   66.56/s  (0.601s,   66.57/s)  LR: 6.400e-05  Data: 0.012 (0.009)
Train: 6 [1900/3167 ( 60%)]  Loss: 3.94 (4.02)  Time: 0.603s,   66.30/s  (0.601s,   66.58/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [1950/3167 ( 62%)]  Loss: 4.10 (4.02)  Time: 0.596s,   67.13/s  (0.601s,   66.59/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [2000/3167 ( 63%)]  Loss: 4.26 (4.02)  Time: 0.595s,   67.24/s  (0.601s,   66.59/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [2050/3167 ( 65%)]  Loss: 3.45 (4.02)  Time: 0.601s,   66.58/s  (0.601s,   66.60/s)  LR: 6.400e-05  Data: 0.012 (0.009)
Train: 6 [2100/3167 ( 66%)]  Loss: 3.68 (4.02)  Time: 0.601s,   66.59/s  (0.601s,   66.61/s)  LR: 6.400e-05  Data: 0.011 (0.009)
Train: 6 [2150/3167 ( 68%)]  Loss: 4.00 (4.02)  Time: 0.593s,   67.44/s  (0.600s,   66.62/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [2200/3167 ( 69%)]  Loss: 3.80 (4.02)  Time: 0.601s,   66.59/s  (0.600s,   66.62/s)  LR: 6.400e-05  Data: 0.011 (0.009)
Train: 6 [2250/3167 ( 71%)]  Loss: 3.89 (4.02)  Time: 0.622s,   64.26/s  (0.600s,   66.63/s)  LR: 6.400e-05  Data: 0.028 (0.009)
Train: 6 [2300/3167 ( 73%)]  Loss: 3.66 (4.02)  Time: 0.595s,   67.17/s  (0.600s,   66.64/s)  LR: 6.400e-05  Data: 0.006 (0.009)
Train: 6 [2350/3167 ( 74%)]  Loss: 3.63 (4.01)  Time: 0.598s,   66.85/s  (0.600s,   66.64/s)  LR: 6.400e-05  Data: 0.009 (0.009)
Train: 6 [2400/3167 ( 76%)]  Loss: 4.12 (4.01)  Time: 0.593s,   67.44/s  (0.600s,   66.65/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [2450/3167 ( 77%)]  Loss: 4.08 (4.01)  Time: 0.596s,   67.13/s  (0.600s,   66.66/s)  LR: 6.400e-05  Data: 0.006 (0.009)
Train: 6 [2500/3167 ( 79%)]  Loss: 3.91 (4.01)  Time: 0.607s,   65.94/s  (0.600s,   66.66/s)  LR: 6.400e-05  Data: 0.010 (0.009)
Train: 6 [2550/3167 ( 81%)]  Loss: 4.23 (4.01)  Time: 0.593s,   67.41/s  (0.600s,   66.67/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [2600/3167 ( 82%)]  Loss: 4.25 (4.01)  Time: 0.607s,   65.94/s  (0.600s,   66.68/s)  LR: 6.400e-05  Data: 0.015 (0.009)
Train: 6 [2650/3167 ( 84%)]  Loss: 3.72 (4.01)  Time: 0.597s,   67.04/s  (0.600s,   66.69/s)  LR: 6.400e-05  Data: 0.007 (0.009)
Train: 6 [2700/3167 ( 85%)]  Loss: 3.55 (4.01)  Time: 0.593s,   67.44/s  (0.600s,   66.69/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [2750/3167 ( 87%)]  Loss: 3.67 (4.01)  Time: 0.593s,   67.46/s  (0.600s,   66.70/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [2800/3167 ( 88%)]  Loss: 4.28 (4.01)  Time: 0.593s,   67.46/s  (0.600s,   66.71/s)  LR: 6.400e-05  Data: 0.004 (0.008)
Train: 6 [2850/3167 ( 90%)]  Loss: 4.08 (4.01)  Time: 0.593s,   67.44/s  (0.600s,   66.72/s)  LR: 6.400e-05  Data: 0.004 (0.008)
Train: 6 [2900/3167 ( 92%)]  Loss: 3.93 (4.01)  Time: 0.593s,   67.45/s  (0.599s,   66.72/s)  LR: 6.400e-05  Data: 0.004 (0.008)
Train: 6 [2950/3167 ( 93%)]  Loss: 3.60 (4.01)  Time: 0.596s,   67.15/s  (0.599s,   66.73/s)  LR: 6.400e-05  Data: 0.007 (0.008)
Train: 6 [3000/3167 ( 95%)]  Loss: 4.10 (4.01)  Time: 0.594s,   67.29/s  (0.599s,   66.74/s)  LR: 6.400e-05  Data: 0.004 (0.008)
Train: 6 [3050/3167 ( 96%)]  Loss: 4.00 (4.01)  Time: 0.596s,   67.11/s  (0.599s,   66.74/s)  LR: 6.400e-05  Data: 0.004 (0.008)
Train: 6 [3100/3167 ( 98%)]  Loss: 4.26 (4.00)  Time: 0.593s,   67.48/s  (0.599s,   66.75/s)  LR: 6.400e-05  Data: 0.004 (0.008)
Train: 6 [3150/3167 ( 99%)]  Loss: 4.09 (4.01)  Time: 0.593s,   67.45/s  (0.599s,   66.76/s)  LR: 6.400e-05  Data: 0.004 (0.008)
Test: [   0/3167]  Time: 0.488 (0.488)  Loss:   3.372 ( 3.372)  Acc@1:  25.000 ( 25.000)  Acc@5:  52.500 ( 52.500)
Test: [  50/3167]  Time: 0.196 (0.199)  Loss:   3.335 ( 3.279)  Acc@1:  35.000 ( 22.206)  Acc@5:  42.500 ( 55.196)
Test: [ 100/3167]  Time: 0.186 (0.196)  Loss:   3.335 ( 3.323)  Acc@1:  25.000 ( 19.257)  Acc@5:  65.000 ( 53.069)
Test: [ 150/3167]  Time: 0.190 (0.195)  Loss:   2.009 ( 3.188)  Acc@1:  47.500 ( 23.775)  Acc@5:  95.000 ( 57.964)
Test: [ 200/3167]  Time: 0.192 (0.195)  Loss:   3.436 ( 3.238)  Acc@1:  17.500 ( 22.301)  Acc@5:  52.500 ( 54.913)
Test: [ 250/3167]  Time: 0.197 (0.194)  Loss:   3.049 ( 3.240)  Acc@1:  27.500 ( 22.530)  Acc@5:  45.000 ( 54.183)
Test: [ 300/3167]  Time: 0.200 (0.194)  Loss:   3.005 ( 3.269)  Acc@1:  20.000 ( 22.301)  Acc@5:  65.000 ( 53.422)
Test: [ 350/3167]  Time: 0.196 (0.194)  Loss:   2.713 ( 3.219)  Acc@1:  50.000 ( 23.426)  Acc@5:  75.000 ( 55.221)
Test: [ 400/3167]  Time: 0.193 (0.194)  Loss:   2.538 ( 3.083)  Acc@1:  40.000 ( 27.681)  Acc@5:  80.000 ( 58.797)
Test: [ 450/3167]  Time: 0.197 (0.194)  Loss:   3.457 ( 3.107)  Acc@1:   2.500 ( 26.541)  Acc@5:  42.500 ( 57.844)
Test: [ 500/3167]  Time: 0.190 (0.194)  Loss:   2.652 ( 3.109)  Acc@1:  45.000 ( 26.986)  Acc@5:  65.000 ( 57.580)
Test: [ 550/3167]  Time: 0.187 (0.194)  Loss:   3.752 ( 3.052)  Acc@1:   2.500 ( 29.129)  Acc@5:  35.000 ( 58.721)
Test: [ 600/3167]  Time: 0.192 (0.194)  Loss:   2.720 ( 3.085)  Acc@1:  35.000 ( 28.207)  Acc@5:  60.000 ( 57.567)
Test: [ 650/3167]  Time: 0.205 (0.194)  Loss:   2.912 ( 3.067)  Acc@1:  32.500 ( 28.856)  Acc@5:  67.500 ( 57.984)
Test: [ 700/3167]  Time: 0.198 (0.194)  Loss:   2.701 ( 3.051)  Acc@1:  50.000 ( 29.540)  Acc@5:  85.000 ( 59.219)
Test: [ 750/3167]  Time: 0.200 (0.194)  Loss:   3.216 ( 3.028)  Acc@1:  42.500 ( 30.459)  Acc@5:  47.500 ( 60.406)
Test: [ 800/3167]  Time: 0.196 (0.194)  Loss:   3.821 ( 3.048)  Acc@1:   5.000 ( 29.925)  Acc@5:  32.500 ( 59.544)
Test: [ 850/3167]  Time: 0.196 (0.194)  Loss:   3.356 ( 3.091)  Acc@1:   7.500 ( 28.414)  Acc@5:  60.000 ( 58.061)
Test: [ 900/3167]  Time: 0.197 (0.194)  Loss:   3.702 ( 3.125)  Acc@1:  12.500 ( 27.345)  Acc@5:  40.000 ( 57.125)
Test: [ 950/3167]  Time: 0.190 (0.194)  Loss:   3.288 ( 3.156)  Acc@1:  22.500 ( 26.406)  Acc@5:  57.500 ( 55.923)
Test: [1000/3167]  Time: 0.194 (0.194)  Loss:   3.207 ( 3.178)  Acc@1:  17.500 ( 25.602)  Acc@5:  60.000 ( 55.190)
Test: [1050/3167]  Time: 0.192 (0.194)  Loss:   2.999 ( 3.170)  Acc@1:  32.500 ( 25.880)  Acc@5:  70.000 ( 55.759)
Test: [1100/3167]  Time: 0.189 (0.194)  Loss:   3.252 ( 3.168)  Acc@1:  42.500 ( 25.670)  Acc@5:  60.000 ( 56.063)
Test: [1150/3167]  Time: 0.198 (0.194)  Loss:   1.887 ( 3.140)  Acc@1:  75.000 ( 26.937)  Acc@5:  92.500 ( 56.944)
Test: [1200/3167]  Time: 0.200 (0.194)  Loss:   2.514 ( 3.119)  Acc@1:  55.000 ( 27.556)  Acc@5:  82.500 ( 57.731)
Test: [1250/3167]  Time: 0.184 (0.194)  Loss:   2.064 ( 3.089)  Acc@1:  65.000 ( 28.723)  Acc@5:  87.500 ( 58.499)
Test: [1300/3167]  Time: 0.197 (0.194)  Loss:   2.658 ( 3.104)  Acc@1:  50.000 ( 28.369)  Acc@5:  82.500 ( 57.911)
Test: [1350/3167]  Time: 0.197 (0.194)  Loss:   3.437 ( 3.131)  Acc@1:  20.000 ( 28.031)  Acc@5:  57.500 ( 57.076)
Test: [1400/3167]  Time: 0.191 (0.194)  Loss:   3.177 ( 3.151)  Acc@1:  30.000 ( 27.550)  Acc@5:  57.500 ( 56.408)
Test: [1450/3167]  Time: 0.202 (0.194)  Loss:   3.155 ( 3.150)  Acc@1:  25.000 ( 27.795)  Acc@5:  55.000 ( 56.506)
Test: [1500/3167]  Time: 0.196 (0.194)  Loss:   3.340 ( 3.132)  Acc@1:  22.500 ( 28.394)  Acc@5:  55.000 ( 56.972)
Test: [1550/3167]  Time: 0.192 (0.194)  Loss:   1.661 ( 3.118)  Acc@1:  80.000 ( 28.814)  Acc@5:  90.000 ( 57.395)
Test: [1600/3167]  Time: 0.191 (0.194)  Loss:   2.863 ( 3.104)  Acc@1:  35.000 ( 29.197)  Acc@5:  57.500 ( 57.958)
Test: [1650/3167]  Time: 0.192 (0.194)  Loss:   2.749 ( 3.092)  Acc@1:  30.000 ( 29.511)  Acc@5:  75.000 ( 58.316)
Test: [1700/3167]  Time: 0.190 (0.194)  Loss:   3.778 ( 3.080)  Acc@1:   7.500 ( 29.924)  Acc@5:  32.500 ( 58.614)
Test: [1750/3167]  Time: 0.189 (0.193)  Loss:   3.597 ( 3.096)  Acc@1:  12.500 ( 29.480)  Acc@5:  37.500 ( 57.998)
Test: [1800/3167]  Time: 0.190 (0.193)  Loss:   3.305 ( 3.104)  Acc@1:  10.000 ( 29.342)  Acc@5:  45.000 ( 57.804)
Test: [1850/3167]  Time: 0.192 (0.193)  Loss:   3.419 ( 3.122)  Acc@1:  15.000 ( 28.668)  Acc@5:  42.500 ( 56.927)
Test: [1900/3167]  Time: 0.199 (0.193)  Loss:   3.815 ( 3.132)  Acc@1:   7.500 ( 28.246)  Acc@5:  32.500 ( 56.712)
Test: [1950/3167]  Time: 0.190 (0.193)  Loss:   4.304 ( 3.143)  Acc@1:   0.000 ( 27.881)  Acc@5:  12.500 ( 56.356)
Test: [2000/3167]  Time: 0.196 (0.193)  Loss:   3.977 ( 3.165)  Acc@1:   5.000 ( 27.303)  Acc@5:  25.000 ( 55.471)
Test: [2050/3167]  Time: 0.189 (0.193)  Loss:   3.749 ( 3.180)  Acc@1:   5.000 ( 26.808)  Acc@5:  25.000 ( 54.842)
Test: [2100/3167]  Time: 0.198 (0.193)  Loss:   3.568 ( 3.181)  Acc@1:  12.500 ( 26.834)  Acc@5:  45.000 ( 54.870)
Test: [2150/3167]  Time: 0.191 (0.193)  Loss:   1.752 ( 3.166)  Acc@1:  70.000 ( 27.234)  Acc@5:  77.500 ( 55.123)
Test: [2200/3167]  Time: 0.188 (0.193)  Loss:   3.237 ( 3.163)  Acc@1:  17.500 ( 27.222)  Acc@5:  52.500 ( 55.245)
Test: [2250/3167]  Time: 0.194 (0.193)  Loss:   3.337 ( 3.172)  Acc@1:  30.000 ( 26.850)  Acc@5:  50.000 ( 54.911)
Test: [2300/3167]  Time: 0.186 (0.193)  Loss:   3.971 ( 3.183)  Acc@1:   0.000 ( 26.445)  Acc@5:  20.000 ( 54.496)
Test: [2350/3167]  Time: 0.187 (0.193)  Loss:   3.780 ( 3.196)  Acc@1:   7.500 ( 25.977)  Acc@5:  42.500 ( 53.952)
Test: [2400/3167]  Time: 0.194 (0.193)  Loss:   3.728 ( 3.190)  Acc@1:   0.000 ( 26.177)  Acc@5:  25.000 ( 53.996)
Test: [2450/3167]  Time: 0.202 (0.193)  Loss:   2.540 ( 3.187)  Acc@1:  40.000 ( 26.203)  Acc@5:  85.000 ( 54.199)
Test: [2500/3167]  Time: 0.188 (0.193)  Loss:   3.003 ( 3.186)  Acc@1:  35.000 ( 26.288)  Acc@5:  70.000 ( 54.324)
Test: [2550/3167]  Time: 0.187 (0.193)  Loss:   3.941 ( 3.169)  Acc@1:   0.000 ( 26.914)  Acc@5:  20.000 ( 54.827)
Test: [2600/3167]  Time: 0.190 (0.193)  Loss:   2.594 ( 3.177)  Acc@1:  47.500 ( 26.769)  Acc@5:  75.000 ( 54.485)
Test: [2650/3167]  Time: 0.190 (0.193)  Loss:   3.295 ( 3.183)  Acc@1:  15.000 ( 26.708)  Acc@5:  55.000 ( 54.346)
Test: [2700/3167]  Time: 0.189 (0.193)  Loss:   2.748 ( 3.183)  Acc@1:  40.000 ( 26.716)  Acc@5:  70.000 ( 54.423)
Test: [2750/3167]  Time: 0.204 (0.193)  Loss:   2.493 ( 3.188)  Acc@1:  40.000 ( 26.545)  Acc@5:  85.000 ( 54.195)
Test: [2800/3167]  Time: 0.191 (0.193)  Loss:   3.725 ( 3.186)  Acc@1:  12.500 ( 26.496)  Acc@5:  52.500 ( 54.395)
Test: [2850/3167]  Time: 0.186 (0.193)  Loss:   3.654 ( 3.202)  Acc@1:  10.000 ( 26.100)  Acc@5:  32.500 ( 53.740)
Test: [2900/3167]  Time: 0.188 (0.193)  Loss:   2.917 ( 3.204)  Acc@1:  37.500 ( 26.125)  Acc@5:  72.500 ( 53.747)
Test: [2950/3167]  Time: 0.193 (0.192)  Loss:   3.601 ( 3.213)  Acc@1:   0.000 ( 25.798)  Acc@5:  32.500 ( 53.322)
Test: [3000/3167]  Time: 0.185 (0.192)  Loss:   4.079 ( 3.225)  Acc@1:   2.500 ( 25.404)  Acc@5:  27.500 ( 52.868)
Test: [3050/3167]  Time: 0.187 (0.192)  Loss:   3.873 ( 3.229)  Acc@1:   7.500 ( 25.243)  Acc@5:  22.500 ( 52.765)
Test: [3100/3167]  Time: 0.193 (0.192)  Loss:   3.779 ( 3.239)  Acc@1:   0.000 ( 24.876)  Acc@5:  32.500 ( 52.340)
Test: [3150/3167]  Time: 0.193 (0.192)  Loss:   3.139 ( 3.242)  Acc@1:  10.000 ( 24.688)  Acc@5:  65.000 ( 52.335)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   2.692 ( 3.241)  Acc@1:  33.333 ( 24.666)  Acc@5:  88.889 ( 52.382)
Test: [   0/124]  Time: 0.700 (0.700)  Loss:   3.569 ( 3.569)  Acc@1:  12.500 ( 12.500)  Acc@5:  47.500 ( 47.500)
Test: [  50/124]  Time: 0.190 (0.201)  Loss:   2.909 ( 3.199)  Acc@1:  47.500 ( 26.127)  Acc@5:  75.000 ( 54.657)
Test: [ 100/124]  Time: 0.189 (0.195)  Loss:   2.195 ( 3.262)  Acc@1:  65.000 ( 24.282)  Acc@5:  82.500 ( 50.990)
Test: [ 124/124]  Time: 0.180 (0.194)  Loss:   2.970 ( 3.323)  Acc@1:  17.500 ( 22.340)  Acc@5:  65.000 ( 49.120)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_3/checkpoint-6.pth.tar', 24.665914167674824)

Train: 7 [   0/3167 (  0%)]  Loss: 4.20 (4.20)  Time: 1.097s,   36.47/s  (1.097s,   36.47/s)  LR: 7.300e-05  Data: 0.476 (0.476)
Train: 7 [  50/3167 (  2%)]  Loss: 4.20 (4.00)  Time: 0.601s,   66.57/s  (0.611s,   65.43/s)  LR: 7.300e-05  Data: 0.012 (0.019)
Train: 7 [ 100/3167 (  3%)]  Loss: 4.15 (3.98)  Time: 0.601s,   66.55/s  (0.606s,   65.98/s)  LR: 7.300e-05  Data: 0.011 (0.014)
Train: 7 [ 150/3167 (  5%)]  Loss: 4.05 (3.99)  Time: 0.608s,   65.83/s  (0.605s,   66.13/s)  LR: 7.300e-05  Data: 0.009 (0.013)
Train: 7 [ 200/3167 (  6%)]  Loss: 4.16 (3.98)  Time: 0.607s,   65.92/s  (0.604s,   66.21/s)  LR: 7.300e-05  Data: 0.011 (0.012)
Train: 7 [ 250/3167 (  8%)]  Loss: 3.95 (3.98)  Time: 0.601s,   66.59/s  (0.603s,   66.28/s)  LR: 7.300e-05  Data: 0.012 (0.011)
Train: 7 [ 300/3167 (  9%)]  Loss: 4.17 (3.98)  Time: 0.600s,   66.65/s  (0.603s,   66.32/s)  LR: 7.300e-05  Data: 0.011 (0.011)
Train: 7 [ 350/3167 ( 11%)]  Loss: 4.24 (3.98)  Time: 0.603s,   66.36/s  (0.603s,   66.35/s)  LR: 7.300e-05  Data: 0.011 (0.011)
Train: 7 [ 400/3167 ( 13%)]  Loss: 4.63 (3.99)  Time: 0.601s,   66.59/s  (0.603s,   66.35/s)  LR: 7.300e-05  Data: 0.012 (0.011)
Train: 7 [ 450/3167 ( 14%)]  Loss: 4.08 (3.99)  Time: 0.605s,   66.08/s  (0.603s,   66.38/s)  LR: 7.300e-05  Data: 0.012 (0.011)
Train: 7 [ 500/3167 ( 16%)]  Loss: 3.56 (3.98)  Time: 0.602s,   66.49/s  (0.602s,   66.41/s)  LR: 7.300e-05  Data: 0.006 (0.011)
Train: 7 [ 550/3167 ( 17%)]  Loss: 3.52 (3.98)  Time: 0.600s,   66.62/s  (0.602s,   66.41/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [ 600/3167 ( 19%)]  Loss: 3.44 (3.98)  Time: 0.598s,   66.89/s  (0.602s,   66.42/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [ 650/3167 ( 21%)]  Loss: 4.14 (3.98)  Time: 0.596s,   67.15/s  (0.602s,   66.44/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [ 700/3167 ( 22%)]  Loss: 4.62 (3.99)  Time: 0.598s,   66.84/s  (0.602s,   66.44/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [ 750/3167 ( 24%)]  Loss: 3.88 (3.99)  Time: 0.598s,   66.85/s  (0.602s,   66.46/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [ 800/3167 ( 25%)]  Loss: 3.88 (3.98)  Time: 0.601s,   66.58/s  (0.602s,   66.46/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [ 850/3167 ( 27%)]  Loss: 3.74 (3.99)  Time: 0.598s,   66.88/s  (0.602s,   66.47/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [ 900/3167 ( 28%)]  Loss: 3.84 (3.98)  Time: 0.596s,   67.14/s  (0.602s,   66.48/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [ 950/3167 ( 30%)]  Loss: 3.93 (3.98)  Time: 0.603s,   66.32/s  (0.602s,   66.48/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [1000/3167 ( 32%)]  Loss: 4.17 (3.98)  Time: 0.600s,   66.64/s  (0.602s,   66.49/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [1050/3167 ( 33%)]  Loss: 3.71 (3.98)  Time: 0.600s,   66.62/s  (0.602s,   66.50/s)  LR: 7.300e-05  Data: 0.011 (0.010)
Train: 7 [1100/3167 ( 35%)]  Loss: 4.32 (3.98)  Time: 0.596s,   67.12/s  (0.601s,   66.50/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [1150/3167 ( 36%)]  Loss: 4.31 (3.98)  Time: 0.605s,   66.13/s  (0.601s,   66.51/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [1200/3167 ( 38%)]  Loss: 4.20 (3.98)  Time: 0.598s,   66.86/s  (0.601s,   66.51/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [1250/3167 ( 39%)]  Loss: 3.60 (3.98)  Time: 0.593s,   67.43/s  (0.601s,   66.52/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [1300/3167 ( 41%)]  Loss: 4.23 (3.98)  Time: 0.601s,   66.54/s  (0.601s,   66.52/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [1350/3167 ( 43%)]  Loss: 4.09 (3.98)  Time: 0.593s,   67.44/s  (0.601s,   66.53/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [1400/3167 ( 44%)]  Loss: 4.16 (3.98)  Time: 0.601s,   66.61/s  (0.601s,   66.53/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [1450/3167 ( 46%)]  Loss: 4.03 (3.98)  Time: 0.600s,   66.62/s  (0.601s,   66.54/s)  LR: 7.300e-05  Data: 0.011 (0.010)
Train: 7 [1500/3167 ( 47%)]  Loss: 4.64 (3.97)  Time: 0.600s,   66.64/s  (0.601s,   66.54/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [1550/3167 ( 49%)]  Loss: 4.12 (3.97)  Time: 0.595s,   67.17/s  (0.601s,   66.55/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [1600/3167 ( 51%)]  Loss: 3.73 (3.97)  Time: 0.593s,   67.43/s  (0.601s,   66.55/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [1650/3167 ( 52%)]  Loss: 4.21 (3.97)  Time: 0.603s,   66.34/s  (0.601s,   66.56/s)  LR: 7.300e-05  Data: 0.012 (0.009)
Train: 7 [1700/3167 ( 54%)]  Loss: 3.90 (3.97)  Time: 0.603s,   66.37/s  (0.601s,   66.57/s)  LR: 7.300e-05  Data: 0.011 (0.009)
Train: 7 [1750/3167 ( 55%)]  Loss: 3.91 (3.97)  Time: 0.598s,   66.85/s  (0.601s,   66.57/s)  LR: 7.300e-05  Data: 0.009 (0.009)
Train: 7 [1800/3167 ( 57%)]  Loss: 3.88 (3.97)  Time: 0.604s,   66.27/s  (0.601s,   66.58/s)  LR: 7.300e-05  Data: 0.012 (0.009)
Train: 7 [1850/3167 ( 58%)]  Loss: 3.94 (3.97)  Time: 0.601s,   66.58/s  (0.601s,   66.59/s)  LR: 7.300e-05  Data: 0.012 (0.009)
Train: 7 [1900/3167 ( 60%)]  Loss: 4.03 (3.97)  Time: 0.593s,   67.45/s  (0.601s,   66.59/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [1950/3167 ( 62%)]  Loss: 3.98 (3.97)  Time: 0.597s,   67.03/s  (0.601s,   66.60/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2000/3167 ( 63%)]  Loss: 4.23 (3.97)  Time: 0.595s,   67.24/s  (0.601s,   66.61/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2050/3167 ( 65%)]  Loss: 4.07 (3.97)  Time: 0.599s,   66.83/s  (0.601s,   66.61/s)  LR: 7.300e-05  Data: 0.009 (0.009)
Train: 7 [2100/3167 ( 66%)]  Loss: 4.15 (3.97)  Time: 0.601s,   66.59/s  (0.600s,   66.61/s)  LR: 7.300e-05  Data: 0.010 (0.009)
Train: 7 [2150/3167 ( 68%)]  Loss: 4.22 (3.97)  Time: 0.593s,   67.46/s  (0.600s,   66.62/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2200/3167 ( 69%)]  Loss: 4.30 (3.97)  Time: 0.596s,   67.11/s  (0.600s,   66.63/s)  LR: 7.300e-05  Data: 0.007 (0.009)
Train: 7 [2250/3167 ( 71%)]  Loss: 3.75 (3.97)  Time: 0.596s,   67.12/s  (0.600s,   66.64/s)  LR: 7.300e-05  Data: 0.007 (0.009)
Train: 7 [2300/3167 ( 73%)]  Loss: 4.10 (3.97)  Time: 0.601s,   66.60/s  (0.600s,   66.65/s)  LR: 7.300e-05  Data: 0.012 (0.009)
Train: 7 [2350/3167 ( 74%)]  Loss: 3.50 (3.97)  Time: 0.593s,   67.44/s  (0.600s,   66.65/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2400/3167 ( 76%)]  Loss: 4.14 (3.97)  Time: 0.593s,   67.44/s  (0.600s,   66.66/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2450/3167 ( 77%)]  Loss: 4.20 (3.97)  Time: 0.593s,   67.46/s  (0.600s,   66.67/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2500/3167 ( 79%)]  Loss: 3.38 (3.96)  Time: 0.593s,   67.46/s  (0.600s,   66.67/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2550/3167 ( 81%)]  Loss: 3.80 (3.96)  Time: 0.596s,   67.10/s  (0.600s,   66.68/s)  LR: 7.300e-05  Data: 0.007 (0.009)
Train: 7 [2600/3167 ( 82%)]  Loss: 3.75 (3.96)  Time: 0.595s,   67.18/s  (0.600s,   66.69/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2650/3167 ( 84%)]  Loss: 3.91 (3.96)  Time: 0.593s,   67.41/s  (0.600s,   66.69/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2700/3167 ( 85%)]  Loss: 4.23 (3.96)  Time: 0.593s,   67.44/s  (0.600s,   66.69/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2750/3167 ( 87%)]  Loss: 4.19 (3.96)  Time: 0.593s,   67.43/s  (0.600s,   66.70/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2800/3167 ( 88%)]  Loss: 4.15 (3.96)  Time: 0.593s,   67.45/s  (0.600s,   66.71/s)  LR: 7.300e-05  Data: 0.004 (0.008)
Train: 7 [2850/3167 ( 90%)]  Loss: 3.93 (3.96)  Time: 0.593s,   67.45/s  (0.600s,   66.72/s)  LR: 7.300e-05  Data: 0.004 (0.008)
Train: 7 [2900/3167 ( 92%)]  Loss: 3.97 (3.96)  Time: 0.608s,   65.74/s  (0.599s,   66.72/s)  LR: 7.300e-05  Data: 0.009 (0.008)
Train: 7 [2950/3167 ( 93%)]  Loss: 4.39 (3.96)  Time: 0.596s,   67.07/s  (0.599s,   66.73/s)  LR: 7.300e-05  Data: 0.007 (0.008)
Train: 7 [3000/3167 ( 95%)]  Loss: 3.91 (3.96)  Time: 0.595s,   67.28/s  (0.599s,   66.74/s)  LR: 7.300e-05  Data: 0.004 (0.008)
Train: 7 [3050/3167 ( 96%)]  Loss: 3.90 (3.96)  Time: 0.599s,   66.81/s  (0.599s,   66.74/s)  LR: 7.300e-05  Data: 0.007 (0.008)
Train: 7 [3100/3167 ( 98%)]  Loss: 3.60 (3.96)  Time: 0.594s,   67.32/s  (0.599s,   66.75/s)  LR: 7.300e-05  Data: 0.004 (0.008)
Train: 7 [3150/3167 ( 99%)]  Loss: 4.09 (3.95)  Time: 0.593s,   67.44/s  (0.599s,   66.76/s)  LR: 7.300e-05  Data: 0.004 (0.008)
Test: [   0/3167]  Time: 0.473 (0.473)  Loss:   3.312 ( 3.312)  Acc@1:  27.500 ( 27.500)  Acc@5:  62.500 ( 62.500)
Test: [  50/3167]  Time: 0.185 (0.199)  Loss:   2.969 ( 3.140)  Acc@1:  32.500 ( 31.373)  Acc@5:  57.500 ( 60.931)
Test: [ 100/3167]  Time: 0.206 (0.196)  Loss:   3.476 ( 3.164)  Acc@1:  10.000 ( 22.772)  Acc@5:  52.500 ( 56.460)
Test: [ 150/3167]  Time: 0.184 (0.195)  Loss:   1.880 ( 3.087)  Acc@1:  70.000 ( 26.672)  Acc@5:  95.000 ( 59.338)
Test: [ 200/3167]  Time: 0.191 (0.195)  Loss:   4.006 ( 3.146)  Acc@1:   0.000 ( 24.453)  Acc@5:  20.000 ( 55.659)
Test: [ 250/3167]  Time: 0.194 (0.195)  Loss:   2.353 ( 3.171)  Acc@1:  45.000 ( 24.283)  Acc@5:  75.000 ( 52.699)
Test: [ 300/3167]  Time: 0.190 (0.194)  Loss:   2.674 ( 3.151)  Acc@1:  27.500 ( 25.490)  Acc@5:  72.500 ( 53.978)
Test: [ 350/3167]  Time: 0.190 (0.194)  Loss:   2.705 ( 3.101)  Acc@1:  40.000 ( 26.681)  Acc@5:  72.500 ( 55.919)
Test: [ 400/3167]  Time: 0.195 (0.194)  Loss:   3.045 ( 2.999)  Acc@1:  25.000 ( 29.825)  Acc@5:  60.000 ( 58.585)
Test: [ 450/3167]  Time: 0.189 (0.194)  Loss:   3.218 ( 3.045)  Acc@1:  10.000 ( 27.955)  Acc@5:  60.000 ( 57.633)
Test: [ 500/3167]  Time: 0.190 (0.194)  Loss:   2.356 ( 3.065)  Acc@1:  45.000 ( 28.258)  Acc@5:  75.000 ( 56.846)
Test: [ 550/3167]  Time: 0.194 (0.194)  Loss:   3.888 ( 3.030)  Acc@1:   2.500 ( 29.569)  Acc@5:  37.500 ( 57.786)
Test: [ 600/3167]  Time: 0.199 (0.194)  Loss:   2.879 ( 3.068)  Acc@1:  35.000 ( 28.265)  Acc@5:  60.000 ( 56.626)
Test: [ 650/3167]  Time: 0.211 (0.194)  Loss:   2.272 ( 3.031)  Acc@1:  60.000 ( 29.531)  Acc@5:  90.000 ( 57.535)
Test: [ 700/3167]  Time: 0.189 (0.194)  Loss:   2.400 ( 2.980)  Acc@1:  57.500 ( 31.598)  Acc@5:  90.000 ( 59.544)
Test: [ 750/3167]  Time: 0.190 (0.194)  Loss:   3.334 ( 2.966)  Acc@1:  37.500 ( 32.330)  Acc@5:  45.000 ( 60.376)
Test: [ 800/3167]  Time: 0.194 (0.194)  Loss:   3.872 ( 2.993)  Acc@1:   0.000 ( 31.604)  Acc@5:  27.500 ( 59.316)
Test: [ 850/3167]  Time: 0.192 (0.194)  Loss:   3.257 ( 3.028)  Acc@1:   7.500 ( 30.270)  Acc@5:  57.500 ( 58.246)
Test: [ 900/3167]  Time: 0.202 (0.194)  Loss:   3.505 ( 3.059)  Acc@1:  15.000 ( 29.337)  Acc@5:  50.000 ( 57.519)
Test: [ 950/3167]  Time: 0.202 (0.194)  Loss:   2.504 ( 3.075)  Acc@1:  52.500 ( 28.954)  Acc@5:  72.500 ( 56.869)
Test: [1000/3167]  Time: 0.187 (0.194)  Loss:   3.119 ( 3.096)  Acc@1:  30.000 ( 28.591)  Acc@5:  70.000 ( 56.279)
Test: [1050/3167]  Time: 0.196 (0.194)  Loss:   2.965 ( 3.088)  Acc@1:  27.500 ( 28.490)  Acc@5:  70.000 ( 56.896)
Test: [1100/3167]  Time: 0.199 (0.194)  Loss:   3.226 ( 3.085)  Acc@1:  27.500 ( 28.386)  Acc@5:  57.500 ( 57.250)
Test: [1150/3167]  Time: 0.185 (0.194)  Loss:   2.063 ( 3.066)  Acc@1:  67.500 ( 29.303)  Acc@5:  87.500 ( 57.878)
Test: [1200/3167]  Time: 0.191 (0.194)  Loss:   2.736 ( 3.046)  Acc@1:  37.500 ( 29.827)  Acc@5:  62.500 ( 58.620)
Test: [1250/3167]  Time: 0.192 (0.194)  Loss:   2.735 ( 3.037)  Acc@1:  47.500 ( 30.360)  Acc@5:  65.000 ( 58.951)
Test: [1300/3167]  Time: 0.185 (0.194)  Loss:   3.283 ( 3.047)  Acc@1:  35.000 ( 29.839)  Acc@5:  67.500 ( 58.780)
Test: [1350/3167]  Time: 0.186 (0.194)  Loss:   3.366 ( 3.074)  Acc@1:  22.500 ( 29.202)  Acc@5:  60.000 ( 57.924)
Test: [1400/3167]  Time: 0.195 (0.194)  Loss:   3.391 ( 3.099)  Acc@1:  30.000 ( 28.651)  Acc@5:  60.000 ( 57.082)
Test: [1450/3167]  Time: 0.201 (0.194)  Loss:   3.284 ( 3.104)  Acc@1:  27.500 ( 28.727)  Acc@5:  50.000 ( 57.071)
Test: [1500/3167]  Time: 0.187 (0.194)  Loss:   3.328 ( 3.083)  Acc@1:  12.500 ( 29.442)  Acc@5:  52.500 ( 57.555)
Test: [1550/3167]  Time: 0.184 (0.194)  Loss:   2.051 ( 3.077)  Acc@1:  67.500 ( 29.447)  Acc@5:  82.500 ( 57.780)
Test: [1600/3167]  Time: 0.190 (0.194)  Loss:   2.243 ( 3.076)  Acc@1:  47.500 ( 29.507)  Acc@5:  80.000 ( 57.886)
Test: [1650/3167]  Time: 0.185 (0.194)  Loss:   2.590 ( 3.055)  Acc@1:  32.500 ( 30.064)  Acc@5:  75.000 ( 58.399)
Test: [1700/3167]  Time: 0.197 (0.194)  Loss:   3.998 ( 3.042)  Acc@1:  12.500 ( 30.560)  Acc@5:  27.500 ( 58.673)
Test: [1750/3167]  Time: 0.195 (0.194)  Loss:   2.931 ( 3.050)  Acc@1:  37.500 ( 30.418)  Acc@5:  55.000 ( 58.312)
Test: [1800/3167]  Time: 0.197 (0.194)  Loss:   2.884 ( 3.058)  Acc@1:  27.500 ( 30.283)  Acc@5:  60.000 ( 58.180)
Test: [1850/3167]  Time: 0.186 (0.194)  Loss:   3.053 ( 3.071)  Acc@1:  20.000 ( 29.727)  Acc@5:  62.500 ( 57.512)
Test: [1900/3167]  Time: 0.203 (0.194)  Loss:   3.467 ( 3.072)  Acc@1:  10.000 ( 29.394)  Acc@5:  55.000 ( 57.649)
Test: [1950/3167]  Time: 0.186 (0.194)  Loss:   4.176 ( 3.074)  Acc@1:   0.000 ( 29.286)  Acc@5:  15.000 ( 57.690)
Test: [2000/3167]  Time: 0.190 (0.194)  Loss:   3.864 ( 3.094)  Acc@1:   5.000 ( 28.718)  Acc@5:  30.000 ( 56.987)
Test: [2050/3167]  Time: 0.184 (0.193)  Loss:   3.878 ( 3.111)  Acc@1:   0.000 ( 28.176)  Acc@5:  10.000 ( 56.136)
Test: [2100/3167]  Time: 0.198 (0.193)  Loss:   2.678 ( 3.112)  Acc@1:  42.500 ( 28.229)  Acc@5:  80.000 ( 56.230)
Test: [2150/3167]  Time: 0.187 (0.193)  Loss:   1.335 ( 3.085)  Acc@1:  77.500 ( 28.987)  Acc@5:  90.000 ( 56.937)
Test: [2200/3167]  Time: 0.188 (0.193)  Loss:   3.135 ( 3.078)  Acc@1:   7.500 ( 29.022)  Acc@5:  60.000 ( 57.146)
Test: [2250/3167]  Time: 0.184 (0.193)  Loss:   3.348 ( 3.087)  Acc@1:  45.000 ( 28.699)  Acc@5:  55.000 ( 56.889)
Test: [2300/3167]  Time: 0.198 (0.193)  Loss:   3.352 ( 3.097)  Acc@1:   5.000 ( 28.360)  Acc@5:  50.000 ( 56.525)
Test: [2350/3167]  Time: 0.194 (0.193)  Loss:   3.575 ( 3.102)  Acc@1:  22.500 ( 28.011)  Acc@5:  55.000 ( 56.456)
Test: [2400/3167]  Time: 0.188 (0.193)  Loss:   3.652 ( 3.095)  Acc@1:   7.500 ( 28.247)  Acc@5:  32.500 ( 56.605)
Test: [2450/3167]  Time: 0.197 (0.193)  Loss:   2.428 ( 3.091)  Acc@1:  35.000 ( 28.312)  Acc@5:  82.500 ( 56.861)
Test: [2500/3167]  Time: 0.195 (0.193)  Loss:   2.861 ( 3.081)  Acc@1:  30.000 ( 28.617)  Acc@5:  65.000 ( 57.249)
Test: [2550/3167]  Time: 0.187 (0.193)  Loss:   4.027 ( 3.069)  Acc@1:   2.500 ( 28.961)  Acc@5:  20.000 ( 57.672)
Test: [2600/3167]  Time: 0.186 (0.193)  Loss:   2.790 ( 3.082)  Acc@1:  40.000 ( 28.705)  Acc@5:  70.000 ( 57.191)
Test: [2650/3167]  Time: 0.189 (0.193)  Loss:   3.477 ( 3.094)  Acc@1:  17.500 ( 28.478)  Acc@5:  47.500 ( 56.861)
Test: [2700/3167]  Time: 0.189 (0.193)  Loss:   2.424 ( 3.093)  Acc@1:  47.500 ( 28.579)  Acc@5:  75.000 ( 56.929)
Test: [2750/3167]  Time: 0.199 (0.193)  Loss:   2.288 ( 3.103)  Acc@1:  52.500 ( 28.431)  Acc@5:  87.500 ( 56.586)
Test: [2800/3167]  Time: 0.192 (0.193)  Loss:   3.879 ( 3.102)  Acc@1:   7.500 ( 28.513)  Acc@5:  42.500 ( 56.675)
Test: [2850/3167]  Time: 0.207 (0.193)  Loss:   3.823 ( 3.116)  Acc@1:  12.500 ( 28.071)  Acc@5:  40.000 ( 56.089)
Test: [2900/3167]  Time: 0.189 (0.193)  Loss:   2.842 ( 3.119)  Acc@1:  45.000 ( 28.083)  Acc@5:  67.500 ( 56.089)
Test: [2950/3167]  Time: 0.195 (0.193)  Loss:   3.882 ( 3.130)  Acc@1:   2.500 ( 27.725)  Acc@5:  32.500 ( 55.624)
Test: [3000/3167]  Time: 0.185 (0.193)  Loss:   4.010 ( 3.144)  Acc@1:  10.000 ( 27.352)  Acc@5:  30.000 ( 55.143)
Test: [3050/3167]  Time: 0.187 (0.193)  Loss:   3.777 ( 3.140)  Acc@1:  12.500 ( 27.524)  Acc@5:  27.500 ( 55.378)
Test: [3100/3167]  Time: 0.186 (0.193)  Loss:   4.080 ( 3.153)  Acc@1:   0.000 ( 27.159)  Acc@5:  25.000 ( 54.970)
Test: [3150/3167]  Time: 0.194 (0.193)  Loss:   3.114 ( 3.152)  Acc@1:   2.500 ( 26.972)  Acc@5:  72.500 ( 55.098)
Test: [3167/3167]  Time: 0.043 (0.193)  Loss:   2.729 ( 3.152)  Acc@1:  11.111 ( 26.875)  Acc@5:  88.889 ( 55.123)
Test: [   0/124]  Time: 0.702 (0.702)  Loss:   3.597 ( 3.597)  Acc@1:  17.500 ( 17.500)  Acc@5:  50.000 ( 50.000)
Test: [  50/124]  Time: 0.186 (0.200)  Loss:   3.657 ( 3.170)  Acc@1:  17.500 ( 25.784)  Acc@5:  42.500 ( 53.824)
Test: [ 100/124]  Time: 0.184 (0.194)  Loss:   2.457 ( 3.178)  Acc@1:  50.000 ( 25.272)  Acc@5:  75.000 ( 53.020)
Test: [ 124/124]  Time: 0.180 (0.193)  Loss:   2.904 ( 3.250)  Acc@1:  15.000 ( 23.780)  Acc@5:  65.000 ( 50.940)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_3/checkpoint-7.pth.tar', 26.875261467094763)

Train: 8 [   0/3167 (  0%)]  Loss: 4.22 (4.22)  Time: 1.098s,   36.43/s  (1.098s,   36.43/s)  LR: 8.200e-05  Data: 0.495 (0.495)
Train: 8 [  50/3167 (  2%)]  Loss: 4.19 (4.01)  Time: 0.598s,   66.87/s  (0.611s,   65.43/s)  LR: 8.200e-05  Data: 0.009 (0.019)
Train: 8 [ 100/3167 (  3%)]  Loss: 4.02 (4.00)  Time: 0.601s,   66.61/s  (0.607s,   65.94/s)  LR: 8.200e-05  Data: 0.009 (0.014)
Train: 8 [ 150/3167 (  5%)]  Loss: 3.42 (3.97)  Time: 0.603s,   66.35/s  (0.605s,   66.12/s)  LR: 8.200e-05  Data: 0.011 (0.013)
Train: 8 [ 200/3167 (  6%)]  Loss: 3.92 (3.96)  Time: 0.596s,   67.13/s  (0.604s,   66.22/s)  LR: 8.200e-05  Data: 0.007 (0.012)
Train: 8 [ 250/3167 (  8%)]  Loss: 4.15 (3.94)  Time: 0.601s,   66.52/s  (0.604s,   66.27/s)  LR: 8.200e-05  Data: 0.012 (0.011)
Train: 8 [ 300/3167 (  9%)]  Loss: 3.96 (3.94)  Time: 0.601s,   66.59/s  (0.603s,   66.32/s)  LR: 8.200e-05  Data: 0.011 (0.011)
Train: 8 [ 350/3167 ( 11%)]  Loss: 3.64 (3.94)  Time: 0.598s,   66.85/s  (0.603s,   66.34/s)  LR: 8.200e-05  Data: 0.009 (0.011)
Train: 8 [ 400/3167 ( 13%)]  Loss: 4.08 (3.93)  Time: 0.598s,   66.88/s  (0.603s,   66.36/s)  LR: 8.200e-05  Data: 0.009 (0.011)
Train: 8 [ 450/3167 ( 14%)]  Loss: 4.06 (3.94)  Time: 0.594s,   67.33/s  (0.603s,   66.39/s)  LR: 8.200e-05  Data: 0.004 (0.010)
Train: 8 [ 500/3167 ( 16%)]  Loss: 3.32 (3.93)  Time: 0.601s,   66.60/s  (0.602s,   66.40/s)  LR: 8.200e-05  Data: 0.011 (0.010)
Train: 8 [ 550/3167 ( 17%)]  Loss: 4.06 (3.93)  Time: 0.596s,   67.16/s  (0.602s,   66.41/s)  LR: 8.200e-05  Data: 0.007 (0.010)
Train: 8 [ 600/3167 ( 19%)]  Loss: 4.00 (3.93)  Time: 0.607s,   65.91/s  (0.602s,   66.42/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [ 650/3167 ( 21%)]  Loss: 3.48 (3.93)  Time: 0.600s,   66.64/s  (0.602s,   66.43/s)  LR: 8.200e-05  Data: 0.011 (0.010)
Train: 8 [ 700/3167 ( 22%)]  Loss: 3.21 (3.93)  Time: 0.606s,   66.03/s  (0.602s,   66.43/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [ 750/3167 ( 24%)]  Loss: 3.71 (3.93)  Time: 0.600s,   66.65/s  (0.602s,   66.45/s)  LR: 8.200e-05  Data: 0.011 (0.010)
Train: 8 [ 800/3167 ( 25%)]  Loss: 3.49 (3.93)  Time: 0.606s,   65.96/s  (0.602s,   66.44/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [ 850/3167 ( 27%)]  Loss: 3.78 (3.92)  Time: 0.603s,   66.36/s  (0.602s,   66.45/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [ 900/3167 ( 28%)]  Loss: 4.14 (3.92)  Time: 0.605s,   66.10/s  (0.602s,   66.46/s)  LR: 8.200e-05  Data: 0.010 (0.010)
Train: 8 [ 950/3167 ( 30%)]  Loss: 3.82 (3.92)  Time: 0.600s,   66.64/s  (0.602s,   66.46/s)  LR: 8.200e-05  Data: 0.011 (0.010)
Train: 8 [1000/3167 ( 32%)]  Loss: 3.70 (3.92)  Time: 0.605s,   66.16/s  (0.602s,   66.46/s)  LR: 8.200e-05  Data: 0.007 (0.010)
Train: 8 [1050/3167 ( 33%)]  Loss: 3.63 (3.92)  Time: 0.602s,   66.40/s  (0.602s,   66.47/s)  LR: 8.200e-05  Data: 0.011 (0.010)
Train: 8 [1100/3167 ( 35%)]  Loss: 4.13 (3.92)  Time: 0.602s,   66.43/s  (0.602s,   66.48/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1150/3167 ( 36%)]  Loss: 3.37 (3.92)  Time: 0.598s,   66.89/s  (0.602s,   66.49/s)  LR: 8.200e-05  Data: 0.007 (0.010)
Train: 8 [1200/3167 ( 38%)]  Loss: 3.42 (3.91)  Time: 0.599s,   66.83/s  (0.602s,   66.49/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [1250/3167 ( 39%)]  Loss: 4.16 (3.91)  Time: 0.601s,   66.59/s  (0.601s,   66.50/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1300/3167 ( 41%)]  Loss: 3.73 (3.91)  Time: 0.595s,   67.19/s  (0.601s,   66.51/s)  LR: 8.200e-05  Data: 0.006 (0.010)
Train: 8 [1350/3167 ( 43%)]  Loss: 3.69 (3.91)  Time: 0.601s,   66.53/s  (0.601s,   66.52/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [1400/3167 ( 44%)]  Loss: 3.96 (3.92)  Time: 0.601s,   66.56/s  (0.601s,   66.53/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [1450/3167 ( 46%)]  Loss: 3.69 (3.91)  Time: 0.599s,   66.81/s  (0.601s,   66.54/s)  LR: 8.200e-05  Data: 0.004 (0.009)
Train: 8 [1500/3167 ( 47%)]  Loss: 3.62 (3.91)  Time: 0.603s,   66.34/s  (0.601s,   66.54/s)  LR: 8.200e-05  Data: 0.012 (0.009)
Train: 8 [1550/3167 ( 49%)]  Loss: 4.12 (3.92)  Time: 0.601s,   66.61/s  (0.601s,   66.55/s)  LR: 8.200e-05  Data: 0.012 (0.009)
Train: 8 [1600/3167 ( 51%)]  Loss: 3.63 (3.92)  Time: 0.601s,   66.61/s  (0.601s,   66.56/s)  LR: 8.200e-05  Data: 0.011 (0.009)
Train: 8 [1650/3167 ( 52%)]  Loss: 3.60 (3.92)  Time: 0.596s,   67.15/s  (0.601s,   66.57/s)  LR: 8.200e-05  Data: 0.007 (0.009)
Train: 8 [1700/3167 ( 54%)]  Loss: 3.88 (3.92)  Time: 0.608s,   65.81/s  (0.601s,   66.58/s)  LR: 8.200e-05  Data: 0.011 (0.009)
Train: 8 [1750/3167 ( 55%)]  Loss: 4.11 (3.92)  Time: 0.601s,   66.60/s  (0.601s,   66.58/s)  LR: 8.200e-05  Data: 0.012 (0.009)
Train: 8 [1800/3167 ( 57%)]  Loss: 3.69 (3.92)  Time: 0.601s,   66.59/s  (0.601s,   66.59/s)  LR: 8.200e-05  Data: 0.006 (0.009)
slurmstepd: error: *** JOB 2080296 ON i14 CANCELLED AT 2024-05-20T04:41:07 DUE TO TIME LIMIT ***
