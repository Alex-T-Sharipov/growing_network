Training with a single process on 1 device (cuda:0).
WARNING: No pretrained configuration specified for MONet_T_16_double model. Using a default. Please add a config to the model pretrained_cfg registry or pass explicitly.
Model MONet_T_16_double created, param count:17509380
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.875
	crop_mode: center
AMP not enabled. Training in float32.
/home/sharipov/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Scheduled epochs: 300. LR stepped per epoch.
Train: 0 [   0/3167 (  0%)]  Loss: 4.61 (4.61)  Time: 7.986s,    5.01/s  (7.986s,    5.01/s)  LR: 1.000e-05  Data: 1.754 (1.754)
Train: 0 [  50/3167 (  2%)]  Loss: 4.58 (4.60)  Time: 0.599s,   66.75/s  (0.745s,   53.70/s)  LR: 1.000e-05  Data: 0.007 (0.042)
Train: 0 [ 100/3167 (  3%)]  Loss: 4.58 (4.59)  Time: 0.598s,   66.90/s  (0.672s,   59.51/s)  LR: 1.000e-05  Data: 0.007 (0.024)
Train: 0 [ 150/3167 (  5%)]  Loss: 4.52 (4.58)  Time: 0.599s,   66.75/s  (0.648s,   61.76/s)  LR: 1.000e-05  Data: 0.007 (0.019)
Train: 0 [ 200/3167 (  6%)]  Loss: 4.54 (4.57)  Time: 0.596s,   67.09/s  (0.635s,   62.98/s)  LR: 1.000e-05  Data: 0.007 (0.016)
Train: 0 [ 250/3167 (  8%)]  Loss: 4.52 (4.56)  Time: 0.598s,   66.90/s  (0.628s,   63.73/s)  LR: 1.000e-05  Data: 0.007 (0.014)
Train: 0 [ 300/3167 (  9%)]  Loss: 4.56 (4.55)  Time: 0.599s,   66.77/s  (0.623s,   64.24/s)  LR: 1.000e-05  Data: 0.007 (0.013)
Train: 0 [ 350/3167 ( 11%)]  Loss: 4.51 (4.55)  Time: 0.598s,   66.93/s  (0.619s,   64.61/s)  LR: 1.000e-05  Data: 0.007 (0.012)
Train: 0 [ 400/3167 ( 13%)]  Loss: 4.44 (4.54)  Time: 0.597s,   66.95/s  (0.616s,   64.89/s)  LR: 1.000e-05  Data: 0.007 (0.011)
Train: 0 [ 450/3167 ( 14%)]  Loss: 4.46 (4.53)  Time: 0.599s,   66.78/s  (0.614s,   65.11/s)  LR: 1.000e-05  Data: 0.007 (0.011)
Train: 0 [ 500/3167 ( 16%)]  Loss: 4.48 (4.53)  Time: 0.597s,   66.97/s  (0.613s,   65.29/s)  LR: 1.000e-05  Data: 0.007 (0.010)
Train: 0 [ 550/3167 ( 17%)]  Loss: 4.52 (4.52)  Time: 0.599s,   66.79/s  (0.611s,   65.43/s)  LR: 1.000e-05  Data: 0.006 (0.010)
Train: 0 [ 600/3167 ( 19%)]  Loss: 4.53 (4.52)  Time: 0.599s,   66.76/s  (0.610s,   65.55/s)  LR: 1.000e-05  Data: 0.007 (0.010)
Train: 0 [ 650/3167 ( 21%)]  Loss: 4.45 (4.52)  Time: 0.597s,   67.02/s  (0.609s,   65.66/s)  LR: 1.000e-05  Data: 0.006 (0.009)
Train: 0 [ 700/3167 ( 22%)]  Loss: 4.25 (4.51)  Time: 0.599s,   66.78/s  (0.608s,   65.75/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [ 750/3167 ( 24%)]  Loss: 4.55 (4.51)  Time: 0.597s,   67.03/s  (0.608s,   65.82/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [ 800/3167 ( 25%)]  Loss: 4.32 (4.51)  Time: 0.597s,   67.02/s  (0.607s,   65.89/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [ 850/3167 ( 27%)]  Loss: 4.38 (4.50)  Time: 0.599s,   66.78/s  (0.606s,   65.95/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [ 900/3167 ( 28%)]  Loss: 4.52 (4.50)  Time: 0.598s,   66.88/s  (0.606s,   66.01/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [ 950/3167 ( 30%)]  Loss: 4.46 (4.50)  Time: 0.596s,   67.12/s  (0.606s,   66.05/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [1000/3167 ( 32%)]  Loss: 4.41 (4.50)  Time: 0.599s,   66.79/s  (0.605s,   66.10/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [1050/3167 ( 33%)]  Loss: 4.46 (4.49)  Time: 0.596s,   67.06/s  (0.605s,   66.14/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1100/3167 ( 35%)]  Loss: 4.55 (4.49)  Time: 0.599s,   66.82/s  (0.604s,   66.17/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1150/3167 ( 36%)]  Loss: 4.61 (4.49)  Time: 0.598s,   66.84/s  (0.604s,   66.21/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1200/3167 ( 38%)]  Loss: 4.46 (4.49)  Time: 0.599s,   66.77/s  (0.604s,   66.24/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1250/3167 ( 39%)]  Loss: 4.48 (4.48)  Time: 0.596s,   67.09/s  (0.604s,   66.26/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1300/3167 ( 41%)]  Loss: 4.56 (4.48)  Time: 0.596s,   67.10/s  (0.603s,   66.29/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1350/3167 ( 43%)]  Loss: 4.45 (4.48)  Time: 0.599s,   66.80/s  (0.603s,   66.31/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1400/3167 ( 44%)]  Loss: 4.57 (4.48)  Time: 0.599s,   66.83/s  (0.603s,   66.33/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1450/3167 ( 46%)]  Loss: 4.47 (4.48)  Time: 0.597s,   66.95/s  (0.603s,   66.35/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1500/3167 ( 47%)]  Loss: 4.63 (4.48)  Time: 0.599s,   66.76/s  (0.603s,   66.37/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1550/3167 ( 49%)]  Loss: 4.59 (4.48)  Time: 0.599s,   66.79/s  (0.602s,   66.39/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1600/3167 ( 51%)]  Loss: 4.45 (4.47)  Time: 0.596s,   67.09/s  (0.602s,   66.41/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1650/3167 ( 52%)]  Loss: 4.39 (4.47)  Time: 0.597s,   67.05/s  (0.602s,   66.42/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1700/3167 ( 54%)]  Loss: 4.47 (4.47)  Time: 0.598s,   66.87/s  (0.602s,   66.44/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1750/3167 ( 55%)]  Loss: 4.39 (4.47)  Time: 0.598s,   66.94/s  (0.602s,   66.45/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1800/3167 ( 57%)]  Loss: 4.43 (4.47)  Time: 0.597s,   67.04/s  (0.602s,   66.47/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1850/3167 ( 58%)]  Loss: 4.31 (4.47)  Time: 0.596s,   67.14/s  (0.602s,   66.48/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1900/3167 ( 60%)]  Loss: 4.46 (4.47)  Time: 0.598s,   66.85/s  (0.602s,   66.49/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1950/3167 ( 62%)]  Loss: 4.41 (4.47)  Time: 0.597s,   66.97/s  (0.601s,   66.51/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2000/3167 ( 63%)]  Loss: 4.19 (4.47)  Time: 0.597s,   66.97/s  (0.601s,   66.52/s)  LR: 1.000e-05  Data: 0.006 (0.008)
Train: 0 [2050/3167 ( 65%)]  Loss: 4.50 (4.47)  Time: 0.597s,   66.95/s  (0.601s,   66.53/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2100/3167 ( 66%)]  Loss: 4.39 (4.46)  Time: 0.599s,   66.73/s  (0.601s,   66.54/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2150/3167 ( 68%)]  Loss: 4.48 (4.46)  Time: 0.596s,   67.13/s  (0.601s,   66.55/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2200/3167 ( 69%)]  Loss: 4.43 (4.46)  Time: 0.600s,   66.62/s  (0.601s,   66.56/s)  LR: 1.000e-05  Data: 0.010 (0.008)
Train: 0 [2250/3167 ( 71%)]  Loss: 4.29 (4.46)  Time: 0.596s,   67.11/s  (0.601s,   66.56/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2300/3167 ( 73%)]  Loss: 4.40 (4.46)  Time: 0.596s,   67.15/s  (0.601s,   66.57/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2350/3167 ( 74%)]  Loss: 4.47 (4.46)  Time: 0.596s,   67.07/s  (0.601s,   66.58/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2400/3167 ( 76%)]  Loss: 4.53 (4.46)  Time: 0.601s,   66.58/s  (0.601s,   66.59/s)  LR: 1.000e-05  Data: 0.009 (0.008)
Train: 0 [2450/3167 ( 77%)]  Loss: 4.35 (4.46)  Time: 0.596s,   67.07/s  (0.601s,   66.60/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2500/3167 ( 79%)]  Loss: 4.26 (4.46)  Time: 0.596s,   67.12/s  (0.601s,   66.61/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2550/3167 ( 81%)]  Loss: 4.30 (4.46)  Time: 0.596s,   67.15/s  (0.600s,   66.61/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2600/3167 ( 82%)]  Loss: 4.44 (4.45)  Time: 0.597s,   67.04/s  (0.600s,   66.62/s)  LR: 1.000e-05  Data: 0.007 (0.007)
Train: 0 [2650/3167 ( 84%)]  Loss: 4.39 (4.45)  Time: 0.598s,   66.84/s  (0.600s,   66.63/s)  LR: 1.000e-05  Data: 0.007 (0.007)
Train: 0 [2700/3167 ( 85%)]  Loss: 4.40 (4.45)  Time: 0.599s,   66.82/s  (0.600s,   66.63/s)  LR: 1.000e-05  Data: 0.007 (0.007)
Train: 0 [2750/3167 ( 87%)]  Loss: 4.39 (4.45)  Time: 0.596s,   67.16/s  (0.600s,   66.64/s)  LR: 1.000e-05  Data: 0.007 (0.007)
Train: 0 [2800/3167 ( 88%)]  Loss: 4.42 (4.45)  Time: 0.598s,   66.87/s  (0.600s,   66.65/s)  LR: 1.000e-05  Data: 0.007 (0.007)
Train: 0 [2850/3167 ( 90%)]  Loss: 4.14 (4.45)  Time: 0.596s,   67.13/s  (0.600s,   66.65/s)  LR: 1.000e-05  Data: 0.007 (0.007)
Train: 0 [2900/3167 ( 92%)]  Loss: 4.46 (4.45)  Time: 0.596s,   67.16/s  (0.600s,   66.66/s)  LR: 1.000e-05  Data: 0.006 (0.007)
Train: 0 [2950/3167 ( 93%)]  Loss: 4.48 (4.45)  Time: 0.599s,   66.83/s  (0.600s,   66.66/s)  LR: 1.000e-05  Data: 0.007 (0.007)
Train: 0 [3000/3167 ( 95%)]  Loss: 4.32 (4.45)  Time: 0.598s,   66.86/s  (0.600s,   66.67/s)  LR: 1.000e-05  Data: 0.007 (0.007)
Train: 0 [3050/3167 ( 96%)]  Loss: 4.54 (4.45)  Time: 0.596s,   67.07/s  (0.600s,   66.67/s)  LR: 1.000e-05  Data: 0.007 (0.007)
Train: 0 [3100/3167 ( 98%)]  Loss: 4.58 (4.45)  Time: 0.599s,   66.75/s  (0.600s,   66.67/s)  LR: 1.000e-05  Data: 0.009 (0.007)
Train: 0 [3150/3167 ( 99%)]  Loss: 4.54 (4.45)  Time: 0.596s,   67.12/s  (0.600s,   66.68/s)  LR: 1.000e-05  Data: 0.007 (0.007)
Test: [   0/3167]  Time: 2.374 (2.374)  Loss:   4.325 ( 4.325)  Acc@1:   2.500 (  2.500)  Acc@5:  15.000 ( 15.000)
Test: [  50/3167]  Time: 0.202 (0.237)  Loss:   4.111 ( 4.132)  Acc@1:  10.000 (  5.833)  Acc@5:  40.000 ( 30.147)
Test: [ 100/3167]  Time: 0.195 (0.216)  Loss:   4.414 ( 4.159)  Acc@1:   0.000 (  5.594)  Acc@5:   2.500 ( 27.351)
Test: [ 150/3167]  Time: 0.187 (0.209)  Loss:   3.744 ( 4.164)  Acc@1:  15.000 (  5.911)  Acc@5:  70.000 ( 26.987)
Test: [ 200/3167]  Time: 0.186 (0.205)  Loss:   4.490 ( 4.210)  Acc@1:   0.000 (  5.386)  Acc@5:   0.000 ( 23.607)
Test: [ 250/3167]  Time: 0.199 (0.202)  Loss:   4.555 ( 4.263)  Acc@1:   0.000 (  4.432)  Acc@5:  10.000 ( 19.731)
Test: [ 300/3167]  Time: 0.189 (0.201)  Loss:   4.002 ( 4.273)  Acc@1:   0.000 (  3.746)  Acc@5:  52.500 ( 20.050)
Test: [ 350/3167]  Time: 0.195 (0.199)  Loss:   3.988 ( 4.246)  Acc@1:  30.000 (  4.865)  Acc@5:  55.000 ( 23.640)
Test: [ 400/3167]  Time: 0.183 (0.198)  Loss:   4.122 ( 4.127)  Acc@1:   0.000 ( 10.549)  Acc@5:  40.000 ( 29.071)
Test: [ 450/3167]  Time: 0.202 (0.197)  Loss:   4.178 ( 4.134)  Acc@1:   0.000 (  9.473)  Acc@5:  30.000 ( 28.692)
Test: [ 500/3167]  Time: 0.187 (0.197)  Loss:   4.419 ( 4.165)  Acc@1:   2.500 (  8.603)  Acc@5:  15.000 ( 26.607)
Test: [ 550/3167]  Time: 0.195 (0.196)  Loss:   4.608 ( 4.126)  Acc@1:   0.000 (  9.569)  Acc@5:   0.000 ( 28.584)
Test: [ 600/3167]  Time: 0.197 (0.195)  Loss:   3.731 ( 4.142)  Acc@1:   5.000 (  9.027)  Acc@5:  42.500 ( 27.903)
Test: [ 650/3167]  Time: 0.188 (0.195)  Loss:   4.439 ( 4.138)  Acc@1:   0.000 (  8.932)  Acc@5:   2.500 ( 28.291)
Test: [ 700/3167]  Time: 0.201 (0.195)  Loss:   4.347 ( 4.156)  Acc@1:   0.000 (  8.327)  Acc@5:   7.500 ( 26.730)
Test: [ 750/3167]  Time: 0.194 (0.195)  Loss:   3.976 ( 4.155)  Acc@1:   5.000 (  8.089)  Acc@5:  45.000 ( 26.485)
Test: [ 800/3167]  Time: 0.187 (0.194)  Loss:   4.429 ( 4.155)  Acc@1:   0.000 (  7.993)  Acc@5:  10.000 ( 26.464)
Test: [ 850/3167]  Time: 0.202 (0.194)  Loss:   4.448 ( 4.172)  Acc@1:   0.000 (  7.535)  Acc@5:   0.000 ( 25.115)
Test: [ 900/3167]  Time: 0.198 (0.194)  Loss:   4.410 ( 4.188)  Acc@1:   0.000 (  7.120)  Acc@5:   5.000 ( 23.826)
Test: [ 950/3167]  Time: 0.185 (0.194)  Loss:   4.219 ( 4.200)  Acc@1:   0.000 (  6.759)  Acc@5:  10.000 ( 22.850)
Test: [1000/3167]  Time: 0.191 (0.194)  Loss:   4.284 ( 4.210)  Acc@1:   0.000 (  6.426)  Acc@5:  15.000 ( 22.020)
Test: [1050/3167]  Time: 0.189 (0.194)  Loss:   3.954 ( 4.202)  Acc@1:   7.500 (  6.299)  Acc@5:  32.500 ( 22.188)
Test: [1100/3167]  Time: 0.192 (0.193)  Loss:   4.383 ( 4.209)  Acc@1:   0.000 (  6.063)  Acc@5:  10.000 ( 21.469)
Test: [1150/3167]  Time: 0.184 (0.193)  Loss:   3.927 ( 4.205)  Acc@1:  12.500 (  5.977)  Acc@5:  42.500 ( 21.898)
Test: [1200/3167]  Time: 0.183 (0.193)  Loss:   3.089 ( 4.190)  Acc@1:  45.000 (  6.715)  Acc@5:  82.500 ( 23.168)
Test: [1250/3167]  Time: 0.185 (0.193)  Loss:   3.513 ( 4.161)  Acc@1:  62.500 (  8.515)  Acc@5:  80.000 ( 25.046)
Test: [1300/3167]  Time: 0.192 (0.193)  Loss:   4.240 ( 4.169)  Acc@1:   0.000 (  8.248)  Acc@5:   5.000 ( 24.406)
Test: [1350/3167]  Time: 0.192 (0.193)  Loss:   4.409 ( 4.182)  Acc@1:   0.000 (  7.942)  Acc@5:   5.000 ( 23.677)
Test: [1400/3167]  Time: 0.191 (0.193)  Loss:   3.711 ( 4.194)  Acc@1:  22.500 (  7.721)  Acc@5:  62.500 ( 23.173)
Test: [1450/3167]  Time: 0.185 (0.193)  Loss:   4.489 ( 4.189)  Acc@1:   0.000 (  7.946)  Acc@5:   0.000 ( 23.803)
Test: [1500/3167]  Time: 0.195 (0.193)  Loss:   4.262 ( 4.166)  Acc@1:   2.500 (  9.059)  Acc@5:  15.000 ( 24.639)
Test: [1550/3167]  Time: 0.184 (0.192)  Loss:   4.073 ( 4.168)  Acc@1:   2.500 (  8.846)  Acc@5:  30.000 ( 24.657)
Test: [1600/3167]  Time: 0.185 (0.192)  Loss:   2.956 ( 4.160)  Acc@1:  37.500 (  8.938)  Acc@5:  77.500 ( 25.334)
Test: [1650/3167]  Time: 0.193 (0.192)  Loss:   4.029 ( 4.141)  Acc@1:   2.500 (  9.511)  Acc@5:  32.500 ( 26.167)
Test: [1700/3167]  Time: 0.199 (0.192)  Loss:   4.170 ( 4.136)  Acc@1:   2.500 (  9.295)  Acc@5:  20.000 ( 26.617)
Test: [1750/3167]  Time: 0.190 (0.192)  Loss:   4.073 ( 4.137)  Acc@1:   0.000 (  9.093)  Acc@5:  27.500 ( 26.696)
Test: [1800/3167]  Time: 0.184 (0.192)  Loss:   4.301 ( 4.138)  Acc@1:   0.000 (  8.995)  Acc@5:  12.500 ( 26.763)
Test: [1850/3167]  Time: 0.213 (0.192)  Loss:   4.555 ( 4.147)  Acc@1:   0.000 (  8.752)  Acc@5:   5.000 ( 26.112)
Test: [1900/3167]  Time: 0.206 (0.192)  Loss:   4.551 ( 4.156)  Acc@1:   0.000 (  8.526)  Acc@5:   0.000 ( 25.526)
Test: [1950/3167]  Time: 0.203 (0.192)  Loss:   4.542 ( 4.162)  Acc@1:   0.000 (  8.348)  Acc@5:   0.000 ( 25.186)
Test: [2000/3167]  Time: 0.187 (0.192)  Loss:   4.708 ( 4.175)  Acc@1:   0.000 (  8.140)  Acc@5:   0.000 ( 24.613)
Test: [2050/3167]  Time: 0.191 (0.192)  Loss:   4.545 ( 4.185)  Acc@1:   0.000 (  7.941)  Acc@5:   0.000 ( 24.014)
Test: [2100/3167]  Time: 0.193 (0.192)  Loss:   4.330 ( 4.185)  Acc@1:   5.000 (  8.109)  Acc@5:  17.500 ( 24.296)
Test: [2150/3167]  Time: 0.204 (0.192)  Loss:   2.001 ( 4.160)  Acc@1:  77.500 (  8.928)  Acc@5:  90.000 ( 24.954)
Test: [2200/3167]  Time: 0.184 (0.192)  Loss:   4.354 ( 4.157)  Acc@1:   0.000 (  9.035)  Acc@5:  15.000 ( 25.258)
Test: [2250/3167]  Time: 0.186 (0.192)  Loss:   4.019 ( 4.163)  Acc@1:   0.000 (  8.845)  Acc@5:  50.000 ( 25.100)
Test: [2300/3167]  Time: 0.201 (0.192)  Loss:   4.374 ( 4.168)  Acc@1:   0.000 (  8.674)  Acc@5:  12.500 ( 25.001)
Test: [2350/3167]  Time: 0.191 (0.192)  Loss:   4.150 ( 4.170)  Acc@1:  10.000 (  8.589)  Acc@5:  47.500 ( 24.899)
Test: [2400/3167]  Time: 0.190 (0.192)  Loss:   4.458 ( 4.169)  Acc@1:   0.000 (  8.799)  Acc@5:   5.000 ( 25.054)
Test: [2450/3167]  Time: 0.184 (0.192)  Loss:   4.083 ( 4.171)  Acc@1:   5.000 (  8.644)  Acc@5:  22.500 ( 24.807)
Test: [2500/3167]  Time: 0.191 (0.191)  Loss:   4.319 ( 4.171)  Acc@1:   5.000 (  8.631)  Acc@5:  30.000 ( 25.034)
Test: [2550/3167]  Time: 0.184 (0.191)  Loss:   4.140 ( 4.166)  Acc@1:   0.000 (  8.580)  Acc@5:  17.500 ( 25.536)
Test: [2600/3167]  Time: 0.184 (0.191)  Loss:   3.988 ( 4.165)  Acc@1:   5.000 (  8.481)  Acc@5:  32.500 ( 25.500)
Test: [2650/3167]  Time: 0.188 (0.191)  Loss:   4.319 ( 4.168)  Acc@1:   2.500 (  8.354)  Acc@5:  20.000 ( 25.290)
Test: [2700/3167]  Time: 0.195 (0.191)  Loss:   4.189 ( 4.170)  Acc@1:   2.500 (  8.245)  Acc@5:  27.500 ( 25.306)
Test: [2750/3167]  Time: 0.186 (0.191)  Loss:   3.948 ( 4.171)  Acc@1:   2.500 (  8.132)  Acc@5:  47.500 ( 25.284)
Test: [2800/3167]  Time: 0.188 (0.191)  Loss:   4.214 ( 4.171)  Acc@1:   0.000 (  8.050)  Acc@5:  27.500 ( 25.443)
Test: [2850/3167]  Time: 0.186 (0.191)  Loss:   3.957 ( 4.174)  Acc@1:   2.500 (  7.930)  Acc@5:  55.000 ( 25.296)
Test: [2900/3167]  Time: 0.201 (0.191)  Loss:   4.182 ( 4.172)  Acc@1:   2.500 (  7.844)  Acc@5:  20.000 ( 25.402)
Test: [2950/3167]  Time: 0.188 (0.191)  Loss:   4.333 ( 4.175)  Acc@1:   0.000 (  7.712)  Acc@5:  10.000 ( 25.034)
Test: [3000/3167]  Time: 0.184 (0.191)  Loss:   4.330 ( 4.178)  Acc@1:   0.000 (  7.584)  Acc@5:   0.000 ( 24.665)
Test: [3050/3167]  Time: 0.186 (0.191)  Loss:   4.416 ( 4.179)  Acc@1:   0.000 (  7.511)  Acc@5:   0.000 ( 24.509)
Test: [3100/3167]  Time: 0.190 (0.191)  Loss:   4.255 ( 4.182)  Acc@1:   0.000 (  7.394)  Acc@5:  20.000 ( 24.276)
Test: [3150/3167]  Time: 0.192 (0.191)  Loss:   4.465 ( 4.186)  Acc@1:   0.000 (  7.280)  Acc@5:   2.500 ( 23.956)
Test: [3167/3167]  Time: 0.320 (0.191)  Loss:   4.452 ( 4.187)  Acc@1:   0.000 (  7.243)  Acc@5:   0.000 ( 23.847)
Test: [   0/124]  Time: 1.855 (1.855)  Loss:   4.317 ( 4.317)  Acc@1:   0.000 (  0.000)  Acc@5:   7.500 (  7.500)
Test: [  50/124]  Time: 0.195 (0.222)  Loss:   4.367 ( 4.204)  Acc@1:   0.000 (  7.353)  Acc@5:  12.500 ( 23.775)
Test: [ 100/124]  Time: 0.185 (0.205)  Loss:   3.542 ( 4.205)  Acc@1:   5.000 (  7.525)  Acc@5:  70.000 ( 25.025)
Test: [ 124/124]  Time: 0.180 (0.202)  Loss:   4.449 ( 4.220)  Acc@1:   0.000 (  6.400)  Acc@5:   2.500 ( 23.280)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_2/checkpoint-0.pth.tar', 7.242933482780668)

Train: 1 [   0/3167 (  0%)]  Loss: 4.38 (4.38)  Time: 1.144s,   34.97/s  (1.144s,   34.97/s)  LR: 1.900e-05  Data: 0.545 (0.545)
Train: 1 [  50/3167 (  2%)]  Loss: 4.40 (4.40)  Time: 0.593s,   67.48/s  (0.609s,   65.70/s)  LR: 1.900e-05  Data: 0.004 (0.017)
Train: 1 [ 100/3167 (  3%)]  Loss: 4.22 (4.38)  Time: 0.596s,   67.15/s  (0.603s,   66.29/s)  LR: 1.900e-05  Data: 0.007 (0.012)
Train: 1 [ 150/3167 (  5%)]  Loss: 4.50 (4.39)  Time: 0.603s,   66.35/s  (0.602s,   66.44/s)  LR: 1.900e-05  Data: 0.004 (0.011)
Train: 1 [ 200/3167 (  6%)]  Loss: 4.33 (4.39)  Time: 0.603s,   66.30/s  (0.601s,   66.52/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [ 250/3167 (  8%)]  Loss: 4.29 (4.39)  Time: 0.605s,   66.07/s  (0.601s,   66.58/s)  LR: 1.900e-05  Data: 0.011 (0.010)
Train: 1 [ 300/3167 (  9%)]  Loss: 4.44 (4.39)  Time: 0.605s,   66.14/s  (0.600s,   66.62/s)  LR: 1.900e-05  Data: 0.009 (0.010)
Train: 1 [ 350/3167 ( 11%)]  Loss: 4.23 (4.40)  Time: 0.596s,   67.15/s  (0.600s,   66.66/s)  LR: 1.900e-05  Data: 0.004 (0.009)
Train: 1 [ 400/3167 ( 13%)]  Loss: 4.11 (4.40)  Time: 0.598s,   66.85/s  (0.600s,   66.67/s)  LR: 1.900e-05  Data: 0.009 (0.009)
Train: 1 [ 450/3167 ( 14%)]  Loss: 4.59 (4.39)  Time: 0.596s,   67.11/s  (0.600s,   66.70/s)  LR: 1.900e-05  Data: 0.007 (0.009)
Train: 1 [ 500/3167 ( 16%)]  Loss: 4.33 (4.39)  Time: 0.598s,   66.87/s  (0.600s,   66.71/s)  LR: 1.900e-05  Data: 0.009 (0.009)
Train: 1 [ 550/3167 ( 17%)]  Loss: 4.24 (4.39)  Time: 0.596s,   67.17/s  (0.599s,   66.73/s)  LR: 1.900e-05  Data: 0.006 (0.009)
Train: 1 [ 600/3167 ( 19%)]  Loss: 4.23 (4.39)  Time: 0.593s,   67.47/s  (0.599s,   66.75/s)  LR: 1.900e-05  Data: 0.004 (0.009)
Train: 1 [ 650/3167 ( 21%)]  Loss: 4.39 (4.39)  Time: 0.601s,   66.54/s  (0.599s,   66.76/s)  LR: 1.900e-05  Data: 0.012 (0.008)
Train: 1 [ 700/3167 ( 22%)]  Loss: 4.34 (4.39)  Time: 0.596s,   67.16/s  (0.599s,   66.77/s)  LR: 1.900e-05  Data: 0.004 (0.008)
Train: 1 [ 750/3167 ( 24%)]  Loss: 4.22 (4.39)  Time: 0.593s,   67.45/s  (0.599s,   66.78/s)  LR: 1.900e-05  Data: 0.004 (0.008)
Train: 1 [ 800/3167 ( 25%)]  Loss: 4.28 (4.39)  Time: 0.596s,   67.16/s  (0.599s,   66.79/s)  LR: 1.900e-05  Data: 0.007 (0.008)
Train: 1 [ 850/3167 ( 27%)]  Loss: 4.28 (4.39)  Time: 0.599s,   66.83/s  (0.599s,   66.79/s)  LR: 1.900e-05  Data: 0.009 (0.008)
Train: 1 [ 900/3167 ( 28%)]  Loss: 4.31 (4.39)  Time: 0.596s,   67.16/s  (0.599s,   66.80/s)  LR: 1.900e-05  Data: 0.006 (0.008)
Train: 1 [ 950/3167 ( 30%)]  Loss: 4.33 (4.39)  Time: 0.595s,   67.20/s  (0.599s,   66.81/s)  LR: 1.900e-05  Data: 0.006 (0.008)
Train: 1 [1000/3167 ( 32%)]  Loss: 4.42 (4.39)  Time: 0.596s,   67.06/s  (0.599s,   66.81/s)  LR: 1.900e-05  Data: 0.007 (0.008)
Train: 1 [1050/3167 ( 33%)]  Loss: 4.35 (4.38)  Time: 0.603s,   66.37/s  (0.599s,   66.82/s)  LR: 1.900e-05  Data: 0.012 (0.008)
Train: 1 [1100/3167 ( 35%)]  Loss: 4.42 (4.38)  Time: 0.598s,   66.89/s  (0.599s,   66.82/s)  LR: 1.900e-05  Data: 0.004 (0.008)
Train: 1 [1150/3167 ( 36%)]  Loss: 4.50 (4.38)  Time: 0.600s,   66.70/s  (0.599s,   66.82/s)  LR: 1.900e-05  Data: 0.009 (0.008)
Train: 1 [1200/3167 ( 38%)]  Loss: 4.52 (4.38)  Time: 0.593s,   67.47/s  (0.599s,   66.83/s)  LR: 1.900e-05  Data: 0.004 (0.008)
Train: 1 [1250/3167 ( 39%)]  Loss: 4.30 (4.38)  Time: 0.593s,   67.46/s  (0.599s,   66.83/s)  LR: 1.900e-05  Data: 0.004 (0.008)
Train: 1 [1300/3167 ( 41%)]  Loss: 4.49 (4.38)  Time: 0.597s,   66.99/s  (0.598s,   66.84/s)  LR: 1.900e-05  Data: 0.006 (0.008)
Train: 1 [1350/3167 ( 43%)]  Loss: 4.15 (4.38)  Time: 0.595s,   67.17/s  (0.598s,   66.84/s)  LR: 1.900e-05  Data: 0.006 (0.008)
Train: 1 [1400/3167 ( 44%)]  Loss: 4.41 (4.38)  Time: 0.605s,   66.07/s  (0.598s,   66.85/s)  LR: 1.900e-05  Data: 0.012 (0.008)
Train: 1 [1450/3167 ( 46%)]  Loss: 4.30 (4.38)  Time: 0.596s,   67.14/s  (0.598s,   66.86/s)  LR: 1.900e-05  Data: 0.006 (0.008)
Train: 1 [1500/3167 ( 47%)]  Loss: 4.41 (4.38)  Time: 0.596s,   67.09/s  (0.598s,   66.86/s)  LR: 1.900e-05  Data: 0.007 (0.008)
Train: 1 [1550/3167 ( 49%)]  Loss: 4.52 (4.38)  Time: 0.598s,   66.86/s  (0.598s,   66.87/s)  LR: 1.900e-05  Data: 0.009 (0.008)
Train: 1 [1600/3167 ( 51%)]  Loss: 4.29 (4.38)  Time: 0.596s,   67.15/s  (0.598s,   66.87/s)  LR: 1.900e-05  Data: 0.004 (0.008)
Train: 1 [1650/3167 ( 52%)]  Loss: 4.40 (4.38)  Time: 0.600s,   66.63/s  (0.598s,   66.88/s)  LR: 1.900e-05  Data: 0.004 (0.008)
Train: 1 [1700/3167 ( 54%)]  Loss: 4.32 (4.38)  Time: 0.596s,   67.11/s  (0.598s,   66.88/s)  LR: 1.900e-05  Data: 0.007 (0.008)
Train: 1 [1750/3167 ( 55%)]  Loss: 4.28 (4.38)  Time: 0.594s,   67.39/s  (0.598s,   66.89/s)  LR: 1.900e-05  Data: 0.004 (0.008)
Train: 1 [1800/3167 ( 57%)]  Loss: 4.42 (4.38)  Time: 0.594s,   67.34/s  (0.598s,   66.89/s)  LR: 1.900e-05  Data: 0.004 (0.007)
Train: 1 [1850/3167 ( 58%)]  Loss: 4.25 (4.38)  Time: 0.601s,   66.53/s  (0.598s,   66.89/s)  LR: 1.900e-05  Data: 0.012 (0.007)
Train: 1 [1900/3167 ( 60%)]  Loss: 4.38 (4.38)  Time: 0.599s,   66.81/s  (0.598s,   66.90/s)  LR: 1.900e-05  Data: 0.007 (0.007)
Train: 1 [1950/3167 ( 62%)]  Loss: 4.41 (4.38)  Time: 0.607s,   65.89/s  (0.598s,   66.90/s)  LR: 1.900e-05  Data: 0.009 (0.007)
Train: 1 [2000/3167 ( 63%)]  Loss: 4.28 (4.38)  Time: 0.597s,   66.99/s  (0.598s,   66.91/s)  LR: 1.900e-05  Data: 0.007 (0.007)
Train: 1 [2050/3167 ( 65%)]  Loss: 4.38 (4.38)  Time: 0.599s,   66.83/s  (0.598s,   66.91/s)  LR: 1.900e-05  Data: 0.009 (0.007)
Train: 1 [2100/3167 ( 66%)]  Loss: 4.48 (4.38)  Time: 0.593s,   67.47/s  (0.598s,   66.91/s)  LR: 1.900e-05  Data: 0.004 (0.007)
Train: 1 [2150/3167 ( 68%)]  Loss: 4.27 (4.38)  Time: 0.600s,   66.70/s  (0.598s,   66.92/s)  LR: 1.900e-05  Data: 0.009 (0.007)
Train: 1 [2200/3167 ( 69%)]  Loss: 4.22 (4.38)  Time: 0.593s,   67.46/s  (0.598s,   66.92/s)  LR: 1.900e-05  Data: 0.004 (0.007)
Train: 1 [2250/3167 ( 71%)]  Loss: 4.38 (4.38)  Time: 0.593s,   67.43/s  (0.598s,   66.92/s)  LR: 1.900e-05  Data: 0.004 (0.007)
Train: 1 [2300/3167 ( 73%)]  Loss: 4.42 (4.37)  Time: 0.598s,   66.88/s  (0.598s,   66.93/s)  LR: 1.900e-05  Data: 0.007 (0.007)
Train: 1 [2350/3167 ( 74%)]  Loss: 4.34 (4.37)  Time: 0.594s,   67.33/s  (0.598s,   66.93/s)  LR: 1.900e-05  Data: 0.004 (0.007)
Train: 1 [2400/3167 ( 76%)]  Loss: 4.25 (4.37)  Time: 0.593s,   67.46/s  (0.598s,   66.93/s)  LR: 1.900e-05  Data: 0.004 (0.007)
Train: 1 [2450/3167 ( 77%)]  Loss: 4.54 (4.37)  Time: 0.596s,   67.08/s  (0.598s,   66.93/s)  LR: 1.900e-05  Data: 0.004 (0.007)
Train: 1 [2500/3167 ( 79%)]  Loss: 4.24 (4.37)  Time: 0.599s,   66.78/s  (0.598s,   66.93/s)  LR: 1.900e-05  Data: 0.010 (0.007)
Train: 1 [2550/3167 ( 81%)]  Loss: 4.58 (4.37)  Time: 0.595s,   67.18/s  (0.598s,   66.94/s)  LR: 1.900e-05  Data: 0.006 (0.007)
Train: 1 [2600/3167 ( 82%)]  Loss: 4.44 (4.37)  Time: 0.595s,   67.20/s  (0.598s,   66.94/s)  LR: 1.900e-05  Data: 0.004 (0.007)
Train: 1 [2650/3167 ( 84%)]  Loss: 4.23 (4.37)  Time: 0.595s,   67.18/s  (0.598s,   66.94/s)  LR: 1.900e-05  Data: 0.004 (0.007)
Train: 1 [2700/3167 ( 85%)]  Loss: 4.36 (4.37)  Time: 0.593s,   67.48/s  (0.598s,   66.94/s)  LR: 1.900e-05  Data: 0.004 (0.007)
Train: 1 [2750/3167 ( 87%)]  Loss: 4.63 (4.37)  Time: 0.596s,   67.16/s  (0.597s,   66.95/s)  LR: 1.900e-05  Data: 0.006 (0.007)
Train: 1 [2800/3167 ( 88%)]  Loss: 4.40 (4.37)  Time: 0.593s,   67.48/s  (0.597s,   66.95/s)  LR: 1.900e-05  Data: 0.004 (0.007)
Train: 1 [2850/3167 ( 90%)]  Loss: 4.40 (4.37)  Time: 0.597s,   67.02/s  (0.597s,   66.95/s)  LR: 1.900e-05  Data: 0.007 (0.007)
Train: 1 [2900/3167 ( 92%)]  Loss: 4.60 (4.37)  Time: 0.599s,   66.80/s  (0.597s,   66.95/s)  LR: 1.900e-05  Data: 0.007 (0.007)
Train: 1 [2950/3167 ( 93%)]  Loss: 4.37 (4.37)  Time: 0.596s,   67.14/s  (0.597s,   66.95/s)  LR: 1.900e-05  Data: 0.007 (0.007)
Train: 1 [3000/3167 ( 95%)]  Loss: 4.12 (4.37)  Time: 0.596s,   67.12/s  (0.597s,   66.95/s)  LR: 1.900e-05  Data: 0.007 (0.007)
Train: 1 [3050/3167 ( 96%)]  Loss: 4.41 (4.37)  Time: 0.602s,   66.48/s  (0.597s,   66.95/s)  LR: 1.900e-05  Data: 0.009 (0.007)
Train: 1 [3100/3167 ( 98%)]  Loss: 4.31 (4.36)  Time: 0.596s,   67.13/s  (0.597s,   66.95/s)  LR: 1.900e-05  Data: 0.007 (0.007)
Train: 1 [3150/3167 ( 99%)]  Loss: 4.14 (4.36)  Time: 0.596s,   67.10/s  (0.597s,   66.96/s)  LR: 1.900e-05  Data: 0.007 (0.007)
Test: [   0/3167]  Time: 0.577 (0.577)  Loss:   4.180 ( 4.180)  Acc@1:   7.500 (  7.500)  Acc@5:  20.000 ( 20.000)
Test: [  50/3167]  Time: 0.192 (0.203)  Loss:   4.141 ( 4.085)  Acc@1:  20.000 (  9.216)  Acc@5:  35.000 ( 33.284)
Test: [ 100/3167]  Time: 0.196 (0.198)  Loss:   4.440 ( 4.173)  Acc@1:   0.000 (  6.609)  Acc@5:   5.000 ( 24.480)
Test: [ 150/3167]  Time: 0.187 (0.197)  Loss:   3.443 ( 4.138)  Acc@1:  10.000 (  6.440)  Acc@5:  67.500 ( 26.507)
Test: [ 200/3167]  Time: 0.190 (0.196)  Loss:   4.282 ( 4.168)  Acc@1:   0.000 (  5.498)  Acc@5:   7.500 ( 23.806)
Test: [ 250/3167]  Time: 0.199 (0.196)  Loss:   4.437 ( 4.194)  Acc@1:   2.500 (  4.552)  Acc@5:   5.000 ( 20.249)
Test: [ 300/3167]  Time: 0.193 (0.195)  Loss:   4.010 ( 4.214)  Acc@1:   0.000 (  4.311)  Acc@5:  40.000 ( 20.449)
Test: [ 350/3167]  Time: 0.192 (0.195)  Loss:   3.273 ( 4.131)  Acc@1:  50.000 (  7.521)  Acc@5:  67.500 ( 24.907)
Test: [ 400/3167]  Time: 0.187 (0.195)  Loss:   3.800 ( 4.013)  Acc@1:  17.500 ( 12.550)  Acc@5:  52.500 ( 30.505)
Test: [ 450/3167]  Time: 0.186 (0.194)  Loss:   3.874 ( 4.002)  Acc@1:   5.000 ( 11.874)  Acc@5:  35.000 ( 30.804)
Test: [ 500/3167]  Time: 0.195 (0.194)  Loss:   4.507 ( 4.050)  Acc@1:   0.000 ( 10.704)  Acc@5:   5.000 ( 28.234)
Test: [ 550/3167]  Time: 0.197 (0.194)  Loss:   4.566 ( 4.014)  Acc@1:   0.000 ( 12.255)  Acc@5:   0.000 ( 29.701)
Test: [ 600/3167]  Time: 0.184 (0.193)  Loss:   3.387 ( 4.026)  Acc@1:   7.500 ( 11.735)  Acc@5:  60.000 ( 29.106)
Test: [ 650/3167]  Time: 0.194 (0.193)  Loss:   4.503 ( 3.990)  Acc@1:   0.000 ( 12.776)  Acc@5:   5.000 ( 30.611)
Test: [ 700/3167]  Time: 0.205 (0.193)  Loss:   3.775 ( 4.001)  Acc@1:  12.500 ( 12.129)  Acc@5:  52.500 ( 30.203)
Test: [ 750/3167]  Time: 0.201 (0.193)  Loss:   3.639 ( 3.993)  Acc@1:  17.500 ( 11.681)  Acc@5:  50.000 ( 30.230)
Test: [ 800/3167]  Time: 0.193 (0.193)  Loss:   4.548 ( 3.997)  Acc@1:   0.000 ( 11.495)  Acc@5:  10.000 ( 30.278)
Test: [ 850/3167]  Time: 0.190 (0.193)  Loss:   4.298 ( 4.018)  Acc@1:   0.000 ( 10.987)  Acc@5:   7.500 ( 29.647)
Test: [ 900/3167]  Time: 0.209 (0.192)  Loss:   4.278 ( 4.034)  Acc@1:   7.500 ( 10.524)  Acc@5:  20.000 ( 28.982)
Test: [ 950/3167]  Time: 0.191 (0.192)  Loss:   3.771 ( 4.044)  Acc@1:   2.500 ( 10.110)  Acc@5:  37.500 ( 28.228)
Test: [1000/3167]  Time: 0.207 (0.192)  Loss:   4.230 ( 4.050)  Acc@1:   0.000 (  9.718)  Acc@5:  12.500 ( 27.410)
Test: [1050/3167]  Time: 0.194 (0.192)  Loss:   3.908 ( 4.048)  Acc@1:   2.500 (  9.462)  Acc@5:  42.500 ( 27.369)
Test: [1100/3167]  Time: 0.203 (0.192)  Loss:   4.313 ( 4.050)  Acc@1:   2.500 (  9.080)  Acc@5:  10.000 ( 26.882)
Test: [1150/3167]  Time: 0.184 (0.192)  Loss:   3.645 ( 4.046)  Acc@1:  30.000 (  9.281)  Acc@5:  62.500 ( 27.381)
Test: [1200/3167]  Time: 0.189 (0.192)  Loss:   3.162 ( 4.030)  Acc@1:  40.000 (  9.548)  Acc@5:  72.500 ( 28.283)
Test: [1250/3167]  Time: 0.188 (0.192)  Loss:   3.160 ( 3.999)  Acc@1:  45.000 ( 10.691)  Acc@5:  82.500 ( 29.966)
Test: [1300/3167]  Time: 0.185 (0.192)  Loss:   3.702 ( 4.005)  Acc@1:   0.000 ( 10.354)  Acc@5:  37.500 ( 29.656)
Test: [1350/3167]  Time: 0.190 (0.192)  Loss:   4.351 ( 4.021)  Acc@1:   2.500 (  9.991)  Acc@5:  20.000 ( 29.114)
Test: [1400/3167]  Time: 0.195 (0.192)  Loss:   3.617 ( 4.039)  Acc@1:  27.500 (  9.727)  Acc@5:  55.000 ( 28.617)
Test: [1450/3167]  Time: 0.187 (0.192)  Loss:   4.437 ( 4.036)  Acc@1:   0.000 (  9.983)  Acc@5:   2.500 ( 28.958)
Test: [1500/3167]  Time: 0.193 (0.192)  Loss:   3.833 ( 4.009)  Acc@1:   7.500 ( 10.986)  Acc@5:  32.500 ( 29.737)
Test: [1550/3167]  Time: 0.197 (0.192)  Loss:   3.030 ( 3.993)  Acc@1:  35.000 ( 11.191)  Acc@5:  82.500 ( 30.542)
Test: [1600/3167]  Time: 0.184 (0.192)  Loss:   2.909 ( 3.975)  Acc@1:  40.000 ( 11.438)  Acc@5:  75.000 ( 31.591)
Test: [1650/3167]  Time: 0.187 (0.192)  Loss:   3.852 ( 3.958)  Acc@1:  17.500 ( 11.978)  Acc@5:  45.000 ( 32.424)
Test: [1700/3167]  Time: 0.198 (0.192)  Loss:   4.306 ( 3.950)  Acc@1:   0.000 ( 12.127)  Acc@5:  12.500 ( 32.894)
Test: [1750/3167]  Time: 0.185 (0.191)  Loss:   3.885 ( 3.955)  Acc@1:   7.500 ( 12.062)  Acc@5:  32.500 ( 32.873)
Test: [1800/3167]  Time: 0.198 (0.191)  Loss:   3.966 ( 3.953)  Acc@1:   5.000 ( 12.057)  Acc@5:  32.500 ( 33.122)
Test: [1850/3167]  Time: 0.197 (0.191)  Loss:   4.723 ( 3.966)  Acc@1:   0.000 ( 11.753)  Acc@5:   0.000 ( 32.519)
Test: [1900/3167]  Time: 0.191 (0.191)  Loss:   4.544 ( 3.982)  Acc@1:   0.000 ( 11.444)  Acc@5:   0.000 ( 31.675)
Test: [1950/3167]  Time: 0.191 (0.191)  Loss:   4.507 ( 3.993)  Acc@1:   5.000 ( 11.164)  Acc@5:  17.500 ( 31.098)
Test: [2000/3167]  Time: 0.184 (0.191)  Loss:   4.601 ( 4.009)  Acc@1:   0.000 ( 10.906)  Acc@5:   0.000 ( 30.506)
Test: [2050/3167]  Time: 0.196 (0.191)  Loss:   4.594 ( 4.023)  Acc@1:   0.000 ( 10.641)  Acc@5:   0.000 ( 29.787)
Test: [2100/3167]  Time: 0.188 (0.191)  Loss:   4.217 ( 4.030)  Acc@1:   7.500 ( 10.554)  Acc@5:  10.000 ( 29.603)
Test: [2150/3167]  Time: 0.193 (0.191)  Loss:   2.069 ( 4.008)  Acc@1:  72.500 ( 11.219)  Acc@5:  80.000 ( 30.064)
Test: [2200/3167]  Time: 0.186 (0.191)  Loss:   3.937 ( 4.005)  Acc@1:   2.500 ( 11.197)  Acc@5:  32.500 ( 30.133)
Test: [2250/3167]  Time: 0.193 (0.191)  Loss:   3.655 ( 4.009)  Acc@1:  27.500 ( 11.093)  Acc@5:  62.500 ( 30.104)
Test: [2300/3167]  Time: 0.189 (0.191)  Loss:   4.402 ( 4.016)  Acc@1:   0.000 ( 11.051)  Acc@5:  12.500 ( 29.946)
Test: [2350/3167]  Time: 0.189 (0.191)  Loss:   4.014 ( 4.020)  Acc@1:  12.500 ( 10.884)  Acc@5:  37.500 ( 29.766)
Test: [2400/3167]  Time: 0.185 (0.191)  Loss:   4.368 ( 4.025)  Acc@1:   0.000 ( 10.822)  Acc@5:  12.500 ( 29.608)
Test: [2450/3167]  Time: 0.194 (0.191)  Loss:   3.678 ( 4.024)  Acc@1:   7.500 ( 10.663)  Acc@5:  42.500 ( 29.564)
Test: [2500/3167]  Time: 0.185 (0.191)  Loss:   4.487 ( 4.027)  Acc@1:  10.000 ( 10.635)  Acc@5:  17.500 ( 29.516)
Test: [2550/3167]  Time: 0.188 (0.191)  Loss:   4.194 ( 4.022)  Acc@1:   0.000 ( 10.574)  Acc@5:   7.500 ( 29.827)
Test: [2600/3167]  Time: 0.184 (0.191)  Loss:   3.888 ( 4.025)  Acc@1:  15.000 ( 10.417)  Acc@5:  40.000 ( 29.553)
Test: [2650/3167]  Time: 0.188 (0.191)  Loss:   3.931 ( 4.029)  Acc@1:  10.000 ( 10.275)  Acc@5:  37.500 ( 29.350)
Test: [2700/3167]  Time: 0.184 (0.191)  Loss:   3.923 ( 4.027)  Acc@1:   2.500 ( 10.205)  Acc@5:  35.000 ( 29.464)
Test: [2750/3167]  Time: 0.192 (0.191)  Loss:   2.959 ( 4.027)  Acc@1:  62.500 ( 10.186)  Acc@5:  85.000 ( 29.407)
Test: [2800/3167]  Time: 0.184 (0.191)  Loss:   4.237 ( 4.019)  Acc@1:   7.500 ( 10.571)  Acc@5:  25.000 ( 29.865)
Test: [2850/3167]  Time: 0.190 (0.191)  Loss:   3.921 ( 4.024)  Acc@1:   7.500 ( 10.430)  Acc@5:  32.500 ( 29.595)
Test: [2900/3167]  Time: 0.184 (0.191)  Loss:   4.044 ( 4.022)  Acc@1:  12.500 ( 10.417)  Acc@5:  35.000 ( 29.742)
Test: [2950/3167]  Time: 0.188 (0.191)  Loss:   3.922 ( 4.024)  Acc@1:   0.000 ( 10.280)  Acc@5:  20.000 ( 29.391)
Test: [3000/3167]  Time: 0.188 (0.191)  Loss:   4.173 ( 4.025)  Acc@1:   0.000 ( 10.114)  Acc@5:   7.500 ( 29.029)
Test: [3050/3167]  Time: 0.197 (0.191)  Loss:   4.542 ( 4.028)  Acc@1:   2.500 (  9.984)  Acc@5:   7.500 ( 28.873)
Test: [3100/3167]  Time: 0.216 (0.191)  Loss:   4.233 ( 4.032)  Acc@1:   0.000 (  9.832)  Acc@5:   5.000 ( 28.576)
Test: [3150/3167]  Time: 0.184 (0.191)  Loss:   4.601 ( 4.039)  Acc@1:   0.000 (  9.677)  Acc@5:   0.000 ( 28.184)
Test: [3167/3167]  Time: 0.043 (0.191)  Loss:   4.583 ( 4.042)  Acc@1:   0.000 (  9.628)  Acc@5:   0.000 ( 28.045)
Test: [   0/124]  Time: 0.758 (0.758)  Loss:   4.219 ( 4.219)  Acc@1:   5.000 (  5.000)  Acc@5:  27.500 ( 27.500)
Test: [  50/124]  Time: 0.204 (0.202)  Loss:   3.904 ( 4.052)  Acc@1:   0.000 (  8.971)  Acc@5:  35.000 ( 28.676)
Test: [ 100/124]  Time: 0.186 (0.196)  Loss:   3.256 ( 4.072)  Acc@1:  10.000 (  9.183)  Acc@5:  70.000 ( 28.738)
Test: [ 124/124]  Time: 0.180 (0.194)  Loss:   4.584 ( 4.085)  Acc@1:   0.000 (  8.500)  Acc@5:   0.000 ( 26.980)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_2/checkpoint-1.pth.tar', 9.628302378264884)

Train: 2 [   0/3167 (  0%)]  Loss: 4.27 (4.27)  Time: 1.131s,   35.38/s  (1.131s,   35.38/s)  LR: 2.800e-05  Data: 0.511 (0.511)
Train: 2 [  50/3167 (  2%)]  Loss: 4.23 (4.34)  Time: 0.598s,   66.86/s  (0.610s,   65.54/s)  LR: 2.800e-05  Data: 0.009 (0.018)
Train: 2 [ 100/3167 (  3%)]  Loss: 4.28 (4.34)  Time: 0.600s,   66.65/s  (0.605s,   66.11/s)  LR: 2.800e-05  Data: 0.011 (0.013)
Train: 2 [ 150/3167 (  5%)]  Loss: 4.50 (4.33)  Time: 0.598s,   66.85/s  (0.603s,   66.28/s)  LR: 2.800e-05  Data: 0.009 (0.012)
Train: 2 [ 200/3167 (  6%)]  Loss: 4.51 (4.34)  Time: 0.605s,   66.15/s  (0.603s,   66.37/s)  LR: 2.800e-05  Data: 0.011 (0.011)
Train: 2 [ 250/3167 (  8%)]  Loss: 4.31 (4.34)  Time: 0.600s,   66.61/s  (0.602s,   66.42/s)  LR: 2.800e-05  Data: 0.011 (0.011)
Train: 2 [ 300/3167 (  9%)]  Loss: 4.25 (4.34)  Time: 0.602s,   66.41/s  (0.602s,   66.46/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [ 350/3167 ( 11%)]  Loss: 4.27 (4.34)  Time: 0.602s,   66.42/s  (0.602s,   66.49/s)  LR: 2.800e-05  Data: 0.009 (0.010)
Train: 2 [ 400/3167 ( 13%)]  Loss: 4.14 (4.34)  Time: 0.601s,   66.57/s  (0.601s,   66.52/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [ 450/3167 ( 14%)]  Loss: 4.27 (4.34)  Time: 0.598s,   66.87/s  (0.601s,   66.54/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [ 500/3167 ( 16%)]  Loss: 4.41 (4.33)  Time: 0.593s,   67.46/s  (0.601s,   66.55/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [ 550/3167 ( 17%)]  Loss: 4.20 (4.33)  Time: 0.596s,   67.12/s  (0.601s,   66.57/s)  LR: 2.800e-05  Data: 0.007 (0.010)
Train: 2 [ 600/3167 ( 19%)]  Loss: 4.25 (4.33)  Time: 0.598s,   66.94/s  (0.601s,   66.58/s)  LR: 2.800e-05  Data: 0.007 (0.009)
Train: 2 [ 650/3167 ( 21%)]  Loss: 4.26 (4.33)  Time: 0.601s,   66.56/s  (0.601s,   66.60/s)  LR: 2.800e-05  Data: 0.011 (0.009)
Train: 2 [ 700/3167 ( 22%)]  Loss: 4.39 (4.33)  Time: 0.596s,   67.14/s  (0.601s,   66.61/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [ 750/3167 ( 24%)]  Loss: 4.16 (4.33)  Time: 0.599s,   66.82/s  (0.600s,   66.62/s)  LR: 2.800e-05  Data: 0.010 (0.009)
Train: 2 [ 800/3167 ( 25%)]  Loss: 4.31 (4.33)  Time: 0.601s,   66.51/s  (0.600s,   66.62/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [ 850/3167 ( 27%)]  Loss: 4.15 (4.33)  Time: 0.594s,   67.32/s  (0.600s,   66.63/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [ 900/3167 ( 28%)]  Loss: 4.47 (4.33)  Time: 0.603s,   66.33/s  (0.600s,   66.63/s)  LR: 2.800e-05  Data: 0.011 (0.009)
Train: 2 [ 950/3167 ( 30%)]  Loss: 4.14 (4.32)  Time: 0.600s,   66.66/s  (0.600s,   66.63/s)  LR: 2.800e-05  Data: 0.011 (0.009)
Train: 2 [1000/3167 ( 32%)]  Loss: 4.53 (4.32)  Time: 0.599s,   66.81/s  (0.600s,   66.64/s)  LR: 2.800e-05  Data: 0.009 (0.009)
Train: 2 [1050/3167 ( 33%)]  Loss: 4.45 (4.32)  Time: 0.601s,   66.56/s  (0.600s,   66.64/s)  LR: 2.800e-05  Data: 0.012 (0.009)
Train: 2 [1100/3167 ( 35%)]  Loss: 4.27 (4.32)  Time: 0.599s,   66.79/s  (0.600s,   66.64/s)  LR: 2.800e-05  Data: 0.007 (0.009)
Train: 2 [1150/3167 ( 36%)]  Loss: 4.40 (4.32)  Time: 0.608s,   65.80/s  (0.600s,   66.65/s)  LR: 2.800e-05  Data: 0.012 (0.009)
Train: 2 [1200/3167 ( 38%)]  Loss: 4.41 (4.32)  Time: 0.601s,   66.60/s  (0.600s,   66.66/s)  LR: 2.800e-05  Data: 0.012 (0.009)
Train: 2 [1250/3167 ( 39%)]  Loss: 4.20 (4.32)  Time: 0.601s,   66.61/s  (0.600s,   66.66/s)  LR: 2.800e-05  Data: 0.006 (0.009)
Train: 2 [1300/3167 ( 41%)]  Loss: 4.53 (4.32)  Time: 0.599s,   66.83/s  (0.600s,   66.67/s)  LR: 2.800e-05  Data: 0.009 (0.009)
Train: 2 [1350/3167 ( 43%)]  Loss: 4.29 (4.32)  Time: 0.596s,   67.11/s  (0.600s,   66.67/s)  LR: 2.800e-05  Data: 0.007 (0.009)
Train: 2 [1400/3167 ( 44%)]  Loss: 4.20 (4.32)  Time: 0.593s,   67.45/s  (0.600s,   66.67/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [1450/3167 ( 46%)]  Loss: 4.44 (4.32)  Time: 0.606s,   66.01/s  (0.600s,   66.68/s)  LR: 2.800e-05  Data: 0.011 (0.009)
Train: 2 [1500/3167 ( 47%)]  Loss: 4.34 (4.32)  Time: 0.595s,   67.28/s  (0.600s,   66.68/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [1550/3167 ( 49%)]  Loss: 4.28 (4.32)  Time: 0.599s,   66.82/s  (0.600s,   66.68/s)  LR: 2.800e-05  Data: 0.006 (0.009)
Train: 2 [1600/3167 ( 51%)]  Loss: 4.51 (4.32)  Time: 0.600s,   66.63/s  (0.600s,   66.69/s)  LR: 2.800e-05  Data: 0.011 (0.009)
Train: 2 [1650/3167 ( 52%)]  Loss: 4.44 (4.32)  Time: 0.596s,   67.16/s  (0.600s,   66.69/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [1700/3167 ( 54%)]  Loss: 4.12 (4.31)  Time: 0.593s,   67.43/s  (0.600s,   66.69/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [1750/3167 ( 55%)]  Loss: 4.41 (4.31)  Time: 0.593s,   67.43/s  (0.600s,   66.70/s)  LR: 2.800e-05  Data: 0.004 (0.008)
Train: 2 [1800/3167 ( 57%)]  Loss: 4.02 (4.31)  Time: 0.599s,   66.81/s  (0.600s,   66.70/s)  LR: 2.800e-05  Data: 0.009 (0.008)
Train: 2 [1850/3167 ( 58%)]  Loss: 4.13 (4.31)  Time: 0.603s,   66.37/s  (0.600s,   66.70/s)  LR: 2.800e-05  Data: 0.009 (0.008)
Train: 2 [1900/3167 ( 60%)]  Loss: 4.14 (4.31)  Time: 0.606s,   66.02/s  (0.600s,   66.71/s)  LR: 2.800e-05  Data: 0.012 (0.008)
Train: 2 [1950/3167 ( 62%)]  Loss: 4.23 (4.31)  Time: 0.601s,   66.53/s  (0.600s,   66.72/s)  LR: 2.800e-05  Data: 0.012 (0.008)
Train: 2 [2000/3167 ( 63%)]  Loss: 4.24 (4.31)  Time: 0.596s,   67.17/s  (0.600s,   66.72/s)  LR: 2.800e-05  Data: 0.006 (0.008)
Train: 2 [2050/3167 ( 65%)]  Loss: 4.38 (4.31)  Time: 0.600s,   66.63/s  (0.599s,   66.72/s)  LR: 2.800e-05  Data: 0.004 (0.008)
Train: 2 [2100/3167 ( 66%)]  Loss: 4.42 (4.31)  Time: 0.596s,   67.11/s  (0.599s,   66.73/s)  LR: 2.800e-05  Data: 0.004 (0.008)
Train: 2 [2150/3167 ( 68%)]  Loss: 4.31 (4.31)  Time: 0.593s,   67.42/s  (0.599s,   66.73/s)  LR: 2.800e-05  Data: 0.004 (0.008)
Train: 2 [2200/3167 ( 69%)]  Loss: 4.00 (4.31)  Time: 0.593s,   67.42/s  (0.599s,   66.74/s)  LR: 2.800e-05  Data: 0.004 (0.008)
Train: 2 [2250/3167 ( 71%)]  Loss: 4.47 (4.30)  Time: 0.602s,   66.49/s  (0.599s,   66.74/s)  LR: 2.800e-05  Data: 0.012 (0.008)
Train: 2 [2300/3167 ( 73%)]  Loss: 4.45 (4.30)  Time: 0.593s,   67.40/s  (0.599s,   66.75/s)  LR: 2.800e-05  Data: 0.004 (0.008)
Train: 2 [2350/3167 ( 74%)]  Loss: 4.48 (4.30)  Time: 0.606s,   66.03/s  (0.599s,   66.75/s)  LR: 2.800e-05  Data: 0.009 (0.008)
Train: 2 [2400/3167 ( 76%)]  Loss: 4.25 (4.30)  Time: 0.596s,   67.11/s  (0.599s,   66.75/s)  LR: 2.800e-05  Data: 0.007 (0.008)
Train: 2 [2450/3167 ( 77%)]  Loss: 4.23 (4.30)  Time: 0.603s,   66.31/s  (0.599s,   66.75/s)  LR: 2.800e-05  Data: 0.012 (0.008)
Train: 2 [2500/3167 ( 79%)]  Loss: 4.16 (4.30)  Time: 0.604s,   66.27/s  (0.599s,   66.76/s)  LR: 2.800e-05  Data: 0.011 (0.008)
Train: 2 [2550/3167 ( 81%)]  Loss: 4.66 (4.30)  Time: 0.596s,   67.14/s  (0.599s,   66.76/s)  LR: 2.800e-05  Data: 0.006 (0.008)
Train: 2 [2600/3167 ( 82%)]  Loss: 4.41 (4.30)  Time: 0.596s,   67.13/s  (0.599s,   66.76/s)  LR: 2.800e-05  Data: 0.004 (0.008)
Train: 2 [2650/3167 ( 84%)]  Loss: 4.04 (4.30)  Time: 0.604s,   66.23/s  (0.599s,   66.77/s)  LR: 2.800e-05  Data: 0.009 (0.008)
Train: 2 [2700/3167 ( 85%)]  Loss: 4.37 (4.30)  Time: 0.597s,   67.05/s  (0.599s,   66.77/s)  LR: 2.800e-05  Data: 0.007 (0.008)
Train: 2 [2750/3167 ( 87%)]  Loss: 4.30 (4.30)  Time: 0.596s,   67.12/s  (0.599s,   66.77/s)  LR: 2.800e-05  Data: 0.007 (0.008)
Train: 2 [2800/3167 ( 88%)]  Loss: 4.17 (4.30)  Time: 0.597s,   66.99/s  (0.599s,   66.78/s)  LR: 2.800e-05  Data: 0.007 (0.008)
Train: 2 [2850/3167 ( 90%)]  Loss: 4.43 (4.30)  Time: 0.599s,   66.81/s  (0.599s,   66.78/s)  LR: 2.800e-05  Data: 0.007 (0.008)
Train: 2 [2900/3167 ( 92%)]  Loss: 4.32 (4.29)  Time: 0.596s,   67.14/s  (0.599s,   66.78/s)  LR: 2.800e-05  Data: 0.007 (0.008)
Train: 2 [2950/3167 ( 93%)]  Loss: 3.93 (4.29)  Time: 0.598s,   66.85/s  (0.599s,   66.79/s)  LR: 2.800e-05  Data: 0.007 (0.008)
Train: 2 [3000/3167 ( 95%)]  Loss: 4.39 (4.29)  Time: 0.599s,   66.80/s  (0.599s,   66.79/s)  LR: 2.800e-05  Data: 0.007 (0.008)
Train: 2 [3050/3167 ( 96%)]  Loss: 4.30 (4.29)  Time: 0.596s,   67.08/s  (0.599s,   66.79/s)  LR: 2.800e-05  Data: 0.007 (0.008)
Train: 2 [3100/3167 ( 98%)]  Loss: 4.33 (4.29)  Time: 0.593s,   67.46/s  (0.599s,   66.79/s)  LR: 2.800e-05  Data: 0.004 (0.008)
Train: 2 [3150/3167 ( 99%)]  Loss: 4.33 (4.29)  Time: 0.599s,   66.80/s  (0.599s,   66.80/s)  LR: 2.800e-05  Data: 0.007 (0.008)
Test: [   0/3167]  Time: 0.516 (0.516)  Loss:   4.208 ( 4.208)  Acc@1:  10.000 ( 10.000)  Acc@5:  22.500 ( 22.500)
Test: [  50/3167]  Time: 0.206 (0.200)  Loss:   3.913 ( 3.997)  Acc@1:  25.000 ( 13.088)  Acc@5:  45.000 ( 35.784)
Test: [ 100/3167]  Time: 0.199 (0.197)  Loss:   4.159 ( 3.981)  Acc@1:   2.500 (  9.950)  Acc@5:  15.000 ( 33.441)
Test: [ 150/3167]  Time: 0.192 (0.196)  Loss:   3.052 ( 3.917)  Acc@1:  40.000 ( 12.450)  Acc@5:  80.000 ( 34.520)
Test: [ 200/3167]  Time: 0.184 (0.195)  Loss:   4.095 ( 3.950)  Acc@1:   7.500 ( 11.443)  Acc@5:  25.000 ( 31.157)
Test: [ 250/3167]  Time: 0.190 (0.195)  Loss:   3.549 ( 3.912)  Acc@1:  17.500 ( 12.002)  Acc@5:  50.000 ( 32.480)
Test: [ 300/3167]  Time: 0.194 (0.195)  Loss:   3.880 ( 3.903)  Acc@1:   0.000 ( 12.284)  Acc@5:  35.000 ( 33.630)
Test: [ 350/3167]  Time: 0.188 (0.195)  Loss:   3.374 ( 3.862)  Acc@1:  40.000 ( 13.184)  Acc@5:  65.000 ( 35.634)
Test: [ 400/3167]  Time: 0.191 (0.194)  Loss:   3.735 ( 3.745)  Acc@1:  10.000 ( 17.675)  Acc@5:  47.500 ( 39.776)
Test: [ 450/3167]  Time: 0.192 (0.194)  Loss:   3.791 ( 3.757)  Acc@1:   0.000 ( 16.347)  Acc@5:  17.500 ( 38.570)
Test: [ 500/3167]  Time: 0.191 (0.194)  Loss:   3.970 ( 3.785)  Acc@1:   5.000 ( 15.329)  Acc@5:  25.000 ( 37.879)
Test: [ 550/3167]  Time: 0.187 (0.194)  Loss:   4.084 ( 3.763)  Acc@1:   0.000 ( 16.520)  Acc@5:  17.500 ( 38.920)
Test: [ 600/3167]  Time: 0.186 (0.194)  Loss:   3.389 ( 3.779)  Acc@1:   5.000 ( 15.387)  Acc@5:  42.500 ( 37.937)
Test: [ 650/3167]  Time: 0.197 (0.194)  Loss:   4.201 ( 3.764)  Acc@1:   0.000 ( 15.684)  Acc@5:  17.500 ( 38.372)
Test: [ 700/3167]  Time: 0.205 (0.193)  Loss:   3.260 ( 3.760)  Acc@1:  45.000 ( 15.699)  Acc@5:  67.500 ( 38.994)
Test: [ 750/3167]  Time: 0.197 (0.193)  Loss:   3.751 ( 3.753)  Acc@1:  15.000 ( 15.516)  Acc@5:  45.000 ( 39.427)
Test: [ 800/3167]  Time: 0.188 (0.193)  Loss:   4.332 ( 3.767)  Acc@1:   0.000 ( 15.290)  Acc@5:  25.000 ( 38.908)
Test: [ 850/3167]  Time: 0.193 (0.193)  Loss:   4.139 ( 3.793)  Acc@1:   0.000 ( 14.580)  Acc@5:   5.000 ( 37.826)
Test: [ 900/3167]  Time: 0.206 (0.193)  Loss:   4.013 ( 3.812)  Acc@1:  10.000 ( 13.962)  Acc@5:  27.500 ( 36.590)
Test: [ 950/3167]  Time: 0.201 (0.193)  Loss:   3.162 ( 3.816)  Acc@1:  27.500 ( 13.956)  Acc@5:  75.000 ( 36.569)
Test: [1000/3167]  Time: 0.189 (0.193)  Loss:   4.138 ( 3.828)  Acc@1:   0.000 ( 13.764)  Acc@5:  20.000 ( 35.912)
Test: [1050/3167]  Time: 0.193 (0.193)  Loss:   3.620 ( 3.826)  Acc@1:  10.000 ( 13.480)  Acc@5:  42.500 ( 36.130)
Test: [1100/3167]  Time: 0.194 (0.193)  Loss:   4.199 ( 3.832)  Acc@1:   2.500 ( 12.970)  Acc@5:   5.000 ( 35.547)
Test: [1150/3167]  Time: 0.191 (0.193)  Loss:   3.596 ( 3.832)  Acc@1:  22.500 ( 13.123)  Acc@5:  62.500 ( 35.780)
Test: [1200/3167]  Time: 0.189 (0.193)  Loss:   2.876 ( 3.810)  Acc@1:  47.500 ( 13.778)  Acc@5:  75.000 ( 36.840)
Test: [1250/3167]  Time: 0.197 (0.193)  Loss:   3.445 ( 3.791)  Acc@1:  42.500 ( 14.870)  Acc@5:  60.000 ( 37.854)
Test: [1300/3167]  Time: 0.186 (0.193)  Loss:   3.704 ( 3.799)  Acc@1:  17.500 ( 14.468)  Acc@5:  42.500 ( 37.354)
Test: [1350/3167]  Time: 0.184 (0.193)  Loss:   4.034 ( 3.816)  Acc@1:   2.500 ( 14.030)  Acc@5:  30.000 ( 36.554)
Test: [1400/3167]  Time: 0.190 (0.192)  Loss:   3.441 ( 3.831)  Acc@1:  47.500 ( 13.681)  Acc@5:  62.500 ( 35.935)
Test: [1450/3167]  Time: 0.184 (0.192)  Loss:   4.124 ( 3.826)  Acc@1:   0.000 ( 14.116)  Acc@5:  15.000 ( 36.394)
Test: [1500/3167]  Time: 0.184 (0.192)  Loss:   3.789 ( 3.807)  Acc@1:  10.000 ( 14.132)  Acc@5:  32.500 ( 36.999)
Test: [1550/3167]  Time: 0.191 (0.192)  Loss:   2.728 ( 3.791)  Acc@1:  70.000 ( 14.691)  Acc@5:  90.000 ( 37.682)
Test: [1600/3167]  Time: 0.194 (0.192)  Loss:   2.659 ( 3.780)  Acc@1:  45.000 ( 15.077)  Acc@5:  72.500 ( 38.212)
Test: [1650/3167]  Time: 0.192 (0.192)  Loss:   3.632 ( 3.761)  Acc@1:  20.000 ( 15.621)  Acc@5:  52.500 ( 38.925)
Test: [1700/3167]  Time: 0.187 (0.192)  Loss:   4.227 ( 3.754)  Acc@1:   2.500 ( 15.667)  Acc@5:  17.500 ( 39.295)
Test: [1750/3167]  Time: 0.185 (0.192)  Loss:   3.818 ( 3.761)  Acc@1:  10.000 ( 15.515)  Acc@5:  37.500 ( 39.071)
Test: [1800/3167]  Time: 0.187 (0.192)  Loss:   3.526 ( 3.759)  Acc@1:  27.500 ( 15.695)  Acc@5:  57.500 ( 39.416)
Test: [1850/3167]  Time: 0.186 (0.192)  Loss:   4.196 ( 3.766)  Acc@1:   5.000 ( 15.506)  Acc@5:  25.000 ( 38.994)
Test: [1900/3167]  Time: 0.200 (0.192)  Loss:   4.204 ( 3.774)  Acc@1:   0.000 ( 15.355)  Acc@5:  17.500 ( 38.812)
Test: [1950/3167]  Time: 0.192 (0.192)  Loss:   4.527 ( 3.780)  Acc@1:   0.000 ( 15.314)  Acc@5:   7.500 ( 38.647)
Test: [2000/3167]  Time: 0.184 (0.192)  Loss:   4.076 ( 3.795)  Acc@1:  12.500 ( 14.980)  Acc@5:  22.500 ( 37.892)
Test: [2050/3167]  Time: 0.184 (0.192)  Loss:   4.366 ( 3.805)  Acc@1:   0.000 ( 14.775)  Acc@5:   0.000 ( 37.340)
Test: [2100/3167]  Time: 0.187 (0.192)  Loss:   4.023 ( 3.811)  Acc@1:   2.500 ( 14.645)  Acc@5:  15.000 ( 37.123)
Test: [2150/3167]  Time: 0.190 (0.192)  Loss:   2.345 ( 3.796)  Acc@1:  62.500 ( 15.077)  Acc@5:  70.000 ( 37.456)
Test: [2200/3167]  Time: 0.199 (0.192)  Loss:   3.622 ( 3.789)  Acc@1:   2.500 ( 15.091)  Acc@5:  47.500 ( 37.729)
Test: [2250/3167]  Time: 0.191 (0.192)  Loss:   3.694 ( 3.793)  Acc@1:  25.000 ( 14.926)  Acc@5:  57.500 ( 37.649)
Test: [2300/3167]  Time: 0.199 (0.192)  Loss:   4.204 ( 3.800)  Acc@1:   2.500 ( 14.800)  Acc@5:  20.000 ( 37.357)
Test: [2350/3167]  Time: 0.192 (0.192)  Loss:   3.382 ( 3.800)  Acc@1:  52.500 ( 14.813)  Acc@5:  65.000 ( 37.315)
Test: [2400/3167]  Time: 0.189 (0.192)  Loss:   4.353 ( 3.797)  Acc@1:   0.000 ( 15.051)  Acc@5:   5.000 ( 37.504)
Test: [2450/3167]  Time: 0.192 (0.192)  Loss:   3.240 ( 3.794)  Acc@1:  30.000 ( 14.926)  Acc@5:  72.500 ( 37.670)
Test: [2500/3167]  Time: 0.184 (0.192)  Loss:   4.171 ( 3.796)  Acc@1:  10.000 ( 14.900)  Acc@5:  30.000 ( 37.674)
Test: [2550/3167]  Time: 0.188 (0.192)  Loss:   3.986 ( 3.785)  Acc@1:   5.000 ( 15.417)  Acc@5:  17.500 ( 38.115)
Test: [2600/3167]  Time: 0.195 (0.192)  Loss:   3.818 ( 3.790)  Acc@1:  12.500 ( 15.237)  Acc@5:  37.500 ( 37.833)
Test: [2650/3167]  Time: 0.201 (0.192)  Loss:   3.861 ( 3.795)  Acc@1:   2.500 ( 15.056)  Acc@5:  37.500 ( 37.670)
Test: [2700/3167]  Time: 0.199 (0.192)  Loss:   3.501 ( 3.794)  Acc@1:  17.500 ( 14.969)  Acc@5:  42.500 ( 37.704)
Test: [2750/3167]  Time: 0.197 (0.192)  Loss:   2.912 ( 3.796)  Acc@1:  27.500 ( 14.846)  Acc@5:  85.000 ( 37.556)
Test: [2800/3167]  Time: 0.188 (0.192)  Loss:   3.989 ( 3.790)  Acc@1:   2.500 ( 14.830)  Acc@5:  32.500 ( 37.866)
Test: [2850/3167]  Time: 0.201 (0.192)  Loss:   3.983 ( 3.795)  Acc@1:  17.500 ( 14.676)  Acc@5:  37.500 ( 37.688)
Test: [2900/3167]  Time: 0.189 (0.192)  Loss:   3.971 ( 3.797)  Acc@1:  10.000 ( 14.685)  Acc@5:  30.000 ( 37.699)
Test: [2950/3167]  Time: 0.199 (0.192)  Loss:   4.026 ( 3.799)  Acc@1:   0.000 ( 14.480)  Acc@5:   5.000 ( 37.336)
Test: [3000/3167]  Time: 0.201 (0.192)  Loss:   4.178 ( 3.805)  Acc@1:   0.000 ( 14.240)  Acc@5:   2.500 ( 36.821)
Test: [3050/3167]  Time: 0.186 (0.192)  Loss:   4.284 ( 3.809)  Acc@1:   2.500 ( 14.077)  Acc@5:  15.000 ( 36.613)
Test: [3100/3167]  Time: 0.184 (0.192)  Loss:   4.171 ( 3.815)  Acc@1:   0.000 ( 13.883)  Acc@5:   7.500 ( 36.274)
Test: [3150/3167]  Time: 0.193 (0.192)  Loss:   4.184 ( 3.820)  Acc@1:   0.000 ( 13.675)  Acc@5:  20.000 ( 35.929)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   4.016 ( 3.822)  Acc@1:   0.000 ( 13.618)  Acc@5:  11.111 ( 35.856)
Test: [   0/124]  Time: 0.846 (0.846)  Loss:   4.311 ( 4.311)  Acc@1:   2.500 (  2.500)  Acc@5:  20.000 ( 20.000)
Test: [  50/124]  Time: 0.184 (0.203)  Loss:   3.908 ( 3.861)  Acc@1:  10.000 ( 13.725)  Acc@5:  32.500 ( 34.412)
Test: [ 100/124]  Time: 0.187 (0.197)  Loss:   2.591 ( 3.844)  Acc@1:  67.500 ( 13.960)  Acc@5:  80.000 ( 35.743)
Test: [ 124/124]  Time: 0.180 (0.195)  Loss:   4.085 ( 3.873)  Acc@1:   0.000 ( 12.420)  Acc@5:  30.000 ( 33.940)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_2/checkpoint-2.pth.tar', 13.617599002281176)

Train: 3 [   0/3167 (  0%)]  Loss: 4.41 (4.41)  Time: 1.137s,   35.18/s  (1.137s,   35.18/s)  LR: 3.700e-05  Data: 0.521 (0.521)
Train: 3 [  50/3167 (  2%)]  Loss: 4.31 (4.25)  Time: 0.596s,   67.12/s  (0.611s,   65.42/s)  LR: 3.700e-05  Data: 0.007 (0.019)
Train: 3 [ 100/3167 (  3%)]  Loss: 4.20 (4.22)  Time: 0.598s,   66.86/s  (0.606s,   65.97/s)  LR: 3.700e-05  Data: 0.006 (0.014)
Train: 3 [ 150/3167 (  5%)]  Loss: 4.16 (4.24)  Time: 0.593s,   67.41/s  (0.605s,   66.14/s)  LR: 3.700e-05  Data: 0.004 (0.013)
Train: 3 [ 200/3167 (  6%)]  Loss: 4.14 (4.24)  Time: 0.601s,   66.58/s  (0.604s,   66.25/s)  LR: 3.700e-05  Data: 0.012 (0.012)
Train: 3 [ 250/3167 (  8%)]  Loss: 4.38 (4.25)  Time: 0.601s,   66.59/s  (0.603s,   66.31/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [ 300/3167 (  9%)]  Loss: 4.17 (4.24)  Time: 0.603s,   66.36/s  (0.603s,   66.34/s)  LR: 3.700e-05  Data: 0.014 (0.011)
Train: 3 [ 350/3167 ( 11%)]  Loss: 4.13 (4.24)  Time: 0.603s,   66.35/s  (0.603s,   66.37/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [ 400/3167 ( 13%)]  Loss: 4.30 (4.24)  Time: 0.605s,   66.07/s  (0.603s,   66.39/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [ 450/3167 ( 14%)]  Loss: 4.35 (4.24)  Time: 0.601s,   66.57/s  (0.602s,   66.41/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [ 500/3167 ( 16%)]  Loss: 3.99 (4.24)  Time: 0.603s,   66.29/s  (0.602s,   66.43/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [ 550/3167 ( 17%)]  Loss: 4.28 (4.24)  Time: 0.601s,   66.59/s  (0.602s,   66.43/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [ 600/3167 ( 19%)]  Loss: 3.87 (4.24)  Time: 0.601s,   66.58/s  (0.602s,   66.44/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [ 650/3167 ( 21%)]  Loss: 4.04 (4.24)  Time: 0.604s,   66.28/s  (0.602s,   66.46/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [ 700/3167 ( 22%)]  Loss: 4.09 (4.24)  Time: 0.606s,   65.98/s  (0.602s,   66.47/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [ 750/3167 ( 24%)]  Loss: 4.27 (4.24)  Time: 0.601s,   66.57/s  (0.602s,   66.48/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [ 800/3167 ( 25%)]  Loss: 3.91 (4.24)  Time: 0.604s,   66.26/s  (0.602s,   66.48/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [ 850/3167 ( 27%)]  Loss: 4.49 (4.23)  Time: 0.601s,   66.55/s  (0.602s,   66.49/s)  LR: 3.700e-05  Data: 0.009 (0.010)
Train: 3 [ 900/3167 ( 28%)]  Loss: 4.01 (4.23)  Time: 0.604s,   66.20/s  (0.602s,   66.48/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [ 950/3167 ( 30%)]  Loss: 4.23 (4.23)  Time: 0.601s,   66.52/s  (0.602s,   66.48/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1000/3167 ( 32%)]  Loss: 3.99 (4.23)  Time: 0.601s,   66.57/s  (0.602s,   66.49/s)  LR: 3.700e-05  Data: 0.010 (0.010)
Train: 3 [1050/3167 ( 33%)]  Loss: 4.31 (4.23)  Time: 0.599s,   66.80/s  (0.602s,   66.49/s)  LR: 3.700e-05  Data: 0.010 (0.010)
Train: 3 [1100/3167 ( 35%)]  Loss: 4.32 (4.23)  Time: 0.602s,   66.50/s  (0.602s,   66.50/s)  LR: 3.700e-05  Data: 0.009 (0.010)
Train: 3 [1150/3167 ( 36%)]  Loss: 4.26 (4.23)  Time: 0.601s,   66.58/s  (0.602s,   66.50/s)  LR: 3.700e-05  Data: 0.006 (0.010)
Train: 3 [1200/3167 ( 38%)]  Loss: 4.19 (4.23)  Time: 0.603s,   66.29/s  (0.601s,   66.51/s)  LR: 3.700e-05  Data: 0.011 (0.010)
Train: 3 [1250/3167 ( 39%)]  Loss: 4.24 (4.23)  Time: 0.604s,   66.19/s  (0.601s,   66.51/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [1300/3167 ( 41%)]  Loss: 4.34 (4.23)  Time: 0.593s,   67.44/s  (0.601s,   66.52/s)  LR: 3.700e-05  Data: 0.004 (0.010)
Train: 3 [1350/3167 ( 43%)]  Loss: 4.27 (4.23)  Time: 0.603s,   66.28/s  (0.601s,   66.53/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1400/3167 ( 44%)]  Loss: 4.25 (4.23)  Time: 0.596s,   67.17/s  (0.601s,   66.53/s)  LR: 3.700e-05  Data: 0.004 (0.010)
Train: 3 [1450/3167 ( 46%)]  Loss: 4.40 (4.23)  Time: 0.608s,   65.82/s  (0.601s,   66.53/s)  LR: 3.700e-05  Data: 0.009 (0.010)
Train: 3 [1500/3167 ( 47%)]  Loss: 3.84 (4.22)  Time: 0.593s,   67.46/s  (0.601s,   66.54/s)  LR: 3.700e-05  Data: 0.004 (0.010)
Train: 3 [1550/3167 ( 49%)]  Loss: 4.27 (4.22)  Time: 0.593s,   67.44/s  (0.601s,   66.54/s)  LR: 3.700e-05  Data: 0.004 (0.010)
Train: 3 [1600/3167 ( 51%)]  Loss: 3.92 (4.22)  Time: 0.605s,   66.11/s  (0.601s,   66.55/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1650/3167 ( 52%)]  Loss: 4.09 (4.22)  Time: 0.603s,   66.32/s  (0.601s,   66.55/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1700/3167 ( 54%)]  Loss: 4.28 (4.22)  Time: 0.609s,   65.68/s  (0.601s,   66.55/s)  LR: 3.700e-05  Data: 0.012 (0.009)
Train: 3 [1750/3167 ( 55%)]  Loss: 3.97 (4.22)  Time: 0.593s,   67.40/s  (0.601s,   66.56/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [1800/3167 ( 57%)]  Loss: 4.20 (4.22)  Time: 0.594s,   67.29/s  (0.601s,   66.57/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [1850/3167 ( 58%)]  Loss: 3.98 (4.22)  Time: 0.600s,   66.65/s  (0.601s,   66.57/s)  LR: 3.700e-05  Data: 0.011 (0.009)
Train: 3 [1900/3167 ( 60%)]  Loss: 4.45 (4.22)  Time: 0.596s,   67.08/s  (0.601s,   66.57/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [1950/3167 ( 62%)]  Loss: 4.36 (4.22)  Time: 0.597s,   66.95/s  (0.601s,   66.58/s)  LR: 3.700e-05  Data: 0.006 (0.009)
Train: 3 [2000/3167 ( 63%)]  Loss: 4.16 (4.22)  Time: 0.593s,   67.46/s  (0.601s,   66.59/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [2050/3167 ( 65%)]  Loss: 4.25 (4.22)  Time: 0.601s,   66.58/s  (0.601s,   66.59/s)  LR: 3.700e-05  Data: 0.012 (0.009)
Train: 3 [2100/3167 ( 66%)]  Loss: 4.22 (4.21)  Time: 0.604s,   66.25/s  (0.601s,   66.60/s)  LR: 3.700e-05  Data: 0.009 (0.009)
Train: 3 [2150/3167 ( 68%)]  Loss: 4.17 (4.21)  Time: 0.597s,   67.00/s  (0.601s,   66.60/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [2200/3167 ( 69%)]  Loss: 4.37 (4.21)  Time: 0.603s,   66.37/s  (0.601s,   66.61/s)  LR: 3.700e-05  Data: 0.010 (0.009)
Train: 3 [2250/3167 ( 71%)]  Loss: 4.41 (4.21)  Time: 0.601s,   66.52/s  (0.600s,   66.61/s)  LR: 3.700e-05  Data: 0.012 (0.009)
Train: 3 [2300/3167 ( 73%)]  Loss: 3.93 (4.21)  Time: 0.601s,   66.58/s  (0.600s,   66.62/s)  LR: 3.700e-05  Data: 0.012 (0.009)
Train: 3 [2350/3167 ( 74%)]  Loss: 4.46 (4.21)  Time: 0.593s,   67.45/s  (0.600s,   66.62/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [2400/3167 ( 76%)]  Loss: 4.22 (4.21)  Time: 0.601s,   66.51/s  (0.600s,   66.63/s)  LR: 3.700e-05  Data: 0.012 (0.009)
Train: 3 [2450/3167 ( 77%)]  Loss: 4.40 (4.21)  Time: 0.599s,   66.78/s  (0.600s,   66.63/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [2500/3167 ( 79%)]  Loss: 4.27 (4.21)  Time: 0.599s,   66.79/s  (0.600s,   66.64/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [2550/3167 ( 81%)]  Loss: 4.34 (4.21)  Time: 0.597s,   66.98/s  (0.600s,   66.64/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [2600/3167 ( 82%)]  Loss: 3.83 (4.21)  Time: 0.601s,   66.53/s  (0.600s,   66.65/s)  LR: 3.700e-05  Data: 0.010 (0.009)
Train: 3 [2650/3167 ( 84%)]  Loss: 3.93 (4.21)  Time: 0.596s,   67.09/s  (0.600s,   66.65/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [2700/3167 ( 85%)]  Loss: 4.56 (4.21)  Time: 0.596s,   67.12/s  (0.600s,   66.66/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [2750/3167 ( 87%)]  Loss: 4.10 (4.20)  Time: 0.601s,   66.52/s  (0.600s,   66.66/s)  LR: 3.700e-05  Data: 0.009 (0.009)
Train: 3 [2800/3167 ( 88%)]  Loss: 3.83 (4.20)  Time: 0.593s,   67.46/s  (0.600s,   66.67/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [2850/3167 ( 90%)]  Loss: 4.32 (4.20)  Time: 0.596s,   67.12/s  (0.600s,   66.67/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [2900/3167 ( 92%)]  Loss: 3.84 (4.20)  Time: 0.596s,   67.10/s  (0.600s,   66.68/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [2950/3167 ( 93%)]  Loss: 4.08 (4.20)  Time: 0.597s,   67.04/s  (0.600s,   66.68/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [3000/3167 ( 95%)]  Loss: 4.15 (4.20)  Time: 0.600s,   66.71/s  (0.600s,   66.69/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [3050/3167 ( 96%)]  Loss: 3.89 (4.20)  Time: 0.596s,   67.09/s  (0.600s,   66.69/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [3100/3167 ( 98%)]  Loss: 4.16 (4.20)  Time: 0.597s,   67.01/s  (0.600s,   66.69/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [3150/3167 ( 99%)]  Loss: 4.00 (4.20)  Time: 0.594s,   67.37/s  (0.600s,   66.70/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Test: [   0/3167]  Time: 0.543 (0.543)  Loss:   4.069 ( 4.069)  Acc@1:  10.000 ( 10.000)  Acc@5:  32.500 ( 32.500)
Test: [  50/3167]  Time: 0.192 (0.201)  Loss:   3.888 ( 3.902)  Acc@1:  22.500 (  9.510)  Acc@5:  45.000 ( 36.520)
Test: [ 100/3167]  Time: 0.191 (0.197)  Loss:   3.982 ( 3.898)  Acc@1:   2.500 (  6.881)  Acc@5:  22.500 ( 33.119)
Test: [ 150/3167]  Time: 0.191 (0.195)  Loss:   2.526 ( 3.744)  Acc@1:  50.000 ( 12.517)  Acc@5:  80.000 ( 38.560)
Test: [ 200/3167]  Time: 0.194 (0.195)  Loss:   4.254 ( 3.764)  Acc@1:   0.000 ( 12.413)  Acc@5:  10.000 ( 36.343)
Test: [ 250/3167]  Time: 0.201 (0.195)  Loss:   3.037 ( 3.741)  Acc@1:  35.000 ( 13.924)  Acc@5:  50.000 ( 35.289)
Test: [ 300/3167]  Time: 0.191 (0.194)  Loss:   3.763 ( 3.743)  Acc@1:   0.000 ( 13.405)  Acc@5:  37.500 ( 35.864)
Test: [ 350/3167]  Time: 0.199 (0.194)  Loss:   3.046 ( 3.692)  Acc@1:  22.500 ( 13.433)  Acc@5:  70.000 ( 38.312)
Test: [ 400/3167]  Time: 0.186 (0.194)  Loss:   3.129 ( 3.524)  Acc@1:  25.000 ( 18.610)  Acc@5:  67.500 ( 43.180)
Test: [ 450/3167]  Time: 0.205 (0.194)  Loss:   3.919 ( 3.554)  Acc@1:   0.000 ( 17.555)  Acc@5:  17.500 ( 42.184)
Test: [ 500/3167]  Time: 0.187 (0.194)  Loss:   3.791 ( 3.606)  Acc@1:  22.500 ( 16.766)  Acc@5:  32.500 ( 40.624)
Test: [ 550/3167]  Time: 0.190 (0.194)  Loss:   4.008 ( 3.554)  Acc@1:  12.500 ( 18.893)  Acc@5:  22.500 ( 42.337)
Test: [ 600/3167]  Time: 0.200 (0.194)  Loss:   2.897 ( 3.558)  Acc@1:  12.500 ( 18.007)  Acc@5:  67.500 ( 42.230)
Test: [ 650/3167]  Time: 0.201 (0.194)  Loss:   3.822 ( 3.511)  Acc@1:  20.000 ( 19.581)  Acc@5:  45.000 ( 43.902)
Test: [ 700/3167]  Time: 0.184 (0.194)  Loss:   3.336 ( 3.512)  Acc@1:  12.500 ( 19.504)  Acc@5:  60.000 ( 44.872)
Test: [ 750/3167]  Time: 0.184 (0.194)  Loss:   3.580 ( 3.503)  Acc@1:  32.500 ( 19.174)  Acc@5:  45.000 ( 45.240)
Test: [ 800/3167]  Time: 0.191 (0.194)  Loss:   4.401 ( 3.526)  Acc@1:   0.000 ( 18.783)  Acc@5:  10.000 ( 44.316)
Test: [ 850/3167]  Time: 0.199 (0.194)  Loss:   3.728 ( 3.553)  Acc@1:   2.500 ( 18.029)  Acc@5:  25.000 ( 43.422)
Test: [ 900/3167]  Time: 0.185 (0.194)  Loss:   4.243 ( 3.587)  Acc@1:   2.500 ( 17.150)  Acc@5:  17.500 ( 42.056)
Test: [ 950/3167]  Time: 0.190 (0.193)  Loss:   3.059 ( 3.600)  Acc@1:  25.000 ( 16.751)  Acc@5:  67.500 ( 41.677)
Test: [1000/3167]  Time: 0.198 (0.193)  Loss:   3.435 ( 3.606)  Acc@1:  12.500 ( 16.399)  Acc@5:  57.500 ( 41.506)
Test: [1050/3167]  Time: 0.196 (0.193)  Loss:   3.417 ( 3.591)  Acc@1:  15.000 ( 16.494)  Acc@5:  50.000 ( 42.412)
Test: [1100/3167]  Time: 0.193 (0.193)  Loss:   3.873 ( 3.583)  Acc@1:  12.500 ( 16.455)  Acc@5:  40.000 ( 43.090)
Test: [1150/3167]  Time: 0.184 (0.193)  Loss:   3.047 ( 3.575)  Acc@1:  42.500 ( 17.168)  Acc@5:  80.000 ( 43.758)
Test: [1200/3167]  Time: 0.196 (0.193)  Loss:   2.794 ( 3.549)  Acc@1:  52.500 ( 18.014)  Acc@5:  75.000 ( 44.996)
Test: [1250/3167]  Time: 0.193 (0.193)  Loss:   3.197 ( 3.536)  Acc@1:  37.500 ( 18.767)  Acc@5:  65.000 ( 45.663)
Test: [1300/3167]  Time: 0.186 (0.193)  Loss:   3.489 ( 3.548)  Acc@1:  10.000 ( 18.311)  Acc@5:  45.000 ( 45.073)
Test: [1350/3167]  Time: 0.204 (0.193)  Loss:   4.011 ( 3.572)  Acc@1:   7.500 ( 17.887)  Acc@5:  32.500 ( 44.169)
Test: [1400/3167]  Time: 0.194 (0.193)  Loss:   3.646 ( 3.598)  Acc@1:  17.500 ( 17.448)  Acc@5:  50.000 ( 43.328)
Test: [1450/3167]  Time: 0.187 (0.193)  Loss:   3.675 ( 3.597)  Acc@1:   7.500 ( 17.529)  Acc@5:  40.000 ( 43.568)
Test: [1500/3167]  Time: 0.198 (0.193)  Loss:   3.410 ( 3.568)  Acc@1:  15.000 ( 18.504)  Acc@5:  57.500 ( 44.462)
Test: [1550/3167]  Time: 0.184 (0.193)  Loss:   2.500 ( 3.551)  Acc@1:  67.500 ( 19.236)  Acc@5:  85.000 ( 45.260)
Test: [1600/3167]  Time: 0.184 (0.193)  Loss:   2.577 ( 3.539)  Acc@1:  50.000 ( 19.714)  Acc@5:  72.500 ( 45.821)
Test: [1650/3167]  Time: 0.188 (0.193)  Loss:   3.348 ( 3.520)  Acc@1:  20.000 ( 20.316)  Acc@5:  60.000 ( 46.422)
Test: [1700/3167]  Time: 0.185 (0.193)  Loss:   4.196 ( 3.512)  Acc@1:   2.500 ( 20.550)  Acc@5:  22.500 ( 46.856)
Test: [1750/3167]  Time: 0.187 (0.193)  Loss:   3.575 ( 3.521)  Acc@1:  10.000 ( 20.238)  Acc@5:  37.500 ( 46.473)
Test: [1800/3167]  Time: 0.185 (0.193)  Loss:   3.355 ( 3.528)  Acc@1:  12.500 ( 19.972)  Acc@5:  45.000 ( 46.238)
Test: [1850/3167]  Time: 0.192 (0.193)  Loss:   4.189 ( 3.541)  Acc@1:  12.500 ( 19.479)  Acc@5:  20.000 ( 45.454)
Test: [1900/3167]  Time: 0.187 (0.193)  Loss:   3.899 ( 3.550)  Acc@1:   0.000 ( 19.221)  Acc@5:  27.500 ( 45.233)
Test: [1950/3167]  Time: 0.188 (0.193)  Loss:   4.587 ( 3.557)  Acc@1:   0.000 ( 19.100)  Acc@5:  10.000 ( 45.044)
Test: [2000/3167]  Time: 0.186 (0.193)  Loss:   3.890 ( 3.576)  Acc@1:   5.000 ( 18.659)  Acc@5:  37.500 ( 44.253)
Test: [2050/3167]  Time: 0.200 (0.192)  Loss:   4.127 ( 3.585)  Acc@1:   0.000 ( 18.365)  Acc@5:  25.000 ( 43.837)
Test: [2100/3167]  Time: 0.197 (0.192)  Loss:   3.798 ( 3.594)  Acc@1:   7.500 ( 18.183)  Acc@5:  30.000 ( 43.542)
Test: [2150/3167]  Time: 0.184 (0.192)  Loss:   2.030 ( 3.576)  Acc@1:  65.000 ( 18.668)  Acc@5:  77.500 ( 43.925)
Test: [2200/3167]  Time: 0.194 (0.192)  Loss:   3.287 ( 3.565)  Acc@1:   5.000 ( 18.745)  Acc@5:  57.500 ( 44.229)
Test: [2250/3167]  Time: 0.187 (0.192)  Loss:   3.714 ( 3.569)  Acc@1:  20.000 ( 18.461)  Acc@5:  55.000 ( 44.125)
Test: [2300/3167]  Time: 0.194 (0.192)  Loss:   4.164 ( 3.580)  Acc@1:   0.000 ( 18.187)  Acc@5:  15.000 ( 43.638)
Test: [2350/3167]  Time: 0.191 (0.192)  Loss:   3.992 ( 3.590)  Acc@1:   5.000 ( 17.850)  Acc@5:  42.500 ( 43.101)
Test: [2400/3167]  Time: 0.187 (0.192)  Loss:   4.347 ( 3.591)  Acc@1:   0.000 ( 17.943)  Acc@5:   7.500 ( 43.078)
Test: [2450/3167]  Time: 0.198 (0.192)  Loss:   2.766 ( 3.587)  Acc@1:  37.500 ( 18.051)  Acc@5:  85.000 ( 43.298)
Test: [2500/3167]  Time: 0.193 (0.192)  Loss:   4.259 ( 3.590)  Acc@1:  12.500 ( 18.034)  Acc@5:  20.000 ( 43.269)
Test: [2550/3167]  Time: 0.191 (0.192)  Loss:   4.127 ( 3.579)  Acc@1:   5.000 ( 18.530)  Acc@5:  20.000 ( 43.658)
Test: [2600/3167]  Time: 0.184 (0.192)  Loss:   3.299 ( 3.586)  Acc@1:  27.500 ( 18.378)  Acc@5:  55.000 ( 43.338)
Test: [2650/3167]  Time: 0.187 (0.192)  Loss:   4.113 ( 3.594)  Acc@1:   0.000 ( 18.183)  Acc@5:  12.500 ( 43.056)
Test: [2700/3167]  Time: 0.188 (0.192)  Loss:   3.258 ( 3.598)  Acc@1:  27.500 ( 18.048)  Acc@5:  52.500 ( 42.829)
Test: [2750/3167]  Time: 0.184 (0.192)  Loss:   2.850 ( 3.602)  Acc@1:  32.500 ( 17.962)  Acc@5:  70.000 ( 42.702)
Test: [2800/3167]  Time: 0.206 (0.192)  Loss:   4.283 ( 3.601)  Acc@1:   0.000 ( 17.908)  Acc@5:   5.000 ( 42.754)
Test: [2850/3167]  Time: 0.184 (0.192)  Loss:   3.915 ( 3.608)  Acc@1:  12.500 ( 17.717)  Acc@5:  40.000 ( 42.474)
Test: [2900/3167]  Time: 0.185 (0.192)  Loss:   3.795 ( 3.610)  Acc@1:  10.000 ( 17.703)  Acc@5:  40.000 ( 42.506)
Test: [2950/3167]  Time: 0.192 (0.192)  Loss:   3.939 ( 3.615)  Acc@1:   0.000 ( 17.464)  Acc@5:  17.500 ( 42.170)
Test: [3000/3167]  Time: 0.187 (0.192)  Loss:   4.097 ( 3.623)  Acc@1:   0.000 ( 17.185)  Acc@5:  15.000 ( 41.695)
Test: [3050/3167]  Time: 0.197 (0.192)  Loss:   4.306 ( 3.625)  Acc@1:   0.000 ( 17.030)  Acc@5:   5.000 ( 41.527)
Test: [3100/3167]  Time: 0.187 (0.192)  Loss:   4.128 ( 3.635)  Acc@1:   0.000 ( 16.791)  Acc@5:  20.000 ( 41.141)
Test: [3150/3167]  Time: 0.185 (0.192)  Loss:   4.156 ( 3.637)  Acc@1:   0.000 ( 16.638)  Acc@5:  17.500 ( 41.065)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   3.868 ( 3.640)  Acc@1:   0.000 ( 16.567)  Acc@5:  33.333 ( 40.971)
Test: [   0/124]  Time: 0.766 (0.766)  Loss:   4.162 ( 4.162)  Acc@1:   2.500 (  2.500)  Acc@5:  20.000 ( 20.000)
Test: [  50/124]  Time: 0.188 (0.202)  Loss:   3.824 ( 3.599)  Acc@1:  15.000 ( 16.618)  Acc@5:  32.500 ( 43.676)
Test: [ 100/124]  Time: 0.184 (0.196)  Loss:   2.430 ( 3.643)  Acc@1:  65.000 ( 17.030)  Acc@5:  87.500 ( 41.683)
Test: [ 124/124]  Time: 0.180 (0.194)  Loss:   4.070 ( 3.697)  Acc@1:   5.000 ( 15.420)  Acc@5:  30.000 ( 39.120)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_2/checkpoint-3.pth.tar', 16.567342073897496)

Train: 4 [   0/3167 (  0%)]  Loss: 3.98 (3.98)  Time: 1.117s,   35.81/s  (1.117s,   35.81/s)  LR: 4.600e-05  Data: 0.514 (0.514)
Train: 4 [  50/3167 (  2%)]  Loss: 3.83 (4.16)  Time: 0.601s,   66.55/s  (0.613s,   65.30/s)  LR: 4.600e-05  Data: 0.009 (0.020)
Train: 4 [ 100/3167 (  3%)]  Loss: 4.45 (4.19)  Time: 0.598s,   66.88/s  (0.607s,   65.93/s)  LR: 4.600e-05  Data: 0.009 (0.014)
Train: 4 [ 150/3167 (  5%)]  Loss: 4.21 (4.18)  Time: 0.599s,   66.73/s  (0.605s,   66.12/s)  LR: 4.600e-05  Data: 0.010 (0.013)
Train: 4 [ 200/3167 (  6%)]  Loss: 4.05 (4.19)  Time: 0.593s,   67.46/s  (0.604s,   66.20/s)  LR: 4.600e-05  Data: 0.004 (0.012)
Train: 4 [ 250/3167 (  8%)]  Loss: 4.28 (4.18)  Time: 0.601s,   66.58/s  (0.604s,   66.27/s)  LR: 4.600e-05  Data: 0.012 (0.012)
Train: 4 [ 300/3167 (  9%)]  Loss: 4.30 (4.17)  Time: 0.600s,   66.64/s  (0.603s,   66.32/s)  LR: 4.600e-05  Data: 0.011 (0.011)
Train: 4 [ 350/3167 ( 11%)]  Loss: 4.03 (4.17)  Time: 0.604s,   66.27/s  (0.603s,   66.35/s)  LR: 4.600e-05  Data: 0.006 (0.011)
Train: 4 [ 400/3167 ( 13%)]  Loss: 4.11 (4.17)  Time: 0.603s,   66.30/s  (0.603s,   66.37/s)  LR: 4.600e-05  Data: 0.011 (0.011)
Train: 4 [ 450/3167 ( 14%)]  Loss: 4.23 (4.17)  Time: 0.601s,   66.58/s  (0.602s,   66.40/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [ 500/3167 ( 16%)]  Loss: 4.33 (4.16)  Time: 0.595s,   67.19/s  (0.602s,   66.42/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [ 550/3167 ( 17%)]  Loss: 4.34 (4.17)  Time: 0.605s,   66.07/s  (0.602s,   66.43/s)  LR: 4.600e-05  Data: 0.011 (0.010)
Train: 4 [ 600/3167 ( 19%)]  Loss: 4.17 (4.16)  Time: 0.605s,   66.09/s  (0.602s,   66.44/s)  LR: 4.600e-05  Data: 0.011 (0.010)
Train: 4 [ 650/3167 ( 21%)]  Loss: 4.06 (4.16)  Time: 0.596s,   67.12/s  (0.602s,   66.45/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [ 700/3167 ( 22%)]  Loss: 4.21 (4.17)  Time: 0.605s,   66.11/s  (0.602s,   66.46/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [ 750/3167 ( 24%)]  Loss: 4.14 (4.16)  Time: 0.593s,   67.46/s  (0.602s,   66.48/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [ 800/3167 ( 25%)]  Loss: 4.05 (4.16)  Time: 0.608s,   65.78/s  (0.602s,   66.48/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [ 850/3167 ( 27%)]  Loss: 4.36 (4.16)  Time: 0.603s,   66.32/s  (0.602s,   66.49/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [ 900/3167 ( 28%)]  Loss: 3.87 (4.16)  Time: 0.600s,   66.63/s  (0.602s,   66.50/s)  LR: 4.600e-05  Data: 0.011 (0.010)
Train: 4 [ 950/3167 ( 30%)]  Loss: 4.34 (4.15)  Time: 0.596s,   67.15/s  (0.602s,   66.50/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [1000/3167 ( 32%)]  Loss: 3.99 (4.15)  Time: 0.607s,   65.90/s  (0.601s,   66.50/s)  LR: 4.600e-05  Data: 0.011 (0.010)
Train: 4 [1050/3167 ( 33%)]  Loss: 4.26 (4.15)  Time: 0.601s,   66.52/s  (0.601s,   66.51/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1100/3167 ( 35%)]  Loss: 4.23 (4.15)  Time: 0.604s,   66.17/s  (0.601s,   66.51/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1150/3167 ( 36%)]  Loss: 3.67 (4.15)  Time: 0.599s,   66.77/s  (0.601s,   66.51/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [1200/3167 ( 38%)]  Loss: 3.94 (4.15)  Time: 0.593s,   67.45/s  (0.601s,   66.52/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [1250/3167 ( 39%)]  Loss: 3.86 (4.14)  Time: 0.601s,   66.57/s  (0.601s,   66.52/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1300/3167 ( 41%)]  Loss: 4.46 (4.14)  Time: 0.598s,   66.87/s  (0.601s,   66.52/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [1350/3167 ( 43%)]  Loss: 4.00 (4.14)  Time: 0.601s,   66.60/s  (0.601s,   66.53/s)  LR: 4.600e-05  Data: 0.011 (0.010)
Train: 4 [1400/3167 ( 44%)]  Loss: 4.28 (4.14)  Time: 0.600s,   66.62/s  (0.601s,   66.53/s)  LR: 4.600e-05  Data: 0.011 (0.010)
Train: 4 [1450/3167 ( 46%)]  Loss: 4.22 (4.14)  Time: 0.599s,   66.82/s  (0.601s,   66.53/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [1500/3167 ( 47%)]  Loss: 4.15 (4.14)  Time: 0.601s,   66.57/s  (0.601s,   66.53/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1550/3167 ( 49%)]  Loss: 4.30 (4.14)  Time: 0.604s,   66.27/s  (0.601s,   66.54/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [1600/3167 ( 51%)]  Loss: 3.88 (4.14)  Time: 0.608s,   65.81/s  (0.601s,   66.54/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [1650/3167 ( 52%)]  Loss: 4.32 (4.14)  Time: 0.593s,   67.43/s  (0.601s,   66.54/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [1700/3167 ( 54%)]  Loss: 4.12 (4.14)  Time: 0.593s,   67.45/s  (0.601s,   66.55/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [1750/3167 ( 55%)]  Loss: 4.13 (4.14)  Time: 0.601s,   66.58/s  (0.601s,   66.55/s)  LR: 4.600e-05  Data: 0.012 (0.009)
Train: 4 [1800/3167 ( 57%)]  Loss: 4.15 (4.14)  Time: 0.604s,   66.18/s  (0.601s,   66.56/s)  LR: 4.600e-05  Data: 0.009 (0.009)
Train: 4 [1850/3167 ( 58%)]  Loss: 4.20 (4.14)  Time: 0.596s,   67.11/s  (0.601s,   66.57/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Train: 4 [1900/3167 ( 60%)]  Loss: 4.22 (4.14)  Time: 0.599s,   66.80/s  (0.601s,   66.57/s)  LR: 4.600e-05  Data: 0.009 (0.009)
Train: 4 [1950/3167 ( 62%)]  Loss: 3.87 (4.14)  Time: 0.599s,   66.81/s  (0.601s,   66.57/s)  LR: 4.600e-05  Data: 0.010 (0.009)
Train: 4 [2000/3167 ( 63%)]  Loss: 4.17 (4.14)  Time: 0.600s,   66.62/s  (0.601s,   66.58/s)  LR: 4.600e-05  Data: 0.011 (0.009)
Train: 4 [2050/3167 ( 65%)]  Loss: 3.99 (4.14)  Time: 0.596s,   67.10/s  (0.601s,   66.58/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Train: 4 [2100/3167 ( 66%)]  Loss: 3.95 (4.14)  Time: 0.593s,   67.44/s  (0.601s,   66.59/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2150/3167 ( 68%)]  Loss: 4.03 (4.14)  Time: 0.598s,   66.84/s  (0.601s,   66.59/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Train: 4 [2200/3167 ( 69%)]  Loss: 4.01 (4.14)  Time: 0.611s,   65.51/s  (0.601s,   66.60/s)  LR: 4.600e-05  Data: 0.012 (0.009)
Train: 4 [2250/3167 ( 71%)]  Loss: 4.27 (4.14)  Time: 0.593s,   67.44/s  (0.601s,   66.60/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2300/3167 ( 73%)]  Loss: 4.18 (4.14)  Time: 0.595s,   67.18/s  (0.601s,   66.61/s)  LR: 4.600e-05  Data: 0.006 (0.009)
Train: 4 [2350/3167 ( 74%)]  Loss: 4.51 (4.14)  Time: 0.601s,   66.55/s  (0.601s,   66.61/s)  LR: 4.600e-05  Data: 0.010 (0.009)
Train: 4 [2400/3167 ( 76%)]  Loss: 4.18 (4.13)  Time: 0.599s,   66.81/s  (0.600s,   66.61/s)  LR: 4.600e-05  Data: 0.009 (0.009)
Train: 4 [2450/3167 ( 77%)]  Loss: 3.57 (4.13)  Time: 0.594s,   67.35/s  (0.600s,   66.62/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2500/3167 ( 79%)]  Loss: 4.15 (4.13)  Time: 0.600s,   66.62/s  (0.600s,   66.62/s)  LR: 4.600e-05  Data: 0.011 (0.009)
Train: 4 [2550/3167 ( 81%)]  Loss: 4.22 (4.13)  Time: 0.596s,   67.11/s  (0.600s,   66.63/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2600/3167 ( 82%)]  Loss: 3.89 (4.13)  Time: 0.597s,   66.95/s  (0.600s,   66.63/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2650/3167 ( 84%)]  Loss: 4.42 (4.13)  Time: 0.599s,   66.79/s  (0.600s,   66.64/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Train: 4 [2700/3167 ( 85%)]  Loss: 4.32 (4.13)  Time: 0.596s,   67.17/s  (0.600s,   66.64/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2750/3167 ( 87%)]  Loss: 4.40 (4.13)  Time: 0.598s,   66.85/s  (0.600s,   66.65/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Train: 4 [2800/3167 ( 88%)]  Loss: 4.08 (4.13)  Time: 0.597s,   66.99/s  (0.600s,   66.65/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Train: 4 [2850/3167 ( 90%)]  Loss: 4.30 (4.13)  Time: 0.599s,   66.80/s  (0.600s,   66.66/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Train: 4 [2900/3167 ( 92%)]  Loss: 3.94 (4.13)  Time: 0.596s,   67.09/s  (0.600s,   66.66/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2950/3167 ( 93%)]  Loss: 4.42 (4.13)  Time: 0.601s,   66.55/s  (0.600s,   66.67/s)  LR: 4.600e-05  Data: 0.012 (0.009)
Train: 4 [3000/3167 ( 95%)]  Loss: 4.05 (4.13)  Time: 0.593s,   67.40/s  (0.600s,   66.67/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [3050/3167 ( 96%)]  Loss: 4.28 (4.13)  Time: 0.598s,   66.90/s  (0.600s,   66.68/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Train: 4 [3100/3167 ( 98%)]  Loss: 3.87 (4.13)  Time: 0.596s,   67.13/s  (0.600s,   66.68/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Train: 4 [3150/3167 ( 99%)]  Loss: 4.16 (4.13)  Time: 0.598s,   66.90/s  (0.600s,   66.68/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Test: [   0/3167]  Time: 0.526 (0.526)  Loss:   4.163 ( 4.163)  Acc@1:   7.500 (  7.500)  Acc@5:  20.000 ( 20.000)
Test: [  50/3167]  Time: 0.198 (0.199)  Loss:   3.754 ( 3.873)  Acc@1:  32.500 ( 11.373)  Acc@5:  50.000 ( 35.392)
Test: [ 100/3167]  Time: 0.197 (0.196)  Loss:   3.639 ( 3.645)  Acc@1:   5.000 ( 12.500)  Acc@5:  40.000 ( 44.505)
Test: [ 150/3167]  Time: 0.191 (0.195)  Loss:   2.257 ( 3.473)  Acc@1:  62.500 ( 19.189)  Acc@5:  82.500 ( 50.050)
Test: [ 200/3167]  Time: 0.194 (0.195)  Loss:   4.077 ( 3.535)  Acc@1:   2.500 ( 17.836)  Acc@5:  15.000 ( 44.179)
Test: [ 250/3167]  Time: 0.201 (0.195)  Loss:   2.643 ( 3.516)  Acc@1:  45.000 ( 18.795)  Acc@5:  65.000 ( 42.689)
Test: [ 300/3167]  Time: 0.203 (0.194)  Loss:   3.758 ( 3.522)  Acc@1:   5.000 ( 18.738)  Acc@5:  32.500 ( 43.048)
Test: [ 350/3167]  Time: 0.203 (0.194)  Loss:   2.970 ( 3.504)  Acc@1:  45.000 ( 19.003)  Acc@5:  75.000 ( 44.330)
Test: [ 400/3167]  Time: 0.190 (0.194)  Loss:   3.273 ( 3.399)  Acc@1:  20.000 ( 22.450)  Acc@5:  55.000 ( 47.855)
Test: [ 450/3167]  Time: 0.190 (0.194)  Loss:   3.706 ( 3.435)  Acc@1:   5.000 ( 20.837)  Acc@5:  35.000 ( 46.358)
Test: [ 500/3167]  Time: 0.192 (0.194)  Loss:   3.183 ( 3.456)  Acc@1:  35.000 ( 21.043)  Acc@5:  55.000 ( 46.208)
Test: [ 550/3167]  Time: 0.199 (0.194)  Loss:   3.956 ( 3.411)  Acc@1:   7.500 ( 22.786)  Acc@5:  27.500 ( 47.523)
Test: [ 600/3167]  Time: 0.191 (0.194)  Loss:   3.157 ( 3.435)  Acc@1:  12.500 ( 21.751)  Acc@5:  52.500 ( 46.647)
Test: [ 650/3167]  Time: 0.192 (0.194)  Loss:   3.522 ( 3.407)  Acc@1:  17.500 ( 22.657)  Acc@5:  47.500 ( 47.512)
Test: [ 700/3167]  Time: 0.189 (0.194)  Loss:   3.245 ( 3.403)  Acc@1:  15.000 ( 22.129)  Acc@5:  67.500 ( 48.445)
Test: [ 750/3167]  Time: 0.187 (0.194)  Loss:   3.430 ( 3.393)  Acc@1:  35.000 ( 22.024)  Acc@5:  47.500 ( 49.174)
Test: [ 800/3167]  Time: 0.196 (0.194)  Loss:   4.232 ( 3.410)  Acc@1:   0.000 ( 21.882)  Acc@5:  27.500 ( 48.461)
Test: [ 850/3167]  Time: 0.199 (0.194)  Loss:   4.000 ( 3.437)  Acc@1:   0.000 ( 21.072)  Acc@5:  17.500 ( 47.388)
Test: [ 900/3167]  Time: 0.187 (0.194)  Loss:   3.954 ( 3.475)  Acc@1:   5.000 ( 20.069)  Acc@5:  30.000 ( 45.782)
Test: [ 950/3167]  Time: 0.199 (0.194)  Loss:   3.311 ( 3.486)  Acc@1:  20.000 ( 19.645)  Acc@5:  50.000 ( 45.442)
Test: [1000/3167]  Time: 0.193 (0.194)  Loss:   3.434 ( 3.510)  Acc@1:  17.500 ( 19.018)  Acc@5:  57.500 ( 44.488)
Test: [1050/3167]  Time: 0.201 (0.194)  Loss:   2.883 ( 3.483)  Acc@1:  35.000 ( 19.755)  Acc@5:  80.000 ( 45.771)
Test: [1100/3167]  Time: 0.194 (0.193)  Loss:   3.428 ( 3.484)  Acc@1:  32.500 ( 19.407)  Acc@5:  62.500 ( 45.509)
Test: [1150/3167]  Time: 0.190 (0.193)  Loss:   2.946 ( 3.469)  Acc@1:  52.500 ( 20.319)  Acc@5:  70.000 ( 46.371)
Test: [1200/3167]  Time: 0.193 (0.193)  Loss:   3.238 ( 3.454)  Acc@1:  22.500 ( 20.712)  Acc@5:  57.500 ( 47.111)
Test: [1250/3167]  Time: 0.198 (0.193)  Loss:   2.870 ( 3.439)  Acc@1:  50.000 ( 21.541)  Acc@5:  65.000 ( 47.836)
Test: [1300/3167]  Time: 0.187 (0.193)  Loss:   3.230 ( 3.439)  Acc@1:  27.500 ( 21.266)  Acc@5:  72.500 ( 48.017)
Test: [1350/3167]  Time: 0.186 (0.193)  Loss:   3.826 ( 3.456)  Acc@1:  10.000 ( 20.962)  Acc@5:  47.500 ( 47.450)
Test: [1400/3167]  Time: 0.195 (0.193)  Loss:   3.057 ( 3.477)  Acc@1:  40.000 ( 20.598)  Acc@5:  65.000 ( 46.726)
Test: [1450/3167]  Time: 0.185 (0.193)  Loss:   3.573 ( 3.471)  Acc@1:  10.000 ( 20.968)  Acc@5:  42.500 ( 47.097)
Test: [1500/3167]  Time: 0.189 (0.193)  Loss:   3.375 ( 3.451)  Acc@1:  17.500 ( 21.571)  Acc@5:  52.500 ( 47.770)
Test: [1550/3167]  Time: 0.194 (0.193)  Loss:   2.331 ( 3.436)  Acc@1:  75.000 ( 22.074)  Acc@5:  87.500 ( 48.411)
Test: [1600/3167]  Time: 0.195 (0.193)  Loss:   2.651 ( 3.426)  Acc@1:  55.000 ( 22.352)  Acc@5:  65.000 ( 48.841)
Test: [1650/3167]  Time: 0.189 (0.193)  Loss:   3.216 ( 3.408)  Acc@1:  22.500 ( 22.936)  Acc@5:  57.500 ( 49.350)
Test: [1700/3167]  Time: 0.184 (0.193)  Loss:   4.207 ( 3.407)  Acc@1:   5.000 ( 22.941)  Acc@5:  15.000 ( 49.574)
Test: [1750/3167]  Time: 0.184 (0.193)  Loss:   3.422 ( 3.416)  Acc@1:  22.500 ( 22.663)  Acc@5:  40.000 ( 49.230)
Test: [1800/3167]  Time: 0.197 (0.193)  Loss:   3.379 ( 3.425)  Acc@1:  15.000 ( 22.386)  Acc@5:  47.500 ( 48.910)
Test: [1850/3167]  Time: 0.196 (0.193)  Loss:   3.764 ( 3.435)  Acc@1:  12.500 ( 21.884)  Acc@5:  32.500 ( 48.223)
Test: [1900/3167]  Time: 0.199 (0.193)  Loss:   3.632 ( 3.439)  Acc@1:  10.000 ( 21.685)  Acc@5:  42.500 ( 48.250)
Test: [1950/3167]  Time: 0.197 (0.192)  Loss:   4.615 ( 3.440)  Acc@1:   5.000 ( 21.685)  Acc@5:  17.500 ( 48.270)
Test: [2000/3167]  Time: 0.197 (0.192)  Loss:   4.040 ( 3.462)  Acc@1:   0.000 ( 21.247)  Acc@5:  27.500 ( 47.436)
Test: [2050/3167]  Time: 0.196 (0.192)  Loss:   3.970 ( 3.474)  Acc@1:   0.000 ( 20.856)  Acc@5:  10.000 ( 46.792)
Test: [2100/3167]  Time: 0.187 (0.192)  Loss:   3.218 ( 3.480)  Acc@1:  17.500 ( 20.762)  Acc@5:  65.000 ( 46.668)
Test: [2150/3167]  Time: 0.187 (0.192)  Loss:   1.773 ( 3.454)  Acc@1:  67.500 ( 21.450)  Acc@5:  82.500 ( 47.354)
Test: [2200/3167]  Time: 0.206 (0.192)  Loss:   3.452 ( 3.448)  Acc@1:   7.500 ( 21.356)  Acc@5:  55.000 ( 47.649)
Test: [2250/3167]  Time: 0.193 (0.192)  Loss:   3.589 ( 3.453)  Acc@1:  17.500 ( 21.088)  Acc@5:  50.000 ( 47.476)
Test: [2300/3167]  Time: 0.188 (0.192)  Loss:   3.893 ( 3.462)  Acc@1:   0.000 ( 20.820)  Acc@5:  15.000 ( 46.964)
Test: [2350/3167]  Time: 0.187 (0.192)  Loss:   3.986 ( 3.470)  Acc@1:   5.000 ( 20.455)  Acc@5:  37.500 ( 46.481)
Test: [2400/3167]  Time: 0.184 (0.192)  Loss:   4.097 ( 3.468)  Acc@1:   2.500 ( 20.559)  Acc@5:  27.500 ( 46.572)
Test: [2450/3167]  Time: 0.188 (0.192)  Loss:   2.766 ( 3.465)  Acc@1:  40.000 ( 20.634)  Acc@5:  85.000 ( 46.791)
Test: [2500/3167]  Time: 0.193 (0.192)  Loss:   3.705 ( 3.463)  Acc@1:  25.000 ( 20.698)  Acc@5:  52.500 ( 46.977)
Test: [2550/3167]  Time: 0.187 (0.192)  Loss:   4.153 ( 3.451)  Acc@1:   2.500 ( 21.255)  Acc@5:  10.000 ( 47.406)
Test: [2600/3167]  Time: 0.186 (0.192)  Loss:   3.390 ( 3.461)  Acc@1:  30.000 ( 21.030)  Acc@5:  50.000 ( 46.971)
Test: [2650/3167]  Time: 0.186 (0.192)  Loss:   3.763 ( 3.470)  Acc@1:   5.000 ( 20.854)  Acc@5:  27.500 ( 46.704)
Test: [2700/3167]  Time: 0.191 (0.192)  Loss:   2.985 ( 3.470)  Acc@1:  37.500 ( 20.850)  Acc@5:  65.000 ( 46.698)
Test: [2750/3167]  Time: 0.195 (0.192)  Loss:   2.675 ( 3.475)  Acc@1:  40.000 ( 20.769)  Acc@5:  87.500 ( 46.539)
Test: [2800/3167]  Time: 0.189 (0.192)  Loss:   4.176 ( 3.474)  Acc@1:   0.000 ( 20.804)  Acc@5:  27.500 ( 46.657)
Test: [2850/3167]  Time: 0.195 (0.192)  Loss:   3.951 ( 3.483)  Acc@1:  12.500 ( 20.507)  Acc@5:  35.000 ( 46.257)
Test: [2900/3167]  Time: 0.192 (0.192)  Loss:   3.550 ( 3.486)  Acc@1:  10.000 ( 20.453)  Acc@5:  50.000 ( 46.232)
Test: [2950/3167]  Time: 0.188 (0.192)  Loss:   3.962 ( 3.492)  Acc@1:   0.000 ( 20.198)  Acc@5:  12.500 ( 45.911)
Test: [3000/3167]  Time: 0.202 (0.192)  Loss:   3.878 ( 3.500)  Acc@1:   7.500 ( 19.915)  Acc@5:  37.500 ( 45.527)
Test: [3050/3167]  Time: 0.188 (0.192)  Loss:   4.018 ( 3.497)  Acc@1:   5.000 ( 20.069)  Acc@5:  12.500 ( 45.742)
Test: [3100/3167]  Time: 0.190 (0.192)  Loss:   3.996 ( 3.506)  Acc@1:   2.500 ( 19.804)  Acc@5:  22.500 ( 45.412)
Test: [3150/3167]  Time: 0.184 (0.192)  Loss:   3.597 ( 3.506)  Acc@1:   0.000 ( 19.597)  Acc@5:  45.000 ( 45.466)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   3.342 ( 3.507)  Acc@1:  22.222 ( 19.546)  Acc@5:  66.667 ( 45.462)
Test: [   0/124]  Time: 0.671 (0.671)  Loss:   4.247 ( 4.247)  Acc@1:   0.000 (  0.000)  Acc@5:  15.000 ( 15.000)
Test: [  50/124]  Time: 0.186 (0.201)  Loss:   3.503 ( 3.509)  Acc@1:  27.500 ( 19.020)  Acc@5:  50.000 ( 44.951)
Test: [ 100/124]  Time: 0.184 (0.196)  Loss:   2.612 ( 3.523)  Acc@1:  65.000 ( 19.010)  Acc@5:  75.000 ( 44.035)
Test: [ 124/124]  Time: 0.180 (0.194)  Loss:   3.540 ( 3.570)  Acc@1:  10.000 ( 17.500)  Acc@5:  47.500 ( 42.620)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_2/checkpoint-4.pth.tar', 19.545501188023717)

Train: 5 [   0/3167 (  0%)]  Loss: 4.28 (4.28)  Time: 1.129s,   35.41/s  (1.129s,   35.41/s)  LR: 5.500e-05  Data: 0.491 (0.491)
Train: 5 [  50/3167 (  2%)]  Loss: 4.13 (4.20)  Time: 0.602s,   66.40/s  (0.612s,   65.32/s)  LR: 5.500e-05  Data: 0.004 (0.020)
Train: 5 [ 100/3167 (  3%)]  Loss: 4.51 (4.15)  Time: 0.610s,   65.62/s  (0.607s,   65.86/s)  LR: 5.500e-05  Data: 0.012 (0.014)
Train: 5 [ 150/3167 (  5%)]  Loss: 4.18 (4.13)  Time: 0.603s,   66.33/s  (0.605s,   66.09/s)  LR: 5.500e-05  Data: 0.012 (0.013)
Train: 5 [ 200/3167 (  6%)]  Loss: 4.22 (4.12)  Time: 0.603s,   66.38/s  (0.604s,   66.19/s)  LR: 5.500e-05  Data: 0.011 (0.012)
Train: 5 [ 250/3167 (  8%)]  Loss: 4.50 (4.11)  Time: 0.598s,   66.89/s  (0.604s,   66.25/s)  LR: 5.500e-05  Data: 0.009 (0.012)
Train: 5 [ 300/3167 (  9%)]  Loss: 3.93 (4.11)  Time: 0.598s,   66.90/s  (0.603s,   66.28/s)  LR: 5.500e-05  Data: 0.009 (0.011)
Train: 5 [ 350/3167 ( 11%)]  Loss: 3.94 (4.11)  Time: 0.602s,   66.40/s  (0.603s,   66.33/s)  LR: 5.500e-05  Data: 0.011 (0.011)
Train: 5 [ 400/3167 ( 13%)]  Loss: 4.27 (4.10)  Time: 0.595s,   67.22/s  (0.603s,   66.35/s)  LR: 5.500e-05  Data: 0.004 (0.011)
Train: 5 [ 450/3167 ( 14%)]  Loss: 4.25 (4.10)  Time: 0.600s,   66.63/s  (0.603s,   66.37/s)  LR: 5.500e-05  Data: 0.011 (0.011)
Train: 5 [ 500/3167 ( 16%)]  Loss: 3.32 (4.09)  Time: 0.611s,   65.47/s  (0.603s,   66.39/s)  LR: 5.500e-05  Data: 0.012 (0.011)
Train: 5 [ 550/3167 ( 17%)]  Loss: 4.48 (4.09)  Time: 0.603s,   66.32/s  (0.603s,   66.38/s)  LR: 5.500e-05  Data: 0.011 (0.011)
Train: 5 [ 600/3167 ( 19%)]  Loss: 4.51 (4.10)  Time: 0.600s,   66.71/s  (0.602s,   66.40/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [ 650/3167 ( 21%)]  Loss: 4.00 (4.10)  Time: 0.598s,   66.85/s  (0.602s,   66.42/s)  LR: 5.500e-05  Data: 0.010 (0.010)
Train: 5 [ 700/3167 ( 22%)]  Loss: 4.36 (4.10)  Time: 0.601s,   66.58/s  (0.602s,   66.43/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [ 750/3167 ( 24%)]  Loss: 4.24 (4.10)  Time: 0.595s,   67.18/s  (0.602s,   66.43/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [ 800/3167 ( 25%)]  Loss: 3.65 (4.09)  Time: 0.602s,   66.39/s  (0.602s,   66.44/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [ 850/3167 ( 27%)]  Loss: 4.08 (4.09)  Time: 0.601s,   66.61/s  (0.602s,   66.45/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [ 900/3167 ( 28%)]  Loss: 3.92 (4.09)  Time: 0.592s,   67.51/s  (0.602s,   66.46/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [ 950/3167 ( 30%)]  Loss: 4.11 (4.09)  Time: 0.595s,   67.25/s  (0.602s,   66.47/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [1000/3167 ( 32%)]  Loss: 3.99 (4.09)  Time: 0.604s,   66.17/s  (0.602s,   66.48/s)  LR: 5.500e-05  Data: 0.014 (0.010)
Train: 5 [1050/3167 ( 33%)]  Loss: 4.37 (4.09)  Time: 0.598s,   66.93/s  (0.602s,   66.48/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [1100/3167 ( 35%)]  Loss: 4.39 (4.09)  Time: 0.593s,   67.50/s  (0.602s,   66.49/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [1150/3167 ( 36%)]  Loss: 4.46 (4.09)  Time: 0.606s,   66.05/s  (0.602s,   66.50/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1200/3167 ( 38%)]  Loss: 4.27 (4.09)  Time: 0.593s,   67.50/s  (0.601s,   66.50/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [1250/3167 ( 39%)]  Loss: 3.95 (4.09)  Time: 0.601s,   66.54/s  (0.601s,   66.51/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1300/3167 ( 41%)]  Loss: 3.91 (4.09)  Time: 0.604s,   66.27/s  (0.601s,   66.51/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [1350/3167 ( 43%)]  Loss: 3.60 (4.09)  Time: 0.610s,   65.59/s  (0.601s,   66.51/s)  LR: 5.500e-05  Data: 0.014 (0.010)
Train: 5 [1400/3167 ( 44%)]  Loss: 4.28 (4.09)  Time: 0.593s,   67.51/s  (0.601s,   66.52/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [1450/3167 ( 46%)]  Loss: 4.04 (4.09)  Time: 0.600s,   66.65/s  (0.601s,   66.53/s)  LR: 5.500e-05  Data: 0.009 (0.010)
Train: 5 [1500/3167 ( 47%)]  Loss: 4.08 (4.09)  Time: 0.597s,   66.98/s  (0.601s,   66.53/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [1550/3167 ( 49%)]  Loss: 4.24 (4.09)  Time: 0.598s,   66.94/s  (0.601s,   66.53/s)  LR: 5.500e-05  Data: 0.006 (0.010)
Train: 5 [1600/3167 ( 51%)]  Loss: 4.17 (4.09)  Time: 0.600s,   66.62/s  (0.601s,   66.54/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1650/3167 ( 52%)]  Loss: 3.74 (4.08)  Time: 0.605s,   66.08/s  (0.601s,   66.54/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1700/3167 ( 54%)]  Loss: 3.97 (4.08)  Time: 0.598s,   66.89/s  (0.601s,   66.55/s)  LR: 5.500e-05  Data: 0.009 (0.010)
Train: 5 [1750/3167 ( 55%)]  Loss: 4.17 (4.08)  Time: 0.593s,   67.50/s  (0.601s,   66.55/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [1800/3167 ( 57%)]  Loss: 4.22 (4.08)  Time: 0.598s,   66.88/s  (0.601s,   66.55/s)  LR: 5.500e-05  Data: 0.009 (0.010)
Train: 5 [1850/3167 ( 58%)]  Loss: 3.65 (4.08)  Time: 0.598s,   66.89/s  (0.601s,   66.56/s)  LR: 5.500e-05  Data: 0.009 (0.010)
Train: 5 [1900/3167 ( 60%)]  Loss: 4.31 (4.08)  Time: 0.601s,   66.58/s  (0.601s,   66.56/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1950/3167 ( 62%)]  Loss: 4.42 (4.08)  Time: 0.603s,   66.31/s  (0.601s,   66.56/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [2000/3167 ( 63%)]  Loss: 3.98 (4.08)  Time: 0.600s,   66.67/s  (0.601s,   66.57/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [2050/3167 ( 65%)]  Loss: 4.20 (4.08)  Time: 0.601s,   66.61/s  (0.601s,   66.57/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [2100/3167 ( 66%)]  Loss: 4.38 (4.08)  Time: 0.608s,   65.74/s  (0.601s,   66.57/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [2150/3167 ( 68%)]  Loss: 3.66 (4.08)  Time: 0.597s,   67.04/s  (0.601s,   66.58/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [2200/3167 ( 69%)]  Loss: 4.14 (4.08)  Time: 0.601s,   66.59/s  (0.601s,   66.58/s)  LR: 5.500e-05  Data: 0.012 (0.009)
Train: 5 [2250/3167 ( 71%)]  Loss: 4.21 (4.08)  Time: 0.601s,   66.54/s  (0.601s,   66.58/s)  LR: 5.500e-05  Data: 0.010 (0.009)
Train: 5 [2300/3167 ( 73%)]  Loss: 4.22 (4.08)  Time: 0.598s,   66.84/s  (0.601s,   66.59/s)  LR: 5.500e-05  Data: 0.007 (0.009)
Train: 5 [2350/3167 ( 74%)]  Loss: 3.93 (4.08)  Time: 0.593s,   67.48/s  (0.601s,   66.60/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2400/3167 ( 76%)]  Loss: 4.38 (4.08)  Time: 0.598s,   66.91/s  (0.601s,   66.60/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2450/3167 ( 77%)]  Loss: 4.31 (4.08)  Time: 0.595s,   67.19/s  (0.601s,   66.61/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2500/3167 ( 79%)]  Loss: 3.82 (4.08)  Time: 0.598s,   66.84/s  (0.600s,   66.61/s)  LR: 5.500e-05  Data: 0.009 (0.009)
Train: 5 [2550/3167 ( 81%)]  Loss: 3.64 (4.08)  Time: 0.600s,   66.66/s  (0.600s,   66.62/s)  LR: 5.500e-05  Data: 0.007 (0.009)
Train: 5 [2600/3167 ( 82%)]  Loss: 4.28 (4.08)  Time: 0.598s,   66.85/s  (0.600s,   66.62/s)  LR: 5.500e-05  Data: 0.007 (0.009)
Train: 5 [2650/3167 ( 84%)]  Loss: 3.80 (4.08)  Time: 0.599s,   66.83/s  (0.600s,   66.63/s)  LR: 5.500e-05  Data: 0.007 (0.009)
Train: 5 [2700/3167 ( 85%)]  Loss: 4.04 (4.08)  Time: 0.601s,   66.60/s  (0.600s,   66.63/s)  LR: 5.500e-05  Data: 0.012 (0.009)
Train: 5 [2750/3167 ( 87%)]  Loss: 4.22 (4.08)  Time: 0.596s,   67.13/s  (0.600s,   66.64/s)  LR: 5.500e-05  Data: 0.007 (0.009)
Train: 5 [2800/3167 ( 88%)]  Loss: 4.04 (4.07)  Time: 0.600s,   66.61/s  (0.600s,   66.64/s)  LR: 5.500e-05  Data: 0.012 (0.009)
Train: 5 [2850/3167 ( 90%)]  Loss: 3.93 (4.07)  Time: 0.596s,   67.15/s  (0.600s,   66.65/s)  LR: 5.500e-05  Data: 0.007 (0.009)
Train: 5 [2900/3167 ( 92%)]  Loss: 3.90 (4.07)  Time: 0.596s,   67.11/s  (0.600s,   66.66/s)  LR: 5.500e-05  Data: 0.007 (0.009)
Train: 5 [2950/3167 ( 93%)]  Loss: 4.28 (4.07)  Time: 0.596s,   67.08/s  (0.600s,   66.66/s)  LR: 5.500e-05  Data: 0.007 (0.009)
Train: 5 [3000/3167 ( 95%)]  Loss: 4.00 (4.07)  Time: 0.596s,   67.10/s  (0.600s,   66.67/s)  LR: 5.500e-05  Data: 0.007 (0.009)
Train: 5 [3050/3167 ( 96%)]  Loss: 4.18 (4.07)  Time: 0.593s,   67.50/s  (0.600s,   66.67/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [3100/3167 ( 98%)]  Loss: 4.10 (4.07)  Time: 0.595s,   67.22/s  (0.600s,   66.68/s)  LR: 5.500e-05  Data: 0.006 (0.009)
Train: 5 [3150/3167 ( 99%)]  Loss: 3.68 (4.07)  Time: 0.598s,   66.93/s  (0.600s,   66.68/s)  LR: 5.500e-05  Data: 0.006 (0.009)
Test: [   0/3167]  Time: 0.504 (0.504)  Loss:   3.967 ( 3.967)  Acc@1:   2.500 (  2.500)  Acc@5:  30.000 ( 30.000)
Test: [  50/3167]  Time: 0.195 (0.198)  Loss:   3.554 ( 3.681)  Acc@1:  32.500 ( 13.431)  Acc@5:  47.500 ( 40.294)
Test: [ 100/3167]  Time: 0.190 (0.195)  Loss:   3.678 ( 3.698)  Acc@1:  17.500 ( 13.441)  Acc@5:  45.000 ( 38.787)
Test: [ 150/3167]  Time: 0.190 (0.194)  Loss:   2.151 ( 3.512)  Acc@1:  62.500 ( 19.652)  Acc@5:  92.500 ( 46.424)
Test: [ 200/3167]  Time: 0.190 (0.193)  Loss:   3.634 ( 3.527)  Acc@1:  12.500 ( 19.577)  Acc@5:  42.500 ( 45.920)
Test: [ 250/3167]  Time: 0.199 (0.193)  Loss:   2.825 ( 3.477)  Acc@1:  30.000 ( 20.598)  Acc@5:  60.000 ( 46.424)
Test: [ 300/3167]  Time: 0.190 (0.192)  Loss:   3.202 ( 3.456)  Acc@1:  20.000 ( 21.620)  Acc@5:  60.000 ( 47.666)
Test: [ 350/3167]  Time: 0.187 (0.192)  Loss:   2.515 ( 3.374)  Acc@1:  62.500 ( 23.868)  Acc@5:  75.000 ( 50.463)
Test: [ 400/3167]  Time: 0.193 (0.192)  Loss:   2.678 ( 3.207)  Acc@1:  32.500 ( 28.435)  Acc@5:  72.500 ( 54.670)
Test: [ 450/3167]  Time: 0.191 (0.193)  Loss:   3.348 ( 3.218)  Acc@1:   2.500 ( 26.951)  Acc@5:  47.500 ( 53.947)
Test: [ 500/3167]  Time: 0.190 (0.193)  Loss:   2.732 ( 3.232)  Acc@1:  50.000 ( 26.971)  Acc@5:  67.500 ( 53.318)
Test: [ 550/3167]  Time: 0.187 (0.193)  Loss:   3.739 ( 3.168)  Acc@1:   2.500 ( 29.197)  Acc@5:  30.000 ( 54.828)
Test: [ 600/3167]  Time: 0.184 (0.193)  Loss:   2.598 ( 3.185)  Acc@1:  27.500 ( 27.953)  Acc@5:  75.000 ( 54.168)
Test: [ 650/3167]  Time: 0.200 (0.193)  Loss:   3.519 ( 3.172)  Acc@1:  30.000 ( 28.387)  Acc@5:  52.500 ( 54.697)
Test: [ 700/3167]  Time: 0.204 (0.193)  Loss:   3.005 ( 3.179)  Acc@1:  37.500 ( 28.577)  Acc@5:  75.000 ( 55.432)
Test: [ 750/3167]  Time: 0.192 (0.193)  Loss:   3.284 ( 3.176)  Acc@1:  42.500 ( 28.026)  Acc@5:  50.000 ( 55.925)
Test: [ 800/3167]  Time: 0.183 (0.193)  Loss:   4.398 ( 3.209)  Acc@1:   0.000 ( 27.425)  Acc@5:  17.500 ( 54.588)
Test: [ 850/3167]  Time: 0.191 (0.193)  Loss:   3.614 ( 3.259)  Acc@1:   2.500 ( 25.952)  Acc@5:  37.500 ( 52.712)
Test: [ 900/3167]  Time: 0.202 (0.193)  Loss:   3.703 ( 3.289)  Acc@1:  10.000 ( 24.720)  Acc@5:  40.000 ( 51.479)
Test: [ 950/3167]  Time: 0.195 (0.193)  Loss:   3.027 ( 3.320)  Acc@1:  27.500 ( 23.864)  Acc@5:  60.000 ( 50.226)
Test: [1000/3167]  Time: 0.186 (0.193)  Loss:   2.940 ( 3.327)  Acc@1:  42.500 ( 23.459)  Acc@5:  72.500 ( 50.097)
Test: [1050/3167]  Time: 0.199 (0.193)  Loss:   3.530 ( 3.317)  Acc@1:  20.000 ( 23.613)  Acc@5:  40.000 ( 50.697)
Test: [1100/3167]  Time: 0.202 (0.193)  Loss:   3.622 ( 3.317)  Acc@1:  22.500 ( 23.383)  Acc@5:  42.500 ( 50.990)
Test: [1150/3167]  Time: 0.201 (0.193)  Loss:   2.382 ( 3.302)  Acc@1:  65.000 ( 24.203)  Acc@5:  85.000 ( 51.631)
Test: [1200/3167]  Time: 0.189 (0.193)  Loss:   3.009 ( 3.283)  Acc@1:  37.500 ( 24.467)  Acc@5:  70.000 ( 52.521)
Test: [1250/3167]  Time: 0.189 (0.193)  Loss:   2.762 ( 3.269)  Acc@1:  47.500 ( 25.166)  Acc@5:  65.000 ( 53.062)
Test: [1300/3167]  Time: 0.194 (0.193)  Loss:   3.271 ( 3.287)  Acc@1:  20.000 ( 24.535)  Acc@5:  62.500 ( 52.160)
Test: [1350/3167]  Time: 0.196 (0.193)  Loss:   3.273 ( 3.314)  Acc@1:  17.500 ( 23.993)  Acc@5:  67.500 ( 51.227)
Test: [1400/3167]  Time: 0.189 (0.193)  Loss:   2.664 ( 3.332)  Acc@1:  50.000 ( 23.656)  Acc@5:  77.500 ( 50.667)
Test: [1450/3167]  Time: 0.192 (0.193)  Loss:   3.171 ( 3.315)  Acc@1:  17.500 ( 24.352)  Acc@5:  67.500 ( 51.387)
Test: [1500/3167]  Time: 0.183 (0.193)  Loss:   3.689 ( 3.297)  Acc@1:   5.000 ( 24.927)  Acc@5:  47.500 ( 51.977)
Test: [1550/3167]  Time: 0.195 (0.193)  Loss:   2.102 ( 3.288)  Acc@1:  80.000 ( 25.285)  Acc@5:  90.000 ( 52.357)
Test: [1600/3167]  Time: 0.191 (0.193)  Loss:   2.713 ( 3.276)  Acc@1:  42.500 ( 25.689)  Acc@5:  57.500 ( 52.864)
Test: [1650/3167]  Time: 0.194 (0.193)  Loss:   3.086 ( 3.263)  Acc@1:  15.000 ( 26.010)  Acc@5:  62.500 ( 53.281)
Test: [1700/3167]  Time: 0.187 (0.193)  Loss:   3.940 ( 3.258)  Acc@1:   2.500 ( 26.168)  Acc@5:  17.500 ( 53.514)
Test: [1750/3167]  Time: 0.189 (0.193)  Loss:   3.628 ( 3.271)  Acc@1:  20.000 ( 25.870)  Acc@5:  37.500 ( 53.023)
Test: [1800/3167]  Time: 0.185 (0.193)  Loss:   3.017 ( 3.271)  Acc@1:  15.000 ( 25.893)  Acc@5:  67.500 ( 53.133)
Test: [1850/3167]  Time: 0.192 (0.193)  Loss:   3.879 ( 3.289)  Acc@1:  15.000 ( 25.420)  Acc@5:  32.500 ( 52.430)
Test: [1900/3167]  Time: 0.190 (0.193)  Loss:   3.862 ( 3.301)  Acc@1:   0.000 ( 25.050)  Acc@5:  32.500 ( 52.115)
Test: [1950/3167]  Time: 0.191 (0.193)  Loss:   4.408 ( 3.317)  Acc@1:   0.000 ( 24.632)  Acc@5:  10.000 ( 51.571)
Test: [2000/3167]  Time: 0.191 (0.193)  Loss:   3.811 ( 3.337)  Acc@1:  10.000 ( 24.117)  Acc@5:  37.500 ( 50.767)
Test: [2050/3167]  Time: 0.203 (0.193)  Loss:   4.309 ( 3.353)  Acc@1:   0.000 ( 23.715)  Acc@5:   7.500 ( 50.029)
Test: [2100/3167]  Time: 0.188 (0.193)  Loss:   3.801 ( 3.359)  Acc@1:  10.000 ( 23.679)  Acc@5:  32.500 ( 49.916)
Test: [2150/3167]  Time: 0.192 (0.193)  Loss:   1.522 ( 3.340)  Acc@1:  77.500 ( 24.118)  Acc@5:  85.000 ( 50.162)
Test: [2200/3167]  Time: 0.204 (0.193)  Loss:   3.046 ( 3.330)  Acc@1:  17.500 ( 24.132)  Acc@5:  70.000 ( 50.480)
Test: [2250/3167]  Time: 0.186 (0.193)  Loss:   3.185 ( 3.337)  Acc@1:  45.000 ( 23.973)  Acc@5:  72.500 ( 50.324)
Test: [2300/3167]  Time: 0.207 (0.193)  Loss:   4.214 ( 3.346)  Acc@1:   0.000 ( 23.821)  Acc@5:  15.000 ( 50.067)
Test: [2350/3167]  Time: 0.189 (0.193)  Loss:   3.434 ( 3.354)  Acc@1:  30.000 ( 23.510)  Acc@5:  60.000 ( 49.767)
Test: [2400/3167]  Time: 0.194 (0.193)  Loss:   3.942 ( 3.344)  Acc@1:   0.000 ( 23.893)  Acc@5:  20.000 ( 50.000)
Test: [2450/3167]  Time: 0.194 (0.192)  Loss:   2.777 ( 3.342)  Acc@1:  40.000 ( 23.886)  Acc@5:  75.000 ( 50.144)
Test: [2500/3167]  Time: 0.197 (0.192)  Loss:   3.924 ( 3.346)  Acc@1:   7.500 ( 23.783)  Acc@5:  47.500 ( 50.152)
Test: [2550/3167]  Time: 0.206 (0.192)  Loss:   3.668 ( 3.337)  Acc@1:   5.000 ( 24.108)  Acc@5:  27.500 ( 50.490)
Test: [2600/3167]  Time: 0.191 (0.192)  Loss:   3.065 ( 3.342)  Acc@1:  32.500 ( 23.908)  Acc@5:  57.500 ( 50.229)
Test: [2650/3167]  Time: 0.191 (0.192)  Loss:   3.032 ( 3.345)  Acc@1:  35.000 ( 23.806)  Acc@5:  75.000 ( 50.209)
Test: [2700/3167]  Time: 0.193 (0.192)  Loss:   2.971 ( 3.340)  Acc@1:  32.500 ( 24.051)  Acc@5:  65.000 ( 50.468)
Test: [2750/3167]  Time: 0.188 (0.192)  Loss:   2.379 ( 3.345)  Acc@1:  52.500 ( 23.929)  Acc@5:  85.000 ( 50.211)
Test: [2800/3167]  Time: 0.186 (0.192)  Loss:   3.705 ( 3.340)  Acc@1:   0.000 ( 24.045)  Acc@5:  37.500 ( 50.399)
Test: [2850/3167]  Time: 0.186 (0.192)  Loss:   3.700 ( 3.350)  Acc@1:  15.000 ( 23.736)  Acc@5:  40.000 ( 50.019)
Test: [2900/3167]  Time: 0.198 (0.192)  Loss:   3.378 ( 3.351)  Acc@1:  30.000 ( 23.736)  Acc@5:  62.500 ( 50.065)
Test: [2950/3167]  Time: 0.194 (0.192)  Loss:   3.685 ( 3.354)  Acc@1:   0.000 ( 23.569)  Acc@5:  37.500 ( 50.046)
Test: [3000/3167]  Time: 0.187 (0.192)  Loss:   3.867 ( 3.362)  Acc@1:   7.500 ( 23.234)  Acc@5:  27.500 ( 49.666)
Test: [3050/3167]  Time: 0.189 (0.192)  Loss:   4.152 ( 3.368)  Acc@1:   0.000 ( 23.028)  Acc@5:  25.000 ( 49.386)
Test: [3100/3167]  Time: 0.188 (0.192)  Loss:   3.738 ( 3.377)  Acc@1:   5.000 ( 22.712)  Acc@5:  40.000 ( 49.040)
Test: [3150/3167]  Time: 0.184 (0.192)  Loss:   3.746 ( 3.385)  Acc@1:   0.000 ( 22.398)  Acc@5:  40.000 ( 48.788)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   3.378 ( 3.387)  Acc@1:  11.111 ( 22.342)  Acc@5:  55.556 ( 48.756)
Test: [   0/124]  Time: 0.619 (0.619)  Loss:   4.177 ( 4.177)  Acc@1:   2.500 (  2.500)  Acc@5:  12.500 ( 12.500)
Test: [  50/124]  Time: 0.188 (0.198)  Loss:   3.438 ( 3.372)  Acc@1:  22.500 ( 21.961)  Acc@5:  57.500 ( 49.804)
Test: [ 100/124]  Time: 0.184 (0.194)  Loss:   2.580 ( 3.416)  Acc@1:  60.000 ( 21.609)  Acc@5:  75.000 ( 47.698)
Test: [ 124/124]  Time: 0.180 (0.193)  Loss:   3.647 ( 3.453)  Acc@1:  12.500 ( 20.540)  Acc@5:  47.500 ( 46.780)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_2/checkpoint-5.pth.tar', 22.342113364260264)

Train: 6 [   0/3167 (  0%)]  Loss: 4.11 (4.11)  Time: 1.088s,   36.78/s  (1.088s,   36.78/s)  LR: 6.400e-05  Data: 0.471 (0.471)
Train: 6 [  50/3167 (  2%)]  Loss: 4.27 (4.05)  Time: 0.604s,   66.21/s  (0.613s,   65.30/s)  LR: 6.400e-05  Data: 0.011 (0.020)
Train: 6 [ 100/3167 (  3%)]  Loss: 4.02 (4.05)  Time: 0.600s,   66.64/s  (0.607s,   65.91/s)  LR: 6.400e-05  Data: 0.011 (0.015)
Train: 6 [ 150/3167 (  5%)]  Loss: 3.72 (4.04)  Time: 0.602s,   66.50/s  (0.605s,   66.10/s)  LR: 6.400e-05  Data: 0.004 (0.013)
Train: 6 [ 200/3167 (  6%)]  Loss: 4.05 (4.03)  Time: 0.609s,   65.66/s  (0.604s,   66.20/s)  LR: 6.400e-05  Data: 0.012 (0.012)
Train: 6 [ 250/3167 (  8%)]  Loss: 3.77 (4.02)  Time: 0.595s,   67.22/s  (0.603s,   66.28/s)  LR: 6.400e-05  Data: 0.004 (0.012)
Train: 6 [ 300/3167 (  9%)]  Loss: 3.47 (4.02)  Time: 0.601s,   66.54/s  (0.603s,   66.33/s)  LR: 6.400e-05  Data: 0.009 (0.011)
Train: 6 [ 350/3167 ( 11%)]  Loss: 4.06 (4.03)  Time: 0.601s,   66.60/s  (0.603s,   66.37/s)  LR: 6.400e-05  Data: 0.012 (0.011)
Train: 6 [ 400/3167 ( 13%)]  Loss: 3.91 (4.03)  Time: 0.602s,   66.42/s  (0.603s,   66.39/s)  LR: 6.400e-05  Data: 0.011 (0.011)
Train: 6 [ 450/3167 ( 14%)]  Loss: 3.99 (4.03)  Time: 0.598s,   66.88/s  (0.602s,   66.42/s)  LR: 6.400e-05  Data: 0.007 (0.011)
Train: 6 [ 500/3167 ( 16%)]  Loss: 3.98 (4.02)  Time: 0.603s,   66.31/s  (0.602s,   66.43/s)  LR: 6.400e-05  Data: 0.014 (0.011)
Train: 6 [ 550/3167 ( 17%)]  Loss: 4.13 (4.03)  Time: 0.609s,   65.72/s  (0.602s,   66.43/s)  LR: 6.400e-05  Data: 0.011 (0.011)
Train: 6 [ 600/3167 ( 19%)]  Loss: 4.28 (4.03)  Time: 0.593s,   67.46/s  (0.602s,   66.45/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [ 650/3167 ( 21%)]  Loss: 3.81 (4.03)  Time: 0.607s,   65.88/s  (0.602s,   66.45/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [ 700/3167 ( 22%)]  Loss: 4.41 (4.03)  Time: 0.601s,   66.58/s  (0.602s,   66.46/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [ 750/3167 ( 24%)]  Loss: 4.22 (4.03)  Time: 0.607s,   65.85/s  (0.602s,   66.46/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [ 800/3167 ( 25%)]  Loss: 4.24 (4.03)  Time: 0.608s,   65.78/s  (0.602s,   66.47/s)  LR: 6.400e-05  Data: 0.011 (0.010)
Train: 6 [ 850/3167 ( 27%)]  Loss: 4.37 (4.02)  Time: 0.593s,   67.49/s  (0.602s,   66.47/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [ 900/3167 ( 28%)]  Loss: 3.66 (4.02)  Time: 0.600s,   66.63/s  (0.602s,   66.48/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [ 950/3167 ( 30%)]  Loss: 3.74 (4.02)  Time: 0.601s,   66.59/s  (0.602s,   66.49/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1000/3167 ( 32%)]  Loss: 3.92 (4.02)  Time: 0.603s,   66.33/s  (0.602s,   66.49/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1050/3167 ( 33%)]  Loss: 3.88 (4.03)  Time: 0.600s,   66.64/s  (0.602s,   66.50/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1100/3167 ( 35%)]  Loss: 3.88 (4.03)  Time: 0.598s,   66.91/s  (0.602s,   66.50/s)  LR: 6.400e-05  Data: 0.009 (0.010)
Train: 6 [1150/3167 ( 36%)]  Loss: 3.85 (4.02)  Time: 0.600s,   66.63/s  (0.601s,   66.50/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1200/3167 ( 38%)]  Loss: 4.00 (4.02)  Time: 0.600s,   66.66/s  (0.601s,   66.51/s)  LR: 6.400e-05  Data: 0.011 (0.010)
Train: 6 [1250/3167 ( 39%)]  Loss: 4.23 (4.02)  Time: 0.599s,   66.73/s  (0.601s,   66.52/s)  LR: 6.400e-05  Data: 0.007 (0.010)
Train: 6 [1300/3167 ( 41%)]  Loss: 4.66 (4.02)  Time: 0.595s,   67.27/s  (0.601s,   66.52/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [1350/3167 ( 43%)]  Loss: 4.23 (4.02)  Time: 0.600s,   66.62/s  (0.601s,   66.52/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1400/3167 ( 44%)]  Loss: 4.15 (4.02)  Time: 0.598s,   66.90/s  (0.601s,   66.53/s)  LR: 6.400e-05  Data: 0.006 (0.010)
Train: 6 [1450/3167 ( 46%)]  Loss: 3.59 (4.02)  Time: 0.601s,   66.61/s  (0.601s,   66.53/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1500/3167 ( 47%)]  Loss: 4.36 (4.02)  Time: 0.602s,   66.46/s  (0.601s,   66.54/s)  LR: 6.400e-05  Data: 0.007 (0.010)
Train: 6 [1550/3167 ( 49%)]  Loss: 4.01 (4.02)  Time: 0.600s,   66.62/s  (0.601s,   66.54/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1600/3167 ( 51%)]  Loss: 3.67 (4.02)  Time: 0.603s,   66.32/s  (0.601s,   66.54/s)  LR: 6.400e-05  Data: 0.009 (0.010)
Train: 6 [1650/3167 ( 52%)]  Loss: 4.05 (4.02)  Time: 0.609s,   65.65/s  (0.601s,   66.55/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1700/3167 ( 54%)]  Loss: 4.33 (4.02)  Time: 0.600s,   66.62/s  (0.601s,   66.55/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1750/3167 ( 55%)]  Loss: 3.57 (4.02)  Time: 0.601s,   66.59/s  (0.601s,   66.56/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1800/3167 ( 57%)]  Loss: 3.82 (4.02)  Time: 0.599s,   66.79/s  (0.601s,   66.56/s)  LR: 6.400e-05  Data: 0.010 (0.010)
Train: 6 [1850/3167 ( 58%)]  Loss: 3.97 (4.02)  Time: 0.601s,   66.60/s  (0.601s,   66.57/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1900/3167 ( 60%)]  Loss: 3.93 (4.02)  Time: 0.601s,   66.57/s  (0.601s,   66.57/s)  LR: 6.400e-05  Data: 0.009 (0.010)
Train: 6 [1950/3167 ( 62%)]  Loss: 4.10 (4.02)  Time: 0.602s,   66.43/s  (0.601s,   66.58/s)  LR: 6.400e-05  Data: 0.007 (0.010)
Train: 6 [2000/3167 ( 63%)]  Loss: 4.26 (4.02)  Time: 0.601s,   66.56/s  (0.601s,   66.58/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [2050/3167 ( 65%)]  Loss: 3.44 (4.02)  Time: 0.602s,   66.45/s  (0.601s,   66.58/s)  LR: 6.400e-05  Data: 0.010 (0.010)
Train: 6 [2100/3167 ( 66%)]  Loss: 3.68 (4.02)  Time: 0.601s,   66.60/s  (0.601s,   66.59/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [2150/3167 ( 68%)]  Loss: 4.00 (4.02)  Time: 0.598s,   66.84/s  (0.601s,   66.59/s)  LR: 6.400e-05  Data: 0.010 (0.009)
Train: 6 [2200/3167 ( 69%)]  Loss: 3.80 (4.02)  Time: 0.603s,   66.32/s  (0.601s,   66.60/s)  LR: 6.400e-05  Data: 0.012 (0.009)
Train: 6 [2250/3167 ( 71%)]  Loss: 3.89 (4.02)  Time: 0.595s,   67.20/s  (0.601s,   66.60/s)  LR: 6.400e-05  Data: 0.007 (0.009)
Train: 6 [2300/3167 ( 73%)]  Loss: 3.66 (4.01)  Time: 0.601s,   66.51/s  (0.601s,   66.61/s)  LR: 6.400e-05  Data: 0.009 (0.009)
Train: 6 [2350/3167 ( 74%)]  Loss: 3.62 (4.01)  Time: 0.603s,   66.35/s  (0.601s,   66.61/s)  LR: 6.400e-05  Data: 0.014 (0.009)
Train: 6 [2400/3167 ( 76%)]  Loss: 4.11 (4.01)  Time: 0.595s,   67.21/s  (0.600s,   66.62/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [2450/3167 ( 77%)]  Loss: 4.08 (4.01)  Time: 0.603s,   66.33/s  (0.600s,   66.62/s)  LR: 6.400e-05  Data: 0.011 (0.009)
Train: 6 [2500/3167 ( 79%)]  Loss: 3.92 (4.01)  Time: 0.598s,   66.84/s  (0.600s,   66.63/s)  LR: 6.400e-05  Data: 0.010 (0.009)
Train: 6 [2550/3167 ( 81%)]  Loss: 4.24 (4.01)  Time: 0.596s,   67.12/s  (0.600s,   66.63/s)  LR: 6.400e-05  Data: 0.007 (0.009)
Train: 6 [2600/3167 ( 82%)]  Loss: 4.25 (4.01)  Time: 0.601s,   66.58/s  (0.600s,   66.64/s)  LR: 6.400e-05  Data: 0.012 (0.009)
Train: 6 [2650/3167 ( 84%)]  Loss: 3.74 (4.01)  Time: 0.599s,   66.73/s  (0.600s,   66.64/s)  LR: 6.400e-05  Data: 0.010 (0.009)
Train: 6 [2700/3167 ( 85%)]  Loss: 3.55 (4.01)  Time: 0.596s,   67.17/s  (0.600s,   66.65/s)  LR: 6.400e-05  Data: 0.007 (0.009)
Train: 6 [2750/3167 ( 87%)]  Loss: 3.67 (4.01)  Time: 0.596s,   67.14/s  (0.600s,   66.66/s)  LR: 6.400e-05  Data: 0.007 (0.009)
Train: 6 [2800/3167 ( 88%)]  Loss: 4.27 (4.01)  Time: 0.596s,   67.15/s  (0.600s,   66.66/s)  LR: 6.400e-05  Data: 0.007 (0.009)
Train: 6 [2850/3167 ( 90%)]  Loss: 4.08 (4.01)  Time: 0.599s,   66.75/s  (0.600s,   66.67/s)  LR: 6.400e-05  Data: 0.007 (0.009)
Train: 6 [2900/3167 ( 92%)]  Loss: 3.92 (4.01)  Time: 0.596s,   67.16/s  (0.600s,   66.67/s)  LR: 6.400e-05  Data: 0.007 (0.009)
Train: 6 [2950/3167 ( 93%)]  Loss: 3.61 (4.01)  Time: 0.593s,   67.48/s  (0.600s,   66.68/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [3000/3167 ( 95%)]  Loss: 4.08 (4.01)  Time: 0.599s,   66.74/s  (0.600s,   66.68/s)  LR: 6.400e-05  Data: 0.010 (0.009)
Train: 6 [3050/3167 ( 96%)]  Loss: 4.00 (4.01)  Time: 0.598s,   66.84/s  (0.600s,   66.68/s)  LR: 6.400e-05  Data: 0.007 (0.009)
Train: 6 [3100/3167 ( 98%)]  Loss: 4.27 (4.00)  Time: 0.600s,   66.61/s  (0.600s,   66.69/s)  LR: 6.400e-05  Data: 0.009 (0.009)
Train: 6 [3150/3167 ( 99%)]  Loss: 4.11 (4.01)  Time: 0.598s,   66.84/s  (0.600s,   66.69/s)  LR: 6.400e-05  Data: 0.007 (0.009)
Test: [   0/3167]  Time: 0.451 (0.451)  Loss:   3.382 ( 3.382)  Acc@1:  17.500 ( 17.500)  Acc@5:  52.500 ( 52.500)
Test: [  50/3167]  Time: 0.209 (0.199)  Loss:   3.324 ( 3.276)  Acc@1:  35.000 ( 22.549)  Acc@5:  45.000 ( 55.000)
Test: [ 100/3167]  Time: 0.184 (0.196)  Loss:   3.352 ( 3.312)  Acc@1:  22.500 ( 19.752)  Acc@5:  62.500 ( 53.193)
Test: [ 150/3167]  Time: 0.197 (0.195)  Loss:   1.988 ( 3.179)  Acc@1:  52.500 ( 24.272)  Acc@5:  92.500 ( 57.980)
Test: [ 200/3167]  Time: 0.191 (0.194)  Loss:   3.431 ( 3.232)  Acc@1:  20.000 ( 22.799)  Acc@5:  57.500 ( 54.950)
Test: [ 250/3167]  Time: 0.203 (0.194)  Loss:   3.048 ( 3.234)  Acc@1:  27.500 ( 23.008)  Acc@5:  45.000 ( 54.283)
Test: [ 300/3167]  Time: 0.205 (0.194)  Loss:   3.012 ( 3.262)  Acc@1:  17.500 ( 22.716)  Acc@5:  65.000 ( 53.621)
Test: [ 350/3167]  Time: 0.194 (0.194)  Loss:   2.702 ( 3.211)  Acc@1:  50.000 ( 23.875)  Acc@5:  72.500 ( 55.370)
Test: [ 400/3167]  Time: 0.200 (0.194)  Loss:   2.529 ( 3.074)  Acc@1:  40.000 ( 28.080)  Acc@5:  80.000 ( 58.953)
Test: [ 450/3167]  Time: 0.192 (0.194)  Loss:   3.440 ( 3.098)  Acc@1:   0.000 ( 26.907)  Acc@5:  45.000 ( 58.154)
Test: [ 500/3167]  Time: 0.195 (0.194)  Loss:   2.655 ( 3.101)  Acc@1:  42.500 ( 27.300)  Acc@5:  70.000 ( 57.854)
Test: [ 550/3167]  Time: 0.187 (0.194)  Loss:   3.754 ( 3.044)  Acc@1:   2.500 ( 29.456)  Acc@5:  32.500 ( 58.966)
Test: [ 600/3167]  Time: 0.202 (0.194)  Loss:   2.694 ( 3.077)  Acc@1:  37.500 ( 28.486)  Acc@5:  60.000 ( 57.841)
Test: [ 650/3167]  Time: 0.188 (0.194)  Loss:   2.917 ( 3.060)  Acc@1:  37.500 ( 29.155)  Acc@5:  67.500 ( 58.210)
Test: [ 700/3167]  Time: 0.187 (0.194)  Loss:   2.717 ( 3.044)  Acc@1:  50.000 ( 29.861)  Acc@5:  82.500 ( 59.394)
Test: [ 750/3167]  Time: 0.196 (0.194)  Loss:   3.186 ( 3.022)  Acc@1:  42.500 ( 30.712)  Acc@5:  47.500 ( 60.559)
Test: [ 800/3167]  Time: 0.199 (0.194)  Loss:   3.842 ( 3.042)  Acc@1:   5.000 ( 30.190)  Acc@5:  32.500 ( 59.697)
Test: [ 850/3167]  Time: 0.194 (0.194)  Loss:   3.357 ( 3.085)  Acc@1:   7.500 ( 28.666)  Acc@5:  57.500 ( 58.196)
Test: [ 900/3167]  Time: 0.193 (0.194)  Loss:   3.706 ( 3.119)  Acc@1:  15.000 ( 27.600)  Acc@5:  40.000 ( 57.250)
Test: [ 950/3167]  Time: 0.192 (0.194)  Loss:   3.321 ( 3.151)  Acc@1:  25.000 ( 26.659)  Acc@5:  55.000 ( 56.033)
Test: [1000/3167]  Time: 0.191 (0.193)  Loss:   3.200 ( 3.174)  Acc@1:  17.500 ( 25.829)  Acc@5:  60.000 ( 55.237)
Test: [1050/3167]  Time: 0.194 (0.193)  Loss:   2.978 ( 3.165)  Acc@1:  32.500 ( 26.135)  Acc@5:  72.500 ( 55.816)
Test: [1100/3167]  Time: 0.194 (0.193)  Loss:   3.247 ( 3.164)  Acc@1:  37.500 ( 25.904)  Acc@5:  65.000 ( 56.122)
Test: [1150/3167]  Time: 0.183 (0.193)  Loss:   1.891 ( 3.136)  Acc@1:  75.000 ( 27.135)  Acc@5:  90.000 ( 56.992)
Test: [1200/3167]  Time: 0.191 (0.193)  Loss:   2.525 ( 3.115)  Acc@1:  52.500 ( 27.735)  Acc@5:  82.500 ( 57.779)
Test: [1250/3167]  Time: 0.191 (0.193)  Loss:   2.080 ( 3.086)  Acc@1:  60.000 ( 28.873)  Acc@5:  87.500 ( 58.521)
Test: [1300/3167]  Time: 0.199 (0.193)  Loss:   2.664 ( 3.101)  Acc@1:  47.500 ( 28.503)  Acc@5:  85.000 ( 57.934)
Test: [1350/3167]  Time: 0.197 (0.193)  Loss:   3.450 ( 3.128)  Acc@1:  20.000 ( 28.148)  Acc@5:  60.000 ( 57.104)
Test: [1400/3167]  Time: 0.201 (0.193)  Loss:   3.204 ( 3.148)  Acc@1:  27.500 ( 27.655)  Acc@5:  57.500 ( 56.444)
Test: [1450/3167]  Time: 0.193 (0.193)  Loss:   3.153 ( 3.148)  Acc@1:  25.000 ( 27.898)  Acc@5:  57.500 ( 56.521)
Test: [1500/3167]  Time: 0.184 (0.193)  Loss:   3.339 ( 3.130)  Acc@1:  22.500 ( 28.473)  Acc@5:  55.000 ( 56.975)
Test: [1550/3167]  Time: 0.194 (0.193)  Loss:   1.682 ( 3.117)  Acc@1:  80.000 ( 28.880)  Acc@5:  90.000 ( 57.407)
Test: [1600/3167]  Time: 0.190 (0.193)  Loss:   2.892 ( 3.103)  Acc@1:  37.500 ( 29.247)  Acc@5:  57.500 ( 57.976)
Test: [1650/3167]  Time: 0.190 (0.193)  Loss:   2.744 ( 3.092)  Acc@1:  30.000 ( 29.532)  Acc@5:  72.500 ( 58.322)
Test: [1700/3167]  Time: 0.184 (0.193)  Loss:   3.792 ( 3.079)  Acc@1:   7.500 ( 29.968)  Acc@5:  30.000 ( 58.623)
Test: [1750/3167]  Time: 0.189 (0.193)  Loss:   3.593 ( 3.096)  Acc@1:  12.500 ( 29.529)  Acc@5:  37.500 ( 58.003)
Test: [1800/3167]  Time: 0.204 (0.193)  Loss:   3.313 ( 3.105)  Acc@1:   7.500 ( 29.366)  Acc@5:  45.000 ( 57.778)
Test: [1850/3167]  Time: 0.189 (0.193)  Loss:   3.442 ( 3.123)  Acc@1:  15.000 ( 28.689)  Acc@5:  40.000 ( 56.919)
Test: [1900/3167]  Time: 0.198 (0.193)  Loss:   3.816 ( 3.133)  Acc@1:   7.500 ( 28.248)  Acc@5:  32.500 ( 56.683)
Test: [1950/3167]  Time: 0.183 (0.193)  Loss:   4.297 ( 3.143)  Acc@1:   0.000 ( 27.899)  Acc@5:  10.000 ( 56.351)
Test: [2000/3167]  Time: 0.185 (0.193)  Loss:   3.962 ( 3.165)  Acc@1:   5.000 ( 27.321)  Acc@5:  25.000 ( 55.481)
Test: [2050/3167]  Time: 0.186 (0.193)  Loss:   3.762 ( 3.180)  Acc@1:   5.000 ( 26.824)  Acc@5:  25.000 ( 54.837)
Test: [2100/3167]  Time: 0.202 (0.193)  Loss:   3.554 ( 3.181)  Acc@1:  10.000 ( 26.862)  Acc@5:  47.500 ( 54.873)
Test: [2150/3167]  Time: 0.192 (0.193)  Loss:   1.792 ( 3.167)  Acc@1:  70.000 ( 27.247)  Acc@5:  77.500 ( 55.123)
Test: [2200/3167]  Time: 0.186 (0.193)  Loss:   3.244 ( 3.163)  Acc@1:  12.500 ( 27.231)  Acc@5:  50.000 ( 55.244)
Test: [2250/3167]  Time: 0.209 (0.192)  Loss:   3.350 ( 3.172)  Acc@1:  27.500 ( 26.869)  Acc@5:  52.500 ( 54.922)
Test: [2300/3167]  Time: 0.191 (0.192)  Loss:   3.973 ( 3.183)  Acc@1:   0.000 ( 26.463)  Acc@5:  22.500 ( 54.488)
Test: [2350/3167]  Time: 0.198 (0.192)  Loss:   3.799 ( 3.196)  Acc@1:   5.000 ( 25.997)  Acc@5:  47.500 ( 53.942)
Test: [2400/3167]  Time: 0.187 (0.192)  Loss:   3.717 ( 3.191)  Acc@1:   0.000 ( 26.188)  Acc@5:  25.000 ( 53.979)
Test: [2450/3167]  Time: 0.191 (0.192)  Loss:   2.565 ( 3.188)  Acc@1:  42.500 ( 26.203)  Acc@5:  82.500 ( 54.182)
Test: [2500/3167]  Time: 0.186 (0.192)  Loss:   3.021 ( 3.188)  Acc@1:  35.000 ( 26.273)  Acc@5:  72.500 ( 54.296)
Test: [2550/3167]  Time: 0.183 (0.192)  Loss:   3.955 ( 3.171)  Acc@1:   0.000 ( 26.886)  Acc@5:  22.500 ( 54.790)
Test: [2600/3167]  Time: 0.187 (0.192)  Loss:   2.615 ( 3.179)  Acc@1:  50.000 ( 26.734)  Acc@5:  70.000 ( 54.435)
Test: [2650/3167]  Time: 0.192 (0.192)  Loss:   3.299 ( 3.185)  Acc@1:  17.500 ( 26.674)  Acc@5:  55.000 ( 54.291)
Test: [2700/3167]  Time: 0.188 (0.192)  Loss:   2.752 ( 3.185)  Acc@1:  42.500 ( 26.691)  Acc@5:  67.500 ( 54.369)
Test: [2750/3167]  Time: 0.187 (0.192)  Loss:   2.481 ( 3.190)  Acc@1:  37.500 ( 26.519)  Acc@5:  87.500 ( 54.140)
Test: [2800/3167]  Time: 0.189 (0.192)  Loss:   3.741 ( 3.188)  Acc@1:  12.500 ( 26.465)  Acc@5:  50.000 ( 54.333)
Test: [2850/3167]  Time: 0.184 (0.192)  Loss:   3.648 ( 3.204)  Acc@1:  10.000 ( 26.068)  Acc@5:  32.500 ( 53.679)
Test: [2900/3167]  Time: 0.195 (0.192)  Loss:   2.926 ( 3.206)  Acc@1:  37.500 ( 26.091)  Acc@5:  72.500 ( 53.689)
Test: [2950/3167]  Time: 0.206 (0.192)  Loss:   3.622 ( 3.215)  Acc@1:   0.000 ( 25.759)  Acc@5:  32.500 ( 53.273)
Test: [3000/3167]  Time: 0.194 (0.192)  Loss:   4.075 ( 3.227)  Acc@1:   5.000 ( 25.362)  Acc@5:  32.500 ( 52.827)
Test: [3050/3167]  Time: 0.185 (0.192)  Loss:   3.870 ( 3.231)  Acc@1:   7.500 ( 25.193)  Acc@5:  25.000 ( 52.723)
Test: [3100/3167]  Time: 0.184 (0.192)  Loss:   3.776 ( 3.241)  Acc@1:   0.000 ( 24.830)  Acc@5:  32.500 ( 52.307)
Test: [3150/3167]  Time: 0.189 (0.192)  Loss:   3.165 ( 3.244)  Acc@1:  12.500 ( 24.635)  Acc@5:  62.500 ( 52.278)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   2.757 ( 3.244)  Acc@1:  44.444 ( 24.611)  Acc@5:  77.778 ( 52.321)
Test: [   0/124]  Time: 0.580 (0.580)  Loss:   3.559 ( 3.559)  Acc@1:   7.500 (  7.500)  Acc@5:  47.500 ( 47.500)
Test: [  50/124]  Time: 0.189 (0.199)  Loss:   2.900 ( 3.195)  Acc@1:  47.500 ( 26.373)  Acc@5:  72.500 ( 55.196)
Test: [ 100/124]  Time: 0.190 (0.194)  Loss:   2.216 ( 3.263)  Acc@1:  65.000 ( 24.307)  Acc@5:  82.500 ( 51.064)
Test: [ 124/124]  Time: 0.180 (0.193)  Loss:   2.991 ( 3.324)  Acc@1:  20.000 ( 22.300)  Acc@5:  67.500 ( 49.140)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_2/checkpoint-6.pth.tar', 24.61066075207061)

Train: 7 [   0/3167 (  0%)]  Loss: 4.21 (4.21)  Time: 1.081s,   37.00/s  (1.081s,   37.00/s)  LR: 7.300e-05  Data: 0.488 (0.488)
Train: 7 [  50/3167 (  2%)]  Loss: 4.21 (4.00)  Time: 0.595s,   67.18/s  (0.610s,   65.58/s)  LR: 7.300e-05  Data: 0.004 (0.019)
Train: 7 [ 100/3167 (  3%)]  Loss: 4.14 (3.98)  Time: 0.603s,   66.34/s  (0.605s,   66.10/s)  LR: 7.300e-05  Data: 0.011 (0.014)
Train: 7 [ 150/3167 (  5%)]  Loss: 4.04 (3.99)  Time: 0.602s,   66.40/s  (0.604s,   66.27/s)  LR: 7.300e-05  Data: 0.011 (0.012)
Train: 7 [ 200/3167 (  6%)]  Loss: 4.16 (3.98)  Time: 0.601s,   66.54/s  (0.603s,   66.35/s)  LR: 7.300e-05  Data: 0.009 (0.012)
Train: 7 [ 250/3167 (  8%)]  Loss: 3.96 (3.98)  Time: 0.593s,   67.44/s  (0.602s,   66.40/s)  LR: 7.300e-05  Data: 0.004 (0.011)
Train: 7 [ 300/3167 (  9%)]  Loss: 4.17 (3.98)  Time: 0.601s,   66.60/s  (0.602s,   66.44/s)  LR: 7.300e-05  Data: 0.012 (0.011)
Train: 7 [ 350/3167 ( 11%)]  Loss: 4.24 (3.98)  Time: 0.593s,   67.43/s  (0.602s,   66.46/s)  LR: 7.300e-05  Data: 0.004 (0.011)
Train: 7 [ 400/3167 ( 13%)]  Loss: 4.63 (3.99)  Time: 0.604s,   66.26/s  (0.602s,   66.46/s)  LR: 7.300e-05  Data: 0.007 (0.011)
Train: 7 [ 450/3167 ( 14%)]  Loss: 4.08 (3.99)  Time: 0.597s,   66.97/s  (0.602s,   66.46/s)  LR: 7.300e-05  Data: 0.004 (0.011)
Train: 7 [ 500/3167 ( 16%)]  Loss: 3.57 (3.98)  Time: 0.596s,   67.16/s  (0.602s,   66.48/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [ 550/3167 ( 17%)]  Loss: 3.53 (3.98)  Time: 0.600s,   66.64/s  (0.602s,   66.48/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [ 600/3167 ( 19%)]  Loss: 3.43 (3.98)  Time: 0.595s,   67.18/s  (0.602s,   66.49/s)  LR: 7.300e-05  Data: 0.006 (0.010)
Train: 7 [ 650/3167 ( 21%)]  Loss: 4.14 (3.98)  Time: 0.607s,   65.91/s  (0.601s,   66.51/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [ 700/3167 ( 22%)]  Loss: 4.62 (3.99)  Time: 0.601s,   66.59/s  (0.601s,   66.51/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [ 750/3167 ( 24%)]  Loss: 3.87 (3.98)  Time: 0.602s,   66.41/s  (0.601s,   66.52/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [ 800/3167 ( 25%)]  Loss: 3.88 (3.98)  Time: 0.603s,   66.29/s  (0.601s,   66.52/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [ 850/3167 ( 27%)]  Loss: 3.75 (3.99)  Time: 0.593s,   67.46/s  (0.601s,   66.53/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [ 900/3167 ( 28%)]  Loss: 3.85 (3.98)  Time: 0.596s,   67.14/s  (0.601s,   66.53/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [ 950/3167 ( 30%)]  Loss: 3.92 (3.98)  Time: 0.602s,   66.49/s  (0.601s,   66.54/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [1000/3167 ( 32%)]  Loss: 4.18 (3.98)  Time: 0.593s,   67.47/s  (0.601s,   66.54/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [1050/3167 ( 33%)]  Loss: 3.69 (3.98)  Time: 0.593s,   67.49/s  (0.601s,   66.54/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [1100/3167 ( 35%)]  Loss: 4.32 (3.98)  Time: 0.601s,   66.58/s  (0.601s,   66.55/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [1150/3167 ( 36%)]  Loss: 4.31 (3.98)  Time: 0.605s,   66.15/s  (0.601s,   66.55/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [1200/3167 ( 38%)]  Loss: 4.19 (3.98)  Time: 0.599s,   66.79/s  (0.601s,   66.55/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [1250/3167 ( 39%)]  Loss: 3.59 (3.98)  Time: 0.600s,   66.61/s  (0.601s,   66.56/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [1300/3167 ( 41%)]  Loss: 4.22 (3.98)  Time: 0.600s,   66.66/s  (0.601s,   66.56/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [1350/3167 ( 43%)]  Loss: 4.10 (3.98)  Time: 0.603s,   66.34/s  (0.601s,   66.57/s)  LR: 7.300e-05  Data: 0.014 (0.010)
Train: 7 [1400/3167 ( 44%)]  Loss: 4.17 (3.98)  Time: 0.593s,   67.48/s  (0.601s,   66.57/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [1450/3167 ( 46%)]  Loss: 4.04 (3.98)  Time: 0.610s,   65.61/s  (0.601s,   66.58/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [1500/3167 ( 47%)]  Loss: 4.61 (3.97)  Time: 0.600s,   66.67/s  (0.601s,   66.58/s)  LR: 7.300e-05  Data: 0.011 (0.010)
Train: 7 [1550/3167 ( 49%)]  Loss: 4.13 (3.97)  Time: 0.599s,   66.74/s  (0.601s,   66.58/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [1600/3167 ( 51%)]  Loss: 3.72 (3.97)  Time: 0.600s,   66.65/s  (0.601s,   66.59/s)  LR: 7.300e-05  Data: 0.011 (0.010)
Train: 7 [1650/3167 ( 52%)]  Loss: 4.22 (3.97)  Time: 0.599s,   66.79/s  (0.601s,   66.60/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [1700/3167 ( 54%)]  Loss: 3.92 (3.97)  Time: 0.593s,   67.48/s  (0.601s,   66.60/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [1750/3167 ( 55%)]  Loss: 3.90 (3.97)  Time: 0.601s,   66.59/s  (0.601s,   66.60/s)  LR: 7.300e-05  Data: 0.012 (0.009)
Train: 7 [1800/3167 ( 57%)]  Loss: 3.87 (3.97)  Time: 0.598s,   66.91/s  (0.601s,   66.61/s)  LR: 7.300e-05  Data: 0.009 (0.009)
Train: 7 [1850/3167 ( 58%)]  Loss: 3.94 (3.97)  Time: 0.601s,   66.56/s  (0.600s,   66.62/s)  LR: 7.300e-05  Data: 0.012 (0.009)
Train: 7 [1900/3167 ( 60%)]  Loss: 4.03 (3.97)  Time: 0.597s,   67.03/s  (0.600s,   66.62/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [1950/3167 ( 62%)]  Loss: 4.00 (3.97)  Time: 0.593s,   67.48/s  (0.600s,   66.63/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2000/3167 ( 63%)]  Loss: 4.23 (3.97)  Time: 0.594s,   67.38/s  (0.600s,   66.63/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2050/3167 ( 65%)]  Loss: 4.08 (3.97)  Time: 0.600s,   66.62/s  (0.600s,   66.64/s)  LR: 7.300e-05  Data: 0.012 (0.009)
Train: 7 [2100/3167 ( 66%)]  Loss: 4.15 (3.97)  Time: 0.601s,   66.59/s  (0.600s,   66.64/s)  LR: 7.300e-05  Data: 0.007 (0.009)
Train: 7 [2150/3167 ( 68%)]  Loss: 4.23 (3.97)  Time: 0.599s,   66.74/s  (0.600s,   66.65/s)  LR: 7.300e-05  Data: 0.009 (0.009)
Train: 7 [2200/3167 ( 69%)]  Loss: 4.30 (3.97)  Time: 0.599s,   66.81/s  (0.600s,   66.65/s)  LR: 7.300e-05  Data: 0.007 (0.009)
Train: 7 [2250/3167 ( 71%)]  Loss: 3.76 (3.97)  Time: 0.601s,   66.61/s  (0.600s,   66.66/s)  LR: 7.300e-05  Data: 0.012 (0.009)
Train: 7 [2300/3167 ( 73%)]  Loss: 4.10 (3.97)  Time: 0.598s,   66.88/s  (0.600s,   66.66/s)  LR: 7.300e-05  Data: 0.007 (0.009)
Train: 7 [2350/3167 ( 74%)]  Loss: 3.49 (3.96)  Time: 0.595s,   67.23/s  (0.600s,   66.67/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2400/3167 ( 76%)]  Loss: 4.15 (3.97)  Time: 0.598s,   66.85/s  (0.600s,   66.67/s)  LR: 7.300e-05  Data: 0.010 (0.009)
Train: 7 [2450/3167 ( 77%)]  Loss: 4.20 (3.97)  Time: 0.598s,   66.86/s  (0.600s,   66.67/s)  LR: 7.300e-05  Data: 0.007 (0.009)
Train: 7 [2500/3167 ( 79%)]  Loss: 3.39 (3.96)  Time: 0.593s,   67.51/s  (0.600s,   66.68/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2550/3167 ( 81%)]  Loss: 3.79 (3.96)  Time: 0.598s,   66.84/s  (0.600s,   66.68/s)  LR: 7.300e-05  Data: 0.007 (0.009)
Train: 7 [2600/3167 ( 82%)]  Loss: 3.75 (3.96)  Time: 0.593s,   67.51/s  (0.600s,   66.69/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2650/3167 ( 84%)]  Loss: 3.92 (3.96)  Time: 0.596s,   67.16/s  (0.600s,   66.69/s)  LR: 7.300e-05  Data: 0.007 (0.009)
Train: 7 [2700/3167 ( 85%)]  Loss: 4.22 (3.96)  Time: 0.601s,   66.59/s  (0.600s,   66.70/s)  LR: 7.300e-05  Data: 0.009 (0.009)
Train: 7 [2750/3167 ( 87%)]  Loss: 4.18 (3.96)  Time: 0.593s,   67.50/s  (0.600s,   66.71/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2800/3167 ( 88%)]  Loss: 4.14 (3.96)  Time: 0.597s,   67.01/s  (0.600s,   66.71/s)  LR: 7.300e-05  Data: 0.007 (0.009)
Train: 7 [2850/3167 ( 90%)]  Loss: 3.93 (3.96)  Time: 0.598s,   66.87/s  (0.600s,   66.71/s)  LR: 7.300e-05  Data: 0.007 (0.009)
Train: 7 [2900/3167 ( 92%)]  Loss: 3.96 (3.96)  Time: 0.595s,   67.17/s  (0.600s,   66.72/s)  LR: 7.300e-05  Data: 0.007 (0.009)
Train: 7 [2950/3167 ( 93%)]  Loss: 4.37 (3.96)  Time: 0.593s,   67.47/s  (0.599s,   66.72/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [3000/3167 ( 95%)]  Loss: 3.91 (3.96)  Time: 0.597s,   67.01/s  (0.599s,   66.73/s)  LR: 7.300e-05  Data: 0.007 (0.009)
Train: 7 [3050/3167 ( 96%)]  Loss: 3.90 (3.96)  Time: 0.596s,   67.14/s  (0.599s,   66.73/s)  LR: 7.300e-05  Data: 0.007 (0.009)
Train: 7 [3100/3167 ( 98%)]  Loss: 3.59 (3.95)  Time: 0.597s,   66.98/s  (0.599s,   66.73/s)  LR: 7.300e-05  Data: 0.007 (0.009)
Train: 7 [3150/3167 ( 99%)]  Loss: 4.09 (3.95)  Time: 0.593s,   67.49/s  (0.599s,   66.74/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Test: [   0/3167]  Time: 0.505 (0.505)  Loss:   3.333 ( 3.333)  Acc@1:  27.500 ( 27.500)  Acc@5:  62.500 ( 62.500)
Test: [  50/3167]  Time: 0.184 (0.200)  Loss:   2.989 ( 3.166)  Acc@1:  32.500 ( 30.294)  Acc@5:  57.500 ( 59.853)
Test: [ 100/3167]  Time: 0.194 (0.196)  Loss:   3.499 ( 3.183)  Acc@1:   7.500 ( 21.980)  Acc@5:  47.500 ( 55.594)
Test: [ 150/3167]  Time: 0.188 (0.195)  Loss:   1.847 ( 3.100)  Acc@1:  72.500 ( 26.076)  Acc@5:  95.000 ( 58.609)
Test: [ 200/3167]  Time: 0.190 (0.194)  Loss:   4.025 ( 3.151)  Acc@1:   0.000 ( 24.179)  Acc@5:  17.500 ( 55.311)
Test: [ 250/3167]  Time: 0.203 (0.194)  Loss:   2.385 ( 3.182)  Acc@1:  40.000 ( 23.894)  Acc@5:  72.500 ( 52.341)
Test: [ 300/3167]  Time: 0.199 (0.194)  Loss:   2.686 ( 3.161)  Acc@1:  32.500 ( 25.058)  Acc@5:  75.000 ( 53.679)
Test: [ 350/3167]  Time: 0.191 (0.194)  Loss:   2.707 ( 3.111)  Acc@1:  40.000 ( 26.204)  Acc@5:  70.000 ( 55.691)
Test: [ 400/3167]  Time: 0.200 (0.194)  Loss:   3.096 ( 3.006)  Acc@1:  25.000 ( 29.426)  Acc@5:  55.000 ( 58.392)
Test: [ 450/3167]  Time: 0.200 (0.194)  Loss:   3.262 ( 3.055)  Acc@1:  10.000 ( 27.528)  Acc@5:  60.000 ( 57.323)
Test: [ 500/3167]  Time: 0.194 (0.194)  Loss:   2.312 ( 3.071)  Acc@1:  45.000 ( 27.934)  Acc@5:  80.000 ( 56.602)
Test: [ 550/3167]  Time: 0.194 (0.194)  Loss:   3.900 ( 3.034)  Acc@1:   0.000 ( 29.310)  Acc@5:  37.500 ( 57.568)
Test: [ 600/3167]  Time: 0.197 (0.194)  Loss:   2.894 ( 3.073)  Acc@1:  32.500 ( 27.991)  Acc@5:  60.000 ( 56.385)
Test: [ 650/3167]  Time: 0.191 (0.194)  Loss:   2.281 ( 3.038)  Acc@1:  60.000 ( 29.224)  Acc@5:  87.500 ( 57.273)
Test: [ 700/3167]  Time: 0.190 (0.194)  Loss:   2.377 ( 2.986)  Acc@1:  62.500 ( 31.320)  Acc@5:  90.000 ( 59.283)
Test: [ 750/3167]  Time: 0.189 (0.194)  Loss:   3.353 ( 2.971)  Acc@1:  40.000 ( 32.114)  Acc@5:  45.000 ( 60.150)
Test: [ 800/3167]  Time: 0.185 (0.194)  Loss:   3.873 ( 2.998)  Acc@1:   0.000 ( 31.389)  Acc@5:  27.500 ( 59.042)
Test: [ 850/3167]  Time: 0.191 (0.194)  Loss:   3.266 ( 3.034)  Acc@1:   7.500 ( 30.026)  Acc@5:  55.000 ( 57.932)
Test: [ 900/3167]  Time: 0.189 (0.194)  Loss:   3.531 ( 3.066)  Acc@1:  15.000 ( 29.070)  Acc@5:  50.000 ( 57.161)
Test: [ 950/3167]  Time: 0.195 (0.194)  Loss:   2.511 ( 3.081)  Acc@1:  47.500 ( 28.683)  Acc@5:  72.500 ( 56.554)
Test: [1000/3167]  Time: 0.191 (0.194)  Loss:   3.115 ( 3.102)  Acc@1:  30.000 ( 28.312)  Acc@5:  67.500 ( 55.959)
Test: [1050/3167]  Time: 0.193 (0.194)  Loss:   2.950 ( 3.093)  Acc@1:  30.000 ( 28.235)  Acc@5:  65.000 ( 56.606)
Test: [1100/3167]  Time: 0.194 (0.194)  Loss:   3.251 ( 3.090)  Acc@1:  30.000 ( 28.097)  Acc@5:  60.000 ( 56.948)
Test: [1150/3167]  Time: 0.192 (0.194)  Loss:   2.078 ( 3.071)  Acc@1:  62.500 ( 28.983)  Acc@5:  90.000 ( 57.574)
Test: [1200/3167]  Time: 0.191 (0.193)  Loss:   2.766 ( 3.052)  Acc@1:  37.500 ( 29.473)  Acc@5:  65.000 ( 58.293)
Test: [1250/3167]  Time: 0.191 (0.193)  Loss:   2.762 ( 3.043)  Acc@1:  37.500 ( 29.984)  Acc@5:  65.000 ( 58.627)
Test: [1300/3167]  Time: 0.189 (0.193)  Loss:   3.270 ( 3.052)  Acc@1:  37.500 ( 29.458)  Acc@5:  65.000 ( 58.470)
Test: [1350/3167]  Time: 0.184 (0.193)  Loss:   3.403 ( 3.080)  Acc@1:  22.500 ( 28.812)  Acc@5:  60.000 ( 57.604)
Test: [1400/3167]  Time: 0.200 (0.193)  Loss:   3.331 ( 3.105)  Acc@1:  30.000 ( 28.241)  Acc@5:  60.000 ( 56.738)
Test: [1450/3167]  Time: 0.194 (0.193)  Loss:   3.291 ( 3.109)  Acc@1:  32.500 ( 28.370)  Acc@5:  45.000 ( 56.764)
Test: [1500/3167]  Time: 0.189 (0.193)  Loss:   3.326 ( 3.088)  Acc@1:  15.000 ( 29.101)  Acc@5:  57.500 ( 57.252)
Test: [1550/3167]  Time: 0.189 (0.193)  Loss:   2.014 ( 3.082)  Acc@1:  67.500 ( 29.110)  Acc@5:  87.500 ( 57.497)
Test: [1600/3167]  Time: 0.189 (0.193)  Loss:   2.255 ( 3.081)  Acc@1:  50.000 ( 29.169)  Acc@5:  80.000 ( 57.587)
Test: [1650/3167]  Time: 0.189 (0.193)  Loss:   2.564 ( 3.059)  Acc@1:  37.500 ( 29.752)  Acc@5:  72.500 ( 58.127)
Test: [1700/3167]  Time: 0.201 (0.193)  Loss:   4.014 ( 3.046)  Acc@1:  15.000 ( 30.243)  Acc@5:  27.500 ( 58.405)
Test: [1750/3167]  Time: 0.184 (0.193)  Loss:   2.937 ( 3.053)  Acc@1:  40.000 ( 30.117)  Acc@5:  55.000 ( 58.073)
Test: [1800/3167]  Time: 0.191 (0.193)  Loss:   2.867 ( 3.062)  Acc@1:  30.000 ( 29.997)  Acc@5:  57.500 ( 57.934)
Test: [1850/3167]  Time: 0.199 (0.193)  Loss:   3.038 ( 3.075)  Acc@1:  20.000 ( 29.456)  Acc@5:  65.000 ( 57.265)
Test: [1900/3167]  Time: 0.197 (0.193)  Loss:   3.458 ( 3.075)  Acc@1:  10.000 ( 29.139)  Acc@5:  52.500 ( 57.411)
Test: [1950/3167]  Time: 0.196 (0.193)  Loss:   4.169 ( 3.076)  Acc@1:   0.000 ( 29.061)  Acc@5:  17.500 ( 57.465)
Test: [2000/3167]  Time: 0.193 (0.193)  Loss:   3.877 ( 3.097)  Acc@1:   5.000 ( 28.490)  Acc@5:  30.000 ( 56.777)
Test: [2050/3167]  Time: 0.186 (0.193)  Loss:   3.883 ( 3.114)  Acc@1:   0.000 ( 27.944)  Acc@5:   5.000 ( 55.922)
Test: [2100/3167]  Time: 0.185 (0.192)  Loss:   2.659 ( 3.115)  Acc@1:  37.500 ( 27.972)  Acc@5:  77.500 ( 56.020)
Test: [2150/3167]  Time: 0.216 (0.192)  Loss:   1.319 ( 3.087)  Acc@1:  75.000 ( 28.742)  Acc@5:  92.500 ( 56.740)
Test: [2200/3167]  Time: 0.193 (0.192)  Loss:   3.123 ( 3.080)  Acc@1:   5.000 ( 28.769)  Acc@5:  60.000 ( 56.965)
Test: [2250/3167]  Time: 0.189 (0.192)  Loss:   3.381 ( 3.089)  Acc@1:  40.000 ( 28.442)  Acc@5:  55.000 ( 56.696)
Test: [2300/3167]  Time: 0.193 (0.192)  Loss:   3.351 ( 3.100)  Acc@1:   5.000 ( 28.094)  Acc@5:  50.000 ( 56.294)
Test: [2350/3167]  Time: 0.188 (0.192)  Loss:   3.581 ( 3.105)  Acc@1:  27.500 ( 27.754)  Acc@5:  55.000 ( 56.229)
Test: [2400/3167]  Time: 0.187 (0.192)  Loss:   3.671 ( 3.097)  Acc@1:   7.500 ( 28.005)  Acc@5:  32.500 ( 56.389)
Test: [2450/3167]  Time: 0.186 (0.192)  Loss:   2.396 ( 3.093)  Acc@1:  32.500 ( 28.101)  Acc@5:  85.000 ( 56.654)
Test: [2500/3167]  Time: 0.186 (0.192)  Loss:   2.854 ( 3.083)  Acc@1:  32.500 ( 28.411)  Acc@5:  65.000 ( 57.042)
Test: [2550/3167]  Time: 0.185 (0.192)  Loss:   4.008 ( 3.070)  Acc@1:   2.500 ( 28.764)  Acc@5:  22.500 ( 57.489)
Test: [2600/3167]  Time: 0.188 (0.192)  Loss:   2.812 ( 3.083)  Acc@1:  40.000 ( 28.512)  Acc@5:  72.500 ( 57.011)
Test: [2650/3167]  Time: 0.191 (0.192)  Loss:   3.506 ( 3.095)  Acc@1:  17.500 ( 28.283)  Acc@5:  45.000 ( 56.674)
Test: [2700/3167]  Time: 0.186 (0.192)  Loss:   2.397 ( 3.094)  Acc@1:  50.000 ( 28.400)  Acc@5:  75.000 ( 56.737)
Test: [2750/3167]  Time: 0.188 (0.192)  Loss:   2.250 ( 3.104)  Acc@1:  50.000 ( 28.257)  Acc@5:  85.000 ( 56.395)
Test: [2800/3167]  Time: 0.189 (0.192)  Loss:   3.912 ( 3.103)  Acc@1:   5.000 ( 28.357)  Acc@5:  40.000 ( 56.496)
Test: [2850/3167]  Time: 0.201 (0.192)  Loss:   3.887 ( 3.117)  Acc@1:  10.000 ( 27.913)  Acc@5:  32.500 ( 55.891)
Test: [2900/3167]  Time: 0.197 (0.192)  Loss:   2.838 ( 3.120)  Acc@1:  45.000 ( 27.921)  Acc@5:  67.500 ( 55.875)
Test: [2950/3167]  Time: 0.205 (0.192)  Loss:   3.883 ( 3.132)  Acc@1:   5.000 ( 27.571)  Acc@5:  27.500 ( 55.385)
Test: [3000/3167]  Time: 0.199 (0.192)  Loss:   4.038 ( 3.146)  Acc@1:  10.000 ( 27.194)  Acc@5:  27.500 ( 54.890)
Test: [3050/3167]  Time: 0.207 (0.192)  Loss:   3.777 ( 3.142)  Acc@1:  15.000 ( 27.353)  Acc@5:  30.000 ( 55.120)
Test: [3100/3167]  Time: 0.186 (0.192)  Loss:   4.111 ( 3.155)  Acc@1:   0.000 ( 26.993)  Acc@5:  25.000 ( 54.701)
Test: [3150/3167]  Time: 0.186 (0.192)  Loss:   3.095 ( 3.154)  Acc@1:   2.500 ( 26.808)  Acc@5:  72.500 ( 54.823)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   2.725 ( 3.154)  Acc@1:  11.111 ( 26.713)  Acc@5:  88.889 ( 54.852)
Test: [   0/124]  Time: 0.548 (0.548)  Loss:   3.593 ( 3.593)  Acc@1:  17.500 ( 17.500)  Acc@5:  50.000 ( 50.000)
Test: [  50/124]  Time: 0.186 (0.199)  Loss:   3.648 ( 3.176)  Acc@1:  20.000 ( 25.735)  Acc@5:  42.500 ( 53.578)
Test: [ 100/124]  Time: 0.184 (0.194)  Loss:   2.435 ( 3.181)  Acc@1:  52.500 ( 25.371)  Acc@5:  75.000 ( 52.896)
Test: [ 124/124]  Time: 0.180 (0.192)  Loss:   2.911 ( 3.253)  Acc@1:  15.000 ( 23.920)  Acc@5:  62.500 ( 50.700)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_2/checkpoint-7.pth.tar', 26.71265855760775)

Train: 8 [   0/3167 (  0%)]  Loss: 4.21 (4.21)  Time: 1.125s,   35.55/s  (1.125s,   35.55/s)  LR: 8.200e-05  Data: 0.533 (0.533)
Train: 8 [  50/3167 (  2%)]  Loss: 4.20 (4.02)  Time: 0.601s,   66.56/s  (0.612s,   65.33/s)  LR: 8.200e-05  Data: 0.012 (0.021)
Train: 8 [ 100/3167 (  3%)]  Loss: 4.05 (4.00)  Time: 0.604s,   66.18/s  (0.607s,   65.91/s)  LR: 8.200e-05  Data: 0.009 (0.015)
Train: 8 [ 150/3167 (  5%)]  Loss: 3.43 (3.97)  Time: 0.610s,   65.52/s  (0.605s,   66.10/s)  LR: 8.200e-05  Data: 0.011 (0.013)
Train: 8 [ 200/3167 (  6%)]  Loss: 3.93 (3.96)  Time: 0.593s,   67.46/s  (0.604s,   66.21/s)  LR: 8.200e-05  Data: 0.004 (0.012)
Train: 8 [ 250/3167 (  8%)]  Loss: 4.14 (3.94)  Time: 0.601s,   66.54/s  (0.604s,   66.28/s)  LR: 8.200e-05  Data: 0.012 (0.012)
Train: 8 [ 300/3167 (  9%)]  Loss: 3.96 (3.94)  Time: 0.604s,   66.25/s  (0.603s,   66.34/s)  LR: 8.200e-05  Data: 0.011 (0.011)
Train: 8 [ 350/3167 ( 11%)]  Loss: 3.64 (3.94)  Time: 0.598s,   66.85/s  (0.603s,   66.35/s)  LR: 8.200e-05  Data: 0.009 (0.011)
Train: 8 [ 400/3167 ( 13%)]  Loss: 4.07 (3.93)  Time: 0.598s,   66.87/s  (0.603s,   66.36/s)  LR: 8.200e-05  Data: 0.009 (0.011)
Train: 8 [ 450/3167 ( 14%)]  Loss: 4.05 (3.94)  Time: 0.604s,   66.18/s  (0.603s,   66.37/s)  LR: 8.200e-05  Data: 0.009 (0.011)
Train: 8 [ 500/3167 ( 16%)]  Loss: 3.32 (3.93)  Time: 0.596s,   67.16/s  (0.603s,   66.38/s)  LR: 8.200e-05  Data: 0.006 (0.011)
Train: 8 [ 550/3167 ( 17%)]  Loss: 4.06 (3.93)  Time: 0.600s,   66.66/s  (0.603s,   66.39/s)  LR: 8.200e-05  Data: 0.011 (0.011)
Train: 8 [ 600/3167 ( 19%)]  Loss: 3.99 (3.93)  Time: 0.598s,   66.86/s  (0.602s,   66.40/s)  LR: 8.200e-05  Data: 0.007 (0.010)
Train: 8 [ 650/3167 ( 21%)]  Loss: 3.49 (3.93)  Time: 0.603s,   66.35/s  (0.602s,   66.41/s)  LR: 8.200e-05  Data: 0.011 (0.010)
Train: 8 [ 700/3167 ( 22%)]  Loss: 3.21 (3.93)  Time: 0.598s,   66.84/s  (0.602s,   66.42/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [ 750/3167 ( 24%)]  Loss: 3.69 (3.93)  Time: 0.600s,   66.63/s  (0.602s,   66.43/s)  LR: 8.200e-05  Data: 0.011 (0.010)
Train: 8 [ 800/3167 ( 25%)]  Loss: 3.48 (3.93)  Time: 0.593s,   67.46/s  (0.602s,   66.44/s)  LR: 8.200e-05  Data: 0.004 (0.010)
Train: 8 [ 850/3167 ( 27%)]  Loss: 3.77 (3.92)  Time: 0.606s,   66.01/s  (0.602s,   66.44/s)  LR: 8.200e-05  Data: 0.011 (0.010)
Train: 8 [ 900/3167 ( 28%)]  Loss: 4.13 (3.92)  Time: 0.604s,   66.27/s  (0.602s,   66.45/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [ 950/3167 ( 30%)]  Loss: 3.81 (3.92)  Time: 0.605s,   66.07/s  (0.602s,   66.45/s)  LR: 8.200e-05  Data: 0.011 (0.010)
Train: 8 [1000/3167 ( 32%)]  Loss: 3.69 (3.92)  Time: 0.598s,   66.90/s  (0.602s,   66.45/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [1050/3167 ( 33%)]  Loss: 3.62 (3.92)  Time: 0.596s,   67.13/s  (0.602s,   66.46/s)  LR: 8.200e-05  Data: 0.004 (0.010)
Train: 8 [1100/3167 ( 35%)]  Loss: 4.13 (3.92)  Time: 0.603s,   66.32/s  (0.602s,   66.47/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [1150/3167 ( 36%)]  Loss: 3.37 (3.92)  Time: 0.601s,   66.51/s  (0.602s,   66.47/s)  LR: 8.200e-05  Data: 0.010 (0.010)
Train: 8 [1200/3167 ( 38%)]  Loss: 3.42 (3.91)  Time: 0.598s,   66.86/s  (0.602s,   66.48/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [1250/3167 ( 39%)]  Loss: 4.16 (3.91)  Time: 0.596s,   67.17/s  (0.602s,   66.48/s)  LR: 8.200e-05  Data: 0.004 (0.010)
Train: 8 [1300/3167 ( 41%)]  Loss: 3.74 (3.91)  Time: 0.603s,   66.33/s  (0.602s,   66.48/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1350/3167 ( 43%)]  Loss: 3.69 (3.91)  Time: 0.601s,   66.56/s  (0.602s,   66.49/s)  LR: 8.200e-05  Data: 0.007 (0.010)
Train: 8 [1400/3167 ( 44%)]  Loss: 3.95 (3.92)  Time: 0.593s,   67.46/s  (0.602s,   66.49/s)  LR: 8.200e-05  Data: 0.004 (0.010)
Train: 8 [1450/3167 ( 46%)]  Loss: 3.69 (3.91)  Time: 0.602s,   66.46/s  (0.602s,   66.49/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1500/3167 ( 47%)]  Loss: 3.61 (3.91)  Time: 0.601s,   66.60/s  (0.602s,   66.50/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1550/3167 ( 49%)]  Loss: 4.12 (3.92)  Time: 0.599s,   66.76/s  (0.601s,   66.50/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [1600/3167 ( 51%)]  Loss: 3.62 (3.92)  Time: 0.603s,   66.32/s  (0.601s,   66.51/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1650/3167 ( 52%)]  Loss: 3.60 (3.92)  Time: 0.600s,   66.61/s  (0.601s,   66.51/s)  LR: 8.200e-05  Data: 0.011 (0.010)
Train: 8 [1700/3167 ( 54%)]  Loss: 3.89 (3.92)  Time: 0.600s,   66.61/s  (0.601s,   66.52/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1750/3167 ( 55%)]  Loss: 4.10 (3.92)  Time: 0.601s,   66.57/s  (0.601s,   66.52/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1800/3167 ( 57%)]  Loss: 3.69 (3.92)  Time: 0.600s,   66.64/s  (0.601s,   66.53/s)  LR: 8.200e-05  Data: 0.011 (0.010)
Train: 8 [1850/3167 ( 58%)]  Loss: 3.94 (3.92)  Time: 0.601s,   66.58/s  (0.601s,   66.53/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1900/3167 ( 60%)]  Loss: 4.24 (3.91)  Time: 0.607s,   65.88/s  (0.601s,   66.53/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1950/3167 ( 62%)]  Loss: 3.62 (3.91)  Time: 0.609s,   65.72/s  (0.601s,   66.54/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [2000/3167 ( 63%)]  Loss: 4.05 (3.91)  Time: 0.598s,   66.94/s  (0.601s,   66.54/s)  LR: 8.200e-05  Data: 0.004 (0.010)
Train: 8 [2050/3167 ( 65%)]  Loss: 4.15 (3.91)  Time: 0.599s,   66.80/s  (0.601s,   66.55/s)  LR: 8.200e-05  Data: 0.010 (0.010)
Train: 8 [2100/3167 ( 66%)]  Loss: 3.64 (3.91)  Time: 0.596s,   67.15/s  (0.601s,   66.55/s)  LR: 8.200e-05  Data: 0.007 (0.009)
Train: 8 [2150/3167 ( 68%)]  Loss: 3.13 (3.91)  Time: 0.593s,   67.43/s  (0.601s,   66.56/s)  LR: 8.200e-05  Data: 0.004 (0.009)
slurmstepd: error: *** JOB 2080295 ON i62 CANCELLED AT 2024-05-19T22:43:40 DUE TO TIME LIMIT ***
