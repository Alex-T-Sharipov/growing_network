Training with a single process on 1 device (cuda:0).
WARNING: No pretrained configuration specified for MONet_T model. Using a default. Please add a config to the model pretrained_cfg registry or pass explicitly.
Model MONet_T created, param count:10165736
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.875
	crop_mode: center
AMP not enabled. Training in float32.
/home/sharipov/monet/venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Scheduled epochs: 10. LR stepped per epoch.
Train: 0 [   0/989 (  0%)]  Loss: 4.61 (4.61)  Time: 14.034s,    9.12/s  (14.034s,    9.12/s)  LR: 1.000e-05  Data: 4.590 (4.590)
Train: 0 [  50/989 (  5%)]  Loss: 4.56 (4.58)  Time: 0.939s,  136.26/s  (1.191s,  107.44/s)  LR: 1.000e-05  Data: 0.021 (0.103)
Train: 0 [ 100/989 ( 10%)]  Loss: 4.37 (4.52)  Time: 0.942s,  135.92/s  (1.064s,  120.26/s)  LR: 1.000e-05  Data: 0.020 (0.059)
Train: 0 [ 150/989 ( 15%)]  Loss: 4.35 (4.49)  Time: 0.930s,  137.58/s  (1.023s,  125.11/s)  LR: 1.000e-05  Data: 0.012 (0.045)
Train: 0 [ 200/989 ( 20%)]  Loss: 4.44 (4.46)  Time: 0.938s,  136.44/s  (1.002s,  127.78/s)  LR: 1.000e-05  Data: 0.020 (0.037)
Train: 0 [ 250/989 ( 25%)]  Loss: 4.27 (4.45)  Time: 0.931s,  137.42/s  (0.989s,  129.46/s)  LR: 1.000e-05  Data: 0.014 (0.033)
Train: 0 [ 300/989 ( 30%)]  Loss: 4.42 (4.44)  Time: 0.938s,  136.46/s  (0.980s,  130.61/s)  LR: 1.000e-05  Data: 0.021 (0.030)
Train: 0 [ 350/989 ( 35%)]  Loss: 4.27 (4.42)  Time: 0.957s,  133.69/s  (0.974s,  131.46/s)  LR: 1.000e-05  Data: 0.009 (0.027)
Train: 0 [ 400/989 ( 40%)]  Loss: 4.32 (4.41)  Time: 0.955s,  134.04/s  (0.969s,  132.07/s)  LR: 1.000e-05  Data: 0.015 (0.026)
Train: 0 [ 450/989 ( 46%)]  Loss: 4.32 (4.40)  Time: 0.946s,  135.30/s  (0.966s,  132.51/s)  LR: 1.000e-05  Data: 0.026 (0.025)
Train: 0 [ 500/989 ( 51%)]  Loss: 4.26 (4.40)  Time: 0.931s,  137.42/s  (0.963s,  132.91/s)  LR: 1.000e-05  Data: 0.015 (0.024)
Train: 0 [ 550/989 ( 56%)]  Loss: 4.33 (4.39)  Time: 0.933s,  137.20/s  (0.961s,  133.20/s)  LR: 1.000e-05  Data: 0.015 (0.023)
Train: 0 [ 600/989 ( 61%)]  Loss: 4.33 (4.38)  Time: 0.926s,  138.18/s  (0.959s,  133.46/s)  LR: 1.000e-05  Data: 0.010 (0.022)
Train: 0 [ 650/989 ( 66%)]  Loss: 4.22 (4.37)  Time: 0.940s,  136.23/s  (0.957s,  133.72/s)  LR: 1.000e-05  Data: 0.012 (0.022)
Train: 0 [ 700/989 ( 71%)]  Loss: 4.28 (4.37)  Time: 0.935s,  136.86/s  (0.956s,  133.94/s)  LR: 1.000e-05  Data: 0.009 (0.021)
Train: 0 [ 750/989 ( 76%)]  Loss: 4.33 (4.36)  Time: 0.950s,  134.81/s  (0.955s,  134.09/s)  LR: 1.000e-05  Data: 0.033 (0.021)
Train: 0 [ 800/989 ( 81%)]  Loss: 4.29 (4.36)  Time: 0.926s,  138.30/s  (0.953s,  134.25/s)  LR: 1.000e-05  Data: 0.009 (0.021)
Train: 0 [ 850/989 ( 86%)]  Loss: 4.16 (4.35)  Time: 0.943s,  135.76/s  (0.953s,  134.38/s)  LR: 1.000e-05  Data: 0.021 (0.020)
Train: 0 [ 900/989 ( 91%)]  Loss: 4.21 (4.35)  Time: 0.929s,  137.77/s  (0.952s,  134.47/s)  LR: 1.000e-05  Data: 0.009 (0.020)
Train: 0 [ 950/989 ( 96%)]  Loss: 4.30 (4.34)  Time: 0.940s,  136.19/s  (0.951s,  134.58/s)  LR: 1.000e-05  Data: 0.017 (0.020)
Test: [   0/39]  Time: 3.483 (3.483)  Loss:   3.981 ( 3.981)  Acc@1:  17.188 ( 17.188)  Acc@5:  35.938 ( 35.938)
Test: [  39/39]  Time: 0.392 (0.427)  Loss:   4.226 ( 4.130)  Acc@1:   0.000 (  7.640)  Acc@5:  25.000 ( 24.840)
Current checkpoints:
 ('./output/train/Exp1_imagenet100/checkpoint-0.pth.tar', 7.64)

Train: 1 [   0/989 (  0%)]  Loss: 4.26 (4.26)  Time: 2.803s,   45.67/s  (2.803s,   45.67/s)  LR: 2.800e-05  Data: 1.426 (1.426)
Train: 1 [  50/989 (  5%)]  Loss: 4.24 (4.25)  Time: 0.936s,  136.74/s  (0.981s,  130.48/s)  LR: 2.800e-05  Data: 0.019 (0.051)
Train: 1 [ 100/989 ( 10%)]  Loss: 4.33 (4.25)  Time: 0.935s,  136.84/s  (0.960s,  133.33/s)  LR: 2.800e-05  Data: 0.019 (0.037)
Train: 1 [ 150/989 ( 15%)]  Loss: 4.23 (4.24)  Time: 0.937s,  136.54/s  (0.953s,  134.38/s)  LR: 2.800e-05  Data: 0.021 (0.031)
Train: 1 [ 200/989 ( 20%)]  Loss: 4.27 (4.24)  Time: 0.936s,  136.75/s  (0.949s,  134.87/s)  LR: 2.800e-05  Data: 0.019 (0.029)
Train: 1 [ 250/989 ( 25%)]  Loss: 4.20 (4.23)  Time: 0.935s,  136.96/s  (0.947s,  135.16/s)  LR: 2.800e-05  Data: 0.017 (0.028)
Train: 1 [ 300/989 ( 30%)]  Loss: 4.34 (4.23)  Time: 0.941s,  136.08/s  (0.946s,  135.37/s)  LR: 2.800e-05  Data: 0.024 (0.027)
Train: 1 [ 350/989 ( 35%)]  Loss: 4.17 (4.22)  Time: 0.941s,  135.96/s  (0.945s,  135.51/s)  LR: 2.800e-05  Data: 0.025 (0.026)
Train: 1 [ 400/989 ( 40%)]  Loss: 4.11 (4.22)  Time: 0.936s,  136.82/s  (0.944s,  135.62/s)  LR: 2.800e-05  Data: 0.019 (0.025)
Train: 1 [ 450/989 ( 46%)]  Loss: 4.22 (4.21)  Time: 0.938s,  136.46/s  (0.943s,  135.70/s)  LR: 2.800e-05  Data: 0.021 (0.025)
Train: 1 [ 500/989 ( 51%)]  Loss: 4.05 (4.21)  Time: 0.938s,  136.44/s  (0.943s,  135.77/s)  LR: 2.800e-05  Data: 0.022 (0.025)
Train: 1 [ 550/989 ( 56%)]  Loss: 4.25 (4.20)  Time: 0.935s,  136.86/s  (0.942s,  135.84/s)  LR: 2.800e-05  Data: 0.019 (0.024)
Train: 1 [ 600/989 ( 61%)]  Loss: 4.06 (4.20)  Time: 0.936s,  136.74/s  (0.942s,  135.90/s)  LR: 2.800e-05  Data: 0.019 (0.024)
Train: 1 [ 650/989 ( 66%)]  Loss: 3.99 (4.19)  Time: 0.933s,  137.12/s  (0.942s,  135.94/s)  LR: 2.800e-05  Data: 0.017 (0.024)
Train: 1 [ 700/989 ( 71%)]  Loss: 4.27 (4.19)  Time: 0.935s,  136.85/s  (0.941s,  135.99/s)  LR: 2.800e-05  Data: 0.019 (0.023)
Train: 1 [ 750/989 ( 76%)]  Loss: 4.13 (4.18)  Time: 0.938s,  136.46/s  (0.941s,  136.04/s)  LR: 2.800e-05  Data: 0.021 (0.023)
Train: 1 [ 800/989 ( 81%)]  Loss: 4.15 (4.18)  Time: 0.936s,  136.81/s  (0.941s,  136.09/s)  LR: 2.800e-05  Data: 0.019 (0.023)
Train: 1 [ 850/989 ( 86%)]  Loss: 4.08 (4.17)  Time: 0.934s,  137.12/s  (0.940s,  136.14/s)  LR: 2.800e-05  Data: 0.017 (0.023)
Train: 1 [ 900/989 ( 91%)]  Loss: 4.26 (4.17)  Time: 0.934s,  137.06/s  (0.940s,  136.18/s)  LR: 2.800e-05  Data: 0.017 (0.022)
Train: 1 [ 950/989 ( 96%)]  Loss: 4.00 (4.16)  Time: 0.938s,  136.48/s  (0.940s,  136.22/s)  LR: 2.800e-05  Data: 0.021 (0.022)
Test: [   0/39]  Time: 1.309 (1.309)  Loss:   3.905 ( 3.905)  Acc@1:  16.406 ( 16.406)  Acc@5:  35.938 ( 35.938)
Test: [  39/39]  Time: 0.026 (0.366)  Loss:   3.637 ( 3.846)  Acc@1:   0.000 ( 12.680)  Acc@5:  50.000 ( 33.320)
Current checkpoints:
 ('./output/train/Exp1_imagenet100/checkpoint-1.pth.tar', 12.68)
 ('./output/train/Exp1_imagenet100/checkpoint-0.pth.tar', 7.64)

Train: 2 [   0/989 (  0%)]  Loss: 4.12 (4.12)  Time: 2.817s,   45.45/s  (2.817s,   45.45/s)  LR: 4.600e-05  Data: 1.448 (1.448)
Train: 2 [  50/989 (  5%)]  Loss: 4.17 (4.05)  Time: 0.938s,  136.51/s  (0.981s,  130.54/s)  LR: 4.600e-05  Data: 0.021 (0.051)
Train: 2 [ 100/989 ( 10%)]  Loss: 4.04 (4.05)  Time: 0.931s,  137.53/s  (0.960s,  133.36/s)  LR: 4.600e-05  Data: 0.014 (0.037)
Train: 2 [ 150/989 ( 15%)]  Loss: 4.01 (4.05)  Time: 0.938s,  136.44/s  (0.953s,  134.38/s)  LR: 4.600e-05  Data: 0.021 (0.031)
Train: 2 [ 200/989 ( 20%)]  Loss: 4.09 (4.05)  Time: 0.941s,  135.96/s  (0.949s,  134.84/s)  LR: 4.600e-05  Data: 0.024 (0.029)
Train: 2 [ 250/989 ( 25%)]  Loss: 4.04 (4.04)  Time: 0.933s,  137.17/s  (0.947s,  135.16/s)  LR: 4.600e-05  Data: 0.016 (0.028)
Train: 2 [ 300/989 ( 30%)]  Loss: 3.88 (4.04)  Time: 0.944s,  135.64/s  (0.946s,  135.36/s)  LR: 4.600e-05  Data: 0.027 (0.027)
Train: 2 [ 350/989 ( 35%)]  Loss: 3.99 (4.04)  Time: 0.938s,  136.43/s  (0.945s,  135.50/s)  LR: 4.600e-05  Data: 0.021 (0.026)
Train: 2 [ 400/989 ( 40%)]  Loss: 3.96 (4.03)  Time: 0.943s,  135.70/s  (0.944s,  135.62/s)  LR: 4.600e-05  Data: 0.026 (0.025)
Train: 2 [ 450/989 ( 46%)]  Loss: 3.93 (4.03)  Time: 0.936s,  136.82/s  (0.943s,  135.72/s)  LR: 4.600e-05  Data: 0.019 (0.025)
Train: 2 [ 500/989 ( 51%)]  Loss: 4.11 (4.02)  Time: 0.939s,  136.33/s  (0.943s,  135.80/s)  LR: 4.600e-05  Data: 0.022 (0.024)
Train: 2 [ 550/989 ( 56%)]  Loss: 3.92 (4.02)  Time: 0.939s,  136.26/s  (0.942s,  135.87/s)  LR: 4.600e-05  Data: 0.022 (0.024)
Train: 2 [ 600/989 ( 61%)]  Loss: 3.81 (4.01)  Time: 0.938s,  136.39/s  (0.942s,  135.93/s)  LR: 4.600e-05  Data: 0.021 (0.024)
Train: 2 [ 650/989 ( 66%)]  Loss: 3.90 (4.01)  Time: 0.939s,  136.31/s  (0.941s,  135.98/s)  LR: 4.600e-05  Data: 0.022 (0.023)
Train: 2 [ 700/989 ( 71%)]  Loss: 3.94 (4.00)  Time: 0.943s,  135.75/s  (0.941s,  136.02/s)  LR: 4.600e-05  Data: 0.026 (0.023)
Train: 2 [ 750/989 ( 76%)]  Loss: 3.91 (4.00)  Time: 0.939s,  136.30/s  (0.941s,  136.08/s)  LR: 4.600e-05  Data: 0.022 (0.023)
Train: 2 [ 800/989 ( 81%)]  Loss: 3.96 (3.99)  Time: 0.934s,  137.10/s  (0.940s,  136.12/s)  LR: 4.600e-05  Data: 0.017 (0.023)
Train: 2 [ 850/989 ( 86%)]  Loss: 3.87 (3.99)  Time: 0.933s,  137.12/s  (0.940s,  136.16/s)  LR: 4.600e-05  Data: 0.016 (0.022)
Train: 2 [ 900/989 ( 91%)]  Loss: 3.82 (3.98)  Time: 0.937s,  136.66/s  (0.940s,  136.19/s)  LR: 4.600e-05  Data: 0.019 (0.022)
Train: 2 [ 950/989 ( 96%)]  Loss: 3.74 (3.98)  Time: 0.940s,  136.23/s  (0.940s,  136.22/s)  LR: 4.600e-05  Data: 0.022 (0.022)
Test: [   0/39]  Time: 1.325 (1.325)  Loss:   3.716 ( 3.716)  Acc@1:  14.062 ( 14.062)  Acc@5:  37.500 ( 37.500)
Test: [  39/39]  Time: 0.026 (0.367)  Loss:   3.746 ( 3.560)  Acc@1:   0.000 ( 17.300)  Acc@5:  25.000 ( 41.960)
Current checkpoints:
 ('./output/train/Exp1_imagenet100/checkpoint-2.pth.tar', 17.3)
 ('./output/train/Exp1_imagenet100/checkpoint-1.pth.tar', 12.68)
 ('./output/train/Exp1_imagenet100/checkpoint-0.pth.tar', 7.64)

Train: 3 [   0/989 (  0%)]  Loss: 3.75 (3.75)  Time: 2.780s,   46.04/s  (2.780s,   46.04/s)  LR: 6.400e-05  Data: 1.438 (1.438)
Train: 3 [  50/989 (  5%)]  Loss: 3.90 (3.87)  Time: 0.938s,  136.52/s  (0.981s,  130.49/s)  LR: 6.400e-05  Data: 0.021 (0.052)
Train: 3 [ 100/989 ( 10%)]  Loss: 3.88 (3.88)  Time: 0.943s,  135.70/s  (0.960s,  133.30/s)  LR: 6.400e-05  Data: 0.027 (0.037)
Train: 3 [ 150/989 ( 15%)]  Loss: 3.99 (3.88)  Time: 0.936s,  136.72/s  (0.953s,  134.28/s)  LR: 6.400e-05  Data: 0.020 (0.032)
Train: 3 [ 200/989 ( 20%)]  Loss: 4.11 (3.87)  Time: 0.938s,  136.46/s  (0.949s,  134.83/s)  LR: 6.400e-05  Data: 0.021 (0.029)
Train: 3 [ 250/989 ( 25%)]  Loss: 3.80 (3.87)  Time: 0.936s,  136.74/s  (0.947s,  135.14/s)  LR: 6.400e-05  Data: 0.016 (0.028)
Train: 3 [ 300/989 ( 30%)]  Loss: 3.79 (3.86)  Time: 0.938s,  136.49/s  (0.946s,  135.33/s)  LR: 6.400e-05  Data: 0.021 (0.027)
Train: 3 [ 350/989 ( 35%)]  Loss: 3.72 (3.86)  Time: 0.933s,  137.16/s  (0.945s,  135.47/s)  LR: 6.400e-05  Data: 0.017 (0.026)
Train: 3 [ 400/989 ( 40%)]  Loss: 3.92 (3.85)  Time: 0.938s,  136.49/s  (0.944s,  135.58/s)  LR: 6.400e-05  Data: 0.021 (0.026)
Train: 3 [ 450/989 ( 46%)]  Loss: 3.73 (3.85)  Time: 0.938s,  136.53/s  (0.943s,  135.67/s)  LR: 6.400e-05  Data: 0.021 (0.025)
Train: 3 [ 500/989 ( 51%)]  Loss: 3.60 (3.84)  Time: 0.936s,  136.73/s  (0.943s,  135.76/s)  LR: 6.400e-05  Data: 0.019 (0.025)
Train: 3 [ 550/989 ( 56%)]  Loss: 3.60 (3.84)  Time: 0.937s,  136.67/s  (0.942s,  135.83/s)  LR: 6.400e-05  Data: 0.020 (0.024)
Train: 3 [ 600/989 ( 61%)]  Loss: 3.68 (3.83)  Time: 0.936s,  136.68/s  (0.942s,  135.89/s)  LR: 6.400e-05  Data: 0.020 (0.024)
Train: 3 [ 650/989 ( 66%)]  Loss: 3.75 (3.83)  Time: 0.936s,  136.75/s  (0.942s,  135.94/s)  LR: 6.400e-05  Data: 0.019 (0.024)
Train: 3 [ 700/989 ( 71%)]  Loss: 3.78 (3.82)  Time: 0.938s,  136.43/s  (0.941s,  135.99/s)  LR: 6.400e-05  Data: 0.022 (0.023)
Train: 3 [ 750/989 ( 76%)]  Loss: 3.65 (3.82)  Time: 0.938s,  136.43/s  (0.941s,  136.04/s)  LR: 6.400e-05  Data: 0.022 (0.023)
Train: 3 [ 800/989 ( 81%)]  Loss: 3.75 (3.81)  Time: 0.934s,  137.07/s  (0.941s,  136.08/s)  LR: 6.400e-05  Data: 0.017 (0.023)
Train: 3 [ 850/989 ( 86%)]  Loss: 3.74 (3.81)  Time: 0.936s,  136.71/s  (0.940s,  136.13/s)  LR: 6.400e-05  Data: 0.019 (0.023)
Train: 3 [ 900/989 ( 91%)]  Loss: 3.64 (3.81)  Time: 0.934s,  137.06/s  (0.940s,  136.17/s)  LR: 6.400e-05  Data: 0.017 (0.022)
Train: 3 [ 950/989 ( 96%)]  Loss: 3.79 (3.80)  Time: 0.934s,  137.12/s  (0.940s,  136.20/s)  LR: 6.400e-05  Data: 0.017 (0.022)
Test: [   0/39]  Time: 1.285 (1.285)  Loss:   3.232 ( 3.232)  Acc@1:  25.781 ( 25.781)  Acc@5:  53.125 ( 53.125)
Test: [  39/39]  Time: 0.026 (0.363)  Loss:   3.074 ( 3.340)  Acc@1:  12.500 ( 19.820)  Acc@5:  62.500 ( 47.060)
Current checkpoints:
 ('./output/train/Exp1_imagenet100/checkpoint-3.pth.tar', 19.82)
 ('./output/train/Exp1_imagenet100/checkpoint-2.pth.tar', 17.3)
 ('./output/train/Exp1_imagenet100/checkpoint-1.pth.tar', 12.68)
 ('./output/train/Exp1_imagenet100/checkpoint-0.pth.tar', 7.64)

Train: 4 [   0/989 (  0%)]  Loss: 3.53 (3.53)  Time: 2.713s,   47.18/s  (2.713s,   47.18/s)  LR: 8.200e-05  Data: 1.401 (1.401)
Train: 4 [  50/989 (  5%)]  Loss: 3.63 (3.71)  Time: 0.937s,  136.54/s  (0.979s,  130.74/s)  LR: 8.200e-05  Data: 0.021 (0.051)
Train: 4 [ 100/989 ( 10%)]  Loss: 3.69 (3.71)  Time: 0.938s,  136.42/s  (0.959s,  133.47/s)  LR: 8.200e-05  Data: 0.022 (0.036)
Train: 4 [ 150/989 ( 15%)]  Loss: 3.68 (3.71)  Time: 0.943s,  135.81/s  (0.952s,  134.43/s)  LR: 8.200e-05  Data: 0.016 (0.032)
Train: 4 [ 200/989 ( 20%)]  Loss: 3.56 (3.70)  Time: 0.941s,  136.02/s  (0.949s,  134.91/s)  LR: 8.200e-05  Data: 0.025 (0.029)
Train: 4 [ 250/989 ( 25%)]  Loss: 3.72 (3.70)  Time: 0.937s,  136.54/s  (0.947s,  135.19/s)  LR: 8.200e-05  Data: 0.021 (0.028)
Train: 4 [ 300/989 ( 30%)]  Loss: 3.63 (3.69)  Time: 0.939s,  136.31/s  (0.945s,  135.40/s)  LR: 8.200e-05  Data: 0.022 (0.027)
Train: 4 [ 350/989 ( 35%)]  Loss: 3.61 (3.69)  Time: 0.935s,  136.87/s  (0.944s,  135.55/s)  LR: 8.200e-05  Data: 0.019 (0.026)
Train: 4 [ 400/989 ( 40%)]  Loss: 3.61 (3.68)  Time: 0.935s,  136.87/s  (0.943s,  135.67/s)  LR: 8.200e-05  Data: 0.019 (0.025)
Train: 4 [ 450/989 ( 46%)]  Loss: 3.57 (3.68)  Time: 0.937s,  136.54/s  (0.943s,  135.77/s)  LR: 8.200e-05  Data: 0.021 (0.025)
Train: 4 [ 500/989 ( 51%)]  Loss: 3.50 (3.68)  Time: 0.933s,  137.14/s  (0.942s,  135.84/s)  LR: 8.200e-05  Data: 0.017 (0.024)
Train: 4 [ 550/989 ( 56%)]  Loss: 3.72 (3.67)  Time: 0.940s,  136.24/s  (0.942s,  135.90/s)  LR: 8.200e-05  Data: 0.023 (0.024)
Train: 4 [ 600/989 ( 61%)]  Loss: 3.72 (3.67)  Time: 0.941s,  136.03/s  (0.942s,  135.95/s)  LR: 8.200e-05  Data: 0.024 (0.024)
Train: 4 [ 650/989 ( 66%)]  Loss: 3.76 (3.66)  Time: 0.934s,  137.11/s  (0.941s,  136.00/s)  LR: 8.200e-05  Data: 0.017 (0.024)
Train: 4 [ 700/989 ( 71%)]  Loss: 3.44 (3.66)  Time: 0.936s,  136.75/s  (0.941s,  136.04/s)  LR: 8.200e-05  Data: 0.019 (0.023)
Train: 4 [ 750/989 ( 76%)]  Loss: 3.57 (3.65)  Time: 0.947s,  135.18/s  (0.941s,  136.08/s)  LR: 8.200e-05  Data: 0.030 (0.023)
Train: 4 [ 800/989 ( 81%)]  Loss: 3.54 (3.65)  Time: 0.933s,  137.15/s  (0.940s,  136.13/s)  LR: 8.200e-05  Data: 0.017 (0.023)
Train: 4 [ 850/989 ( 86%)]  Loss: 3.60 (3.64)  Time: 0.934s,  137.06/s  (0.940s,  136.17/s)  LR: 8.200e-05  Data: 0.017 (0.023)
Train: 4 [ 900/989 ( 91%)]  Loss: 3.66 (3.64)  Time: 0.937s,  136.67/s  (0.940s,  136.20/s)  LR: 8.200e-05  Data: 0.019 (0.022)
Train: 4 [ 950/989 ( 96%)]  Loss: 3.51 (3.63)  Time: 0.934s,  137.00/s  (0.940s,  136.23/s)  LR: 8.200e-05  Data: 0.017 (0.022)
Test: [   0/39]  Time: 1.308 (1.308)  Loss:   3.372 ( 3.372)  Acc@1:  19.531 ( 19.531)  Acc@5:  54.688 ( 54.688)
Test: [  39/39]  Time: 0.026 (0.365)  Loss:   3.465 ( 3.078)  Acc@1:   0.000 ( 25.880)  Acc@5:  25.000 ( 54.500)
Current checkpoints:
 ('./output/train/Exp1_imagenet100/checkpoint-4.pth.tar', 25.88)
 ('./output/train/Exp1_imagenet100/checkpoint-3.pth.tar', 19.82)
 ('./output/train/Exp1_imagenet100/checkpoint-2.pth.tar', 17.3)
 ('./output/train/Exp1_imagenet100/checkpoint-1.pth.tar', 12.68)
 ('./output/train/Exp1_imagenet100/checkpoint-0.pth.tar', 7.64)

Train: 5 [   0/989 (  0%)]  Loss: 3.72 (3.72)  Time: 2.728s,   46.93/s  (2.728s,   46.93/s)  LR: 5.000e-05  Data: 1.395 (1.395)
Train: 5 [  50/989 (  5%)]  Loss: 3.53 (3.52)  Time: 0.937s,  136.60/s  (0.979s,  130.70/s)  LR: 5.000e-05  Data: 0.021 (0.051)
Train: 5 [ 100/989 ( 10%)]  Loss: 3.54 (3.49)  Time: 0.938s,  136.49/s  (0.959s,  133.42/s)  LR: 5.000e-05  Data: 0.021 (0.037)
Train: 5 [ 150/989 ( 15%)]  Loss: 3.63 (3.49)  Time: 0.944s,  135.64/s  (0.953s,  134.38/s)  LR: 5.000e-05  Data: 0.026 (0.032)
Train: 5 [ 200/989 ( 20%)]  Loss: 3.45 (3.49)  Time: 0.935s,  136.87/s  (0.949s,  134.86/s)  LR: 5.000e-05  Data: 0.018 (0.029)
Train: 5 [ 250/989 ( 25%)]  Loss: 3.45 (3.48)  Time: 0.936s,  136.77/s  (0.947s,  135.18/s)  LR: 5.000e-05  Data: 0.019 (0.028)
Train: 5 [ 300/989 ( 30%)]  Loss: 3.50 (3.48)  Time: 0.938s,  136.52/s  (0.946s,  135.37/s)  LR: 5.000e-05  Data: 0.021 (0.027)
Train: 5 [ 350/989 ( 35%)]  Loss: 3.43 (3.48)  Time: 0.941s,  136.01/s  (0.945s,  135.51/s)  LR: 5.000e-05  Data: 0.024 (0.026)
Train: 5 [ 400/989 ( 40%)]  Loss: 3.34 (3.48)  Time: 0.933s,  137.14/s  (0.944s,  135.62/s)  LR: 5.000e-05  Data: 0.017 (0.026)
Train: 5 [ 450/989 ( 46%)]  Loss: 3.46 (3.47)  Time: 0.934s,  137.10/s  (0.943s,  135.71/s)  LR: 5.000e-05  Data: 0.017 (0.025)
Train: 5 [ 500/989 ( 51%)]  Loss: 3.59 (3.47)  Time: 0.943s,  135.74/s  (0.943s,  135.78/s)  LR: 5.000e-05  Data: 0.026 (0.025)
Train: 5 [ 550/989 ( 56%)]  Loss: 3.36 (3.47)  Time: 0.940s,  136.11/s  (0.942s,  135.84/s)  LR: 5.000e-05  Data: 0.024 (0.024)
Train: 5 [ 600/989 ( 61%)]  Loss: 3.31 (3.46)  Time: 0.933s,  137.19/s  (0.942s,  135.89/s)  LR: 5.000e-05  Data: 0.016 (0.024)
Train: 5 [ 650/989 ( 66%)]  Loss: 3.53 (3.46)  Time: 0.941s,  135.96/s  (0.942s,  135.94/s)  LR: 5.000e-05  Data: 0.025 (0.024)
Train: 5 [ 700/989 ( 71%)]  Loss: 3.52 (3.46)  Time: 0.934s,  137.07/s  (0.941s,  135.99/s)  LR: 5.000e-05  Data: 0.017 (0.024)
Train: 5 [ 750/989 ( 76%)]  Loss: 3.24 (3.45)  Time: 0.934s,  137.01/s  (0.941s,  136.03/s)  LR: 5.000e-05  Data: 0.017 (0.023)
Train: 5 [ 800/989 ( 81%)]  Loss: 3.56 (3.45)  Time: 0.937s,  136.56/s  (0.941s,  136.08/s)  LR: 5.000e-05  Data: 0.021 (0.023)
Train: 5 [ 850/989 ( 86%)]  Loss: 3.56 (3.45)  Time: 0.936s,  136.79/s  (0.940s,  136.12/s)  LR: 5.000e-05  Data: 0.019 (0.023)
Train: 5 [ 900/989 ( 91%)]  Loss: 3.43 (3.44)  Time: 0.934s,  137.06/s  (0.940s,  136.16/s)  LR: 5.000e-05  Data: 0.017 (0.023)
Train: 5 [ 950/989 ( 96%)]  Loss: 3.40 (3.44)  Time: 0.934s,  137.01/s  (0.940s,  136.18/s)  LR: 5.000e-05  Data: 0.017 (0.022)
Test: [   0/39]  Time: 1.293 (1.293)  Loss:   3.037 ( 3.037)  Acc@1:  22.656 ( 22.656)  Acc@5:  57.031 ( 57.031)
Test: [  39/39]  Time: 0.026 (0.366)  Loss:   2.193 ( 2.868)  Acc@1:  37.500 ( 29.240)  Acc@5:  75.000 ( 60.020)
Current checkpoints:
 ('./output/train/Exp1_imagenet100/checkpoint-5.pth.tar', 29.24)
 ('./output/train/Exp1_imagenet100/checkpoint-4.pth.tar', 25.88)
 ('./output/train/Exp1_imagenet100/checkpoint-3.pth.tar', 19.82)
 ('./output/train/Exp1_imagenet100/checkpoint-2.pth.tar', 17.3)
 ('./output/train/Exp1_imagenet100/checkpoint-1.pth.tar', 12.68)
 ('./output/train/Exp1_imagenet100/checkpoint-0.pth.tar', 7.64)

Train: 6 [   0/989 (  0%)]  Loss: 3.56 (3.56)  Time: 2.726s,   46.96/s  (2.726s,   46.96/s)  LR: 3.455e-05  Data: 1.386 (1.386)
Train: 6 [  50/989 (  5%)]  Loss: 3.27 (3.36)  Time: 0.933s,  137.22/s  (0.979s,  130.81/s)  LR: 3.455e-05  Data: 0.016 (0.050)
Train: 6 [ 100/989 ( 10%)]  Loss: 3.32 (3.35)  Time: 0.944s,  135.64/s  (0.959s,  133.44/s)  LR: 3.455e-05  Data: 0.027 (0.037)
Train: 6 [ 150/989 ( 15%)]  Loss: 3.27 (3.35)  Time: 0.945s,  135.44/s  (0.952s,  134.38/s)  LR: 3.455e-05  Data: 0.029 (0.032)
Train: 6 [ 200/989 ( 20%)]  Loss: 3.31 (3.35)  Time: 0.935s,  136.84/s  (0.949s,  134.87/s)  LR: 3.455e-05  Data: 0.019 (0.029)
Train: 6 [ 250/989 ( 25%)]  Loss: 3.36 (3.35)  Time: 0.943s,  135.68/s  (0.947s,  135.19/s)  LR: 3.455e-05  Data: 0.027 (0.028)
Train: 6 [ 300/989 ( 30%)]  Loss: 3.33 (3.35)  Time: 0.942s,  135.87/s  (0.945s,  135.41/s)  LR: 3.455e-05  Data: 0.025 (0.026)
Train: 6 [ 350/989 ( 35%)]  Loss: 3.22 (3.35)  Time: 0.949s,  134.85/s  (0.944s,  135.54/s)  LR: 3.455e-05  Data: 0.033 (0.026)
Train: 6 [ 400/989 ( 40%)]  Loss: 3.26 (3.34)  Time: 0.935s,  136.84/s  (0.944s,  135.64/s)  LR: 3.455e-05  Data: 0.019 (0.025)
Train: 6 [ 450/989 ( 46%)]  Loss: 3.59 (3.34)  Time: 0.938s,  136.48/s  (0.943s,  135.72/s)  LR: 3.455e-05  Data: 0.022 (0.025)
Train: 6 [ 500/989 ( 51%)]  Loss: 3.53 (3.34)  Time: 0.945s,  135.45/s  (0.943s,  135.78/s)  LR: 3.455e-05  Data: 0.028 (0.025)
Train: 6 [ 550/989 ( 56%)]  Loss: 3.30 (3.34)  Time: 0.944s,  135.64/s  (0.942s,  135.82/s)  LR: 3.455e-05  Data: 0.027 (0.024)
Train: 6 [ 600/989 ( 61%)]  Loss: 3.37 (3.34)  Time: 0.938s,  136.47/s  (0.942s,  135.88/s)  LR: 3.455e-05  Data: 0.021 (0.024)
Train: 6 [ 650/989 ( 66%)]  Loss: 3.46 (3.33)  Time: 0.933s,  137.19/s  (0.942s,  135.94/s)  LR: 3.455e-05  Data: 0.017 (0.024)
Train: 6 [ 700/989 ( 71%)]  Loss: 3.35 (3.33)  Time: 0.933s,  137.15/s  (0.941s,  135.99/s)  LR: 3.455e-05  Data: 0.017 (0.024)
Train: 6 [ 750/989 ( 76%)]  Loss: 3.34 (3.33)  Time: 0.936s,  136.73/s  (0.941s,  136.04/s)  LR: 3.455e-05  Data: 0.019 (0.023)
Train: 6 [ 800/989 ( 81%)]  Loss: 3.22 (3.33)  Time: 0.936s,  136.76/s  (0.941s,  136.08/s)  LR: 3.455e-05  Data: 0.019 (0.023)
Train: 6 [ 850/989 ( 86%)]  Loss: 3.19 (3.33)  Time: 0.934s,  137.03/s  (0.940s,  136.13/s)  LR: 3.455e-05  Data: 0.017 (0.023)
Train: 6 [ 900/989 ( 91%)]  Loss: 3.08 (3.33)  Time: 0.934s,  136.97/s  (0.940s,  136.16/s)  LR: 3.455e-05  Data: 0.018 (0.023)
Train: 6 [ 950/989 ( 96%)]  Loss: 3.33 (3.33)  Time: 0.935s,  136.93/s  (0.940s,  136.19/s)  LR: 3.455e-05  Data: 0.018 (0.022)
Test: [   0/39]  Time: 1.307 (1.307)  Loss:   2.956 ( 2.956)  Acc@1:  25.781 ( 25.781)  Acc@5:  60.156 ( 60.156)
Test: [  39/39]  Time: 0.026 (0.368)  Loss:   2.890 ( 2.773)  Acc@1:   0.000 ( 31.640)  Acc@5:  75.000 ( 62.880)
Current checkpoints:
 ('./output/train/Exp1_imagenet100/checkpoint-6.pth.tar', 31.64)
 ('./output/train/Exp1_imagenet100/checkpoint-5.pth.tar', 29.24)
 ('./output/train/Exp1_imagenet100/checkpoint-4.pth.tar', 25.88)
 ('./output/train/Exp1_imagenet100/checkpoint-3.pth.tar', 19.82)
 ('./output/train/Exp1_imagenet100/checkpoint-2.pth.tar', 17.3)
 ('./output/train/Exp1_imagenet100/checkpoint-1.pth.tar', 12.68)
 ('./output/train/Exp1_imagenet100/checkpoint-0.pth.tar', 7.64)

Train: 7 [   0/989 (  0%)]  Loss: 3.28 (3.28)  Time: 2.805s,   45.64/s  (2.805s,   45.64/s)  LR: 2.061e-05  Data: 1.452 (1.452)
Train: 7 [  50/989 (  5%)]  Loss: 3.12 (3.29)  Time: 0.935s,  136.83/s  (0.981s,  130.51/s)  LR: 2.061e-05  Data: 0.019 (0.052)
Train: 7 [ 100/989 ( 10%)]  Loss: 3.11 (3.27)  Time: 0.944s,  135.62/s  (0.960s,  133.38/s)  LR: 2.061e-05  Data: 0.027 (0.037)
Train: 7 [ 150/989 ( 15%)]  Loss: 3.47 (3.27)  Time: 0.941s,  135.98/s  (0.953s,  134.34/s)  LR: 2.061e-05  Data: 0.025 (0.032)
Train: 7 [ 200/989 ( 20%)]  Loss: 3.41 (3.27)  Time: 0.940s,  136.10/s  (0.949s,  134.82/s)  LR: 2.061e-05  Data: 0.024 (0.029)
Train: 7 [ 250/989 ( 25%)]  Loss: 3.33 (3.27)  Time: 0.938s,  136.46/s  (0.948s,  135.07/s)  LR: 2.061e-05  Data: 0.021 (0.028)
Train: 7 [ 300/989 ( 30%)]  Loss: 3.47 (3.27)  Time: 0.938s,  136.51/s  (0.946s,  135.30/s)  LR: 2.061e-05  Data: 0.021 (0.027)
Train: 7 [ 350/989 ( 35%)]  Loss: 3.34 (3.26)  Time: 0.939s,  136.35/s  (0.945s,  135.46/s)  LR: 2.061e-05  Data: 0.022 (0.026)
Train: 7 [ 400/989 ( 40%)]  Loss: 3.17 (3.26)  Time: 0.951s,  134.63/s  (0.944s,  135.58/s)  LR: 2.061e-05  Data: 0.034 (0.026)
Train: 7 [ 450/989 ( 46%)]  Loss: 3.08 (3.26)  Time: 0.938s,  136.48/s  (0.943s,  135.68/s)  LR: 2.061e-05  Data: 0.021 (0.025)
Train: 7 [ 500/989 ( 51%)]  Loss: 3.19 (3.26)  Time: 0.933s,  137.12/s  (0.943s,  135.75/s)  LR: 2.061e-05  Data: 0.017 (0.025)
Train: 7 [ 550/989 ( 56%)]  Loss: 3.43 (3.26)  Time: 0.938s,  136.44/s  (0.942s,  135.81/s)  LR: 2.061e-05  Data: 0.021 (0.024)
slurmstepd: error: *** JOB 2004241 ON i23 CANCELLED AT 2024-02-29T01:43:32 DUE TO TIME LIMIT ***
