Training with a single process on 1 device (cuda:0).
WARNING: No pretrained configuration specified for MONet_T_16_double model. Using a default. Please add a config to the model pretrained_cfg registry or pass explicitly.
Model MONet_T_16_double created, param count:17509380
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.875
	crop_mode: center
AMP not enabled. Training in float32.
/home/sharipov/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Scheduled epochs: 300. LR stepped per epoch.
Train: 0 [   0/3167 (  0%)]  Loss: 4.61 (4.61)  Time: 4.584s,    8.73/s  (4.584s,    8.73/s)  LR: 1.000e-05  Data: 1.874 (1.874)
Train: 0 [  50/3167 (  2%)]  Loss: 4.58 (4.60)  Time: 0.600s,   66.70/s  (0.678s,   58.99/s)  LR: 1.000e-05  Data: 0.004 (0.042)
Train: 0 [ 100/3167 (  3%)]  Loss: 4.58 (4.59)  Time: 0.601s,   66.59/s  (0.639s,   62.61/s)  LR: 1.000e-05  Data: 0.007 (0.024)
Train: 0 [ 150/3167 (  5%)]  Loss: 4.52 (4.58)  Time: 0.601s,   66.51/s  (0.626s,   63.93/s)  LR: 1.000e-05  Data: 0.009 (0.019)
Train: 0 [ 200/3167 (  6%)]  Loss: 4.54 (4.57)  Time: 0.598s,   66.92/s  (0.619s,   64.61/s)  LR: 1.000e-05  Data: 0.007 (0.016)
Train: 0 [ 250/3167 (  8%)]  Loss: 4.52 (4.56)  Time: 0.600s,   66.66/s  (0.615s,   65.01/s)  LR: 1.000e-05  Data: 0.007 (0.014)
Train: 0 [ 300/3167 (  9%)]  Loss: 4.56 (4.55)  Time: 0.601s,   66.58/s  (0.613s,   65.28/s)  LR: 1.000e-05  Data: 0.010 (0.013)
Train: 0 [ 350/3167 ( 11%)]  Loss: 4.51 (4.55)  Time: 0.605s,   66.13/s  (0.611s,   65.46/s)  LR: 1.000e-05  Data: 0.009 (0.012)
Train: 0 [ 400/3167 ( 13%)]  Loss: 4.44 (4.54)  Time: 0.603s,   66.34/s  (0.610s,   65.61/s)  LR: 1.000e-05  Data: 0.009 (0.012)
Train: 0 [ 450/3167 ( 14%)]  Loss: 4.46 (4.53)  Time: 0.598s,   66.88/s  (0.608s,   65.74/s)  LR: 1.000e-05  Data: 0.007 (0.011)
Train: 0 [ 500/3167 ( 16%)]  Loss: 4.48 (4.53)  Time: 0.599s,   66.76/s  (0.608s,   65.83/s)  LR: 1.000e-05  Data: 0.007 (0.011)
Train: 0 [ 550/3167 ( 17%)]  Loss: 4.52 (4.52)  Time: 0.605s,   66.12/s  (0.607s,   65.91/s)  LR: 1.000e-05  Data: 0.012 (0.010)
Train: 0 [ 600/3167 ( 19%)]  Loss: 4.53 (4.52)  Time: 0.600s,   66.64/s  (0.606s,   65.97/s)  LR: 1.000e-05  Data: 0.009 (0.010)
Train: 0 [ 650/3167 ( 21%)]  Loss: 4.45 (4.52)  Time: 0.599s,   66.77/s  (0.606s,   66.03/s)  LR: 1.000e-05  Data: 0.006 (0.010)
Train: 0 [ 700/3167 ( 22%)]  Loss: 4.25 (4.51)  Time: 0.597s,   66.95/s  (0.605s,   66.07/s)  LR: 1.000e-05  Data: 0.007 (0.010)
Train: 0 [ 750/3167 ( 24%)]  Loss: 4.55 (4.51)  Time: 0.599s,   66.75/s  (0.605s,   66.11/s)  LR: 1.000e-05  Data: 0.007 (0.010)
Train: 0 [ 800/3167 ( 25%)]  Loss: 4.32 (4.51)  Time: 0.600s,   66.62/s  (0.605s,   66.15/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [ 850/3167 ( 27%)]  Loss: 4.38 (4.50)  Time: 0.597s,   66.98/s  (0.604s,   66.19/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [ 900/3167 ( 28%)]  Loss: 4.52 (4.50)  Time: 0.598s,   66.92/s  (0.604s,   66.21/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [ 950/3167 ( 30%)]  Loss: 4.46 (4.50)  Time: 0.601s,   66.58/s  (0.604s,   66.24/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [1000/3167 ( 32%)]  Loss: 4.41 (4.50)  Time: 0.603s,   66.31/s  (0.604s,   66.26/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [1050/3167 ( 33%)]  Loss: 4.46 (4.49)  Time: 0.603s,   66.31/s  (0.603s,   66.28/s)  LR: 1.000e-05  Data: 0.010 (0.009)
Train: 0 [1100/3167 ( 35%)]  Loss: 4.55 (4.49)  Time: 0.601s,   66.52/s  (0.603s,   66.30/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [1150/3167 ( 36%)]  Loss: 4.61 (4.49)  Time: 0.600s,   66.66/s  (0.603s,   66.32/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [1200/3167 ( 38%)]  Loss: 4.46 (4.49)  Time: 0.601s,   66.52/s  (0.603s,   66.33/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [1250/3167 ( 39%)]  Loss: 4.48 (4.48)  Time: 0.597s,   66.96/s  (0.603s,   66.35/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [1300/3167 ( 41%)]  Loss: 4.56 (4.48)  Time: 0.598s,   66.93/s  (0.603s,   66.36/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [1350/3167 ( 43%)]  Loss: 4.45 (4.48)  Time: 0.601s,   66.55/s  (0.603s,   66.38/s)  LR: 1.000e-05  Data: 0.007 (0.009)
Train: 0 [1400/3167 ( 44%)]  Loss: 4.57 (4.48)  Time: 0.594s,   67.31/s  (0.602s,   66.39/s)  LR: 1.000e-05  Data: 0.004 (0.008)
Train: 0 [1450/3167 ( 46%)]  Loss: 4.47 (4.48)  Time: 0.603s,   66.38/s  (0.602s,   66.40/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1500/3167 ( 47%)]  Loss: 4.63 (4.48)  Time: 0.603s,   66.33/s  (0.602s,   66.41/s)  LR: 1.000e-05  Data: 0.010 (0.008)
Train: 0 [1550/3167 ( 49%)]  Loss: 4.59 (4.48)  Time: 0.602s,   66.43/s  (0.602s,   66.42/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1600/3167 ( 51%)]  Loss: 4.45 (4.47)  Time: 0.603s,   66.37/s  (0.602s,   66.43/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1650/3167 ( 52%)]  Loss: 4.39 (4.47)  Time: 0.600s,   66.62/s  (0.602s,   66.44/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1700/3167 ( 54%)]  Loss: 4.47 (4.47)  Time: 0.598s,   66.83/s  (0.602s,   66.45/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1750/3167 ( 55%)]  Loss: 4.39 (4.47)  Time: 0.600s,   66.70/s  (0.602s,   66.46/s)  LR: 1.000e-05  Data: 0.009 (0.008)
Train: 0 [1800/3167 ( 57%)]  Loss: 4.43 (4.47)  Time: 0.598s,   66.92/s  (0.602s,   66.46/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1850/3167 ( 58%)]  Loss: 4.31 (4.47)  Time: 0.597s,   66.97/s  (0.602s,   66.47/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1900/3167 ( 60%)]  Loss: 4.46 (4.47)  Time: 0.597s,   66.97/s  (0.602s,   66.48/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [1950/3167 ( 62%)]  Loss: 4.41 (4.47)  Time: 0.599s,   66.75/s  (0.602s,   66.49/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2000/3167 ( 63%)]  Loss: 4.19 (4.47)  Time: 0.600s,   66.67/s  (0.602s,   66.50/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2050/3167 ( 65%)]  Loss: 4.50 (4.47)  Time: 0.600s,   66.68/s  (0.601s,   66.50/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2100/3167 ( 66%)]  Loss: 4.39 (4.46)  Time: 0.601s,   66.60/s  (0.601s,   66.51/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2150/3167 ( 68%)]  Loss: 4.48 (4.46)  Time: 0.601s,   66.57/s  (0.601s,   66.51/s)  LR: 1.000e-05  Data: 0.010 (0.008)
Train: 0 [2200/3167 ( 69%)]  Loss: 4.43 (4.46)  Time: 0.600s,   66.65/s  (0.601s,   66.52/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2250/3167 ( 71%)]  Loss: 4.29 (4.46)  Time: 0.600s,   66.71/s  (0.601s,   66.52/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2300/3167 ( 73%)]  Loss: 4.40 (4.46)  Time: 0.600s,   66.72/s  (0.601s,   66.53/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2350/3167 ( 74%)]  Loss: 4.47 (4.46)  Time: 0.599s,   66.83/s  (0.601s,   66.53/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2400/3167 ( 76%)]  Loss: 4.53 (4.46)  Time: 0.600s,   66.67/s  (0.601s,   66.54/s)  LR: 1.000e-05  Data: 0.009 (0.008)
Train: 0 [2450/3167 ( 77%)]  Loss: 4.35 (4.46)  Time: 0.601s,   66.53/s  (0.601s,   66.54/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2500/3167 ( 79%)]  Loss: 4.26 (4.46)  Time: 0.598s,   66.90/s  (0.601s,   66.54/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2550/3167 ( 81%)]  Loss: 4.30 (4.46)  Time: 0.597s,   67.00/s  (0.601s,   66.55/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2600/3167 ( 82%)]  Loss: 4.43 (4.45)  Time: 0.600s,   66.70/s  (0.601s,   66.55/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2650/3167 ( 84%)]  Loss: 4.39 (4.45)  Time: 0.600s,   66.65/s  (0.601s,   66.55/s)  LR: 1.000e-05  Data: 0.010 (0.008)
Train: 0 [2700/3167 ( 85%)]  Loss: 4.40 (4.45)  Time: 0.598s,   66.90/s  (0.601s,   66.55/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2750/3167 ( 87%)]  Loss: 4.39 (4.45)  Time: 0.598s,   66.90/s  (0.601s,   66.56/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2800/3167 ( 88%)]  Loss: 4.42 (4.45)  Time: 0.600s,   66.65/s  (0.601s,   66.56/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2850/3167 ( 90%)]  Loss: 4.14 (4.45)  Time: 0.599s,   66.78/s  (0.601s,   66.56/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2900/3167 ( 92%)]  Loss: 4.46 (4.45)  Time: 0.602s,   66.42/s  (0.601s,   66.57/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [2950/3167 ( 93%)]  Loss: 4.48 (4.45)  Time: 0.600s,   66.68/s  (0.601s,   66.57/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [3000/3167 ( 95%)]  Loss: 4.32 (4.45)  Time: 0.601s,   66.58/s  (0.601s,   66.57/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [3050/3167 ( 96%)]  Loss: 4.54 (4.45)  Time: 0.600s,   66.63/s  (0.601s,   66.57/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [3100/3167 ( 98%)]  Loss: 4.58 (4.45)  Time: 0.600s,   66.64/s  (0.601s,   66.58/s)  LR: 1.000e-05  Data: 0.009 (0.008)
Train: 0 [3150/3167 ( 99%)]  Loss: 4.54 (4.45)  Time: 0.601s,   66.51/s  (0.601s,   66.58/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Test: [   0/3167]  Time: 1.987 (1.987)  Loss:   4.325 ( 4.325)  Acc@1:   2.500 (  2.500)  Acc@5:  15.000 ( 15.000)
Test: [  50/3167]  Time: 0.192 (0.226)  Loss:   4.111 ( 4.132)  Acc@1:  10.000 (  5.931)  Acc@5:  42.500 ( 30.147)
Test: [ 100/3167]  Time: 0.189 (0.209)  Loss:   4.414 ( 4.159)  Acc@1:   0.000 (  5.644)  Acc@5:   2.500 ( 27.426)
Test: [ 150/3167]  Time: 0.192 (0.203)  Loss:   3.744 ( 4.164)  Acc@1:  17.500 (  5.927)  Acc@5:  70.000 ( 27.020)
Test: [ 200/3167]  Time: 0.190 (0.199)  Loss:   4.490 ( 4.210)  Acc@1:   0.000 (  5.423)  Acc@5:   0.000 ( 23.644)
Test: [ 250/3167]  Time: 0.193 (0.198)  Loss:   4.555 ( 4.263)  Acc@1:   0.000 (  4.472)  Acc@5:  10.000 ( 19.751)
Test: [ 300/3167]  Time: 0.192 (0.197)  Loss:   4.002 ( 4.273)  Acc@1:   0.000 (  3.787)  Acc@5:  52.500 ( 20.075)
Test: [ 350/3167]  Time: 0.189 (0.196)  Loss:   3.989 ( 4.246)  Acc@1:  30.000 (  4.893)  Acc@5:  55.000 ( 23.668)
Test: [ 400/3167]  Time: 0.188 (0.195)  Loss:   4.123 ( 4.127)  Acc@1:   0.000 ( 10.542)  Acc@5:  40.000 ( 29.077)
Test: [ 450/3167]  Time: 0.191 (0.195)  Loss:   4.180 ( 4.134)  Acc@1:   0.000 (  9.468)  Acc@5:  30.000 ( 28.692)
Test: [ 500/3167]  Time: 0.190 (0.195)  Loss:   4.420 ( 4.165)  Acc@1:   2.500 (  8.598)  Acc@5:  15.000 ( 26.607)
Test: [ 550/3167]  Time: 0.191 (0.195)  Loss:   4.608 ( 4.126)  Acc@1:   0.000 (  9.564)  Acc@5:   0.000 ( 28.580)
Test: [ 600/3167]  Time: 0.207 (0.194)  Loss:   3.731 ( 4.142)  Acc@1:   5.000 (  9.014)  Acc@5:  42.500 ( 27.895)
Test: [ 650/3167]  Time: 0.193 (0.194)  Loss:   4.440 ( 4.138)  Acc@1:   0.000 (  8.917)  Acc@5:   2.500 ( 28.283)
Test: [ 700/3167]  Time: 0.194 (0.194)  Loss:   4.348 ( 4.156)  Acc@1:   0.000 (  8.313)  Acc@5:   7.500 ( 26.726)
Test: [ 750/3167]  Time: 0.199 (0.194)  Loss:   3.976 ( 4.155)  Acc@1:   5.000 (  8.069)  Acc@5:  45.000 ( 26.485)
Test: [ 800/3167]  Time: 0.189 (0.194)  Loss:   4.428 ( 4.155)  Acc@1:   0.000 (  7.978)  Acc@5:  10.000 ( 26.464)
Test: [ 850/3167]  Time: 0.194 (0.193)  Loss:   4.448 ( 4.172)  Acc@1:   0.000 (  7.521)  Acc@5:   0.000 ( 25.118)
Test: [ 900/3167]  Time: 0.190 (0.193)  Loss:   4.411 ( 4.188)  Acc@1:   0.000 (  7.106)  Acc@5:   5.000 ( 23.829)
Test: [ 950/3167]  Time: 0.188 (0.193)  Loss:   4.219 ( 4.200)  Acc@1:   0.000 (  6.746)  Acc@5:  10.000 ( 22.847)
Test: [1000/3167]  Time: 0.188 (0.193)  Loss:   4.284 ( 4.210)  Acc@1:   0.000 (  6.414)  Acc@5:  15.000 ( 22.015)
Test: [1050/3167]  Time: 0.187 (0.193)  Loss:   3.953 ( 4.202)  Acc@1:   7.500 (  6.284)  Acc@5:  32.500 ( 22.176)
Test: [1100/3167]  Time: 0.188 (0.193)  Loss:   4.384 ( 4.209)  Acc@1:   0.000 (  6.049)  Acc@5:  10.000 ( 21.449)
Test: [1150/3167]  Time: 0.191 (0.193)  Loss:   3.926 ( 4.205)  Acc@1:  12.500 (  5.964)  Acc@5:  42.500 ( 21.877)
Test: [1200/3167]  Time: 0.200 (0.193)  Loss:   3.090 ( 4.190)  Acc@1:  45.000 (  6.709)  Acc@5:  82.500 ( 23.137)
Test: [1250/3167]  Time: 0.190 (0.193)  Loss:   3.512 ( 4.162)  Acc@1:  62.500 (  8.505)  Acc@5:  80.000 ( 25.016)
Test: [1300/3167]  Time: 0.188 (0.193)  Loss:   4.241 ( 4.169)  Acc@1:   0.000 (  8.238)  Acc@5:   5.000 ( 24.372)
Test: [1350/3167]  Time: 0.190 (0.192)  Loss:   4.411 ( 4.182)  Acc@1:   0.000 (  7.933)  Acc@5:   5.000 ( 23.634)
Test: [1400/3167]  Time: 0.187 (0.192)  Loss:   3.712 ( 4.194)  Acc@1:  22.500 (  7.712)  Acc@5:  62.500 ( 23.132)
Test: [1450/3167]  Time: 0.188 (0.192)  Loss:   4.489 ( 4.189)  Acc@1:   0.000 (  7.936)  Acc@5:   0.000 ( 23.761)
Test: [1500/3167]  Time: 0.189 (0.192)  Loss:   4.262 ( 4.166)  Acc@1:   2.500 (  9.051)  Acc@5:  15.000 ( 24.599)
Test: [1550/3167]  Time: 0.190 (0.192)  Loss:   4.074 ( 4.168)  Acc@1:   2.500 (  8.835)  Acc@5:  30.000 ( 24.612)
Test: [1600/3167]  Time: 0.189 (0.192)  Loss:   2.956 ( 4.160)  Acc@1:  37.500 (  8.926)  Acc@5:  77.500 ( 25.276)
Test: [1650/3167]  Time: 0.191 (0.192)  Loss:   4.030 ( 4.141)  Acc@1:   2.500 (  9.497)  Acc@5:  32.500 ( 26.110)
Test: [1700/3167]  Time: 0.188 (0.192)  Loss:   4.171 ( 4.136)  Acc@1:   2.500 (  9.278)  Acc@5:  20.000 ( 26.552)
Test: [1750/3167]  Time: 0.184 (0.192)  Loss:   4.073 ( 4.137)  Acc@1:   0.000 (  9.078)  Acc@5:  25.000 ( 26.630)
Test: [1800/3167]  Time: 0.200 (0.192)  Loss:   4.302 ( 4.138)  Acc@1:   0.000 (  8.980)  Acc@5:  12.500 ( 26.695)
Test: [1850/3167]  Time: 0.188 (0.192)  Loss:   4.555 ( 4.147)  Acc@1:   0.000 (  8.737)  Acc@5:   5.000 ( 26.047)
Test: [1900/3167]  Time: 0.192 (0.192)  Loss:   4.550 ( 4.156)  Acc@1:   0.000 (  8.513)  Acc@5:   0.000 ( 25.466)
Test: [1950/3167]  Time: 0.189 (0.192)  Loss:   4.542 ( 4.162)  Acc@1:   0.000 (  8.334)  Acc@5:   0.000 ( 25.127)
Test: [2000/3167]  Time: 0.192 (0.192)  Loss:   4.709 ( 4.175)  Acc@1:   0.000 (  8.126)  Acc@5:   0.000 ( 24.554)
Test: [2050/3167]  Time: 0.189 (0.192)  Loss:   4.545 ( 4.185)  Acc@1:   0.000 (  7.928)  Acc@5:   0.000 ( 23.957)
Test: [2100/3167]  Time: 0.192 (0.192)  Loss:   4.328 ( 4.185)  Acc@1:   5.000 (  8.095)  Acc@5:  17.500 ( 24.237)
Test: [2150/3167]  Time: 0.192 (0.192)  Loss:   2.003 ( 4.160)  Acc@1:  77.500 (  8.914)  Acc@5:  90.000 ( 24.897)
Test: [2200/3167]  Time: 0.193 (0.192)  Loss:   4.353 ( 4.157)  Acc@1:   0.000 (  9.022)  Acc@5:  15.000 ( 25.209)
Test: [2250/3167]  Time: 0.188 (0.191)  Loss:   4.019 ( 4.163)  Acc@1:   0.000 (  8.833)  Acc@5:  50.000 ( 25.052)
Test: [2300/3167]  Time: 0.188 (0.191)  Loss:   4.375 ( 4.168)  Acc@1:   0.000 (  8.661)  Acc@5:  12.500 ( 24.955)
Test: [2350/3167]  Time: 0.192 (0.191)  Loss:   4.150 ( 4.170)  Acc@1:  10.000 (  8.574)  Acc@5:  50.000 ( 24.856)
Test: [2400/3167]  Time: 0.190 (0.191)  Loss:   4.457 ( 4.169)  Acc@1:   0.000 (  8.786)  Acc@5:   5.000 ( 25.012)
Test: [2450/3167]  Time: 0.190 (0.191)  Loss:   4.083 ( 4.171)  Acc@1:   5.000 (  8.629)  Acc@5:  22.500 ( 24.764)
Test: [2500/3167]  Time: 0.188 (0.191)  Loss:   4.318 ( 4.171)  Acc@1:   5.000 (  8.613)  Acc@5:  30.000 ( 24.993)
Test: [2550/3167]  Time: 0.189 (0.191)  Loss:   4.141 ( 4.166)  Acc@1:   0.000 (  8.561)  Acc@5:  17.500 ( 25.496)
Test: [2600/3167]  Time: 0.187 (0.191)  Loss:   3.988 ( 4.165)  Acc@1:   5.000 (  8.463)  Acc@5:  32.500 ( 25.466)
Test: [2650/3167]  Time: 0.190 (0.191)  Loss:   4.319 ( 4.168)  Acc@1:   2.500 (  8.336)  Acc@5:  20.000 ( 25.256)
Test: [2700/3167]  Time: 0.186 (0.191)  Loss:   4.188 ( 4.170)  Acc@1:   2.500 (  8.229)  Acc@5:  27.500 ( 25.271)
Test: [2750/3167]  Time: 0.188 (0.191)  Loss:   3.949 ( 4.171)  Acc@1:   2.500 (  8.116)  Acc@5:  45.000 ( 25.248)
Test: [2800/3167]  Time: 0.188 (0.191)  Loss:   4.213 ( 4.171)  Acc@1:   0.000 (  8.036)  Acc@5:  27.500 ( 25.405)
Test: [2850/3167]  Time: 0.186 (0.191)  Loss:   3.957 ( 4.174)  Acc@1:   2.500 (  7.916)  Acc@5:  55.000 ( 25.258)
Test: [2900/3167]  Time: 0.188 (0.191)  Loss:   4.183 ( 4.172)  Acc@1:   2.500 (  7.831)  Acc@5:  20.000 ( 25.367)
Test: [2950/3167]  Time: 0.186 (0.191)  Loss:   4.334 ( 4.175)  Acc@1:   0.000 (  7.699)  Acc@5:   7.500 ( 24.997)
Test: [3000/3167]  Time: 0.188 (0.191)  Loss:   4.328 ( 4.178)  Acc@1:   0.000 (  7.572)  Acc@5:   0.000 ( 24.628)
Test: [3050/3167]  Time: 0.188 (0.191)  Loss:   4.415 ( 4.179)  Acc@1:   0.000 (  7.500)  Acc@5:   0.000 ( 24.474)
Test: [3100/3167]  Time: 0.188 (0.191)  Loss:   4.256 ( 4.182)  Acc@1:   0.000 (  7.383)  Acc@5:  22.500 ( 24.242)
Test: [3150/3167]  Time: 0.186 (0.191)  Loss:   4.464 ( 4.186)  Acc@1:   0.000 (  7.270)  Acc@5:   2.500 ( 23.923)
Test: [3167/3167]  Time: 0.098 (0.191)  Loss:   4.453 ( 4.187)  Acc@1:   0.000 (  7.233)  Acc@5:   0.000 ( 23.815)
Test: [   0/124]  Time: 1.727 (1.727)  Loss:   4.315 ( 4.315)  Acc@1:   0.000 (  0.000)  Acc@5:   7.500 (  7.500)
Test: [  50/124]  Time: 0.189 (0.221)  Loss:   4.368 ( 4.204)  Acc@1:   0.000 (  7.402)  Acc@5:  12.500 ( 23.824)
Test: [ 100/124]  Time: 0.187 (0.205)  Loss:   3.542 ( 4.205)  Acc@1:   5.000 (  7.574)  Acc@5:  70.000 ( 25.025)
Test: [ 124/124]  Time: 0.180 (0.202)  Loss:   4.449 ( 4.220)  Acc@1:   0.000 (  6.420)  Acc@5:   2.500 ( 23.340)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_1/checkpoint-0.pth.tar', 7.23267213412372)

Train: 1 [   0/3167 (  0%)]  Loss: 4.38 (4.38)  Time: 1.153s,   34.69/s  (1.153s,   34.69/s)  LR: 1.900e-05  Data: 0.515 (0.515)
Train: 1 [  50/3167 (  2%)]  Loss: 4.40 (4.40)  Time: 0.602s,   66.49/s  (0.613s,   65.26/s)  LR: 1.900e-05  Data: 0.010 (0.019)
Train: 1 [ 100/3167 (  3%)]  Loss: 4.22 (4.38)  Time: 0.602s,   66.44/s  (0.608s,   65.81/s)  LR: 1.900e-05  Data: 0.012 (0.015)
Train: 1 [ 150/3167 (  5%)]  Loss: 4.50 (4.39)  Time: 0.602s,   66.45/s  (0.606s,   66.02/s)  LR: 1.900e-05  Data: 0.012 (0.013)
Train: 1 [ 200/3167 (  6%)]  Loss: 4.33 (4.39)  Time: 0.604s,   66.21/s  (0.605s,   66.12/s)  LR: 1.900e-05  Data: 0.011 (0.012)
Train: 1 [ 250/3167 (  8%)]  Loss: 4.29 (4.39)  Time: 0.604s,   66.23/s  (0.605s,   66.16/s)  LR: 1.900e-05  Data: 0.009 (0.012)
Train: 1 [ 300/3167 (  9%)]  Loss: 4.44 (4.39)  Time: 0.605s,   66.16/s  (0.604s,   66.21/s)  LR: 1.900e-05  Data: 0.012 (0.011)
Train: 1 [ 350/3167 ( 11%)]  Loss: 4.23 (4.40)  Time: 0.600s,   66.72/s  (0.604s,   66.24/s)  LR: 1.900e-05  Data: 0.009 (0.011)
Train: 1 [ 400/3167 ( 13%)]  Loss: 4.11 (4.40)  Time: 0.607s,   65.88/s  (0.604s,   66.25/s)  LR: 1.900e-05  Data: 0.012 (0.011)
Train: 1 [ 450/3167 ( 14%)]  Loss: 4.59 (4.39)  Time: 0.594s,   67.33/s  (0.604s,   66.27/s)  LR: 1.900e-05  Data: 0.004 (0.011)
Train: 1 [ 500/3167 ( 16%)]  Loss: 4.33 (4.40)  Time: 0.605s,   66.14/s  (0.604s,   66.27/s)  LR: 1.900e-05  Data: 0.012 (0.011)
Train: 1 [ 550/3167 ( 17%)]  Loss: 4.24 (4.39)  Time: 0.610s,   65.52/s  (0.603s,   66.28/s)  LR: 1.900e-05  Data: 0.011 (0.011)
Train: 1 [ 600/3167 ( 19%)]  Loss: 4.23 (4.39)  Time: 0.601s,   66.50/s  (0.603s,   66.29/s)  LR: 1.900e-05  Data: 0.011 (0.011)
Train: 1 [ 650/3167 ( 21%)]  Loss: 4.39 (4.39)  Time: 0.594s,   67.37/s  (0.603s,   66.30/s)  LR: 1.900e-05  Data: 0.004 (0.010)
Train: 1 [ 700/3167 ( 22%)]  Loss: 4.34 (4.39)  Time: 0.599s,   66.79/s  (0.603s,   66.31/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [ 750/3167 ( 24%)]  Loss: 4.22 (4.39)  Time: 0.604s,   66.24/s  (0.603s,   66.32/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [ 800/3167 ( 25%)]  Loss: 4.28 (4.39)  Time: 0.594s,   67.35/s  (0.603s,   66.32/s)  LR: 1.900e-05  Data: 0.004 (0.010)
Train: 1 [ 850/3167 ( 27%)]  Loss: 4.28 (4.39)  Time: 0.606s,   66.01/s  (0.603s,   66.32/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [ 900/3167 ( 28%)]  Loss: 4.31 (4.39)  Time: 0.602s,   66.47/s  (0.603s,   66.33/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [ 950/3167 ( 30%)]  Loss: 4.33 (4.39)  Time: 0.602s,   66.45/s  (0.603s,   66.34/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [1000/3167 ( 32%)]  Loss: 4.42 (4.39)  Time: 0.599s,   66.83/s  (0.603s,   66.34/s)  LR: 1.900e-05  Data: 0.004 (0.010)
Train: 1 [1050/3167 ( 33%)]  Loss: 4.35 (4.38)  Time: 0.597s,   67.00/s  (0.603s,   66.35/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [1100/3167 ( 35%)]  Loss: 4.42 (4.38)  Time: 0.609s,   65.66/s  (0.603s,   66.35/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [1150/3167 ( 36%)]  Loss: 4.50 (4.38)  Time: 0.604s,   66.23/s  (0.603s,   66.35/s)  LR: 1.900e-05  Data: 0.011 (0.010)
Train: 1 [1200/3167 ( 38%)]  Loss: 4.52 (4.38)  Time: 0.597s,   66.95/s  (0.603s,   66.36/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [1250/3167 ( 39%)]  Loss: 4.30 (4.38)  Time: 0.604s,   66.21/s  (0.603s,   66.36/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [1300/3167 ( 41%)]  Loss: 4.49 (4.38)  Time: 0.602s,   66.49/s  (0.603s,   66.36/s)  LR: 1.900e-05  Data: 0.011 (0.010)
Train: 1 [1350/3167 ( 43%)]  Loss: 4.15 (4.38)  Time: 0.606s,   65.98/s  (0.603s,   66.36/s)  LR: 1.900e-05  Data: 0.011 (0.010)
Train: 1 [1400/3167 ( 44%)]  Loss: 4.41 (4.38)  Time: 0.605s,   66.14/s  (0.603s,   66.36/s)  LR: 1.900e-05  Data: 0.010 (0.010)
Train: 1 [1450/3167 ( 46%)]  Loss: 4.30 (4.38)  Time: 0.614s,   65.10/s  (0.603s,   66.36/s)  LR: 1.900e-05  Data: 0.014 (0.010)
Train: 1 [1500/3167 ( 47%)]  Loss: 4.41 (4.38)  Time: 0.598s,   66.84/s  (0.603s,   66.37/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [1550/3167 ( 49%)]  Loss: 4.52 (4.38)  Time: 0.597s,   67.04/s  (0.603s,   66.37/s)  LR: 1.900e-05  Data: 0.006 (0.010)
Train: 1 [1600/3167 ( 51%)]  Loss: 4.28 (4.38)  Time: 0.596s,   67.07/s  (0.603s,   66.36/s)  LR: 1.900e-05  Data: 0.006 (0.010)
Train: 1 [1650/3167 ( 52%)]  Loss: 4.40 (4.38)  Time: 0.599s,   66.82/s  (0.603s,   66.36/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [1700/3167 ( 54%)]  Loss: 4.32 (4.38)  Time: 0.605s,   66.14/s  (0.603s,   66.37/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [1750/3167 ( 55%)]  Loss: 4.28 (4.38)  Time: 0.599s,   66.78/s  (0.603s,   66.37/s)  LR: 1.900e-05  Data: 0.006 (0.010)
Train: 1 [1800/3167 ( 57%)]  Loss: 4.42 (4.38)  Time: 0.600s,   66.70/s  (0.603s,   66.37/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [1850/3167 ( 58%)]  Loss: 4.25 (4.38)  Time: 0.602s,   66.40/s  (0.603s,   66.37/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [1900/3167 ( 60%)]  Loss: 4.38 (4.38)  Time: 0.609s,   65.63/s  (0.603s,   66.37/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [1950/3167 ( 62%)]  Loss: 4.41 (4.38)  Time: 0.602s,   66.45/s  (0.603s,   66.37/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [2000/3167 ( 63%)]  Loss: 4.28 (4.38)  Time: 0.597s,   66.99/s  (0.603s,   66.37/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [2050/3167 ( 65%)]  Loss: 4.38 (4.38)  Time: 0.602s,   66.46/s  (0.603s,   66.37/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [2100/3167 ( 66%)]  Loss: 4.48 (4.38)  Time: 0.602s,   66.42/s  (0.603s,   66.37/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [2150/3167 ( 68%)]  Loss: 4.27 (4.38)  Time: 0.595s,   67.21/s  (0.603s,   66.37/s)  LR: 1.900e-05  Data: 0.004 (0.010)
Train: 1 [2200/3167 ( 69%)]  Loss: 4.22 (4.38)  Time: 0.598s,   66.93/s  (0.603s,   66.37/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [2250/3167 ( 71%)]  Loss: 4.38 (4.38)  Time: 0.600s,   66.71/s  (0.603s,   66.37/s)  LR: 1.900e-05  Data: 0.006 (0.010)
Train: 1 [2300/3167 ( 73%)]  Loss: 4.42 (4.37)  Time: 0.604s,   66.25/s  (0.603s,   66.38/s)  LR: 1.900e-05  Data: 0.009 (0.010)
Train: 1 [2350/3167 ( 74%)]  Loss: 4.34 (4.37)  Time: 0.602s,   66.40/s  (0.603s,   66.38/s)  LR: 1.900e-05  Data: 0.009 (0.010)
Train: 1 [2400/3167 ( 76%)]  Loss: 4.25 (4.37)  Time: 0.605s,   66.13/s  (0.603s,   66.38/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [2450/3167 ( 77%)]  Loss: 4.54 (4.37)  Time: 0.602s,   66.44/s  (0.603s,   66.38/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [2500/3167 ( 79%)]  Loss: 4.24 (4.37)  Time: 0.597s,   66.99/s  (0.603s,   66.38/s)  LR: 1.900e-05  Data: 0.004 (0.010)
Train: 1 [2550/3167 ( 81%)]  Loss: 4.58 (4.37)  Time: 0.598s,   66.86/s  (0.603s,   66.38/s)  LR: 1.900e-05  Data: 0.006 (0.010)
Train: 1 [2600/3167 ( 82%)]  Loss: 4.44 (4.37)  Time: 0.602s,   66.42/s  (0.603s,   66.38/s)  LR: 1.900e-05  Data: 0.009 (0.010)
Train: 1 [2650/3167 ( 84%)]  Loss: 4.23 (4.37)  Time: 0.597s,   66.99/s  (0.603s,   66.39/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [2700/3167 ( 85%)]  Loss: 4.36 (4.37)  Time: 0.602s,   66.42/s  (0.602s,   66.39/s)  LR: 1.900e-05  Data: 0.009 (0.010)
Train: 1 [2750/3167 ( 87%)]  Loss: 4.63 (4.37)  Time: 0.597s,   67.03/s  (0.602s,   66.40/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [2800/3167 ( 88%)]  Loss: 4.40 (4.37)  Time: 0.602s,   66.41/s  (0.602s,   66.40/s)  LR: 1.900e-05  Data: 0.011 (0.010)
Train: 1 [2850/3167 ( 90%)]  Loss: 4.40 (4.37)  Time: 0.598s,   66.87/s  (0.602s,   66.41/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [2900/3167 ( 92%)]  Loss: 4.60 (4.37)  Time: 0.600s,   66.71/s  (0.602s,   66.41/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [2950/3167 ( 93%)]  Loss: 4.37 (4.37)  Time: 0.600s,   66.70/s  (0.602s,   66.42/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [3000/3167 ( 95%)]  Loss: 4.11 (4.37)  Time: 0.599s,   66.81/s  (0.602s,   66.42/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [3050/3167 ( 96%)]  Loss: 4.41 (4.37)  Time: 0.596s,   67.08/s  (0.602s,   66.43/s)  LR: 1.900e-05  Data: 0.004 (0.010)
Train: 1 [3100/3167 ( 98%)]  Loss: 4.30 (4.36)  Time: 0.597s,   66.99/s  (0.602s,   66.43/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [3150/3167 ( 99%)]  Loss: 4.14 (4.36)  Time: 0.600s,   66.66/s  (0.602s,   66.43/s)  LR: 1.900e-05  Data: 0.007 (0.009)
Test: [   0/3167]  Time: 0.507 (0.507)  Loss:   4.181 ( 4.181)  Acc@1:   7.500 (  7.500)  Acc@5:  20.000 ( 20.000)
Test: [  50/3167]  Time: 0.192 (0.198)  Loss:   4.141 ( 4.086)  Acc@1:  20.000 (  9.265)  Acc@5:  35.000 ( 33.333)
Test: [ 100/3167]  Time: 0.190 (0.194)  Loss:   4.438 ( 4.172)  Acc@1:   0.000 (  6.658)  Acc@5:   5.000 ( 24.629)
Test: [ 150/3167]  Time: 0.190 (0.193)  Loss:   3.442 ( 4.137)  Acc@1:  10.000 (  6.474)  Acc@5:  67.500 ( 26.623)
Test: [ 200/3167]  Time: 0.189 (0.193)  Loss:   4.282 ( 4.168)  Acc@1:   0.000 (  5.560)  Acc@5:   7.500 ( 23.930)
Test: [ 250/3167]  Time: 0.191 (0.192)  Loss:   4.437 ( 4.194)  Acc@1:   0.000 (  4.572)  Acc@5:   5.000 ( 20.329)
Test: [ 300/3167]  Time: 0.196 (0.192)  Loss:   4.008 ( 4.214)  Acc@1:   0.000 (  4.302)  Acc@5:  40.000 ( 20.507)
Test: [ 350/3167]  Time: 0.191 (0.192)  Loss:   3.273 ( 4.131)  Acc@1:  50.000 (  7.457)  Acc@5:  67.500 ( 24.950)
Test: [ 400/3167]  Time: 0.191 (0.192)  Loss:   3.800 ( 4.013)  Acc@1:  20.000 ( 12.469)  Acc@5:  55.000 ( 30.549)
Test: [ 450/3167]  Time: 0.190 (0.192)  Loss:   3.875 ( 4.002)  Acc@1:   7.500 ( 11.802)  Acc@5:  35.000 ( 30.831)
Test: [ 500/3167]  Time: 0.191 (0.192)  Loss:   4.504 ( 4.050)  Acc@1:   0.000 ( 10.634)  Acc@5:   5.000 ( 28.263)
Test: [ 550/3167]  Time: 0.186 (0.192)  Loss:   4.565 ( 4.014)  Acc@1:   0.000 ( 12.178)  Acc@5:   0.000 ( 29.741)
Test: [ 600/3167]  Time: 0.191 (0.192)  Loss:   3.387 ( 4.026)  Acc@1:   7.500 ( 11.672)  Acc@5:  60.000 ( 29.143)
Test: [ 650/3167]  Time: 0.189 (0.192)  Loss:   4.502 ( 3.990)  Acc@1:   0.000 ( 12.715)  Acc@5:   5.000 ( 30.618)
Test: [ 700/3167]  Time: 0.191 (0.192)  Loss:   3.775 ( 4.001)  Acc@1:  12.500 ( 12.076)  Acc@5:  52.500 ( 30.210)
Test: [ 750/3167]  Time: 0.191 (0.192)  Loss:   3.639 ( 3.993)  Acc@1:  17.500 ( 11.644)  Acc@5:  47.500 ( 30.220)
Test: [ 800/3167]  Time: 0.193 (0.192)  Loss:   4.550 ( 3.997)  Acc@1:   0.000 ( 11.467)  Acc@5:  10.000 ( 30.268)
Test: [ 850/3167]  Time: 0.193 (0.192)  Loss:   4.297 ( 4.018)  Acc@1:   0.000 ( 10.964)  Acc@5:   7.500 ( 29.653)
Test: [ 900/3167]  Time: 0.190 (0.192)  Loss:   4.278 ( 4.034)  Acc@1:   7.500 ( 10.499)  Acc@5:  20.000 ( 28.979)
Test: [ 950/3167]  Time: 0.196 (0.192)  Loss:   3.772 ( 4.044)  Acc@1:   2.500 ( 10.084)  Acc@5:  37.500 ( 28.233)
Test: [1000/3167]  Time: 0.197 (0.192)  Loss:   4.231 ( 4.050)  Acc@1:   0.000 (  9.695)  Acc@5:  12.500 ( 27.413)
Test: [1050/3167]  Time: 0.201 (0.192)  Loss:   3.907 ( 4.048)  Acc@1:   2.500 (  9.439)  Acc@5:  42.500 ( 27.383)
Test: [1100/3167]  Time: 0.184 (0.192)  Loss:   4.313 ( 4.050)  Acc@1:   2.500 (  9.060)  Acc@5:   7.500 ( 26.898)
Test: [1150/3167]  Time: 0.191 (0.192)  Loss:   3.646 ( 4.046)  Acc@1:  30.000 (  9.257)  Acc@5:  62.500 ( 27.407)
Test: [1200/3167]  Time: 0.193 (0.192)  Loss:   3.162 ( 4.030)  Acc@1:  40.000 (  9.515)  Acc@5:  72.500 ( 28.297)
Test: [1250/3167]  Time: 0.195 (0.192)  Loss:   3.158 ( 3.999)  Acc@1:  45.000 ( 10.661)  Acc@5:  82.500 ( 29.984)
Test: [1300/3167]  Time: 0.191 (0.192)  Loss:   3.705 ( 4.005)  Acc@1:   0.000 ( 10.327)  Acc@5:  40.000 ( 29.669)
Test: [1350/3167]  Time: 0.194 (0.192)  Loss:   4.354 ( 4.021)  Acc@1:   2.500 (  9.965)  Acc@5:  20.000 ( 29.121)
Test: [1400/3167]  Time: 0.196 (0.192)  Loss:   3.614 ( 4.039)  Acc@1:  27.500 (  9.702)  Acc@5:  55.000 ( 28.624)
Test: [1450/3167]  Time: 0.194 (0.192)  Loss:   4.437 ( 4.035)  Acc@1:   0.000 (  9.967)  Acc@5:   2.500 ( 28.971)
Test: [1500/3167]  Time: 0.195 (0.192)  Loss:   3.834 ( 4.008)  Acc@1:   7.500 ( 10.974)  Acc@5:  32.500 ( 29.755)
Test: [1550/3167]  Time: 0.197 (0.192)  Loss:   3.031 ( 3.993)  Acc@1:  35.000 ( 11.181)  Acc@5:  85.000 ( 30.553)
Test: [1600/3167]  Time: 0.187 (0.192)  Loss:   2.907 ( 3.975)  Acc@1:  40.000 ( 11.430)  Acc@5:  75.000 ( 31.604)
Test: [1650/3167]  Time: 0.191 (0.192)  Loss:   3.853 ( 3.958)  Acc@1:  17.500 ( 11.972)  Acc@5:  45.000 ( 32.441)
Test: [1700/3167]  Time: 0.191 (0.192)  Loss:   4.308 ( 3.950)  Acc@1:   0.000 ( 12.119)  Acc@5:  12.500 ( 32.906)
Test: [1750/3167]  Time: 0.189 (0.192)  Loss:   3.886 ( 3.955)  Acc@1:   7.500 ( 12.052)  Acc@5:  32.500 ( 32.887)
Test: [1800/3167]  Time: 0.196 (0.192)  Loss:   3.965 ( 3.953)  Acc@1:   5.000 ( 12.047)  Acc@5:  32.500 ( 33.130)
Test: [1850/3167]  Time: 0.191 (0.192)  Loss:   4.725 ( 3.966)  Acc@1:   0.000 ( 11.742)  Acc@5:   0.000 ( 32.530)
Test: [1900/3167]  Time: 0.192 (0.192)  Loss:   4.543 ( 3.982)  Acc@1:   0.000 ( 11.433)  Acc@5:   0.000 ( 31.685)
Test: [1950/3167]  Time: 0.190 (0.192)  Loss:   4.504 ( 3.993)  Acc@1:   5.000 ( 11.155)  Acc@5:  20.000 ( 31.102)
Test: [2000/3167]  Time: 0.191 (0.192)  Loss:   4.601 ( 4.009)  Acc@1:   0.000 ( 10.900)  Acc@5:   0.000 ( 30.511)
Test: [2050/3167]  Time: 0.189 (0.192)  Loss:   4.591 ( 4.023)  Acc@1:   0.000 ( 10.635)  Acc@5:   0.000 ( 29.792)
Test: [2100/3167]  Time: 0.190 (0.192)  Loss:   4.217 ( 4.030)  Acc@1:   7.500 ( 10.549)  Acc@5:  10.000 ( 29.607)
Test: [2150/3167]  Time: 0.192 (0.192)  Loss:   2.067 ( 4.008)  Acc@1:  72.500 ( 11.216)  Acc@5:  80.000 ( 30.073)
Test: [2200/3167]  Time: 0.184 (0.192)  Loss:   3.938 ( 4.005)  Acc@1:   2.500 ( 11.192)  Acc@5:  35.000 ( 30.145)
Test: [2250/3167]  Time: 0.192 (0.192)  Loss:   3.662 ( 4.009)  Acc@1:  30.000 ( 11.088)  Acc@5:  62.500 ( 30.116)
Test: [2300/3167]  Time: 0.191 (0.192)  Loss:   4.400 ( 4.016)  Acc@1:   0.000 ( 11.048)  Acc@5:  12.500 ( 29.952)
Test: [2350/3167]  Time: 0.197 (0.192)  Loss:   4.016 ( 4.020)  Acc@1:  12.500 ( 10.880)  Acc@5:  37.500 ( 29.770)
Test: [2400/3167]  Time: 0.191 (0.192)  Loss:   4.371 ( 4.024)  Acc@1:   0.000 ( 10.820)  Acc@5:  12.500 ( 29.611)
Test: [2450/3167]  Time: 0.184 (0.192)  Loss:   3.680 ( 4.024)  Acc@1:   7.500 ( 10.664)  Acc@5:  42.500 ( 29.569)
Test: [2500/3167]  Time: 0.210 (0.192)  Loss:   4.482 ( 4.027)  Acc@1:  10.000 ( 10.635)  Acc@5:  17.500 ( 29.516)
Test: [2550/3167]  Time: 0.202 (0.192)  Loss:   4.193 ( 4.022)  Acc@1:   0.000 ( 10.569)  Acc@5:   7.500 ( 29.828)
Test: [2600/3167]  Time: 0.192 (0.192)  Loss:   3.892 ( 4.025)  Acc@1:  15.000 ( 10.412)  Acc@5:  40.000 ( 29.553)
Test: [2650/3167]  Time: 0.190 (0.192)  Loss:   3.933 ( 4.029)  Acc@1:   7.500 ( 10.271)  Acc@5:  37.500 ( 29.346)
Test: [2700/3167]  Time: 0.188 (0.192)  Loss:   3.926 ( 4.027)  Acc@1:   2.500 ( 10.198)  Acc@5:  30.000 ( 29.465)
Test: [2750/3167]  Time: 0.188 (0.192)  Loss:   2.962 ( 4.027)  Acc@1:  62.500 ( 10.177)  Acc@5:  85.000 ( 29.409)
Test: [2800/3167]  Time: 0.192 (0.192)  Loss:   4.236 ( 4.019)  Acc@1:   7.500 ( 10.559)  Acc@5:  25.000 ( 29.866)
Test: [2850/3167]  Time: 0.186 (0.192)  Loss:   3.921 ( 4.024)  Acc@1:  10.000 ( 10.418)  Acc@5:  32.500 ( 29.593)
Test: [2900/3167]  Time: 0.186 (0.192)  Loss:   4.046 ( 4.022)  Acc@1:  12.500 ( 10.408)  Acc@5:  32.500 ( 29.742)
Test: [2950/3167]  Time: 0.190 (0.192)  Loss:   3.924 ( 4.023)  Acc@1:   0.000 ( 10.271)  Acc@5:  15.000 ( 29.389)
Test: [3000/3167]  Time: 0.187 (0.192)  Loss:   4.173 ( 4.025)  Acc@1:   0.000 ( 10.106)  Acc@5:   7.500 ( 29.029)
Test: [3050/3167]  Time: 0.188 (0.192)  Loss:   4.539 ( 4.028)  Acc@1:   0.000 (  9.975)  Acc@5:   7.500 ( 28.873)
Test: [3100/3167]  Time: 0.186 (0.191)  Loss:   4.235 ( 4.032)  Acc@1:   0.000 (  9.823)  Acc@5:   5.000 ( 28.574)
Test: [3150/3167]  Time: 0.188 (0.191)  Loss:   4.600 ( 4.038)  Acc@1:   0.000 (  9.668)  Acc@5:   0.000 ( 28.182)
Test: [3167/3167]  Time: 0.043 (0.191)  Loss:   4.582 ( 4.041)  Acc@1:   0.000 (  9.620)  Acc@5:   0.000 ( 28.043)
Test: [   0/124]  Time: 0.526 (0.526)  Loss:   4.222 ( 4.222)  Acc@1:   5.000 (  5.000)  Acc@5:  25.000 ( 25.000)
Test: [  50/124]  Time: 0.186 (0.195)  Loss:   3.907 ( 4.052)  Acc@1:   0.000 (  8.971)  Acc@5:  35.000 ( 28.529)
Test: [ 100/124]  Time: 0.186 (0.191)  Loss:   3.257 ( 4.072)  Acc@1:  10.000 (  9.208)  Acc@5:  70.000 ( 28.688)
Test: [ 124/124]  Time: 0.180 (0.190)  Loss:   4.585 ( 4.085)  Acc@1:   0.000 (  8.480)  Acc@5:   0.000 ( 26.960)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_1/checkpoint-1.pth.tar', 9.619619698632084)

Train: 2 [   0/3167 (  0%)]  Loss: 4.27 (4.27)  Time: 1.060s,   37.73/s  (1.060s,   37.73/s)  LR: 2.800e-05  Data: 0.461 (0.461)
Train: 2 [  50/3167 (  2%)]  Loss: 4.23 (4.34)  Time: 0.596s,   67.06/s  (0.613s,   65.26/s)  LR: 2.800e-05  Data: 0.004 (0.020)
Train: 2 [ 100/3167 (  3%)]  Loss: 4.27 (4.34)  Time: 0.604s,   66.23/s  (0.608s,   65.77/s)  LR: 2.800e-05  Data: 0.011 (0.015)
Train: 2 [ 150/3167 (  5%)]  Loss: 4.50 (4.33)  Time: 0.602s,   66.42/s  (0.606s,   66.00/s)  LR: 2.800e-05  Data: 0.012 (0.013)
Train: 2 [ 200/3167 (  6%)]  Loss: 4.52 (4.34)  Time: 0.600s,   66.68/s  (0.606s,   66.06/s)  LR: 2.800e-05  Data: 0.006 (0.012)
Train: 2 [ 250/3167 (  8%)]  Loss: 4.31 (4.34)  Time: 0.601s,   66.51/s  (0.605s,   66.10/s)  LR: 2.800e-05  Data: 0.011 (0.012)
Train: 2 [ 300/3167 (  9%)]  Loss: 4.26 (4.34)  Time: 0.603s,   66.37/s  (0.605s,   66.14/s)  LR: 2.800e-05  Data: 0.012 (0.011)
Train: 2 [ 350/3167 ( 11%)]  Loss: 4.26 (4.34)  Time: 0.602s,   66.45/s  (0.605s,   66.16/s)  LR: 2.800e-05  Data: 0.010 (0.011)
Train: 2 [ 400/3167 ( 13%)]  Loss: 4.14 (4.34)  Time: 0.605s,   66.15/s  (0.604s,   66.18/s)  LR: 2.800e-05  Data: 0.012 (0.011)
Train: 2 [ 450/3167 ( 14%)]  Loss: 4.27 (4.33)  Time: 0.604s,   66.22/s  (0.604s,   66.20/s)  LR: 2.800e-05  Data: 0.011 (0.011)
Train: 2 [ 500/3167 ( 16%)]  Loss: 4.41 (4.33)  Time: 0.597s,   66.97/s  (0.604s,   66.20/s)  LR: 2.800e-05  Data: 0.007 (0.011)
Train: 2 [ 550/3167 ( 17%)]  Loss: 4.20 (4.33)  Time: 0.605s,   66.12/s  (0.604s,   66.21/s)  LR: 2.800e-05  Data: 0.012 (0.011)
Train: 2 [ 600/3167 ( 19%)]  Loss: 4.25 (4.33)  Time: 0.594s,   67.36/s  (0.604s,   66.22/s)  LR: 2.800e-05  Data: 0.004 (0.011)
Train: 2 [ 650/3167 ( 21%)]  Loss: 4.26 (4.33)  Time: 0.607s,   65.93/s  (0.604s,   66.22/s)  LR: 2.800e-05  Data: 0.012 (0.011)
Train: 2 [ 700/3167 ( 22%)]  Loss: 4.39 (4.33)  Time: 0.608s,   65.82/s  (0.604s,   66.22/s)  LR: 2.800e-05  Data: 0.012 (0.011)
Train: 2 [ 750/3167 ( 24%)]  Loss: 4.15 (4.33)  Time: 0.602s,   66.42/s  (0.604s,   66.22/s)  LR: 2.800e-05  Data: 0.012 (0.011)
Train: 2 [ 800/3167 ( 25%)]  Loss: 4.30 (4.33)  Time: 0.604s,   66.25/s  (0.604s,   66.22/s)  LR: 2.800e-05  Data: 0.011 (0.011)
Train: 2 [ 850/3167 ( 27%)]  Loss: 4.16 (4.33)  Time: 0.611s,   65.52/s  (0.604s,   66.23/s)  LR: 2.800e-05  Data: 0.012 (0.011)
Train: 2 [ 900/3167 ( 28%)]  Loss: 4.47 (4.33)  Time: 0.602s,   66.50/s  (0.604s,   66.23/s)  LR: 2.800e-05  Data: 0.011 (0.011)
Train: 2 [ 950/3167 ( 30%)]  Loss: 4.15 (4.32)  Time: 0.601s,   66.55/s  (0.604s,   66.23/s)  LR: 2.800e-05  Data: 0.009 (0.011)
Train: 2 [1000/3167 ( 32%)]  Loss: 4.53 (4.32)  Time: 0.602s,   66.49/s  (0.604s,   66.24/s)  LR: 2.800e-05  Data: 0.011 (0.011)
Train: 2 [1050/3167 ( 33%)]  Loss: 4.45 (4.32)  Time: 0.602s,   66.49/s  (0.604s,   66.24/s)  LR: 2.800e-05  Data: 0.011 (0.011)
Train: 2 [1100/3167 ( 35%)]  Loss: 4.27 (4.32)  Time: 0.596s,   67.10/s  (0.604s,   66.24/s)  LR: 2.800e-05  Data: 0.004 (0.011)
Train: 2 [1150/3167 ( 36%)]  Loss: 4.40 (4.32)  Time: 0.604s,   66.20/s  (0.604s,   66.24/s)  LR: 2.800e-05  Data: 0.009 (0.011)
Train: 2 [1200/3167 ( 38%)]  Loss: 4.41 (4.32)  Time: 0.606s,   65.96/s  (0.604s,   66.25/s)  LR: 2.800e-05  Data: 0.009 (0.011)
Train: 2 [1250/3167 ( 39%)]  Loss: 4.21 (4.32)  Time: 0.599s,   66.80/s  (0.604s,   66.25/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1300/3167 ( 41%)]  Loss: 4.53 (4.32)  Time: 0.605s,   66.15/s  (0.604s,   66.26/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [1350/3167 ( 43%)]  Loss: 4.29 (4.32)  Time: 0.604s,   66.20/s  (0.604s,   66.26/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [1400/3167 ( 44%)]  Loss: 4.20 (4.32)  Time: 0.605s,   66.11/s  (0.604s,   66.27/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [1450/3167 ( 46%)]  Loss: 4.44 (4.32)  Time: 0.603s,   66.35/s  (0.604s,   66.27/s)  LR: 2.800e-05  Data: 0.011 (0.010)
Train: 2 [1500/3167 ( 47%)]  Loss: 4.34 (4.32)  Time: 0.600s,   66.68/s  (0.604s,   66.28/s)  LR: 2.800e-05  Data: 0.010 (0.010)
Train: 2 [1550/3167 ( 49%)]  Loss: 4.29 (4.32)  Time: 0.601s,   66.61/s  (0.603s,   66.28/s)  LR: 2.800e-05  Data: 0.009 (0.010)
Train: 2 [1600/3167 ( 51%)]  Loss: 4.51 (4.32)  Time: 0.601s,   66.50/s  (0.603s,   66.28/s)  LR: 2.800e-05  Data: 0.011 (0.010)
Train: 2 [1650/3167 ( 52%)]  Loss: 4.44 (4.32)  Time: 0.601s,   66.55/s  (0.603s,   66.29/s)  LR: 2.800e-05  Data: 0.009 (0.010)
Train: 2 [1700/3167 ( 54%)]  Loss: 4.12 (4.31)  Time: 0.605s,   66.12/s  (0.603s,   66.29/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [1750/3167 ( 55%)]  Loss: 4.41 (4.31)  Time: 0.603s,   66.38/s  (0.603s,   66.29/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [1800/3167 ( 57%)]  Loss: 4.03 (4.31)  Time: 0.604s,   66.18/s  (0.603s,   66.30/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [1850/3167 ( 58%)]  Loss: 4.13 (4.31)  Time: 0.602s,   66.41/s  (0.603s,   66.30/s)  LR: 2.800e-05  Data: 0.011 (0.010)
Train: 2 [1900/3167 ( 60%)]  Loss: 4.14 (4.31)  Time: 0.607s,   65.93/s  (0.603s,   66.30/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [1950/3167 ( 62%)]  Loss: 4.23 (4.31)  Time: 0.602s,   66.45/s  (0.603s,   66.30/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [2000/3167 ( 63%)]  Loss: 4.24 (4.31)  Time: 0.602s,   66.44/s  (0.603s,   66.31/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [2050/3167 ( 65%)]  Loss: 4.38 (4.31)  Time: 0.601s,   66.60/s  (0.603s,   66.31/s)  LR: 2.800e-05  Data: 0.007 (0.010)
Train: 2 [2100/3167 ( 66%)]  Loss: 4.42 (4.31)  Time: 0.602s,   66.44/s  (0.603s,   66.31/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [2150/3167 ( 68%)]  Loss: 4.31 (4.31)  Time: 0.600s,   66.68/s  (0.603s,   66.31/s)  LR: 2.800e-05  Data: 0.010 (0.010)
Train: 2 [2200/3167 ( 69%)]  Loss: 4.00 (4.31)  Time: 0.600s,   66.70/s  (0.603s,   66.31/s)  LR: 2.800e-05  Data: 0.009 (0.010)
Train: 2 [2250/3167 ( 71%)]  Loss: 4.48 (4.30)  Time: 0.597s,   67.01/s  (0.603s,   66.32/s)  LR: 2.800e-05  Data: 0.007 (0.010)
Train: 2 [2300/3167 ( 73%)]  Loss: 4.45 (4.30)  Time: 0.605s,   66.15/s  (0.603s,   66.32/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [2350/3167 ( 74%)]  Loss: 4.48 (4.30)  Time: 0.608s,   65.83/s  (0.603s,   66.32/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [2400/3167 ( 76%)]  Loss: 4.25 (4.30)  Time: 0.596s,   67.07/s  (0.603s,   66.33/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [2450/3167 ( 77%)]  Loss: 4.23 (4.30)  Time: 0.604s,   66.19/s  (0.603s,   66.33/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [2500/3167 ( 79%)]  Loss: 4.16 (4.30)  Time: 0.602s,   66.45/s  (0.603s,   66.34/s)  LR: 2.800e-05  Data: 0.009 (0.010)
Train: 2 [2550/3167 ( 81%)]  Loss: 4.66 (4.30)  Time: 0.600s,   66.63/s  (0.603s,   66.34/s)  LR: 2.800e-05  Data: 0.009 (0.010)
Train: 2 [2600/3167 ( 82%)]  Loss: 4.41 (4.30)  Time: 0.602s,   66.41/s  (0.603s,   66.35/s)  LR: 2.800e-05  Data: 0.010 (0.010)
Train: 2 [2650/3167 ( 84%)]  Loss: 4.05 (4.30)  Time: 0.603s,   66.37/s  (0.603s,   66.35/s)  LR: 2.800e-05  Data: 0.009 (0.010)
Train: 2 [2700/3167 ( 85%)]  Loss: 4.37 (4.30)  Time: 0.598s,   66.93/s  (0.603s,   66.36/s)  LR: 2.800e-05  Data: 0.007 (0.010)
Train: 2 [2750/3167 ( 87%)]  Loss: 4.30 (4.30)  Time: 0.599s,   66.73/s  (0.603s,   66.36/s)  LR: 2.800e-05  Data: 0.007 (0.010)
Train: 2 [2800/3167 ( 88%)]  Loss: 4.16 (4.30)  Time: 0.603s,   66.39/s  (0.603s,   66.37/s)  LR: 2.800e-05  Data: 0.009 (0.010)
Train: 2 [2850/3167 ( 90%)]  Loss: 4.42 (4.30)  Time: 0.602s,   66.43/s  (0.603s,   66.38/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [2900/3167 ( 92%)]  Loss: 4.32 (4.29)  Time: 0.603s,   66.34/s  (0.603s,   66.38/s)  LR: 2.800e-05  Data: 0.009 (0.010)
Train: 2 [2950/3167 ( 93%)]  Loss: 3.93 (4.29)  Time: 0.599s,   66.78/s  (0.603s,   66.39/s)  LR: 2.800e-05  Data: 0.007 (0.010)
Train: 2 [3000/3167 ( 95%)]  Loss: 4.39 (4.29)  Time: 0.597s,   66.95/s  (0.602s,   66.39/s)  LR: 2.800e-05  Data: 0.007 (0.010)
Train: 2 [3050/3167 ( 96%)]  Loss: 4.31 (4.29)  Time: 0.599s,   66.73/s  (0.602s,   66.40/s)  LR: 2.800e-05  Data: 0.007 (0.010)
Train: 2 [3100/3167 ( 98%)]  Loss: 4.33 (4.29)  Time: 0.603s,   66.36/s  (0.602s,   66.41/s)  LR: 2.800e-05  Data: 0.009 (0.010)
Train: 2 [3150/3167 ( 99%)]  Loss: 4.33 (4.29)  Time: 0.597s,   66.97/s  (0.602s,   66.41/s)  LR: 2.800e-05  Data: 0.007 (0.010)
Test: [   0/3167]  Time: 0.521 (0.521)  Loss:   4.205 ( 4.205)  Acc@1:  10.000 ( 10.000)  Acc@5:  22.500 ( 22.500)
Test: [  50/3167]  Time: 0.188 (0.198)  Loss:   3.910 ( 3.995)  Acc@1:  25.000 ( 13.088)  Acc@5:  45.000 ( 35.882)
Test: [ 100/3167]  Time: 0.184 (0.195)  Loss:   4.159 ( 3.977)  Acc@1:   2.500 ( 10.025)  Acc@5:  15.000 ( 33.441)
Test: [ 150/3167]  Time: 0.190 (0.194)  Loss:   3.034 ( 3.911)  Acc@1:  42.500 ( 12.682)  Acc@5:  80.000 ( 34.619)
Test: [ 200/3167]  Time: 0.194 (0.193)  Loss:   4.106 ( 3.945)  Acc@1:   7.500 ( 11.667)  Acc@5:  25.000 ( 31.194)
Test: [ 250/3167]  Time: 0.187 (0.193)  Loss:   3.547 ( 3.909)  Acc@1:  17.500 ( 12.191)  Acc@5:  50.000 ( 32.480)
Test: [ 300/3167]  Time: 0.193 (0.193)  Loss:   3.878 ( 3.901)  Acc@1:   0.000 ( 12.417)  Acc@5:  35.000 ( 33.596)
Test: [ 350/3167]  Time: 0.191 (0.193)  Loss:   3.378 ( 3.860)  Acc@1:  40.000 ( 13.362)  Acc@5:  65.000 ( 35.598)
Test: [ 400/3167]  Time: 0.191 (0.193)  Loss:   3.716 ( 3.743)  Acc@1:  10.000 ( 17.824)  Acc@5:  47.500 ( 39.751)
Test: [ 450/3167]  Time: 0.198 (0.193)  Loss:   3.795 ( 3.755)  Acc@1:   0.000 ( 16.486)  Acc@5:  17.500 ( 38.525)
Test: [ 500/3167]  Time: 0.191 (0.193)  Loss:   3.968 ( 3.783)  Acc@1:   5.000 ( 15.444)  Acc@5:  22.500 ( 37.809)
Test: [ 550/3167]  Time: 0.198 (0.193)  Loss:   4.089 ( 3.762)  Acc@1:   0.000 ( 16.620)  Acc@5:  15.000 ( 38.866)
Test: [ 600/3167]  Time: 0.193 (0.193)  Loss:   3.382 ( 3.778)  Acc@1:   5.000 ( 15.487)  Acc@5:  45.000 ( 37.858)
Test: [ 650/3167]  Time: 0.188 (0.193)  Loss:   4.195 ( 3.762)  Acc@1:   0.000 ( 15.780)  Acc@5:  17.500 ( 38.272)
Test: [ 700/3167]  Time: 0.186 (0.193)  Loss:   3.257 ( 3.759)  Acc@1:  45.000 ( 15.763)  Acc@5:  70.000 ( 38.905)
Test: [ 750/3167]  Time: 0.192 (0.193)  Loss:   3.752 ( 3.751)  Acc@1:  15.000 ( 15.583)  Acc@5:  45.000 ( 39.397)
Test: [ 800/3167]  Time: 0.193 (0.194)  Loss:   4.331 ( 3.765)  Acc@1:   0.000 ( 15.368)  Acc@5:  20.000 ( 38.873)
Test: [ 850/3167]  Time: 0.201 (0.193)  Loss:   4.132 ( 3.791)  Acc@1:   0.000 ( 14.662)  Acc@5:   5.000 ( 37.808)
Test: [ 900/3167]  Time: 0.203 (0.193)  Loss:   4.012 ( 3.810)  Acc@1:  10.000 ( 14.046)  Acc@5:  27.500 ( 36.570)
Test: [ 950/3167]  Time: 0.187 (0.193)  Loss:   3.179 ( 3.815)  Acc@1:  25.000 ( 14.033)  Acc@5:  75.000 ( 36.540)
Test: [1000/3167]  Time: 0.201 (0.193)  Loss:   4.141 ( 3.827)  Acc@1:   0.000 ( 13.844)  Acc@5:  15.000 ( 35.879)
Test: [1050/3167]  Time: 0.187 (0.194)  Loss:   3.619 ( 3.824)  Acc@1:  10.000 ( 13.544)  Acc@5:  42.500 ( 36.080)
Test: [1100/3167]  Time: 0.191 (0.194)  Loss:   4.195 ( 3.830)  Acc@1:   2.500 ( 13.031)  Acc@5:   5.000 ( 35.497)
Test: [1150/3167]  Time: 0.208 (0.194)  Loss:   3.593 ( 3.830)  Acc@1:  22.500 ( 13.186)  Acc@5:  62.500 ( 35.734)
Test: [1200/3167]  Time: 0.186 (0.194)  Loss:   2.869 ( 3.808)  Acc@1:  47.500 ( 13.832)  Acc@5:  75.000 ( 36.805)
Test: [1250/3167]  Time: 0.201 (0.194)  Loss:   3.450 ( 3.789)  Acc@1:  45.000 ( 14.940)  Acc@5:  60.000 ( 37.826)
Test: [1300/3167]  Time: 0.195 (0.194)  Loss:   3.702 ( 3.798)  Acc@1:  20.000 ( 14.535)  Acc@5:  42.500 ( 37.327)
Test: [1350/3167]  Time: 0.195 (0.194)  Loss:   4.032 ( 3.814)  Acc@1:   2.500 ( 14.095)  Acc@5:  32.500 ( 36.527)
Test: [1400/3167]  Time: 0.198 (0.194)  Loss:   3.432 ( 3.830)  Acc@1:  45.000 ( 13.742)  Acc@5:  62.500 ( 35.917)
Test: [1450/3167]  Time: 0.194 (0.194)  Loss:   4.117 ( 3.825)  Acc@1:   0.000 ( 14.185)  Acc@5:  17.500 ( 36.385)
Test: [1500/3167]  Time: 0.190 (0.194)  Loss:   3.784 ( 3.806)  Acc@1:   7.500 ( 14.194)  Acc@5:  32.500 ( 36.997)
Test: [1550/3167]  Time: 0.194 (0.194)  Loss:   2.737 ( 3.790)  Acc@1:  70.000 ( 14.753)  Acc@5:  90.000 ( 37.689)
Test: [1600/3167]  Time: 0.200 (0.194)  Loss:   2.660 ( 3.778)  Acc@1:  45.000 ( 15.130)  Acc@5:  72.500 ( 38.209)
Test: [1650/3167]  Time: 0.193 (0.194)  Loss:   3.631 ( 3.759)  Acc@1:  20.000 ( 15.674)  Acc@5:  52.500 ( 38.920)
Test: [1700/3167]  Time: 0.191 (0.194)  Loss:   4.226 ( 3.753)  Acc@1:   2.500 ( 15.736)  Acc@5:  17.500 ( 39.302)
Test: [1750/3167]  Time: 0.202 (0.194)  Loss:   3.814 ( 3.760)  Acc@1:  10.000 ( 15.584)  Acc@5:  35.000 ( 39.076)
Test: [1800/3167]  Time: 0.189 (0.194)  Loss:   3.515 ( 3.757)  Acc@1:  25.000 ( 15.757)  Acc@5:  57.500 ( 39.416)
Test: [1850/3167]  Time: 0.206 (0.194)  Loss:   4.199 ( 3.765)  Acc@1:   5.000 ( 15.566)  Acc@5:  22.500 ( 39.005)
Test: [1900/3167]  Time: 0.188 (0.194)  Loss:   4.206 ( 3.773)  Acc@1:   0.000 ( 15.420)  Acc@5:  15.000 ( 38.820)
Test: [1950/3167]  Time: 0.190 (0.194)  Loss:   4.526 ( 3.778)  Acc@1:   0.000 ( 15.375)  Acc@5:   7.500 ( 38.662)
Test: [2000/3167]  Time: 0.190 (0.194)  Loss:   4.080 ( 3.794)  Acc@1:  10.000 ( 15.040)  Acc@5:  22.500 ( 37.910)
Test: [2050/3167]  Time: 0.191 (0.194)  Loss:   4.366 ( 3.803)  Acc@1:   0.000 ( 14.832)  Acc@5:   0.000 ( 37.355)
Test: [2100/3167]  Time: 0.188 (0.194)  Loss:   4.017 ( 3.810)  Acc@1:   2.500 ( 14.701)  Acc@5:  12.500 ( 37.139)
Test: [2150/3167]  Time: 0.205 (0.194)  Loss:   2.341 ( 3.795)  Acc@1:  60.000 ( 15.128)  Acc@5:  70.000 ( 37.480)
Test: [2200/3167]  Time: 0.195 (0.194)  Loss:   3.613 ( 3.788)  Acc@1:   2.500 ( 15.137)  Acc@5:  47.500 ( 37.766)
Test: [2250/3167]  Time: 0.196 (0.194)  Loss:   3.700 ( 3.792)  Acc@1:  25.000 ( 14.967)  Acc@5:  55.000 ( 37.681)
Test: [2300/3167]  Time: 0.188 (0.194)  Loss:   4.197 ( 3.799)  Acc@1:   2.500 ( 14.842)  Acc@5:  20.000 ( 37.386)
Test: [2350/3167]  Time: 0.191 (0.194)  Loss:   3.382 ( 3.799)  Acc@1:  52.500 ( 14.847)  Acc@5:  62.500 ( 37.339)
Test: [2400/3167]  Time: 0.200 (0.194)  Loss:   4.355 ( 3.795)  Acc@1:   0.000 ( 15.079)  Acc@5:   2.500 ( 37.517)
Test: [2450/3167]  Time: 0.192 (0.194)  Loss:   3.245 ( 3.793)  Acc@1:  30.000 ( 14.954)  Acc@5:  72.500 ( 37.688)
Test: [2500/3167]  Time: 0.195 (0.194)  Loss:   4.170 ( 3.795)  Acc@1:  10.000 ( 14.935)  Acc@5:  30.000 ( 37.693)
Test: [2550/3167]  Time: 0.193 (0.194)  Loss:   3.993 ( 3.783)  Acc@1:   5.000 ( 15.450)  Acc@5:  17.500 ( 38.137)
Test: [2600/3167]  Time: 0.195 (0.194)  Loss:   3.815 ( 3.788)  Acc@1:  12.500 ( 15.271)  Acc@5:  37.500 ( 37.852)
Test: [2650/3167]  Time: 0.198 (0.194)  Loss:   3.868 ( 3.794)  Acc@1:   2.500 ( 15.086)  Acc@5:  37.500 ( 37.695)
Test: [2700/3167]  Time: 0.184 (0.194)  Loss:   3.500 ( 3.792)  Acc@1:  15.000 ( 14.993)  Acc@5:  47.500 ( 37.732)
Test: [2750/3167]  Time: 0.206 (0.194)  Loss:   2.921 ( 3.794)  Acc@1:  27.500 ( 14.866)  Acc@5:  85.000 ( 37.589)
Test: [2800/3167]  Time: 0.186 (0.194)  Loss:   3.988 ( 3.788)  Acc@1:   2.500 ( 14.846)  Acc@5:  32.500 ( 37.903)
Test: [2850/3167]  Time: 0.186 (0.194)  Loss:   3.989 ( 3.793)  Acc@1:  15.000 ( 14.691)  Acc@5:  37.500 ( 37.725)
Test: [2900/3167]  Time: 0.184 (0.194)  Loss:   3.963 ( 3.795)  Acc@1:  10.000 ( 14.696)  Acc@5:  30.000 ( 37.735)
Test: [2950/3167]  Time: 0.188 (0.194)  Loss:   4.033 ( 3.798)  Acc@1:   0.000 ( 14.489)  Acc@5:   7.500 ( 37.375)
Test: [3000/3167]  Time: 0.187 (0.194)  Loss:   4.184 ( 3.804)  Acc@1:   0.000 ( 14.251)  Acc@5:   0.000 ( 36.852)
Test: [3050/3167]  Time: 0.190 (0.193)  Loss:   4.281 ( 3.807)  Acc@1:   2.500 ( 14.086)  Acc@5:  15.000 ( 36.646)
Test: [3100/3167]  Time: 0.193 (0.193)  Loss:   4.173 ( 3.814)  Acc@1:   0.000 ( 13.892)  Acc@5:   7.500 ( 36.308)
Test: [3150/3167]  Time: 0.204 (0.193)  Loss:   4.181 ( 3.819)  Acc@1:   0.000 ( 13.685)  Acc@5:  20.000 ( 35.961)
Test: [3167/3167]  Time: 0.043 (0.193)  Loss:   4.017 ( 3.821)  Acc@1:   0.000 ( 13.629)  Acc@5:  11.111 ( 35.886)
Test: [   0/124]  Time: 0.531 (0.531)  Loss:   4.308 ( 4.308)  Acc@1:   2.500 (  2.500)  Acc@5:  20.000 ( 20.000)
Test: [  50/124]  Time: 0.186 (0.195)  Loss:   3.902 ( 3.860)  Acc@1:  10.000 ( 13.382)  Acc@5:  32.500 ( 34.069)
Test: [ 100/124]  Time: 0.187 (0.190)  Loss:   2.589 ( 3.843)  Acc@1:  67.500 ( 13.911)  Acc@5:  80.000 ( 35.594)
Test: [ 124/124]  Time: 0.180 (0.190)  Loss:   4.083 ( 3.872)  Acc@1:   0.000 ( 12.380)  Acc@5:  30.000 ( 33.840)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_1/checkpoint-2.pth.tar', 13.628649685450197)

Train: 3 [   0/3167 (  0%)]  Loss: 4.41 (4.41)  Time: 1.104s,   36.23/s  (1.104s,   36.23/s)  LR: 3.700e-05  Data: 0.492 (0.492)
Train: 3 [  50/3167 (  2%)]  Loss: 4.31 (4.25)  Time: 0.602s,   66.44/s  (0.613s,   65.28/s)  LR: 3.700e-05  Data: 0.012 (0.020)
Train: 3 [ 100/3167 (  3%)]  Loss: 4.20 (4.22)  Time: 0.604s,   66.19/s  (0.608s,   65.79/s)  LR: 3.700e-05  Data: 0.012 (0.015)
Train: 3 [ 150/3167 (  5%)]  Loss: 4.16 (4.24)  Time: 0.604s,   66.24/s  (0.607s,   65.94/s)  LR: 3.700e-05  Data: 0.011 (0.013)
Train: 3 [ 200/3167 (  6%)]  Loss: 4.14 (4.24)  Time: 0.607s,   65.95/s  (0.606s,   66.02/s)  LR: 3.700e-05  Data: 0.012 (0.013)
Train: 3 [ 250/3167 (  8%)]  Loss: 4.38 (4.25)  Time: 0.604s,   66.19/s  (0.605s,   66.10/s)  LR: 3.700e-05  Data: 0.011 (0.012)
Train: 3 [ 300/3167 (  9%)]  Loss: 4.17 (4.24)  Time: 0.604s,   66.20/s  (0.605s,   66.13/s)  LR: 3.700e-05  Data: 0.011 (0.012)
Train: 3 [ 350/3167 ( 11%)]  Loss: 4.13 (4.24)  Time: 0.602s,   66.45/s  (0.605s,   66.16/s)  LR: 3.700e-05  Data: 0.012 (0.012)
Train: 3 [ 400/3167 ( 13%)]  Loss: 4.30 (4.24)  Time: 0.602s,   66.42/s  (0.604s,   66.18/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [ 450/3167 ( 14%)]  Loss: 4.35 (4.24)  Time: 0.604s,   66.25/s  (0.604s,   66.18/s)  LR: 3.700e-05  Data: 0.007 (0.011)
Train: 3 [ 500/3167 ( 16%)]  Loss: 3.99 (4.24)  Time: 0.596s,   67.06/s  (0.604s,   66.19/s)  LR: 3.700e-05  Data: 0.004 (0.011)
Train: 3 [ 550/3167 ( 17%)]  Loss: 4.27 (4.24)  Time: 0.614s,   65.18/s  (0.604s,   66.20/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [ 600/3167 ( 19%)]  Loss: 3.86 (4.24)  Time: 0.606s,   65.97/s  (0.604s,   66.20/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [ 650/3167 ( 21%)]  Loss: 4.04 (4.24)  Time: 0.602s,   66.48/s  (0.604s,   66.21/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [ 700/3167 ( 22%)]  Loss: 4.10 (4.24)  Time: 0.603s,   66.32/s  (0.604s,   66.22/s)  LR: 3.700e-05  Data: 0.011 (0.011)
Train: 3 [ 750/3167 ( 24%)]  Loss: 4.27 (4.24)  Time: 0.607s,   65.89/s  (0.604s,   66.23/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [ 800/3167 ( 25%)]  Loss: 3.92 (4.24)  Time: 0.599s,   66.72/s  (0.604s,   66.23/s)  LR: 3.700e-05  Data: 0.009 (0.011)
Train: 3 [ 850/3167 ( 27%)]  Loss: 4.49 (4.23)  Time: 0.603s,   66.32/s  (0.604s,   66.25/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [ 900/3167 ( 28%)]  Loss: 4.01 (4.23)  Time: 0.610s,   65.62/s  (0.604s,   66.25/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [ 950/3167 ( 30%)]  Loss: 4.23 (4.23)  Time: 0.605s,   66.14/s  (0.604s,   66.26/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [1000/3167 ( 32%)]  Loss: 4.00 (4.23)  Time: 0.614s,   65.11/s  (0.604s,   66.26/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [1050/3167 ( 33%)]  Loss: 4.31 (4.23)  Time: 0.605s,   66.09/s  (0.604s,   66.26/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [1100/3167 ( 35%)]  Loss: 4.32 (4.23)  Time: 0.599s,   66.76/s  (0.604s,   66.26/s)  LR: 3.700e-05  Data: 0.004 (0.011)
Train: 3 [1150/3167 ( 36%)]  Loss: 4.25 (4.23)  Time: 0.604s,   66.26/s  (0.604s,   66.27/s)  LR: 3.700e-05  Data: 0.011 (0.010)
Train: 3 [1200/3167 ( 38%)]  Loss: 4.19 (4.23)  Time: 0.599s,   66.72/s  (0.604s,   66.28/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [1250/3167 ( 39%)]  Loss: 4.25 (4.23)  Time: 0.602s,   66.50/s  (0.603s,   66.28/s)  LR: 3.700e-05  Data: 0.011 (0.010)
Train: 3 [1300/3167 ( 41%)]  Loss: 4.33 (4.23)  Time: 0.602s,   66.45/s  (0.603s,   66.29/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1350/3167 ( 43%)]  Loss: 4.27 (4.23)  Time: 0.602s,   66.44/s  (0.603s,   66.29/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1400/3167 ( 44%)]  Loss: 4.25 (4.23)  Time: 0.605s,   66.12/s  (0.603s,   66.29/s)  LR: 3.700e-05  Data: 0.009 (0.010)
Train: 3 [1450/3167 ( 46%)]  Loss: 4.39 (4.23)  Time: 0.602s,   66.47/s  (0.603s,   66.29/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1500/3167 ( 47%)]  Loss: 3.84 (4.22)  Time: 0.608s,   65.83/s  (0.603s,   66.29/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1550/3167 ( 49%)]  Loss: 4.28 (4.22)  Time: 0.597s,   67.03/s  (0.603s,   66.30/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [1600/3167 ( 51%)]  Loss: 3.93 (4.22)  Time: 0.604s,   66.20/s  (0.603s,   66.30/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [1650/3167 ( 52%)]  Loss: 4.10 (4.22)  Time: 0.597s,   66.99/s  (0.603s,   66.30/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [1700/3167 ( 54%)]  Loss: 4.28 (4.22)  Time: 0.597s,   67.01/s  (0.603s,   66.31/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [1750/3167 ( 55%)]  Loss: 3.97 (4.22)  Time: 0.603s,   66.38/s  (0.603s,   66.31/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1800/3167 ( 57%)]  Loss: 4.20 (4.22)  Time: 0.602s,   66.49/s  (0.603s,   66.32/s)  LR: 3.700e-05  Data: 0.011 (0.010)
Train: 3 [1850/3167 ( 58%)]  Loss: 3.97 (4.22)  Time: 0.601s,   66.58/s  (0.603s,   66.32/s)  LR: 3.700e-05  Data: 0.004 (0.010)
Train: 3 [1900/3167 ( 60%)]  Loss: 4.45 (4.22)  Time: 0.600s,   66.67/s  (0.603s,   66.32/s)  LR: 3.700e-05  Data: 0.010 (0.010)
Train: 3 [1950/3167 ( 62%)]  Loss: 4.37 (4.22)  Time: 0.601s,   66.54/s  (0.603s,   66.32/s)  LR: 3.700e-05  Data: 0.011 (0.010)
Train: 3 [2000/3167 ( 63%)]  Loss: 4.15 (4.22)  Time: 0.604s,   66.20/s  (0.603s,   66.33/s)  LR: 3.700e-05  Data: 0.011 (0.010)
Train: 3 [2050/3167 ( 65%)]  Loss: 4.25 (4.22)  Time: 0.604s,   66.20/s  (0.603s,   66.33/s)  LR: 3.700e-05  Data: 0.014 (0.010)
Train: 3 [2100/3167 ( 66%)]  Loss: 4.21 (4.21)  Time: 0.594s,   67.34/s  (0.603s,   66.33/s)  LR: 3.700e-05  Data: 0.004 (0.010)
Train: 3 [2150/3167 ( 68%)]  Loss: 4.16 (4.21)  Time: 0.610s,   65.57/s  (0.603s,   66.33/s)  LR: 3.700e-05  Data: 0.011 (0.010)
Train: 3 [2200/3167 ( 69%)]  Loss: 4.37 (4.21)  Time: 0.602s,   66.41/s  (0.603s,   66.33/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [2250/3167 ( 71%)]  Loss: 4.41 (4.21)  Time: 0.599s,   66.81/s  (0.603s,   66.33/s)  LR: 3.700e-05  Data: 0.004 (0.010)
Train: 3 [2300/3167 ( 73%)]  Loss: 3.92 (4.21)  Time: 0.604s,   66.21/s  (0.603s,   66.33/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [2350/3167 ( 74%)]  Loss: 4.45 (4.21)  Time: 0.602s,   66.43/s  (0.603s,   66.34/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [2400/3167 ( 76%)]  Loss: 4.21 (4.21)  Time: 0.603s,   66.38/s  (0.603s,   66.34/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [2450/3167 ( 77%)]  Loss: 4.40 (4.21)  Time: 0.601s,   66.58/s  (0.603s,   66.34/s)  LR: 3.700e-05  Data: 0.010 (0.010)
Train: 3 [2500/3167 ( 79%)]  Loss: 4.27 (4.21)  Time: 0.603s,   66.37/s  (0.603s,   66.35/s)  LR: 3.700e-05  Data: 0.010 (0.010)
Train: 3 [2550/3167 ( 81%)]  Loss: 4.34 (4.21)  Time: 0.602s,   66.46/s  (0.603s,   66.35/s)  LR: 3.700e-05  Data: 0.010 (0.010)
Train: 3 [2600/3167 ( 82%)]  Loss: 3.84 (4.21)  Time: 0.605s,   66.10/s  (0.603s,   66.35/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [2650/3167 ( 84%)]  Loss: 3.93 (4.21)  Time: 0.603s,   66.38/s  (0.603s,   66.35/s)  LR: 3.700e-05  Data: 0.010 (0.010)
Train: 3 [2700/3167 ( 85%)]  Loss: 4.56 (4.21)  Time: 0.601s,   66.58/s  (0.603s,   66.36/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [2750/3167 ( 87%)]  Loss: 4.08 (4.20)  Time: 0.602s,   66.40/s  (0.603s,   66.36/s)  LR: 3.700e-05  Data: 0.009 (0.010)
Train: 3 [2800/3167 ( 88%)]  Loss: 3.83 (4.20)  Time: 0.602s,   66.45/s  (0.603s,   66.37/s)  LR: 3.700e-05  Data: 0.011 (0.010)
Train: 3 [2850/3167 ( 90%)]  Loss: 4.32 (4.20)  Time: 0.597s,   67.00/s  (0.603s,   66.37/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [2900/3167 ( 92%)]  Loss: 3.83 (4.20)  Time: 0.600s,   66.68/s  (0.603s,   66.37/s)  LR: 3.700e-05  Data: 0.009 (0.010)
Train: 3 [2950/3167 ( 93%)]  Loss: 4.08 (4.20)  Time: 0.605s,   66.10/s  (0.603s,   66.38/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [3000/3167 ( 95%)]  Loss: 4.15 (4.20)  Time: 0.601s,   66.57/s  (0.603s,   66.38/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [3050/3167 ( 96%)]  Loss: 3.89 (4.20)  Time: 0.604s,   66.22/s  (0.603s,   66.39/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [3100/3167 ( 98%)]  Loss: 4.17 (4.20)  Time: 0.599s,   66.80/s  (0.602s,   66.39/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [3150/3167 ( 99%)]  Loss: 4.00 (4.20)  Time: 0.602s,   66.49/s  (0.602s,   66.40/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Test: [   0/3167]  Time: 0.524 (0.524)  Loss:   4.067 ( 4.067)  Acc@1:  10.000 ( 10.000)  Acc@5:  32.500 ( 32.500)
Test: [  50/3167]  Time: 0.206 (0.201)  Loss:   3.888 ( 3.902)  Acc@1:  25.000 (  9.608)  Acc@5:  45.000 ( 36.275)
Test: [ 100/3167]  Time: 0.193 (0.197)  Loss:   3.987 ( 3.896)  Acc@1:   2.500 (  6.881)  Acc@5:  25.000 ( 33.119)
Test: [ 150/3167]  Time: 0.189 (0.196)  Loss:   2.534 ( 3.743)  Acc@1:  42.500 ( 12.483)  Acc@5:  80.000 ( 38.510)
Test: [ 200/3167]  Time: 0.188 (0.195)  Loss:   4.260 ( 3.763)  Acc@1:   0.000 ( 12.326)  Acc@5:  10.000 ( 36.281)
Test: [ 250/3167]  Time: 0.194 (0.194)  Loss:   3.039 ( 3.741)  Acc@1:  35.000 ( 13.835)  Acc@5:  50.000 ( 35.269)
Test: [ 300/3167]  Time: 0.191 (0.194)  Loss:   3.765 ( 3.743)  Acc@1:   0.000 ( 13.397)  Acc@5:  37.500 ( 35.814)
Test: [ 350/3167]  Time: 0.196 (0.194)  Loss:   3.039 ( 3.691)  Acc@1:  22.500 ( 13.462)  Acc@5:  72.500 ( 38.255)
Test: [ 400/3167]  Time: 0.191 (0.194)  Loss:   3.140 ( 3.524)  Acc@1:  25.000 ( 18.660)  Acc@5:  65.000 ( 43.130)
Test: [ 450/3167]  Time: 0.204 (0.194)  Loss:   3.929 ( 3.555)  Acc@1:   0.000 ( 17.594)  Acc@5:  17.500 ( 42.151)
Test: [ 500/3167]  Time: 0.191 (0.194)  Loss:   3.793 ( 3.607)  Acc@1:  22.500 ( 16.796)  Acc@5:  30.000 ( 40.519)
Test: [ 550/3167]  Time: 0.191 (0.194)  Loss:   4.004 ( 3.555)  Acc@1:  12.500 ( 18.929)  Acc@5:  20.000 ( 42.232)
Test: [ 600/3167]  Time: 0.198 (0.194)  Loss:   2.900 ( 3.559)  Acc@1:  12.500 ( 18.062)  Acc@5:  65.000 ( 42.155)
Test: [ 650/3167]  Time: 0.201 (0.194)  Loss:   3.822 ( 3.511)  Acc@1:  17.500 ( 19.624)  Acc@5:  45.000 ( 43.817)
Test: [ 700/3167]  Time: 0.191 (0.194)  Loss:   3.331 ( 3.512)  Acc@1:  12.500 ( 19.554)  Acc@5:  60.000 ( 44.843)
Test: [ 750/3167]  Time: 0.191 (0.194)  Loss:   3.589 ( 3.502)  Acc@1:  32.500 ( 19.248)  Acc@5:  45.000 ( 45.283)
Test: [ 800/3167]  Time: 0.197 (0.194)  Loss:   4.389 ( 3.526)  Acc@1:   0.000 ( 18.855)  Acc@5:   7.500 ( 44.351)
Test: [ 850/3167]  Time: 0.192 (0.194)  Loss:   3.730 ( 3.552)  Acc@1:   2.500 ( 18.099)  Acc@5:  25.000 ( 43.434)
Test: [ 900/3167]  Time: 0.187 (0.194)  Loss:   4.234 ( 3.587)  Acc@1:   5.000 ( 17.234)  Acc@5:  17.500 ( 42.087)
Test: [ 950/3167]  Time: 0.191 (0.194)  Loss:   3.080 ( 3.600)  Acc@1:  22.500 ( 16.835)  Acc@5:  62.500 ( 41.703)
Test: [1000/3167]  Time: 0.198 (0.194)  Loss:   3.438 ( 3.606)  Acc@1:  15.000 ( 16.479)  Acc@5:  60.000 ( 41.523)
Test: [1050/3167]  Time: 0.188 (0.194)  Loss:   3.429 ( 3.591)  Acc@1:  15.000 ( 16.575)  Acc@5:  50.000 ( 42.438)
Test: [1100/3167]  Time: 0.200 (0.194)  Loss:   3.878 ( 3.583)  Acc@1:  10.000 ( 16.521)  Acc@5:  37.500 ( 43.095)
Test: [1150/3167]  Time: 0.191 (0.194)  Loss:   3.042 ( 3.575)  Acc@1:  45.000 ( 17.231)  Acc@5:  80.000 ( 43.773)
Test: [1200/3167]  Time: 0.193 (0.194)  Loss:   2.795 ( 3.549)  Acc@1:  52.500 ( 18.087)  Acc@5:  75.000 ( 45.010)
Test: [1250/3167]  Time: 0.186 (0.194)  Loss:   3.206 ( 3.536)  Acc@1:  37.500 ( 18.829)  Acc@5:  65.000 ( 45.683)
Test: [1300/3167]  Time: 0.193 (0.194)  Loss:   3.494 ( 3.548)  Acc@1:  10.000 ( 18.365)  Acc@5:  45.000 ( 45.094)
Test: [1350/3167]  Time: 0.191 (0.194)  Loss:   4.014 ( 3.572)  Acc@1:   7.500 ( 17.955)  Acc@5:  32.500 ( 44.210)
Test: [1400/3167]  Time: 0.192 (0.194)  Loss:   3.630 ( 3.598)  Acc@1:  17.500 ( 17.525)  Acc@5:  50.000 ( 43.376)
Test: [1450/3167]  Time: 0.189 (0.194)  Loss:   3.682 ( 3.597)  Acc@1:  10.000 ( 17.596)  Acc@5:  37.500 ( 43.611)
Test: [1500/3167]  Time: 0.190 (0.194)  Loss:   3.413 ( 3.568)  Acc@1:  17.500 ( 18.589)  Acc@5:  55.000 ( 44.490)
Test: [1550/3167]  Time: 0.193 (0.194)  Loss:   2.514 ( 3.550)  Acc@1:  67.500 ( 19.307)  Acc@5:  85.000 ( 45.280)
Test: [1600/3167]  Time: 0.207 (0.194)  Loss:   2.583 ( 3.539)  Acc@1:  50.000 ( 19.786)  Acc@5:  72.500 ( 45.845)
Test: [1650/3167]  Time: 0.190 (0.194)  Loss:   3.343 ( 3.520)  Acc@1:  25.000 ( 20.401)  Acc@5:  60.000 ( 46.443)
Test: [1700/3167]  Time: 0.195 (0.194)  Loss:   4.198 ( 3.512)  Acc@1:   2.500 ( 20.632)  Acc@5:  20.000 ( 46.871)
Test: [1750/3167]  Time: 0.194 (0.194)  Loss:   3.586 ( 3.521)  Acc@1:  10.000 ( 20.316)  Acc@5:  35.000 ( 46.485)
Test: [1800/3167]  Time: 0.190 (0.194)  Loss:   3.349 ( 3.528)  Acc@1:  12.500 ( 20.042)  Acc@5:  47.500 ( 46.251)
Test: [1850/3167]  Time: 0.190 (0.194)  Loss:   4.175 ( 3.540)  Acc@1:  12.500 ( 19.546)  Acc@5:  20.000 ( 45.471)
Test: [1900/3167]  Time: 0.203 (0.194)  Loss:   3.903 ( 3.550)  Acc@1:   0.000 ( 19.298)  Acc@5:  30.000 ( 45.251)
Test: [1950/3167]  Time: 0.186 (0.194)  Loss:   4.591 ( 3.556)  Acc@1:   0.000 ( 19.176)  Acc@5:  12.500 ( 45.073)
Test: [2000/3167]  Time: 0.187 (0.194)  Loss:   3.895 ( 3.575)  Acc@1:   5.000 ( 18.731)  Acc@5:  35.000 ( 44.290)
Test: [2050/3167]  Time: 0.195 (0.194)  Loss:   4.119 ( 3.584)  Acc@1:   0.000 ( 18.430)  Acc@5:  25.000 ( 43.875)
Test: [2100/3167]  Time: 0.190 (0.194)  Loss:   3.803 ( 3.594)  Acc@1:   7.500 ( 18.246)  Acc@5:  25.000 ( 43.578)
Test: [2150/3167]  Time: 0.192 (0.194)  Loss:   2.027 ( 3.575)  Acc@1:  67.500 ( 18.735)  Acc@5:  77.500 ( 43.962)
Test: [2200/3167]  Time: 0.185 (0.194)  Loss:   3.283 ( 3.564)  Acc@1:   2.500 ( 18.813)  Acc@5:  57.500 ( 44.256)
Test: [2250/3167]  Time: 0.197 (0.194)  Loss:   3.718 ( 3.568)  Acc@1:  20.000 ( 18.535)  Acc@5:  50.000 ( 44.160)
Test: [2300/3167]  Time: 0.198 (0.194)  Loss:   4.157 ( 3.580)  Acc@1:   0.000 ( 18.266)  Acc@5:  12.500 ( 43.672)
Test: [2350/3167]  Time: 0.198 (0.194)  Loss:   3.995 ( 3.589)  Acc@1:   5.000 ( 17.934)  Acc@5:  42.500 ( 43.140)
Test: [2400/3167]  Time: 0.189 (0.194)  Loss:   4.350 ( 3.590)  Acc@1:   0.000 ( 18.023)  Acc@5:   5.000 ( 43.111)
Test: [2450/3167]  Time: 0.190 (0.194)  Loss:   2.780 ( 3.587)  Acc@1:  35.000 ( 18.132)  Acc@5:  85.000 ( 43.336)
Test: [2500/3167]  Time: 0.185 (0.194)  Loss:   4.252 ( 3.589)  Acc@1:  10.000 ( 18.105)  Acc@5:  22.500 ( 43.323)
Test: [2550/3167]  Time: 0.195 (0.194)  Loss:   4.129 ( 3.578)  Acc@1:   2.500 ( 18.603)  Acc@5:  22.500 ( 43.711)
Test: [2600/3167]  Time: 0.194 (0.194)  Loss:   3.305 ( 3.586)  Acc@1:  27.500 ( 18.449)  Acc@5:  55.000 ( 43.384)
Test: [2650/3167]  Time: 0.186 (0.194)  Loss:   4.109 ( 3.594)  Acc@1:   0.000 ( 18.253)  Acc@5:  12.500 ( 43.097)
Test: [2700/3167]  Time: 0.186 (0.194)  Loss:   3.258 ( 3.597)  Acc@1:  27.500 ( 18.121)  Acc@5:  52.500 ( 42.870)
Test: [2750/3167]  Time: 0.188 (0.194)  Loss:   2.845 ( 3.601)  Acc@1:  35.000 ( 18.038)  Acc@5:  72.500 ( 42.748)
Test: [2800/3167]  Time: 0.198 (0.194)  Loss:   4.286 ( 3.600)  Acc@1:   0.000 ( 17.987)  Acc@5:   5.000 ( 42.805)
Test: [2850/3167]  Time: 0.189 (0.194)  Loss:   3.922 ( 3.607)  Acc@1:  12.500 ( 17.794)  Acc@5:  40.000 ( 42.527)
Test: [2900/3167]  Time: 0.188 (0.194)  Loss:   3.797 ( 3.609)  Acc@1:  10.000 ( 17.774)  Acc@5:  45.000 ( 42.562)
Test: [2950/3167]  Time: 0.190 (0.194)  Loss:   3.946 ( 3.615)  Acc@1:   0.000 ( 17.538)  Acc@5:  22.500 ( 42.231)
Test: [3000/3167]  Time: 0.188 (0.194)  Loss:   4.102 ( 3.622)  Acc@1:   0.000 ( 17.256)  Acc@5:  15.000 ( 41.760)
Test: [3050/3167]  Time: 0.188 (0.194)  Loss:   4.307 ( 3.625)  Acc@1:   0.000 ( 17.092)  Acc@5:   5.000 ( 41.592)
Test: [3100/3167]  Time: 0.190 (0.193)  Loss:   4.129 ( 3.634)  Acc@1:   2.500 ( 16.853)  Acc@5:  20.000 ( 41.204)
Test: [3150/3167]  Time: 0.188 (0.193)  Loss:   4.137 ( 3.637)  Acc@1:   0.000 ( 16.695)  Acc@5:  17.500 ( 41.125)
Test: [3167/3167]  Time: 0.043 (0.193)  Loss:   3.862 ( 3.640)  Acc@1:   0.000 ( 16.627)  Acc@5:  33.333 ( 41.030)
Test: [   0/124]  Time: 0.546 (0.546)  Loss:   4.166 ( 4.166)  Acc@1:   2.500 (  2.500)  Acc@5:  15.000 ( 15.000)
Test: [  50/124]  Time: 0.185 (0.194)  Loss:   3.810 ( 3.598)  Acc@1:  17.500 ( 16.716)  Acc@5:  32.500 ( 43.578)
Test: [ 100/124]  Time: 0.188 (0.190)  Loss:   2.414 ( 3.642)  Acc@1:  65.000 ( 17.104)  Acc@5:  87.500 ( 41.559)
Test: [ 124/124]  Time: 0.180 (0.189)  Loss:   4.065 ( 3.696)  Acc@1:   2.500 ( 15.460)  Acc@5:  30.000 ( 39.060)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_1/checkpoint-3.pth.tar', 16.62654216230296)

Train: 4 [   0/3167 (  0%)]  Loss: 3.99 (3.99)  Time: 1.170s,   34.18/s  (1.170s,   34.18/s)  LR: 4.600e-05  Data: 0.548 (0.548)
Train: 4 [  50/3167 (  2%)]  Loss: 3.83 (4.16)  Time: 0.604s,   66.27/s  (0.614s,   65.12/s)  LR: 4.600e-05  Data: 0.011 (0.021)
Train: 4 [ 100/3167 (  3%)]  Loss: 4.44 (4.19)  Time: 0.604s,   66.23/s  (0.608s,   65.74/s)  LR: 4.600e-05  Data: 0.011 (0.016)
Train: 4 [ 150/3167 (  5%)]  Loss: 4.22 (4.18)  Time: 0.601s,   66.52/s  (0.606s,   65.96/s)  LR: 4.600e-05  Data: 0.012 (0.014)
Train: 4 [ 200/3167 (  6%)]  Loss: 4.05 (4.19)  Time: 0.604s,   66.23/s  (0.605s,   66.08/s)  LR: 4.600e-05  Data: 0.012 (0.013)
Train: 4 [ 250/3167 (  8%)]  Loss: 4.27 (4.18)  Time: 0.604s,   66.25/s  (0.605s,   66.15/s)  LR: 4.600e-05  Data: 0.012 (0.012)
Train: 4 [ 300/3167 (  9%)]  Loss: 4.30 (4.17)  Time: 0.601s,   66.52/s  (0.604s,   66.19/s)  LR: 4.600e-05  Data: 0.009 (0.012)
Train: 4 [ 350/3167 ( 11%)]  Loss: 4.02 (4.17)  Time: 0.599s,   66.72/s  (0.604s,   66.23/s)  LR: 4.600e-05  Data: 0.010 (0.011)
Train: 4 [ 400/3167 ( 13%)]  Loss: 4.11 (4.17)  Time: 0.601s,   66.55/s  (0.604s,   66.25/s)  LR: 4.600e-05  Data: 0.004 (0.011)
Train: 4 [ 450/3167 ( 14%)]  Loss: 4.24 (4.17)  Time: 0.604s,   66.24/s  (0.604s,   66.27/s)  LR: 4.600e-05  Data: 0.011 (0.011)
Train: 4 [ 500/3167 ( 16%)]  Loss: 4.32 (4.16)  Time: 0.602s,   66.45/s  (0.603s,   66.29/s)  LR: 4.600e-05  Data: 0.009 (0.011)
Train: 4 [ 550/3167 ( 17%)]  Loss: 4.34 (4.17)  Time: 0.601s,   66.55/s  (0.603s,   66.30/s)  LR: 4.600e-05  Data: 0.011 (0.011)
Train: 4 [ 600/3167 ( 19%)]  Loss: 4.17 (4.16)  Time: 0.604s,   66.24/s  (0.603s,   66.31/s)  LR: 4.600e-05  Data: 0.012 (0.011)
Train: 4 [ 650/3167 ( 21%)]  Loss: 4.06 (4.16)  Time: 0.594s,   67.39/s  (0.603s,   66.32/s)  LR: 4.600e-05  Data: 0.004 (0.011)
Train: 4 [ 700/3167 ( 22%)]  Loss: 4.22 (4.17)  Time: 0.604s,   66.27/s  (0.603s,   66.32/s)  LR: 4.600e-05  Data: 0.011 (0.011)
Train: 4 [ 750/3167 ( 24%)]  Loss: 4.13 (4.16)  Time: 0.601s,   66.51/s  (0.603s,   66.33/s)  LR: 4.600e-05  Data: 0.012 (0.011)
Train: 4 [ 800/3167 ( 25%)]  Loss: 4.05 (4.16)  Time: 0.606s,   65.98/s  (0.603s,   66.34/s)  LR: 4.600e-05  Data: 0.009 (0.011)
Train: 4 [ 850/3167 ( 27%)]  Loss: 4.35 (4.16)  Time: 0.602s,   66.42/s  (0.603s,   66.35/s)  LR: 4.600e-05  Data: 0.009 (0.011)
Train: 4 [ 900/3167 ( 28%)]  Loss: 3.87 (4.16)  Time: 0.593s,   67.40/s  (0.603s,   66.35/s)  LR: 4.600e-05  Data: 0.004 (0.011)
Train: 4 [ 950/3167 ( 30%)]  Loss: 4.34 (4.15)  Time: 0.601s,   66.60/s  (0.603s,   66.36/s)  LR: 4.600e-05  Data: 0.011 (0.010)
Train: 4 [1000/3167 ( 32%)]  Loss: 3.99 (4.15)  Time: 0.601s,   66.57/s  (0.603s,   66.36/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [1050/3167 ( 33%)]  Loss: 4.26 (4.15)  Time: 0.596s,   67.11/s  (0.603s,   66.36/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [1100/3167 ( 35%)]  Loss: 4.23 (4.15)  Time: 0.594s,   67.31/s  (0.603s,   66.37/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [1150/3167 ( 36%)]  Loss: 3.67 (4.15)  Time: 0.604s,   66.24/s  (0.603s,   66.37/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1200/3167 ( 38%)]  Loss: 3.94 (4.15)  Time: 0.604s,   66.27/s  (0.603s,   66.37/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1250/3167 ( 39%)]  Loss: 3.86 (4.14)  Time: 0.601s,   66.54/s  (0.603s,   66.37/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [1300/3167 ( 41%)]  Loss: 4.46 (4.14)  Time: 0.604s,   66.25/s  (0.603s,   66.37/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1350/3167 ( 43%)]  Loss: 4.00 (4.14)  Time: 0.597s,   67.05/s  (0.603s,   66.38/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [1400/3167 ( 44%)]  Loss: 4.29 (4.14)  Time: 0.601s,   66.52/s  (0.603s,   66.38/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1450/3167 ( 46%)]  Loss: 4.22 (4.14)  Time: 0.593s,   67.40/s  (0.603s,   66.38/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [1500/3167 ( 47%)]  Loss: 4.15 (4.14)  Time: 0.608s,   65.84/s  (0.603s,   66.38/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1550/3167 ( 49%)]  Loss: 4.30 (4.14)  Time: 0.605s,   66.15/s  (0.603s,   66.39/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1600/3167 ( 51%)]  Loss: 3.89 (4.14)  Time: 0.596s,   67.09/s  (0.603s,   66.39/s)  LR: 4.600e-05  Data: 0.006 (0.010)
Train: 4 [1650/3167 ( 52%)]  Loss: 4.32 (4.14)  Time: 0.602s,   66.50/s  (0.602s,   66.39/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1700/3167 ( 54%)]  Loss: 4.12 (4.14)  Time: 0.602s,   66.49/s  (0.602s,   66.39/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1750/3167 ( 55%)]  Loss: 4.14 (4.14)  Time: 0.600s,   66.70/s  (0.602s,   66.39/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [1800/3167 ( 57%)]  Loss: 4.15 (4.14)  Time: 0.602s,   66.40/s  (0.602s,   66.40/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1850/3167 ( 58%)]  Loss: 4.20 (4.14)  Time: 0.604s,   66.18/s  (0.602s,   66.40/s)  LR: 4.600e-05  Data: 0.011 (0.010)
Train: 4 [1900/3167 ( 60%)]  Loss: 4.22 (4.14)  Time: 0.601s,   66.52/s  (0.602s,   66.40/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [1950/3167 ( 62%)]  Loss: 3.87 (4.14)  Time: 0.601s,   66.61/s  (0.602s,   66.41/s)  LR: 4.600e-05  Data: 0.010 (0.010)
Train: 4 [2000/3167 ( 63%)]  Loss: 4.17 (4.14)  Time: 0.603s,   66.30/s  (0.602s,   66.41/s)  LR: 4.600e-05  Data: 0.011 (0.010)
Train: 4 [2050/3167 ( 65%)]  Loss: 3.99 (4.14)  Time: 0.602s,   66.49/s  (0.602s,   66.41/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [2100/3167 ( 66%)]  Loss: 3.95 (4.14)  Time: 0.601s,   66.52/s  (0.602s,   66.41/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [2150/3167 ( 68%)]  Loss: 4.02 (4.14)  Time: 0.607s,   65.90/s  (0.602s,   66.41/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [2200/3167 ( 69%)]  Loss: 4.01 (4.14)  Time: 0.603s,   66.33/s  (0.602s,   66.42/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [2250/3167 ( 71%)]  Loss: 4.27 (4.14)  Time: 0.599s,   66.75/s  (0.602s,   66.42/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [2300/3167 ( 73%)]  Loss: 4.18 (4.14)  Time: 0.599s,   66.73/s  (0.602s,   66.42/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [2350/3167 ( 74%)]  Loss: 4.51 (4.14)  Time: 0.600s,   66.69/s  (0.602s,   66.43/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [2400/3167 ( 76%)]  Loss: 4.18 (4.13)  Time: 0.601s,   66.52/s  (0.602s,   66.43/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [2450/3167 ( 77%)]  Loss: 3.58 (4.13)  Time: 0.596s,   67.09/s  (0.602s,   66.43/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [2500/3167 ( 79%)]  Loss: 4.14 (4.13)  Time: 0.604s,   66.21/s  (0.602s,   66.44/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [2550/3167 ( 81%)]  Loss: 4.22 (4.13)  Time: 0.599s,   66.77/s  (0.602s,   66.44/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [2600/3167 ( 82%)]  Loss: 3.90 (4.13)  Time: 0.601s,   66.53/s  (0.602s,   66.45/s)  LR: 4.600e-05  Data: 0.010 (0.010)
Train: 4 [2650/3167 ( 84%)]  Loss: 4.43 (4.13)  Time: 0.598s,   66.88/s  (0.602s,   66.45/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [2700/3167 ( 85%)]  Loss: 4.32 (4.13)  Time: 0.599s,   66.78/s  (0.602s,   66.45/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [2750/3167 ( 87%)]  Loss: 4.39 (4.13)  Time: 0.596s,   67.09/s  (0.602s,   66.46/s)  LR: 4.600e-05  Data: 0.006 (0.010)
Train: 4 [2800/3167 ( 88%)]  Loss: 4.08 (4.13)  Time: 0.597s,   67.00/s  (0.602s,   66.46/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [2850/3167 ( 90%)]  Loss: 4.30 (4.13)  Time: 0.599s,   66.76/s  (0.602s,   66.46/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [2900/3167 ( 92%)]  Loss: 3.94 (4.13)  Time: 0.598s,   66.87/s  (0.602s,   66.47/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [2950/3167 ( 93%)]  Loss: 4.43 (4.13)  Time: 0.602s,   66.47/s  (0.602s,   66.47/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [3000/3167 ( 95%)]  Loss: 4.04 (4.13)  Time: 0.599s,   66.77/s  (0.602s,   66.48/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [3050/3167 ( 96%)]  Loss: 4.29 (4.13)  Time: 0.603s,   66.33/s  (0.602s,   66.48/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [3100/3167 ( 98%)]  Loss: 3.87 (4.13)  Time: 0.599s,   66.74/s  (0.602s,   66.48/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [3150/3167 ( 99%)]  Loss: 4.16 (4.13)  Time: 0.599s,   66.81/s  (0.602s,   66.49/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Test: [   0/3167]  Time: 0.528 (0.528)  Loss:   4.174 ( 4.174)  Acc@1:   5.000 (  5.000)  Acc@5:  20.000 ( 20.000)
Test: [  50/3167]  Time: 0.202 (0.198)  Loss:   3.787 ( 3.888)  Acc@1:  32.500 ( 10.637)  Acc@5:  47.500 ( 34.265)
Test: [ 100/3167]  Time: 0.191 (0.195)  Loss:   3.626 ( 3.654)  Acc@1:   7.500 ( 12.252)  Acc@5:  37.500 ( 43.861)
Test: [ 150/3167]  Time: 0.193 (0.194)  Loss:   2.265 ( 3.476)  Acc@1:  62.500 ( 19.040)  Acc@5:  82.500 ( 49.752)
Test: [ 200/3167]  Time: 0.191 (0.193)  Loss:   4.066 ( 3.539)  Acc@1:   2.500 ( 17.637)  Acc@5:  12.500 ( 43.781)
Test: [ 250/3167]  Time: 0.191 (0.193)  Loss:   2.641 ( 3.519)  Acc@1:  47.500 ( 18.645)  Acc@5:  67.500 ( 42.361)
Test: [ 300/3167]  Time: 0.191 (0.193)  Loss:   3.760 ( 3.525)  Acc@1:   5.000 ( 18.646)  Acc@5:  32.500 ( 42.757)
Test: [ 350/3167]  Time: 0.195 (0.193)  Loss:   2.969 ( 3.507)  Acc@1:  45.000 ( 18.896)  Acc@5:  75.000 ( 44.024)
Test: [ 400/3167]  Time: 0.186 (0.193)  Loss:   3.287 ( 3.402)  Acc@1:  22.500 ( 22.425)  Acc@5:  57.500 ( 47.475)
Test: [ 450/3167]  Time: 0.191 (0.193)  Loss:   3.738 ( 3.441)  Acc@1:   2.500 ( 20.748)  Acc@5:  35.000 ( 45.881)
Test: [ 500/3167]  Time: 0.191 (0.193)  Loss:   3.192 ( 3.462)  Acc@1:  37.500 ( 20.968)  Acc@5:  50.000 ( 45.689)
Test: [ 550/3167]  Time: 0.201 (0.193)  Loss:   3.961 ( 3.418)  Acc@1:   7.500 ( 22.722)  Acc@5:  27.500 ( 47.015)
Test: [ 600/3167]  Time: 0.189 (0.193)  Loss:   3.147 ( 3.441)  Acc@1:  15.000 ( 21.693)  Acc@5:  52.500 ( 46.102)
Test: [ 650/3167]  Time: 0.206 (0.193)  Loss:   3.503 ( 3.413)  Acc@1:  22.500 ( 22.623)  Acc@5:  47.500 ( 46.982)
Test: [ 700/3167]  Time: 0.200 (0.193)  Loss:   3.279 ( 3.409)  Acc@1:  12.500 ( 22.079)  Acc@5:  65.000 ( 47.896)
Test: [ 750/3167]  Time: 0.198 (0.193)  Loss:   3.414 ( 3.398)  Acc@1:  37.500 ( 21.991)  Acc@5:  50.000 ( 48.652)
Test: [ 800/3167]  Time: 0.206 (0.193)  Loss:   4.227 ( 3.414)  Acc@1:   2.500 ( 21.873)  Acc@5:  17.500 ( 47.953)
Test: [ 850/3167]  Time: 0.197 (0.193)  Loss:   4.000 ( 3.441)  Acc@1:   0.000 ( 21.063)  Acc@5:  17.500 ( 46.889)
Test: [ 900/3167]  Time: 0.190 (0.193)  Loss:   3.951 ( 3.478)  Acc@1:   7.500 ( 20.067)  Acc@5:  30.000 ( 45.358)
Test: [ 950/3167]  Time: 0.190 (0.193)  Loss:   3.330 ( 3.489)  Acc@1:  15.000 ( 19.642)  Acc@5:  52.500 ( 45.039)
Test: [1000/3167]  Time: 0.210 (0.193)  Loss:   3.445 ( 3.514)  Acc@1:  17.500 ( 19.021)  Acc@5:  55.000 ( 44.078)
Test: [1050/3167]  Time: 0.198 (0.193)  Loss:   2.894 ( 3.487)  Acc@1:  32.500 ( 19.769)  Acc@5:  77.500 ( 45.376)
Test: [1100/3167]  Time: 0.201 (0.193)  Loss:   3.396 ( 3.487)  Acc@1:  27.500 ( 19.450)  Acc@5:  62.500 ( 45.163)
Test: [1150/3167]  Time: 0.188 (0.193)  Loss:   2.958 ( 3.472)  Acc@1:  50.000 ( 20.374)  Acc@5:  72.500 ( 46.079)
Test: [1200/3167]  Time: 0.192 (0.193)  Loss:   3.230 ( 3.456)  Acc@1:  22.500 ( 20.779)  Acc@5:  60.000 ( 46.855)
Test: [1250/3167]  Time: 0.196 (0.193)  Loss:   2.859 ( 3.441)  Acc@1:  50.000 ( 21.589)  Acc@5:  65.000 ( 47.608)
Test: [1300/3167]  Time: 0.195 (0.193)  Loss:   3.235 ( 3.441)  Acc@1:  27.500 ( 21.337)  Acc@5:  75.000 ( 47.788)
Test: [1350/3167]  Time: 0.192 (0.193)  Loss:   3.822 ( 3.458)  Acc@1:  10.000 ( 21.036)  Acc@5:  47.500 ( 47.241)
Test: [1400/3167]  Time: 0.190 (0.193)  Loss:   3.070 ( 3.478)  Acc@1:  37.500 ( 20.676)  Acc@5:  60.000 ( 46.529)
Test: [1450/3167]  Time: 0.192 (0.193)  Loss:   3.595 ( 3.473)  Acc@1:  12.500 ( 21.034)  Acc@5:  42.500 ( 46.897)
Test: [1500/3167]  Time: 0.192 (0.193)  Loss:   3.381 ( 3.453)  Acc@1:  17.500 ( 21.629)  Acc@5:  52.500 ( 47.567)
Test: [1550/3167]  Time: 0.201 (0.193)  Loss:   2.364 ( 3.438)  Acc@1:  72.500 ( 22.121)  Acc@5:  87.500 ( 48.233)
Test: [1600/3167]  Time: 0.185 (0.193)  Loss:   2.669 ( 3.428)  Acc@1:  52.500 ( 22.383)  Acc@5:  65.000 ( 48.663)
Test: [1650/3167]  Time: 0.184 (0.193)  Loss:   3.209 ( 3.411)  Acc@1:  22.500 ( 22.966)  Acc@5:  55.000 ( 49.179)
Test: [1700/3167]  Time: 0.197 (0.193)  Loss:   4.227 ( 3.410)  Acc@1:   5.000 ( 22.956)  Acc@5:  17.500 ( 49.400)
Test: [1750/3167]  Time: 0.190 (0.193)  Loss:   3.412 ( 3.418)  Acc@1:  22.500 ( 22.671)  Acc@5:  42.500 ( 49.069)
Test: [1800/3167]  Time: 0.191 (0.193)  Loss:   3.376 ( 3.428)  Acc@1:  15.000 ( 22.368)  Acc@5:  47.500 ( 48.701)
Test: [1850/3167]  Time: 0.192 (0.193)  Loss:   3.760 ( 3.438)  Acc@1:  15.000 ( 21.872)  Acc@5:  32.500 ( 48.013)
Test: [1900/3167]  Time: 0.188 (0.193)  Loss:   3.642 ( 3.442)  Acc@1:   7.500 ( 21.668)  Acc@5:  45.000 ( 48.034)
Test: [1950/3167]  Time: 0.187 (0.193)  Loss:   4.622 ( 3.443)  Acc@1:   7.500 ( 21.653)  Acc@5:  15.000 ( 48.055)
Test: [2000/3167]  Time: 0.200 (0.193)  Loss:   4.063 ( 3.465)  Acc@1:   2.500 ( 21.214)  Acc@5:  22.500 ( 47.224)
Test: [2050/3167]  Time: 0.184 (0.193)  Loss:   3.957 ( 3.477)  Acc@1:   0.000 ( 20.820)  Acc@5:  10.000 ( 46.578)
Test: [2100/3167]  Time: 0.184 (0.194)  Loss:   3.191 ( 3.483)  Acc@1:  20.000 ( 20.732)  Acc@5:  65.000 ( 46.470)
Test: [2150/3167]  Time: 0.186 (0.194)  Loss:   1.788 ( 3.458)  Acc@1:  67.500 ( 21.402)  Acc@5:  82.500 ( 47.151)
Test: [2200/3167]  Time: 0.197 (0.194)  Loss:   3.438 ( 3.451)  Acc@1:   7.500 ( 21.308)  Acc@5:  55.000 ( 47.477)
Test: [2250/3167]  Time: 0.199 (0.194)  Loss:   3.584 ( 3.455)  Acc@1:  20.000 ( 21.048)  Acc@5:  52.500 ( 47.300)
Test: [2300/3167]  Time: 0.194 (0.194)  Loss:   3.884 ( 3.465)  Acc@1:   0.000 ( 20.783)  Acc@5:  15.000 ( 46.788)
Test: [2350/3167]  Time: 0.184 (0.194)  Loss:   3.995 ( 3.472)  Acc@1:  15.000 ( 20.432)  Acc@5:  37.500 ( 46.315)
Test: [2400/3167]  Time: 0.190 (0.194)  Loss:   4.126 ( 3.470)  Acc@1:   2.500 ( 20.546)  Acc@5:  25.000 ( 46.414)
Test: [2450/3167]  Time: 0.189 (0.194)  Loss:   2.768 ( 3.468)  Acc@1:  42.500 ( 20.617)  Acc@5:  82.500 ( 46.630)
Test: [2500/3167]  Time: 0.196 (0.194)  Loss:   3.697 ( 3.466)  Acc@1:  25.000 ( 20.678)  Acc@5:  55.000 ( 46.808)
Test: [2550/3167]  Time: 0.187 (0.194)  Loss:   4.144 ( 3.455)  Acc@1:   2.500 ( 21.230)  Acc@5:  10.000 ( 47.235)
Test: [2600/3167]  Time: 0.184 (0.194)  Loss:   3.395 ( 3.464)  Acc@1:  30.000 ( 21.003)  Acc@5:  47.500 ( 46.795)
Test: [2650/3167]  Time: 0.191 (0.194)  Loss:   3.787 ( 3.474)  Acc@1:   5.000 ( 20.833)  Acc@5:  27.500 ( 46.532)
Test: [2700/3167]  Time: 0.192 (0.194)  Loss:   2.974 ( 3.473)  Acc@1:  32.500 ( 20.827)  Acc@5:  65.000 ( 46.520)
Test: [2750/3167]  Time: 0.194 (0.194)  Loss:   2.679 ( 3.478)  Acc@1:  42.500 ( 20.759)  Acc@5:  87.500 ( 46.370)
Test: [2800/3167]  Time: 0.187 (0.194)  Loss:   4.173 ( 3.477)  Acc@1:   0.000 ( 20.801)  Acc@5:  27.500 ( 46.496)
Test: [2850/3167]  Time: 0.186 (0.193)  Loss:   3.961 ( 3.486)  Acc@1:  10.000 ( 20.495)  Acc@5:  32.500 ( 46.087)
Test: [2900/3167]  Time: 0.187 (0.193)  Loss:   3.548 ( 3.489)  Acc@1:  10.000 ( 20.440)  Acc@5:  52.500 ( 46.063)
Test: [2950/3167]  Time: 0.188 (0.193)  Loss:   3.956 ( 3.495)  Acc@1:   0.000 ( 20.187)  Acc@5:  20.000 ( 45.742)
Test: [3000/3167]  Time: 0.188 (0.193)  Loss:   3.876 ( 3.503)  Acc@1:   7.500 ( 19.903)  Acc@5:  37.500 ( 45.362)
Test: [3050/3167]  Time: 0.188 (0.193)  Loss:   4.001 ( 3.500)  Acc@1:   5.000 ( 20.054)  Acc@5:  17.500 ( 45.588)
Test: [3100/3167]  Time: 0.187 (0.193)  Loss:   3.993 ( 3.509)  Acc@1:   2.500 ( 19.790)  Acc@5:  25.000 ( 45.260)
Test: [3150/3167]  Time: 0.189 (0.193)  Loss:   3.593 ( 3.509)  Acc@1:   0.000 ( 19.581)  Acc@5:  45.000 ( 45.321)
Test: [3167/3167]  Time: 0.043 (0.193)  Loss:   3.321 ( 3.510)  Acc@1:  22.222 ( 19.531)  Acc@5:  66.667 ( 45.314)
Test: [   0/124]  Time: 0.535 (0.535)  Loss:   4.252 ( 4.252)  Acc@1:   0.000 (  0.000)  Acc@5:  12.500 ( 12.500)
Test: [  50/124]  Time: 0.185 (0.194)  Loss:   3.500 ( 3.511)  Acc@1:  27.500 ( 19.363)  Acc@5:  55.000 ( 44.804)
Test: [ 100/124]  Time: 0.186 (0.191)  Loss:   2.633 ( 3.527)  Acc@1:  62.500 ( 19.084)  Acc@5:  75.000 ( 43.886)
Test: [ 124/124]  Time: 0.180 (0.190)  Loss:   3.524 ( 3.574)  Acc@1:  12.500 ( 17.720)  Acc@5:  47.500 ( 42.440)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_1/checkpoint-4.pth.tar', 19.530503832294333)

Train: 5 [   0/3167 (  0%)]  Loss: 4.29 (4.29)  Time: 1.135s,   35.26/s  (1.135s,   35.26/s)  LR: 5.500e-05  Data: 0.532 (0.532)
Train: 5 [  50/3167 (  2%)]  Loss: 4.14 (4.20)  Time: 0.603s,   66.38/s  (0.614s,   65.16/s)  LR: 5.500e-05  Data: 0.011 (0.021)
Train: 5 [ 100/3167 (  3%)]  Loss: 4.50 (4.15)  Time: 0.599s,   66.74/s  (0.609s,   65.73/s)  LR: 5.500e-05  Data: 0.007 (0.016)
Train: 5 [ 150/3167 (  5%)]  Loss: 4.18 (4.13)  Time: 0.594s,   67.39/s  (0.607s,   65.95/s)  LR: 5.500e-05  Data: 0.004 (0.014)
Train: 5 [ 200/3167 (  6%)]  Loss: 4.22 (4.12)  Time: 0.601s,   66.59/s  (0.606s,   66.05/s)  LR: 5.500e-05  Data: 0.006 (0.013)
Train: 5 [ 250/3167 (  8%)]  Loss: 4.50 (4.11)  Time: 0.605s,   66.09/s  (0.605s,   66.12/s)  LR: 5.500e-05  Data: 0.012 (0.012)
Train: 5 [ 300/3167 (  9%)]  Loss: 3.93 (4.11)  Time: 0.599s,   66.79/s  (0.605s,   66.16/s)  LR: 5.500e-05  Data: 0.006 (0.012)
Train: 5 [ 350/3167 ( 11%)]  Loss: 3.93 (4.10)  Time: 0.605s,   66.12/s  (0.604s,   66.18/s)  LR: 5.500e-05  Data: 0.012 (0.012)
Train: 5 [ 400/3167 ( 13%)]  Loss: 4.28 (4.10)  Time: 0.602s,   66.45/s  (0.604s,   66.21/s)  LR: 5.500e-05  Data: 0.012 (0.011)
Train: 5 [ 450/3167 ( 14%)]  Loss: 4.26 (4.10)  Time: 0.601s,   66.55/s  (0.604s,   66.22/s)  LR: 5.500e-05  Data: 0.004 (0.011)
Train: 5 [ 500/3167 ( 16%)]  Loss: 3.34 (4.09)  Time: 0.602s,   66.50/s  (0.604s,   66.23/s)  LR: 5.500e-05  Data: 0.009 (0.011)
Train: 5 [ 550/3167 ( 17%)]  Loss: 4.48 (4.09)  Time: 0.601s,   66.58/s  (0.604s,   66.25/s)  LR: 5.500e-05  Data: 0.011 (0.011)
Train: 5 [ 600/3167 ( 19%)]  Loss: 4.51 (4.10)  Time: 0.603s,   66.30/s  (0.604s,   66.24/s)  LR: 5.500e-05  Data: 0.011 (0.011)
Train: 5 [ 650/3167 ( 21%)]  Loss: 4.00 (4.10)  Time: 0.604s,   66.26/s  (0.604s,   66.25/s)  LR: 5.500e-05  Data: 0.012 (0.011)
Train: 5 [ 700/3167 ( 22%)]  Loss: 4.36 (4.10)  Time: 0.604s,   66.22/s  (0.604s,   66.27/s)  LR: 5.500e-05  Data: 0.012 (0.011)
Train: 5 [ 750/3167 ( 24%)]  Loss: 4.23 (4.10)  Time: 0.604s,   66.26/s  (0.604s,   66.27/s)  LR: 5.500e-05  Data: 0.014 (0.011)
Train: 5 [ 800/3167 ( 25%)]  Loss: 3.66 (4.09)  Time: 0.604s,   66.28/s  (0.604s,   66.28/s)  LR: 5.500e-05  Data: 0.012 (0.011)
Train: 5 [ 850/3167 ( 27%)]  Loss: 4.08 (4.09)  Time: 0.602s,   66.50/s  (0.603s,   66.29/s)  LR: 5.500e-05  Data: 0.012 (0.011)
Train: 5 [ 900/3167 ( 28%)]  Loss: 3.92 (4.09)  Time: 0.597s,   67.04/s  (0.603s,   66.29/s)  LR: 5.500e-05  Data: 0.006 (0.011)
Train: 5 [ 950/3167 ( 30%)]  Loss: 4.12 (4.09)  Time: 0.611s,   65.47/s  (0.603s,   66.30/s)  LR: 5.500e-05  Data: 0.012 (0.011)
Train: 5 [1000/3167 ( 32%)]  Loss: 3.99 (4.09)  Time: 0.603s,   66.30/s  (0.603s,   66.31/s)  LR: 5.500e-05  Data: 0.011 (0.011)
Train: 5 [1050/3167 ( 33%)]  Loss: 4.37 (4.09)  Time: 0.599s,   66.83/s  (0.603s,   66.31/s)  LR: 5.500e-05  Data: 0.007 (0.011)
Train: 5 [1100/3167 ( 35%)]  Loss: 4.38 (4.09)  Time: 0.604s,   66.20/s  (0.603s,   66.32/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1150/3167 ( 36%)]  Loss: 4.46 (4.09)  Time: 0.601s,   66.51/s  (0.603s,   66.32/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1200/3167 ( 38%)]  Loss: 4.27 (4.09)  Time: 0.605s,   66.07/s  (0.603s,   66.32/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1250/3167 ( 39%)]  Loss: 3.94 (4.09)  Time: 0.601s,   66.52/s  (0.603s,   66.32/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [1300/3167 ( 41%)]  Loss: 3.91 (4.09)  Time: 0.601s,   66.59/s  (0.603s,   66.32/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [1350/3167 ( 43%)]  Loss: 3.60 (4.09)  Time: 0.604s,   66.26/s  (0.603s,   66.33/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1400/3167 ( 44%)]  Loss: 4.28 (4.09)  Time: 0.604s,   66.24/s  (0.603s,   66.33/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [1450/3167 ( 46%)]  Loss: 4.04 (4.09)  Time: 0.602s,   66.48/s  (0.603s,   66.34/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1500/3167 ( 47%)]  Loss: 4.07 (4.08)  Time: 0.603s,   66.36/s  (0.603s,   66.34/s)  LR: 5.500e-05  Data: 0.009 (0.010)
Train: 5 [1550/3167 ( 49%)]  Loss: 4.25 (4.09)  Time: 0.601s,   66.54/s  (0.603s,   66.34/s)  LR: 5.500e-05  Data: 0.009 (0.010)
Train: 5 [1600/3167 ( 51%)]  Loss: 4.17 (4.09)  Time: 0.600s,   66.72/s  (0.603s,   66.35/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [1650/3167 ( 52%)]  Loss: 3.73 (4.08)  Time: 0.601s,   66.55/s  (0.603s,   66.35/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1700/3167 ( 54%)]  Loss: 3.97 (4.08)  Time: 0.604s,   66.17/s  (0.603s,   66.35/s)  LR: 5.500e-05  Data: 0.009 (0.010)
Train: 5 [1750/3167 ( 55%)]  Loss: 4.17 (4.08)  Time: 0.606s,   66.00/s  (0.603s,   66.35/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1800/3167 ( 57%)]  Loss: 4.22 (4.08)  Time: 0.594s,   67.37/s  (0.603s,   66.36/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [1850/3167 ( 58%)]  Loss: 3.64 (4.08)  Time: 0.598s,   66.86/s  (0.603s,   66.36/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [1900/3167 ( 60%)]  Loss: 4.31 (4.08)  Time: 0.599s,   66.78/s  (0.603s,   66.36/s)  LR: 5.500e-05  Data: 0.009 (0.010)
Train: 5 [1950/3167 ( 62%)]  Loss: 4.42 (4.08)  Time: 0.601s,   66.56/s  (0.603s,   66.36/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [2000/3167 ( 63%)]  Loss: 3.98 (4.08)  Time: 0.604s,   66.21/s  (0.603s,   66.36/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [2050/3167 ( 65%)]  Loss: 4.20 (4.08)  Time: 0.596s,   67.08/s  (0.603s,   66.37/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [2100/3167 ( 66%)]  Loss: 4.37 (4.08)  Time: 0.607s,   65.93/s  (0.603s,   66.37/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [2150/3167 ( 68%)]  Loss: 3.66 (4.08)  Time: 0.601s,   66.54/s  (0.603s,   66.37/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [2200/3167 ( 69%)]  Loss: 4.14 (4.08)  Time: 0.602s,   66.47/s  (0.603s,   66.38/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [2250/3167 ( 71%)]  Loss: 4.21 (4.08)  Time: 0.594s,   67.38/s  (0.603s,   66.38/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [2300/3167 ( 73%)]  Loss: 4.23 (4.08)  Time: 0.604s,   66.24/s  (0.603s,   66.39/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [2350/3167 ( 74%)]  Loss: 3.94 (4.08)  Time: 0.603s,   66.35/s  (0.603s,   66.39/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [2400/3167 ( 76%)]  Loss: 4.38 (4.08)  Time: 0.603s,   66.39/s  (0.602s,   66.39/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [2450/3167 ( 77%)]  Loss: 4.31 (4.08)  Time: 0.600s,   66.66/s  (0.602s,   66.40/s)  LR: 5.500e-05  Data: 0.010 (0.010)
Train: 5 [2500/3167 ( 79%)]  Loss: 3.81 (4.08)  Time: 0.599s,   66.77/s  (0.602s,   66.40/s)  LR: 5.500e-05  Data: 0.009 (0.010)
Train: 5 [2550/3167 ( 81%)]  Loss: 3.64 (4.08)  Time: 0.601s,   66.54/s  (0.602s,   66.40/s)  LR: 5.500e-05  Data: 0.010 (0.010)
Train: 5 [2600/3167 ( 82%)]  Loss: 4.28 (4.08)  Time: 0.605s,   66.09/s  (0.602s,   66.41/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [2650/3167 ( 84%)]  Loss: 3.80 (4.08)  Time: 0.600s,   66.67/s  (0.602s,   66.41/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [2700/3167 ( 85%)]  Loss: 4.04 (4.08)  Time: 0.599s,   66.80/s  (0.602s,   66.41/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [2750/3167 ( 87%)]  Loss: 4.21 (4.08)  Time: 0.599s,   66.75/s  (0.602s,   66.42/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [2800/3167 ( 88%)]  Loss: 4.05 (4.07)  Time: 0.597s,   67.04/s  (0.602s,   66.43/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [2850/3167 ( 90%)]  Loss: 3.92 (4.07)  Time: 0.596s,   67.08/s  (0.602s,   66.43/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [2900/3167 ( 92%)]  Loss: 3.90 (4.07)  Time: 0.600s,   66.66/s  (0.602s,   66.44/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [2950/3167 ( 93%)]  Loss: 4.27 (4.07)  Time: 0.600s,   66.72/s  (0.602s,   66.45/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [3000/3167 ( 95%)]  Loss: 4.01 (4.07)  Time: 0.600s,   66.65/s  (0.602s,   66.45/s)  LR: 5.500e-05  Data: 0.010 (0.010)
Train: 5 [3050/3167 ( 96%)]  Loss: 4.18 (4.07)  Time: 0.602s,   66.46/s  (0.602s,   66.45/s)  LR: 5.500e-05  Data: 0.010 (0.010)
Train: 5 [3100/3167 ( 98%)]  Loss: 4.11 (4.07)  Time: 0.599s,   66.76/s  (0.602s,   66.46/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [3150/3167 ( 99%)]  Loss: 3.67 (4.07)  Time: 0.599s,   66.77/s  (0.602s,   66.46/s)  LR: 5.500e-05  Data: 0.009 (0.010)
Test: [   0/3167]  Time: 0.488 (0.488)  Loss:   3.980 ( 3.980)  Acc@1:   2.500 (  2.500)  Acc@5:  30.000 ( 30.000)
Test: [  50/3167]  Time: 0.206 (0.197)  Loss:   3.537 ( 3.679)  Acc@1:  32.500 ( 13.039)  Acc@5:  47.500 ( 40.392)
Test: [ 100/3167]  Time: 0.198 (0.194)  Loss:   3.669 ( 3.697)  Acc@1:  17.500 ( 13.243)  Acc@5:  45.000 ( 38.738)
Test: [ 150/3167]  Time: 0.188 (0.194)  Loss:   2.166 ( 3.512)  Acc@1:  62.500 ( 19.586)  Acc@5:  92.500 ( 46.242)
Test: [ 200/3167]  Time: 0.193 (0.193)  Loss:   3.620 ( 3.529)  Acc@1:   7.500 ( 19.415)  Acc@5:  42.500 ( 45.833)
Test: [ 250/3167]  Time: 0.191 (0.193)  Loss:   2.834 ( 3.479)  Acc@1:  30.000 ( 20.478)  Acc@5:  57.500 ( 46.414)
Test: [ 300/3167]  Time: 0.189 (0.192)  Loss:   3.198 ( 3.455)  Acc@1:  20.000 ( 21.537)  Acc@5:  62.500 ( 47.741)
Test: [ 350/3167]  Time: 0.191 (0.192)  Loss:   2.496 ( 3.372)  Acc@1:  62.500 ( 23.818)  Acc@5:  75.000 ( 50.627)
Test: [ 400/3167]  Time: 0.196 (0.192)  Loss:   2.668 ( 3.204)  Acc@1:  35.000 ( 28.423)  Acc@5:  72.500 ( 54.888)
Test: [ 450/3167]  Time: 0.192 (0.192)  Loss:   3.349 ( 3.215)  Acc@1:   2.500 ( 26.984)  Acc@5:  42.500 ( 54.163)
Test: [ 500/3167]  Time: 0.189 (0.192)  Loss:   2.737 ( 3.229)  Acc@1:  52.500 ( 27.021)  Acc@5:  65.000 ( 53.493)
Test: [ 550/3167]  Time: 0.195 (0.192)  Loss:   3.734 ( 3.165)  Acc@1:   2.500 ( 29.229)  Acc@5:  27.500 ( 54.959)
Test: [ 600/3167]  Time: 0.200 (0.192)  Loss:   2.620 ( 3.183)  Acc@1:  27.500 ( 27.958)  Acc@5:  75.000 ( 54.251)
Test: [ 650/3167]  Time: 0.202 (0.192)  Loss:   3.513 ( 3.170)  Acc@1:  30.000 ( 28.379)  Acc@5:  52.500 ( 54.796)
Test: [ 700/3167]  Time: 0.212 (0.193)  Loss:   3.014 ( 3.178)  Acc@1:  35.000 ( 28.545)  Acc@5:  75.000 ( 55.485)
Test: [ 750/3167]  Time: 0.186 (0.193)  Loss:   3.295 ( 3.175)  Acc@1:  42.500 ( 27.999)  Acc@5:  50.000 ( 55.979)
Test: [ 800/3167]  Time: 0.191 (0.193)  Loss:   4.391 ( 3.209)  Acc@1:   0.000 ( 27.406)  Acc@5:  15.000 ( 54.644)
Test: [ 850/3167]  Time: 0.186 (0.193)  Loss:   3.622 ( 3.258)  Acc@1:   2.500 ( 25.922)  Acc@5:  40.000 ( 52.717)
Test: [ 900/3167]  Time: 0.191 (0.193)  Loss:   3.707 ( 3.290)  Acc@1:   5.000 ( 24.686)  Acc@5:  40.000 ( 51.443)
Test: [ 950/3167]  Time: 0.197 (0.193)  Loss:   3.018 ( 3.320)  Acc@1:  25.000 ( 23.822)  Acc@5:  62.500 ( 50.200)
Test: [1000/3167]  Time: 0.189 (0.193)  Loss:   2.945 ( 3.327)  Acc@1:  37.500 ( 23.409)  Acc@5:  75.000 ( 50.072)
Test: [1050/3167]  Time: 0.187 (0.193)  Loss:   3.515 ( 3.317)  Acc@1:  20.000 ( 23.580)  Acc@5:  37.500 ( 50.661)
Test: [1100/3167]  Time: 0.190 (0.193)  Loss:   3.628 ( 3.318)  Acc@1:  22.500 ( 23.342)  Acc@5:  42.500 ( 50.917)
Test: [1150/3167]  Time: 0.201 (0.193)  Loss:   2.361 ( 3.302)  Acc@1:  65.000 ( 24.162)  Acc@5:  82.500 ( 51.579)
Test: [1200/3167]  Time: 0.184 (0.193)  Loss:   2.991 ( 3.283)  Acc@1:  40.000 ( 24.413)  Acc@5:  70.000 ( 52.456)
Test: [1250/3167]  Time: 0.209 (0.193)  Loss:   2.745 ( 3.269)  Acc@1:  50.000 ( 25.142)  Acc@5:  65.000 ( 53.034)
Test: [1300/3167]  Time: 0.189 (0.193)  Loss:   3.287 ( 3.287)  Acc@1:  20.000 ( 24.506)  Acc@5:  62.500 ( 52.156)
Test: [1350/3167]  Time: 0.190 (0.193)  Loss:   3.269 ( 3.314)  Acc@1:  20.000 ( 23.967)  Acc@5:  67.500 ( 51.203)
Test: [1400/3167]  Time: 0.196 (0.193)  Loss:   2.685 ( 3.332)  Acc@1:  47.500 ( 23.633)  Acc@5:  75.000 ( 50.650)
Test: [1450/3167]  Time: 0.191 (0.193)  Loss:   3.177 ( 3.315)  Acc@1:  15.000 ( 24.319)  Acc@5:  67.500 ( 51.363)
Test: [1500/3167]  Time: 0.197 (0.193)  Loss:   3.686 ( 3.297)  Acc@1:   7.500 ( 24.880)  Acc@5:  50.000 ( 51.962)
Test: [1550/3167]  Time: 0.192 (0.193)  Loss:   2.076 ( 3.288)  Acc@1:  82.500 ( 25.260)  Acc@5:  90.000 ( 52.369)
Test: [1600/3167]  Time: 0.184 (0.193)  Loss:   2.708 ( 3.275)  Acc@1:  42.500 ( 25.659)  Acc@5:  57.500 ( 52.870)
Test: [1650/3167]  Time: 0.198 (0.193)  Loss:   3.088 ( 3.262)  Acc@1:  15.000 ( 25.981)  Acc@5:  62.500 ( 53.292)
Test: [1700/3167]  Time: 0.185 (0.193)  Loss:   3.946 ( 3.257)  Acc@1:   2.500 ( 26.135)  Acc@5:  17.500 ( 53.527)
Test: [1750/3167]  Time: 0.203 (0.193)  Loss:   3.643 ( 3.270)  Acc@1:  20.000 ( 25.827)  Acc@5:  35.000 ( 53.024)
Test: [1800/3167]  Time: 0.206 (0.193)  Loss:   3.025 ( 3.271)  Acc@1:  22.500 ( 25.850)  Acc@5:  67.500 ( 53.126)
Test: [1850/3167]  Time: 0.185 (0.193)  Loss:   3.924 ( 3.289)  Acc@1:  15.000 ( 25.374)  Acc@5:  32.500 ( 52.415)
Test: [1900/3167]  Time: 0.193 (0.193)  Loss:   3.863 ( 3.301)  Acc@1:   0.000 ( 24.996)  Acc@5:  32.500 ( 52.088)
Test: [1950/3167]  Time: 0.190 (0.193)  Loss:   4.407 ( 3.317)  Acc@1:   0.000 ( 24.585)  Acc@5:  10.000 ( 51.545)
Test: [2000/3167]  Time: 0.187 (0.193)  Loss:   3.794 ( 3.337)  Acc@1:  10.000 ( 24.065)  Acc@5:  37.500 ( 50.756)
Test: [2050/3167]  Time: 0.200 (0.193)  Loss:   4.311 ( 3.352)  Acc@1:   0.000 ( 23.667)  Acc@5:   5.000 ( 50.028)
Test: [2100/3167]  Time: 0.199 (0.193)  Loss:   3.789 ( 3.359)  Acc@1:  10.000 ( 23.635)  Acc@5:  30.000 ( 49.905)
Test: [2150/3167]  Time: 0.198 (0.193)  Loss:   1.521 ( 3.340)  Acc@1:  77.500 ( 24.078)  Acc@5:  82.500 ( 50.149)
Test: [2200/3167]  Time: 0.188 (0.193)  Loss:   3.058 ( 3.330)  Acc@1:  15.000 ( 24.096)  Acc@5:  70.000 ( 50.476)
Test: [2250/3167]  Time: 0.191 (0.193)  Loss:   3.181 ( 3.337)  Acc@1:  45.000 ( 23.939)  Acc@5:  70.000 ( 50.328)
Test: [2300/3167]  Time: 0.194 (0.193)  Loss:   4.216 ( 3.346)  Acc@1:   0.000 ( 23.802)  Acc@5:  17.500 ( 50.071)
Test: [2350/3167]  Time: 0.189 (0.193)  Loss:   3.428 ( 3.354)  Acc@1:  32.500 ( 23.499)  Acc@5:  60.000 ( 49.769)
Test: [2400/3167]  Time: 0.185 (0.193)  Loss:   3.957 ( 3.344)  Acc@1:   0.000 ( 23.879)  Acc@5:  25.000 ( 49.995)
Test: [2450/3167]  Time: 0.199 (0.193)  Loss:   2.801 ( 3.342)  Acc@1:  37.500 ( 23.828)  Acc@5:  75.000 ( 50.132)
Test: [2500/3167]  Time: 0.186 (0.193)  Loss:   3.922 ( 3.346)  Acc@1:   7.500 ( 23.722)  Acc@5:  45.000 ( 50.137)
Test: [2550/3167]  Time: 0.188 (0.193)  Loss:   3.669 ( 3.338)  Acc@1:   5.000 ( 24.057)  Acc@5:  27.500 ( 50.472)
Test: [2600/3167]  Time: 0.193 (0.193)  Loss:   3.058 ( 3.342)  Acc@1:  32.500 ( 23.861)  Acc@5:  55.000 ( 50.223)
Test: [2650/3167]  Time: 0.186 (0.193)  Loss:   3.028 ( 3.344)  Acc@1:  32.500 ( 23.757)  Acc@5:  72.500 ( 50.207)
Test: [2700/3167]  Time: 0.188 (0.193)  Loss:   2.973 ( 3.340)  Acc@1:  32.500 ( 23.990)  Acc@5:  62.500 ( 50.466)
Test: [2750/3167]  Time: 0.191 (0.193)  Loss:   2.380 ( 3.344)  Acc@1:  50.000 ( 23.867)  Acc@5:  85.000 ( 50.219)
Test: [2800/3167]  Time: 0.187 (0.193)  Loss:   3.701 ( 3.339)  Acc@1:   0.000 ( 23.979)  Acc@5:  40.000 ( 50.414)
Test: [2850/3167]  Time: 0.189 (0.193)  Loss:   3.703 ( 3.349)  Acc@1:  12.500 ( 23.662)  Acc@5:  40.000 ( 50.037)
Test: [2900/3167]  Time: 0.186 (0.193)  Loss:   3.411 ( 3.351)  Acc@1:  27.500 ( 23.651)  Acc@5:  60.000 ( 50.081)
Test: [2950/3167]  Time: 0.186 (0.193)  Loss:   3.688 ( 3.353)  Acc@1:   0.000 ( 23.487)  Acc@5:  37.500 ( 50.065)
Test: [3000/3167]  Time: 0.201 (0.193)  Loss:   3.870 ( 3.361)  Acc@1:   7.500 ( 23.150)  Acc@5:  30.000 ( 49.678)
Test: [3050/3167]  Time: 0.187 (0.192)  Loss:   4.160 ( 3.367)  Acc@1:   0.000 ( 22.942)  Acc@5:  22.500 ( 49.399)
Test: [3100/3167]  Time: 0.185 (0.192)  Loss:   3.727 ( 3.376)  Acc@1:   7.500 ( 22.628)  Acc@5:  37.500 ( 49.054)
Test: [3150/3167]  Time: 0.191 (0.192)  Loss:   3.752 ( 3.385)  Acc@1:   0.000 ( 22.319)  Acc@5:  42.500 ( 48.805)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   3.414 ( 3.387)  Acc@1:  11.111 ( 22.268)  Acc@5:  55.556 ( 48.774)
Test: [   0/124]  Time: 0.532 (0.532)  Loss:   4.184 ( 4.184)  Acc@1:   2.500 (  2.500)  Acc@5:  12.500 ( 12.500)
Test: [  50/124]  Time: 0.185 (0.194)  Loss:   3.441 ( 3.372)  Acc@1:  20.000 ( 21.814)  Acc@5:  57.500 ( 49.461)
Test: [ 100/124]  Time: 0.186 (0.190)  Loss:   2.582 ( 3.417)  Acc@1:  60.000 ( 21.559)  Acc@5:  77.500 ( 47.475)
Test: [ 124/124]  Time: 0.180 (0.189)  Loss:   3.646 ( 3.454)  Acc@1:  12.500 ( 20.600)  Acc@5:  47.500 ( 46.440)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_1/checkpoint-5.pth.tar', 22.26791592012541)

Train: 6 [   0/3167 (  0%)]  Loss: 4.11 (4.11)  Time: 1.076s,   37.16/s  (1.076s,   37.16/s)  LR: 6.400e-05  Data: 0.457 (0.457)
Train: 6 [  50/3167 (  2%)]  Loss: 4.26 (4.05)  Time: 0.593s,   67.41/s  (0.612s,   65.36/s)  LR: 6.400e-05  Data: 0.004 (0.018)
Train: 6 [ 100/3167 (  3%)]  Loss: 4.03 (4.05)  Time: 0.601s,   66.59/s  (0.607s,   65.86/s)  LR: 6.400e-05  Data: 0.011 (0.014)
Train: 6 [ 150/3167 (  5%)]  Loss: 3.72 (4.04)  Time: 0.605s,   66.17/s  (0.606s,   66.01/s)  LR: 6.400e-05  Data: 0.012 (0.013)
Train: 6 [ 200/3167 (  6%)]  Loss: 4.05 (4.03)  Time: 0.604s,   66.19/s  (0.605s,   66.07/s)  LR: 6.400e-05  Data: 0.012 (0.012)
Train: 6 [ 250/3167 (  8%)]  Loss: 3.79 (4.02)  Time: 0.601s,   66.59/s  (0.605s,   66.13/s)  LR: 6.400e-05  Data: 0.011 (0.012)
Train: 6 [ 300/3167 (  9%)]  Loss: 3.46 (4.02)  Time: 0.604s,   66.25/s  (0.604s,   66.17/s)  LR: 6.400e-05  Data: 0.012 (0.011)
Train: 6 [ 350/3167 ( 11%)]  Loss: 4.05 (4.04)  Time: 0.604s,   66.24/s  (0.604s,   66.19/s)  LR: 6.400e-05  Data: 0.012 (0.011)
Train: 6 [ 400/3167 ( 13%)]  Loss: 3.91 (4.03)  Time: 0.603s,   66.33/s  (0.604s,   66.19/s)  LR: 6.400e-05  Data: 0.011 (0.011)
Train: 6 [ 450/3167 ( 14%)]  Loss: 3.99 (4.03)  Time: 0.604s,   66.19/s  (0.604s,   66.20/s)  LR: 6.400e-05  Data: 0.012 (0.011)
Train: 6 [ 500/3167 ( 16%)]  Loss: 3.98 (4.02)  Time: 0.605s,   66.15/s  (0.604s,   66.20/s)  LR: 6.400e-05  Data: 0.012 (0.011)
Train: 6 [ 550/3167 ( 17%)]  Loss: 4.13 (4.03)  Time: 0.601s,   66.56/s  (0.604s,   66.22/s)  LR: 6.400e-05  Data: 0.011 (0.011)
Train: 6 [ 600/3167 ( 19%)]  Loss: 4.27 (4.03)  Time: 0.601s,   66.57/s  (0.604s,   66.23/s)  LR: 6.400e-05  Data: 0.011 (0.011)
Train: 6 [ 650/3167 ( 21%)]  Loss: 3.80 (4.03)  Time: 0.617s,   64.80/s  (0.604s,   66.23/s)  LR: 6.400e-05  Data: 0.012 (0.011)
Train: 6 [ 700/3167 ( 22%)]  Loss: 4.40 (4.03)  Time: 0.616s,   64.93/s  (0.604s,   66.24/s)  LR: 6.400e-05  Data: 0.009 (0.011)
Train: 6 [ 750/3167 ( 24%)]  Loss: 4.22 (4.03)  Time: 0.601s,   66.55/s  (0.604s,   66.25/s)  LR: 6.400e-05  Data: 0.012 (0.011)
Train: 6 [ 800/3167 ( 25%)]  Loss: 4.25 (4.03)  Time: 0.601s,   66.52/s  (0.604s,   66.25/s)  LR: 6.400e-05  Data: 0.009 (0.011)
Train: 6 [ 850/3167 ( 27%)]  Loss: 4.38 (4.02)  Time: 0.601s,   66.54/s  (0.604s,   66.27/s)  LR: 6.400e-05  Data: 0.012 (0.011)
Train: 6 [ 900/3167 ( 28%)]  Loss: 3.68 (4.02)  Time: 0.598s,   66.95/s  (0.604s,   66.27/s)  LR: 6.400e-05  Data: 0.004 (0.011)
Train: 6 [ 950/3167 ( 30%)]  Loss: 3.75 (4.02)  Time: 0.601s,   66.51/s  (0.604s,   66.28/s)  LR: 6.400e-05  Data: 0.012 (0.011)
Train: 6 [1000/3167 ( 32%)]  Loss: 3.93 (4.02)  Time: 0.601s,   66.58/s  (0.603s,   66.28/s)  LR: 6.400e-05  Data: 0.011 (0.011)
Train: 6 [1050/3167 ( 33%)]  Loss: 3.89 (4.03)  Time: 0.601s,   66.51/s  (0.603s,   66.28/s)  LR: 6.400e-05  Data: 0.012 (0.011)
Train: 6 [1100/3167 ( 35%)]  Loss: 3.89 (4.03)  Time: 0.607s,   65.85/s  (0.603s,   66.29/s)  LR: 6.400e-05  Data: 0.011 (0.011)
Train: 6 [1150/3167 ( 36%)]  Loss: 3.85 (4.02)  Time: 0.609s,   65.69/s  (0.603s,   66.30/s)  LR: 6.400e-05  Data: 0.012 (0.011)
Train: 6 [1200/3167 ( 38%)]  Loss: 4.00 (4.02)  Time: 0.599s,   66.78/s  (0.603s,   66.31/s)  LR: 6.400e-05  Data: 0.009 (0.010)
Train: 6 [1250/3167 ( 39%)]  Loss: 4.22 (4.03)  Time: 0.605s,   66.07/s  (0.603s,   66.31/s)  LR: 6.400e-05  Data: 0.011 (0.010)
Train: 6 [1300/3167 ( 41%)]  Loss: 4.65 (4.02)  Time: 0.601s,   66.56/s  (0.603s,   66.32/s)  LR: 6.400e-05  Data: 0.011 (0.010)
Train: 6 [1350/3167 ( 43%)]  Loss: 4.23 (4.02)  Time: 0.593s,   67.40/s  (0.603s,   66.32/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [1400/3167 ( 44%)]  Loss: 4.16 (4.02)  Time: 0.601s,   66.53/s  (0.603s,   66.33/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1450/3167 ( 46%)]  Loss: 3.59 (4.02)  Time: 0.599s,   66.78/s  (0.603s,   66.33/s)  LR: 6.400e-05  Data: 0.007 (0.010)
Train: 6 [1500/3167 ( 47%)]  Loss: 4.36 (4.02)  Time: 0.607s,   65.88/s  (0.603s,   66.34/s)  LR: 6.400e-05  Data: 0.010 (0.010)
Train: 6 [1550/3167 ( 49%)]  Loss: 4.00 (4.02)  Time: 0.593s,   67.41/s  (0.603s,   66.35/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [1600/3167 ( 51%)]  Loss: 3.68 (4.02)  Time: 0.599s,   66.75/s  (0.603s,   66.35/s)  LR: 6.400e-05  Data: 0.007 (0.010)
Train: 6 [1650/3167 ( 52%)]  Loss: 4.06 (4.02)  Time: 0.601s,   66.52/s  (0.603s,   66.35/s)  LR: 6.400e-05  Data: 0.009 (0.010)
Train: 6 [1700/3167 ( 54%)]  Loss: 4.32 (4.02)  Time: 0.604s,   66.26/s  (0.603s,   66.35/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1750/3167 ( 55%)]  Loss: 3.58 (4.02)  Time: 0.608s,   65.84/s  (0.603s,   66.36/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1800/3167 ( 57%)]  Loss: 3.82 (4.02)  Time: 0.608s,   65.74/s  (0.603s,   66.36/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1850/3167 ( 58%)]  Loss: 3.98 (4.02)  Time: 0.601s,   66.56/s  (0.603s,   66.36/s)  LR: 6.400e-05  Data: 0.011 (0.010)
Train: 6 [1900/3167 ( 60%)]  Loss: 3.94 (4.02)  Time: 0.607s,   65.87/s  (0.603s,   66.36/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1950/3167 ( 62%)]  Loss: 4.10 (4.02)  Time: 0.599s,   66.80/s  (0.603s,   66.37/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [2000/3167 ( 63%)]  Loss: 4.26 (4.02)  Time: 0.602s,   66.50/s  (0.603s,   66.37/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [2050/3167 ( 65%)]  Loss: 3.44 (4.02)  Time: 0.602s,   66.48/s  (0.603s,   66.38/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [2100/3167 ( 66%)]  Loss: 3.68 (4.02)  Time: 0.599s,   66.76/s  (0.603s,   66.38/s)  LR: 6.400e-05  Data: 0.009 (0.010)
Train: 6 [2150/3167 ( 68%)]  Loss: 4.02 (4.02)  Time: 0.604s,   66.26/s  (0.603s,   66.38/s)  LR: 6.400e-05  Data: 0.007 (0.010)
Train: 6 [2200/3167 ( 69%)]  Loss: 3.79 (4.02)  Time: 0.600s,   66.72/s  (0.603s,   66.38/s)  LR: 6.400e-05  Data: 0.007 (0.010)
Train: 6 [2250/3167 ( 71%)]  Loss: 3.88 (4.02)  Time: 0.601s,   66.52/s  (0.603s,   66.39/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [2300/3167 ( 73%)]  Loss: 3.66 (4.02)  Time: 0.601s,   66.53/s  (0.603s,   66.39/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [2350/3167 ( 74%)]  Loss: 3.62 (4.01)  Time: 0.596s,   67.09/s  (0.602s,   66.39/s)  LR: 6.400e-05  Data: 0.007 (0.010)
Train: 6 [2400/3167 ( 76%)]  Loss: 4.10 (4.01)  Time: 0.599s,   66.75/s  (0.602s,   66.40/s)  LR: 6.400e-05  Data: 0.010 (0.010)
Train: 6 [2450/3167 ( 77%)]  Loss: 4.08 (4.01)  Time: 0.600s,   66.72/s  (0.602s,   66.40/s)  LR: 6.400e-05  Data: 0.009 (0.010)
Train: 6 [2500/3167 ( 79%)]  Loss: 3.93 (4.01)  Time: 0.604s,   66.18/s  (0.602s,   66.40/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [2550/3167 ( 81%)]  Loss: 4.24 (4.01)  Time: 0.599s,   66.73/s  (0.602s,   66.41/s)  LR: 6.400e-05  Data: 0.010 (0.010)
Train: 6 [2600/3167 ( 82%)]  Loss: 4.25 (4.01)  Time: 0.594s,   67.39/s  (0.602s,   66.41/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [2650/3167 ( 84%)]  Loss: 3.72 (4.01)  Time: 0.601s,   66.55/s  (0.602s,   66.41/s)  LR: 6.400e-05  Data: 0.007 (0.010)
Train: 6 [2700/3167 ( 85%)]  Loss: 3.55 (4.01)  Time: 0.596s,   67.08/s  (0.602s,   66.42/s)  LR: 6.400e-05  Data: 0.007 (0.010)
Train: 6 [2750/3167 ( 87%)]  Loss: 3.67 (4.01)  Time: 0.597s,   66.99/s  (0.602s,   66.42/s)  LR: 6.400e-05  Data: 0.007 (0.010)
Train: 6 [2800/3167 ( 88%)]  Loss: 4.28 (4.01)  Time: 0.597s,   67.05/s  (0.602s,   66.43/s)  LR: 6.400e-05  Data: 0.007 (0.010)
Train: 6 [2850/3167 ( 90%)]  Loss: 4.08 (4.01)  Time: 0.601s,   66.54/s  (0.602s,   66.43/s)  LR: 6.400e-05  Data: 0.010 (0.010)
Train: 6 [2900/3167 ( 92%)]  Loss: 3.92 (4.01)  Time: 0.597s,   66.97/s  (0.602s,   66.44/s)  LR: 6.400e-05  Data: 0.008 (0.010)
Train: 6 [2950/3167 ( 93%)]  Loss: 3.61 (4.01)  Time: 0.600s,   66.68/s  (0.602s,   66.44/s)  LR: 6.400e-05  Data: 0.007 (0.010)
Train: 6 [3000/3167 ( 95%)]  Loss: 4.10 (4.01)  Time: 0.599s,   66.77/s  (0.602s,   66.45/s)  LR: 6.400e-05  Data: 0.009 (0.010)
Train: 6 [3050/3167 ( 96%)]  Loss: 4.01 (4.01)  Time: 0.597s,   67.04/s  (0.602s,   66.45/s)  LR: 6.400e-05  Data: 0.007 (0.010)
Train: 6 [3100/3167 ( 98%)]  Loss: 4.26 (4.00)  Time: 0.594s,   67.34/s  (0.602s,   66.46/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [3150/3167 ( 99%)]  Loss: 4.10 (4.01)  Time: 0.599s,   66.73/s  (0.602s,   66.46/s)  LR: 6.400e-05  Data: 0.010 (0.010)
Test: [   0/3167]  Time: 0.494 (0.494)  Loss:   3.372 ( 3.372)  Acc@1:  20.000 ( 20.000)  Acc@5:  50.000 ( 50.000)
Test: [  50/3167]  Time: 0.191 (0.198)  Loss:   3.317 ( 3.275)  Acc@1:  35.000 ( 22.451)  Acc@5:  42.500 ( 55.049)
Test: [ 100/3167]  Time: 0.191 (0.195)  Loss:   3.325 ( 3.314)  Acc@1:  27.500 ( 19.653)  Acc@5:  62.500 ( 53.243)
Test: [ 150/3167]  Time: 0.190 (0.194)  Loss:   1.964 ( 3.174)  Acc@1:  55.000 ( 24.272)  Acc@5:  92.500 ( 58.146)
Test: [ 200/3167]  Time: 0.191 (0.193)  Loss:   3.431 ( 3.224)  Acc@1:  15.000 ( 22.736)  Acc@5:  52.500 ( 55.137)
Test: [ 250/3167]  Time: 0.193 (0.193)  Loss:   3.052 ( 3.230)  Acc@1:  27.500 ( 22.859)  Acc@5:  50.000 ( 54.333)
Test: [ 300/3167]  Time: 0.191 (0.193)  Loss:   3.013 ( 3.263)  Acc@1:  20.000 ( 22.525)  Acc@5:  65.000 ( 53.505)
Test: [ 350/3167]  Time: 0.191 (0.193)  Loss:   2.765 ( 3.219)  Acc@1:  45.000 ( 23.412)  Acc@5:  70.000 ( 55.071)
Test: [ 400/3167]  Time: 0.192 (0.193)  Loss:   2.554 ( 3.084)  Acc@1:  40.000 ( 27.606)  Acc@5:  80.000 ( 58.554)
Test: [ 450/3167]  Time: 0.190 (0.192)  Loss:   3.472 ( 3.111)  Acc@1:   0.000 ( 26.463)  Acc@5:  42.500 ( 57.567)
Test: [ 500/3167]  Time: 0.191 (0.192)  Loss:   2.617 ( 3.113)  Acc@1:  50.000 ( 26.911)  Acc@5:  67.500 ( 57.360)
Test: [ 550/3167]  Time: 0.190 (0.192)  Loss:   3.794 ( 3.055)  Acc@1:   2.500 ( 29.038)  Acc@5:  32.500 ( 58.512)
Test: [ 600/3167]  Time: 0.192 (0.192)  Loss:   2.709 ( 3.090)  Acc@1:  37.500 ( 28.062)  Acc@5:  60.000 ( 57.292)
Test: [ 650/3167]  Time: 0.191 (0.192)  Loss:   2.869 ( 3.073)  Acc@1:  32.500 ( 28.702)  Acc@5:  70.000 ( 57.680)
Test: [ 700/3167]  Time: 0.207 (0.192)  Loss:   2.665 ( 3.054)  Acc@1:  52.500 ( 29.511)  Acc@5:  85.000 ( 58.994)
Test: [ 750/3167]  Time: 0.189 (0.192)  Loss:   3.258 ( 3.030)  Acc@1:  40.000 ( 30.486)  Acc@5:  50.000 ( 60.213)
Test: [ 800/3167]  Time: 0.191 (0.192)  Loss:   3.828 ( 3.051)  Acc@1:   2.500 ( 29.900)  Acc@5:  37.500 ( 59.363)
Test: [ 850/3167]  Time: 0.187 (0.192)  Loss:   3.368 ( 3.092)  Acc@1:   7.500 ( 28.399)  Acc@5:  57.500 ( 57.917)
Test: [ 900/3167]  Time: 0.190 (0.193)  Loss:   3.670 ( 3.125)  Acc@1:  12.500 ( 27.328)  Acc@5:  40.000 ( 56.995)
Test: [ 950/3167]  Time: 0.202 (0.193)  Loss:   3.297 ( 3.156)  Acc@1:  22.500 ( 26.396)  Acc@5:  55.000 ( 55.818)
Test: [1000/3167]  Time: 0.191 (0.193)  Loss:   3.241 ( 3.179)  Acc@1:  17.500 ( 25.579)  Acc@5:  55.000 ( 55.055)
Test: [1050/3167]  Time: 0.207 (0.193)  Loss:   3.014 ( 3.172)  Acc@1:  27.500 ( 25.802)  Acc@5:  72.500 ( 55.569)
Test: [1100/3167]  Time: 0.206 (0.193)  Loss:   3.203 ( 3.170)  Acc@1:  42.500 ( 25.652)  Acc@5:  65.000 ( 55.945)
Test: [1150/3167]  Time: 0.188 (0.193)  Loss:   1.919 ( 3.141)  Acc@1:  75.000 ( 26.892)  Acc@5:  90.000 ( 56.833)
Test: [1200/3167]  Time: 0.205 (0.193)  Loss:   2.512 ( 3.120)  Acc@1:  57.500 ( 27.542)  Acc@5:  82.500 ( 57.642)
Test: [1250/3167]  Time: 0.184 (0.193)  Loss:   2.081 ( 3.091)  Acc@1:  65.000 ( 28.703)  Acc@5:  85.000 ( 58.391)
Test: [1300/3167]  Time: 0.186 (0.193)  Loss:   2.654 ( 3.105)  Acc@1:  52.500 ( 28.357)  Acc@5:  82.500 ( 57.836)
Test: [1350/3167]  Time: 0.190 (0.193)  Loss:   3.426 ( 3.131)  Acc@1:  20.000 ( 28.018)  Acc@5:  62.500 ( 57.013)
Test: [1400/3167]  Time: 0.199 (0.193)  Loss:   3.168 ( 3.151)  Acc@1:  32.500 ( 27.554)  Acc@5:  57.500 ( 56.360)
Test: [1450/3167]  Time: 0.190 (0.193)  Loss:   3.163 ( 3.150)  Acc@1:  22.500 ( 27.798)  Acc@5:  55.000 ( 56.468)
Test: [1500/3167]  Time: 0.186 (0.193)  Loss:   3.359 ( 3.133)  Acc@1:  17.500 ( 28.343)  Acc@5:  55.000 ( 56.919)
Test: [1550/3167]  Time: 0.203 (0.193)  Loss:   1.636 ( 3.119)  Acc@1:  80.000 ( 28.757)  Acc@5:  90.000 ( 57.336)
Test: [1600/3167]  Time: 0.200 (0.193)  Loss:   2.889 ( 3.106)  Acc@1:  35.000 ( 29.071)  Acc@5:  57.500 ( 57.881)
Test: [1650/3167]  Time: 0.184 (0.193)  Loss:   2.774 ( 3.095)  Acc@1:  32.500 ( 29.358)  Acc@5:  72.500 ( 58.225)
Test: [1700/3167]  Time: 0.192 (0.193)  Loss:   3.778 ( 3.082)  Acc@1:   7.500 ( 29.777)  Acc@5:  30.000 ( 58.527)
Test: [1750/3167]  Time: 0.191 (0.193)  Loss:   3.577 ( 3.098)  Acc@1:  12.500 ( 29.355)  Acc@5:  40.000 ( 57.925)
Test: [1800/3167]  Time: 0.184 (0.193)  Loss:   3.287 ( 3.107)  Acc@1:   7.500 ( 29.184)  Acc@5:  47.500 ( 57.704)
Test: [1850/3167]  Time: 0.202 (0.193)  Loss:   3.390 ( 3.124)  Acc@1:  15.000 ( 28.518)  Acc@5:  40.000 ( 56.854)
Test: [1900/3167]  Time: 0.194 (0.193)  Loss:   3.808 ( 3.134)  Acc@1:   7.500 ( 28.110)  Acc@5:  35.000 ( 56.661)
Test: [1950/3167]  Time: 0.199 (0.193)  Loss:   4.315 ( 3.144)  Acc@1:   0.000 ( 27.754)  Acc@5:  10.000 ( 56.333)
Test: [2000/3167]  Time: 0.194 (0.193)  Loss:   3.975 ( 3.166)  Acc@1:   5.000 ( 27.173)  Acc@5:  25.000 ( 55.447)
Test: [2050/3167]  Time: 0.189 (0.193)  Loss:   3.739 ( 3.181)  Acc@1:   2.500 ( 26.677)  Acc@5:  25.000 ( 54.832)
Test: [2100/3167]  Time: 0.191 (0.193)  Loss:   3.508 ( 3.182)  Acc@1:  15.000 ( 26.699)  Acc@5:  42.500 ( 54.869)
Test: [2150/3167]  Time: 0.204 (0.193)  Loss:   1.781 ( 3.167)  Acc@1:  70.000 ( 27.116)  Acc@5:  77.500 ( 55.136)
Test: [2200/3167]  Time: 0.192 (0.193)  Loss:   3.256 ( 3.163)  Acc@1:  15.000 ( 27.105)  Acc@5:  52.500 ( 55.267)
Test: [2250/3167]  Time: 0.203 (0.193)  Loss:   3.348 ( 3.173)  Acc@1:  32.500 ( 26.740)  Acc@5:  52.500 ( 54.910)
Test: [2300/3167]  Time: 0.191 (0.193)  Loss:   3.940 ( 3.184)  Acc@1:   0.000 ( 26.330)  Acc@5:  20.000 ( 54.487)
Test: [2350/3167]  Time: 0.188 (0.193)  Loss:   3.772 ( 3.197)  Acc@1:  10.000 ( 25.869)  Acc@5:  45.000 ( 53.946)
Test: [2400/3167]  Time: 0.210 (0.194)  Loss:   3.728 ( 3.191)  Acc@1:   0.000 ( 26.057)  Acc@5:  22.500 ( 53.987)
Test: [2450/3167]  Time: 0.188 (0.194)  Loss:   2.564 ( 3.188)  Acc@1:  47.500 ( 26.066)  Acc@5:  85.000 ( 54.180)
Test: [2500/3167]  Time: 0.197 (0.194)  Loss:   2.965 ( 3.187)  Acc@1:  35.000 ( 26.179)  Acc@5:  70.000 ( 54.333)
Test: [2550/3167]  Time: 0.196 (0.194)  Loss:   3.932 ( 3.169)  Acc@1:   0.000 ( 26.822)  Acc@5:  25.000 ( 54.857)
Test: [2600/3167]  Time: 0.189 (0.194)  Loss:   2.591 ( 3.177)  Acc@1:  50.000 ( 26.671)  Acc@5:  70.000 ( 54.520)
Test: [2650/3167]  Time: 0.191 (0.193)  Loss:   3.324 ( 3.183)  Acc@1:  20.000 ( 26.613)  Acc@5:  52.500 ( 54.369)
Test: [2700/3167]  Time: 0.189 (0.193)  Loss:   2.741 ( 3.183)  Acc@1:  42.500 ( 26.633)  Acc@5:  70.000 ( 54.443)
Test: [2750/3167]  Time: 0.204 (0.193)  Loss:   2.482 ( 3.188)  Acc@1:  40.000 ( 26.459)  Acc@5:  87.500 ( 54.216)
Test: [2800/3167]  Time: 0.189 (0.193)  Loss:   3.710 ( 3.186)  Acc@1:  17.500 ( 26.397)  Acc@5:  50.000 ( 54.417)
Test: [2850/3167]  Time: 0.188 (0.193)  Loss:   3.712 ( 3.202)  Acc@1:  10.000 ( 26.008)  Acc@5:  27.500 ( 53.784)
Test: [2900/3167]  Time: 0.186 (0.193)  Loss:   2.887 ( 3.203)  Acc@1:  37.500 ( 26.038)  Acc@5:  70.000 ( 53.782)
Test: [2950/3167]  Time: 0.198 (0.193)  Loss:   3.598 ( 3.213)  Acc@1:   0.000 ( 25.714)  Acc@5:  32.500 ( 53.368)
Test: [3000/3167]  Time: 0.188 (0.193)  Loss:   4.086 ( 3.225)  Acc@1:   2.500 ( 25.312)  Acc@5:  25.000 ( 52.910)
Test: [3050/3167]  Time: 0.186 (0.193)  Loss:   3.848 ( 3.228)  Acc@1:   7.500 ( 25.152)  Acc@5:  25.000 ( 52.807)
Test: [3100/3167]  Time: 0.185 (0.193)  Loss:   3.787 ( 3.238)  Acc@1:   0.000 ( 24.786)  Acc@5:  35.000 ( 52.385)
Test: [3150/3167]  Time: 0.187 (0.193)  Loss:   3.116 ( 3.241)  Acc@1:  12.500 ( 24.596)  Acc@5:  67.500 ( 52.382)
Test: [3167/3167]  Time: 0.043 (0.193)  Loss:   2.712 ( 3.241)  Acc@1:  44.444 ( 24.570)  Acc@5:  77.778 ( 52.428)
Test: [   0/124]  Time: 0.551 (0.551)  Loss:   3.558 ( 3.558)  Acc@1:  10.000 ( 10.000)  Acc@5:  42.500 ( 42.500)
Test: [  50/124]  Time: 0.186 (0.196)  Loss:   2.919 ( 3.198)  Acc@1:  47.500 ( 26.422)  Acc@5:  72.500 ( 54.706)
Test: [ 100/124]  Time: 0.188 (0.191)  Loss:   2.177 ( 3.263)  Acc@1:  65.000 ( 24.530)  Acc@5:  82.500 ( 51.040)
Test: [ 124/124]  Time: 0.180 (0.190)  Loss:   2.944 ( 3.322)  Acc@1:  17.500 ( 22.580)  Acc@5:  67.500 ( 49.140)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_1/checkpoint-6.pth.tar', 24.570404691954895)

Train: 7 [   0/3167 (  0%)]  Loss: 4.20 (4.20)  Time: 1.109s,   36.08/s  (1.109s,   36.08/s)  LR: 7.300e-05  Data: 0.513 (0.513)
Train: 7 [  50/3167 (  2%)]  Loss: 4.17 (4.00)  Time: 0.605s,   66.17/s  (0.614s,   65.17/s)  LR: 7.300e-05  Data: 0.009 (0.020)
Train: 7 [ 100/3167 (  3%)]  Loss: 4.14 (3.97)  Time: 0.597s,   67.03/s  (0.608s,   65.77/s)  LR: 7.300e-05  Data: 0.004 (0.015)
Train: 7 [ 150/3167 (  5%)]  Loss: 4.05 (3.99)  Time: 0.603s,   66.29/s  (0.606s,   65.96/s)  LR: 7.300e-05  Data: 0.011 (0.014)
Train: 7 [ 200/3167 (  6%)]  Loss: 4.17 (3.98)  Time: 0.605s,   66.13/s  (0.606s,   66.05/s)  LR: 7.300e-05  Data: 0.011 (0.013)
Train: 7 [ 250/3167 (  8%)]  Loss: 3.97 (3.98)  Time: 0.602s,   66.48/s  (0.605s,   66.09/s)  LR: 7.300e-05  Data: 0.012 (0.012)
Train: 7 [ 300/3167 (  9%)]  Loss: 4.18 (3.98)  Time: 0.604s,   66.23/s  (0.605s,   66.12/s)  LR: 7.300e-05  Data: 0.011 (0.012)
Train: 7 [ 350/3167 ( 11%)]  Loss: 4.25 (3.98)  Time: 0.604s,   66.28/s  (0.605s,   66.15/s)  LR: 7.300e-05  Data: 0.011 (0.012)
Train: 7 [ 400/3167 ( 13%)]  Loss: 4.63 (3.99)  Time: 0.603s,   66.34/s  (0.605s,   66.16/s)  LR: 7.300e-05  Data: 0.012 (0.011)
Train: 7 [ 450/3167 ( 14%)]  Loss: 4.09 (3.99)  Time: 0.602s,   66.44/s  (0.604s,   66.17/s)  LR: 7.300e-05  Data: 0.012 (0.011)
Train: 7 [ 500/3167 ( 16%)]  Loss: 3.57 (3.98)  Time: 0.611s,   65.44/s  (0.604s,   66.18/s)  LR: 7.300e-05  Data: 0.012 (0.011)
Train: 7 [ 550/3167 ( 17%)]  Loss: 3.51 (3.98)  Time: 0.602s,   66.48/s  (0.604s,   66.19/s)  LR: 7.300e-05  Data: 0.012 (0.011)
Train: 7 [ 600/3167 ( 19%)]  Loss: 3.43 (3.98)  Time: 0.602s,   66.49/s  (0.604s,   66.19/s)  LR: 7.300e-05  Data: 0.011 (0.011)
Train: 7 [ 650/3167 ( 21%)]  Loss: 4.13 (3.98)  Time: 0.602s,   66.46/s  (0.604s,   66.21/s)  LR: 7.300e-05  Data: 0.007 (0.011)
Train: 7 [ 700/3167 ( 22%)]  Loss: 4.62 (3.99)  Time: 0.599s,   66.74/s  (0.604s,   66.21/s)  LR: 7.300e-05  Data: 0.009 (0.011)
Train: 7 [ 750/3167 ( 24%)]  Loss: 3.86 (3.98)  Time: 0.600s,   66.69/s  (0.604s,   66.22/s)  LR: 7.300e-05  Data: 0.010 (0.011)
Train: 7 [ 800/3167 ( 25%)]  Loss: 3.88 (3.98)  Time: 0.610s,   65.59/s  (0.604s,   66.23/s)  LR: 7.300e-05  Data: 0.012 (0.011)
Train: 7 [ 850/3167 ( 27%)]  Loss: 3.75 (3.98)  Time: 0.609s,   65.65/s  (0.604s,   66.23/s)  LR: 7.300e-05  Data: 0.012 (0.011)
Train: 7 [ 900/3167 ( 28%)]  Loss: 3.85 (3.98)  Time: 0.610s,   65.58/s  (0.604s,   66.24/s)  LR: 7.300e-05  Data: 0.011 (0.011)
Train: 7 [ 950/3167 ( 30%)]  Loss: 3.92 (3.98)  Time: 0.606s,   65.98/s  (0.604s,   66.25/s)  LR: 7.300e-05  Data: 0.006 (0.011)
Train: 7 [1000/3167 ( 32%)]  Loss: 4.18 (3.98)  Time: 0.601s,   66.51/s  (0.604s,   66.26/s)  LR: 7.300e-05  Data: 0.011 (0.011)
Train: 7 [1050/3167 ( 33%)]  Loss: 3.72 (3.98)  Time: 0.608s,   65.82/s  (0.604s,   66.26/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [1100/3167 ( 35%)]  Loss: 4.33 (3.98)  Time: 0.600s,   66.69/s  (0.604s,   66.27/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [1150/3167 ( 36%)]  Loss: 4.30 (3.98)  Time: 0.600s,   66.70/s  (0.604s,   66.27/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [1200/3167 ( 38%)]  Loss: 4.21 (3.98)  Time: 0.605s,   66.14/s  (0.604s,   66.27/s)  LR: 7.300e-05  Data: 0.011 (0.010)
Train: 7 [1250/3167 ( 39%)]  Loss: 3.58 (3.98)  Time: 0.607s,   65.95/s  (0.604s,   66.27/s)  LR: 7.300e-05  Data: 0.011 (0.010)
Train: 7 [1300/3167 ( 41%)]  Loss: 4.23 (3.98)  Time: 0.608s,   65.82/s  (0.604s,   66.28/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [1350/3167 ( 43%)]  Loss: 4.09 (3.98)  Time: 0.604s,   66.27/s  (0.604s,   66.28/s)  LR: 7.300e-05  Data: 0.014 (0.010)
Train: 7 [1400/3167 ( 44%)]  Loss: 4.15 (3.98)  Time: 0.607s,   65.90/s  (0.603s,   66.29/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [1450/3167 ( 46%)]  Loss: 4.03 (3.98)  Time: 0.597s,   67.05/s  (0.603s,   66.28/s)  LR: 7.300e-05  Data: 0.006 (0.010)
Train: 7 [1500/3167 ( 47%)]  Loss: 4.62 (3.97)  Time: 0.599s,   66.79/s  (0.603s,   66.29/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [1550/3167 ( 49%)]  Loss: 4.14 (3.97)  Time: 0.611s,   65.41/s  (0.603s,   66.29/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [1600/3167 ( 51%)]  Loss: 3.73 (3.97)  Time: 0.600s,   66.71/s  (0.603s,   66.29/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [1650/3167 ( 52%)]  Loss: 4.24 (3.97)  Time: 0.602s,   66.42/s  (0.603s,   66.29/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [1700/3167 ( 54%)]  Loss: 3.92 (3.97)  Time: 0.602s,   66.50/s  (0.603s,   66.30/s)  LR: 7.300e-05  Data: 0.011 (0.010)
Train: 7 [1750/3167 ( 55%)]  Loss: 3.92 (3.97)  Time: 0.600s,   66.71/s  (0.603s,   66.30/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [1800/3167 ( 57%)]  Loss: 3.88 (3.97)  Time: 0.608s,   65.81/s  (0.603s,   66.30/s)  LR: 7.300e-05  Data: 0.014 (0.010)
Train: 7 [1850/3167 ( 58%)]  Loss: 3.93 (3.97)  Time: 0.594s,   67.33/s  (0.603s,   66.31/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [1900/3167 ( 60%)]  Loss: 4.03 (3.97)  Time: 0.602s,   66.44/s  (0.603s,   66.31/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [1950/3167 ( 62%)]  Loss: 3.98 (3.97)  Time: 0.602s,   66.49/s  (0.603s,   66.31/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [2000/3167 ( 63%)]  Loss: 4.24 (3.97)  Time: 0.603s,   66.36/s  (0.603s,   66.31/s)  LR: 7.300e-05  Data: 0.013 (0.010)
Train: 7 [2050/3167 ( 65%)]  Loss: 4.08 (3.97)  Time: 0.598s,   66.89/s  (0.603s,   66.32/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [2100/3167 ( 66%)]  Loss: 4.15 (3.97)  Time: 0.600s,   66.70/s  (0.603s,   66.32/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [2150/3167 ( 68%)]  Loss: 4.23 (3.97)  Time: 0.599s,   66.78/s  (0.603s,   66.32/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [2200/3167 ( 69%)]  Loss: 4.30 (3.97)  Time: 0.605s,   66.07/s  (0.603s,   66.33/s)  LR: 7.300e-05  Data: 0.010 (0.010)
Train: 7 [2250/3167 ( 71%)]  Loss: 3.76 (3.97)  Time: 0.597s,   67.02/s  (0.603s,   66.33/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [2300/3167 ( 73%)]  Loss: 4.11 (3.97)  Time: 0.604s,   66.20/s  (0.603s,   66.33/s)  LR: 7.300e-05  Data: 0.011 (0.010)
Train: 7 [2350/3167 ( 74%)]  Loss: 3.48 (3.96)  Time: 0.609s,   65.69/s  (0.603s,   66.34/s)  LR: 7.300e-05  Data: 0.011 (0.010)
Train: 7 [2400/3167 ( 76%)]  Loss: 4.15 (3.97)  Time: 0.600s,   66.64/s  (0.603s,   66.34/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [2450/3167 ( 77%)]  Loss: 4.19 (3.97)  Time: 0.598s,   66.83/s  (0.603s,   66.34/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [2500/3167 ( 79%)]  Loss: 3.38 (3.96)  Time: 0.601s,   66.51/s  (0.603s,   66.35/s)  LR: 7.300e-05  Data: 0.011 (0.010)
Train: 7 [2550/3167 ( 81%)]  Loss: 3.78 (3.96)  Time: 0.598s,   66.87/s  (0.603s,   66.35/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [2600/3167 ( 82%)]  Loss: 3.75 (3.96)  Time: 0.605s,   66.13/s  (0.603s,   66.36/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [2650/3167 ( 84%)]  Loss: 3.91 (3.96)  Time: 0.597s,   66.95/s  (0.603s,   66.36/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [2700/3167 ( 85%)]  Loss: 4.24 (3.96)  Time: 0.595s,   67.27/s  (0.603s,   66.37/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [2750/3167 ( 87%)]  Loss: 4.19 (3.96)  Time: 0.602s,   66.41/s  (0.603s,   66.37/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [2800/3167 ( 88%)]  Loss: 4.14 (3.96)  Time: 0.600s,   66.71/s  (0.603s,   66.38/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [2850/3167 ( 90%)]  Loss: 3.92 (3.96)  Time: 0.599s,   66.73/s  (0.603s,   66.39/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [2900/3167 ( 92%)]  Loss: 3.96 (3.96)  Time: 0.605s,   66.08/s  (0.602s,   66.39/s)  LR: 7.300e-05  Data: 0.010 (0.010)
Train: 7 [2950/3167 ( 93%)]  Loss: 4.37 (3.96)  Time: 0.599s,   66.76/s  (0.602s,   66.40/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [3000/3167 ( 95%)]  Loss: 3.93 (3.96)  Time: 0.597s,   66.99/s  (0.602s,   66.40/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [3050/3167 ( 96%)]  Loss: 3.90 (3.96)  Time: 0.597s,   66.97/s  (0.602s,   66.41/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [3100/3167 ( 98%)]  Loss: 3.58 (3.95)  Time: 0.599s,   66.73/s  (0.602s,   66.41/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [3150/3167 ( 99%)]  Loss: 4.08 (3.95)  Time: 0.599s,   66.77/s  (0.602s,   66.42/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Test: [   0/3167]  Time: 0.526 (0.526)  Loss:   3.267 ( 3.267)  Acc@1:  30.000 ( 30.000)  Acc@5:  62.500 ( 62.500)
Test: [  50/3167]  Time: 0.203 (0.199)  Loss:   2.965 ( 3.111)  Acc@1:  32.500 ( 32.108)  Acc@5:  55.000 ( 61.765)
Test: [ 100/3167]  Time: 0.199 (0.195)  Loss:   3.489 ( 3.132)  Acc@1:  10.000 ( 23.144)  Acc@5:  50.000 ( 57.500)
Test: [ 150/3167]  Time: 0.185 (0.194)  Loss:   1.867 ( 3.071)  Acc@1:  72.500 ( 26.838)  Acc@5:  95.000 ( 59.868)
Test: [ 200/3167]  Time: 0.190 (0.193)  Loss:   4.029 ( 3.138)  Acc@1:   0.000 ( 24.602)  Acc@5:  17.500 ( 55.896)
Test: [ 250/3167]  Time: 0.191 (0.192)  Loss:   2.303 ( 3.166)  Acc@1:  47.500 ( 24.442)  Acc@5:  75.000 ( 52.958)
Test: [ 300/3167]  Time: 0.192 (0.192)  Loss:   2.647 ( 3.140)  Acc@1:  32.500 ( 25.939)  Acc@5:  77.500 ( 54.560)
Test: [ 350/3167]  Time: 0.191 (0.192)  Loss:   2.693 ( 3.090)  Acc@1:  37.500 ( 27.030)  Acc@5:  72.500 ( 56.481)
Test: [ 400/3167]  Time: 0.191 (0.192)  Loss:   3.044 ( 2.988)  Acc@1:  25.000 ( 30.050)  Acc@5:  60.000 ( 59.115)
Test: [ 450/3167]  Time: 0.184 (0.192)  Loss:   3.220 ( 3.034)  Acc@1:  15.000 ( 28.210)  Acc@5:  57.500 ( 58.132)
Test: [ 500/3167]  Time: 0.204 (0.192)  Loss:   2.315 ( 3.058)  Acc@1:  45.000 ( 28.408)  Acc@5:  75.000 ( 57.146)
Test: [ 550/3167]  Time: 0.192 (0.192)  Loss:   3.914 ( 3.025)  Acc@1:   0.000 ( 29.614)  Acc@5:  37.500 ( 58.035)
Test: [ 600/3167]  Time: 0.192 (0.192)  Loss:   2.902 ( 3.064)  Acc@1:  35.000 ( 28.282)  Acc@5:  62.500 ( 56.847)
Test: [ 650/3167]  Time: 0.190 (0.192)  Loss:   2.253 ( 3.028)  Acc@1:  60.000 ( 29.505)  Acc@5:  90.000 ( 57.700)
Test: [ 700/3167]  Time: 0.192 (0.192)  Loss:   2.400 ( 2.977)  Acc@1:  60.000 ( 31.551)  Acc@5:  90.000 ( 59.693)
Test: [ 750/3167]  Time: 0.196 (0.192)  Loss:   3.275 ( 2.961)  Acc@1:  45.000 ( 32.314)  Acc@5:  45.000 ( 60.516)
Test: [ 800/3167]  Time: 0.190 (0.192)  Loss:   3.847 ( 2.987)  Acc@1:   0.000 ( 31.629)  Acc@5:  27.500 ( 59.516)
Test: [ 850/3167]  Time: 0.208 (0.192)  Loss:   3.270 ( 3.024)  Acc@1:   7.500 ( 30.279)  Acc@5:  55.000 ( 58.358)
Test: [ 900/3167]  Time: 0.194 (0.192)  Loss:   3.511 ( 3.055)  Acc@1:  15.000 ( 29.323)  Acc@5:  50.000 ( 57.594)
Test: [ 950/3167]  Time: 0.187 (0.192)  Loss:   2.463 ( 3.071)  Acc@1:  52.500 ( 28.938)  Acc@5:  72.500 ( 56.930)
Test: [1000/3167]  Time: 0.188 (0.192)  Loss:   3.125 ( 3.092)  Acc@1:  25.000 ( 28.599)  Acc@5:  70.000 ( 56.371)
Test: [1050/3167]  Time: 0.191 (0.192)  Loss:   2.994 ( 3.085)  Acc@1:  27.500 ( 28.449)  Acc@5:  65.000 ( 56.972)
Test: [1100/3167]  Time: 0.188 (0.192)  Loss:   3.236 ( 3.082)  Acc@1:  30.000 ( 28.304)  Acc@5:  60.000 ( 57.302)
Test: [1150/3167]  Time: 0.184 (0.192)  Loss:   2.038 ( 3.063)  Acc@1:  65.000 ( 29.205)  Acc@5:  90.000 ( 57.930)
Test: [1200/3167]  Time: 0.199 (0.192)  Loss:   2.734 ( 3.044)  Acc@1:  37.500 ( 29.690)  Acc@5:  62.500 ( 58.649)
Test: [1250/3167]  Time: 0.190 (0.192)  Loss:   2.768 ( 3.035)  Acc@1:  42.500 ( 30.230)  Acc@5:  62.500 ( 58.969)
Test: [1300/3167]  Time: 0.191 (0.192)  Loss:   3.328 ( 3.046)  Acc@1:  37.500 ( 29.685)  Acc@5:  60.000 ( 58.776)
Test: [1350/3167]  Time: 0.197 (0.192)  Loss:   3.376 ( 3.073)  Acc@1:  20.000 ( 29.034)  Acc@5:  60.000 ( 57.935)
Test: [1400/3167]  Time: 0.191 (0.192)  Loss:   3.379 ( 3.098)  Acc@1:  25.000 ( 28.483)  Acc@5:  57.500 ( 57.090)
Test: [1450/3167]  Time: 0.200 (0.192)  Loss:   3.342 ( 3.104)  Acc@1:  27.500 ( 28.525)  Acc@5:  45.000 ( 57.050)
Test: [1500/3167]  Time: 0.191 (0.192)  Loss:   3.352 ( 3.083)  Acc@1:  12.500 ( 29.270)  Acc@5:  57.500 ( 57.538)
Test: [1550/3167]  Time: 0.196 (0.192)  Loss:   2.067 ( 3.078)  Acc@1:  65.000 ( 29.241)  Acc@5:  85.000 ( 57.745)
Test: [1600/3167]  Time: 0.190 (0.192)  Loss:   2.247 ( 3.078)  Acc@1:  47.500 ( 29.293)  Acc@5:  80.000 ( 57.817)
Test: [1650/3167]  Time: 0.203 (0.192)  Loss:   2.553 ( 3.055)  Acc@1:  32.500 ( 29.870)  Acc@5:  75.000 ( 58.340)
Test: [1700/3167]  Time: 0.189 (0.192)  Loss:   4.038 ( 3.044)  Acc@1:  10.000 ( 30.345)  Acc@5:  27.500 ( 58.614)
Test: [1750/3167]  Time: 0.199 (0.192)  Loss:   2.964 ( 3.052)  Acc@1:  35.000 ( 30.196)  Acc@5:  55.000 ( 58.251)
Test: [1800/3167]  Time: 0.204 (0.192)  Loss:   2.885 ( 3.059)  Acc@1:  25.000 ( 30.092)  Acc@5:  60.000 ( 58.143)
Test: [1850/3167]  Time: 0.204 (0.193)  Loss:   3.011 ( 3.072)  Acc@1:  25.000 ( 29.545)  Acc@5:  62.500 ( 57.474)
Test: [1900/3167]  Time: 0.191 (0.193)  Loss:   3.529 ( 3.073)  Acc@1:  10.000 ( 29.196)  Acc@5:  45.000 ( 57.596)
Test: [1950/3167]  Time: 0.192 (0.193)  Loss:   4.242 ( 3.074)  Acc@1:   0.000 ( 29.147)  Acc@5:  12.500 ( 57.644)
Test: [2000/3167]  Time: 0.194 (0.193)  Loss:   3.866 ( 3.095)  Acc@1:   5.000 ( 28.568)  Acc@5:  30.000 ( 56.913)
Test: [2050/3167]  Time: 0.190 (0.193)  Loss:   3.898 ( 3.113)  Acc@1:   0.000 ( 28.020)  Acc@5:   5.000 ( 56.063)
Test: [2100/3167]  Time: 0.207 (0.193)  Loss:   2.664 ( 3.113)  Acc@1:  40.000 ( 28.069)  Acc@5:  77.500 ( 56.168)
Test: [2150/3167]  Time: 0.188 (0.193)  Loss:   1.297 ( 3.085)  Acc@1:  75.000 ( 28.860)  Acc@5:  90.000 ( 56.886)
Test: [2200/3167]  Time: 0.194 (0.193)  Loss:   3.146 ( 3.078)  Acc@1:   5.000 ( 28.882)  Acc@5:  62.500 ( 57.107)
Test: [2250/3167]  Time: 0.189 (0.193)  Loss:   3.376 ( 3.087)  Acc@1:  40.000 ( 28.562)  Acc@5:  55.000 ( 56.841)
Test: [2300/3167]  Time: 0.188 (0.193)  Loss:   3.382 ( 3.097)  Acc@1:   7.500 ( 28.216)  Acc@5:  50.000 ( 56.442)
Test: [2350/3167]  Time: 0.188 (0.193)  Loss:   3.654 ( 3.104)  Acc@1:  22.500 ( 27.840)  Acc@5:  47.500 ( 56.313)
Test: [2400/3167]  Time: 0.197 (0.193)  Loss:   3.646 ( 3.097)  Acc@1:  10.000 ( 28.067)  Acc@5:  35.000 ( 56.457)
Test: [2450/3167]  Time: 0.203 (0.193)  Loss:   2.378 ( 3.092)  Acc@1:  37.500 ( 28.153)  Acc@5:  85.000 ( 56.723)
Test: [2500/3167]  Time: 0.184 (0.193)  Loss:   2.805 ( 3.082)  Acc@1:  32.500 ( 28.483)  Acc@5:  65.000 ( 57.115)
Test: [2550/3167]  Time: 0.187 (0.193)  Loss:   4.014 ( 3.069)  Acc@1:   2.500 ( 28.853)  Acc@5:  17.500 ( 57.551)
Test: [2600/3167]  Time: 0.193 (0.193)  Loss:   2.849 ( 3.083)  Acc@1:  37.500 ( 28.593)  Acc@5:  70.000 ( 57.067)
Test: [2650/3167]  Time: 0.197 (0.193)  Loss:   3.530 ( 3.095)  Acc@1:  17.500 ( 28.336)  Acc@5:  45.000 ( 56.698)
Test: [2700/3167]  Time: 0.186 (0.193)  Loss:   2.449 ( 3.095)  Acc@1:  47.500 ( 28.421)  Acc@5:  75.000 ( 56.748)
Test: [2750/3167]  Time: 0.199 (0.193)  Loss:   2.324 ( 3.105)  Acc@1:  50.000 ( 28.266)  Acc@5:  85.000 ( 56.388)
Test: [2800/3167]  Time: 0.198 (0.193)  Loss:   3.884 ( 3.105)  Acc@1:  12.500 ( 28.351)  Acc@5:  47.500 ( 56.487)
Test: [2850/3167]  Time: 0.189 (0.192)  Loss:   3.884 ( 3.119)  Acc@1:  10.000 ( 27.910)  Acc@5:  35.000 ( 55.901)
Test: [2900/3167]  Time: 0.188 (0.192)  Loss:   2.866 ( 3.122)  Acc@1:  45.000 ( 27.904)  Acc@5:  67.500 ( 55.887)
Test: [2950/3167]  Time: 0.188 (0.192)  Loss:   3.964 ( 3.134)  Acc@1:   2.500 ( 27.548)  Acc@5:  20.000 ( 55.380)
Test: [3000/3167]  Time: 0.190 (0.192)  Loss:   4.018 ( 3.149)  Acc@1:   7.500 ( 27.167)  Acc@5:  20.000 ( 54.876)
Test: [3050/3167]  Time: 0.192 (0.192)  Loss:   3.790 ( 3.144)  Acc@1:  12.500 ( 27.333)  Acc@5:  30.000 ( 55.100)
Test: [3100/3167]  Time: 0.202 (0.192)  Loss:   4.110 ( 3.157)  Acc@1:   0.000 ( 26.975)  Acc@5:  22.500 ( 54.672)
Test: [3150/3167]  Time: 0.187 (0.192)  Loss:   3.088 ( 3.157)  Acc@1:   7.500 ( 26.789)  Acc@5:  70.000 ( 54.787)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   2.713 ( 3.157)  Acc@1:  11.111 ( 26.697)  Acc@5:  88.889 ( 54.818)
Test: [   0/124]  Time: 0.532 (0.532)  Loss:   3.539 ( 3.539)  Acc@1:  17.500 ( 17.500)  Acc@5:  55.000 ( 55.000)
Test: [  50/124]  Time: 0.187 (0.196)  Loss:   3.653 ( 3.168)  Acc@1:  20.000 ( 25.735)  Acc@5:  42.500 ( 53.873)
Test: [ 100/124]  Time: 0.186 (0.191)  Loss:   2.462 ( 3.179)  Acc@1:  50.000 ( 25.074)  Acc@5:  75.000 ( 52.871)
Test: [ 124/124]  Time: 0.180 (0.190)  Loss:   2.901 ( 3.254)  Acc@1:  12.500 ( 23.620)  Acc@5:  65.000 ( 50.740)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_1/checkpoint-7.pth.tar', 26.696871867366294)

Train: 8 [   0/3167 (  0%)]  Loss: 4.22 (4.22)  Time: 1.125s,   35.56/s  (1.125s,   35.56/s)  LR: 8.200e-05  Data: 0.527 (0.527)
Train: 8 [  50/3167 (  2%)]  Loss: 4.19 (4.02)  Time: 0.605s,   66.14/s  (0.613s,   65.25/s)  LR: 8.200e-05  Data: 0.012 (0.019)
Train: 8 [ 100/3167 (  3%)]  Loss: 4.04 (4.00)  Time: 0.604s,   66.20/s  (0.608s,   65.74/s)  LR: 8.200e-05  Data: 0.011 (0.015)
Train: 8 [ 150/3167 (  5%)]  Loss: 3.41 (3.97)  Time: 0.610s,   65.52/s  (0.607s,   65.91/s)  LR: 8.200e-05  Data: 0.011 (0.014)
Train: 8 [ 200/3167 (  6%)]  Loss: 3.95 (3.96)  Time: 0.602s,   66.44/s  (0.606s,   66.00/s)  LR: 8.200e-05  Data: 0.012 (0.013)
Train: 8 [ 250/3167 (  8%)]  Loss: 4.15 (3.94)  Time: 0.609s,   65.65/s  (0.606s,   66.04/s)  LR: 8.200e-05  Data: 0.012 (0.012)
Train: 8 [ 300/3167 (  9%)]  Loss: 3.97 (3.94)  Time: 0.602s,   66.48/s  (0.605s,   66.10/s)  LR: 8.200e-05  Data: 0.011 (0.012)
Train: 8 [ 350/3167 ( 11%)]  Loss: 3.66 (3.94)  Time: 0.594s,   67.34/s  (0.605s,   66.12/s)  LR: 8.200e-05  Data: 0.004 (0.012)
Train: 8 [ 400/3167 ( 13%)]  Loss: 4.08 (3.93)  Time: 0.606s,   66.04/s  (0.605s,   66.15/s)  LR: 8.200e-05  Data: 0.012 (0.011)
Train: 8 [ 450/3167 ( 14%)]  Loss: 4.05 (3.94)  Time: 0.612s,   65.40/s  (0.605s,   66.17/s)  LR: 8.200e-05  Data: 0.013 (0.011)
Train: 8 [ 500/3167 ( 16%)]  Loss: 3.31 (3.93)  Time: 0.607s,   65.86/s  (0.604s,   66.18/s)  LR: 8.200e-05  Data: 0.011 (0.011)
Train: 8 [ 550/3167 ( 17%)]  Loss: 4.08 (3.93)  Time: 0.607s,   65.85/s  (0.604s,   66.18/s)  LR: 8.200e-05  Data: 0.012 (0.011)
Train: 8 [ 600/3167 ( 19%)]  Loss: 3.98 (3.93)  Time: 0.594s,   67.31/s  (0.604s,   66.19/s)  LR: 8.200e-05  Data: 0.004 (0.011)
Train: 8 [ 650/3167 ( 21%)]  Loss: 3.48 (3.93)  Time: 0.594s,   67.29/s  (0.604s,   66.20/s)  LR: 8.200e-05  Data: 0.004 (0.011)
Train: 8 [ 700/3167 ( 22%)]  Loss: 3.21 (3.93)  Time: 0.600s,   66.69/s  (0.604s,   66.21/s)  LR: 8.200e-05  Data: 0.010 (0.011)
Train: 8 [ 750/3167 ( 24%)]  Loss: 3.70 (3.93)  Time: 0.604s,   66.23/s  (0.604s,   66.22/s)  LR: 8.200e-05  Data: 0.012 (0.011)
Train: 8 [ 800/3167 ( 25%)]  Loss: 3.48 (3.93)  Time: 0.602s,   66.46/s  (0.604s,   66.22/s)  LR: 8.200e-05  Data: 0.012 (0.011)
Train: 8 [ 850/3167 ( 27%)]  Loss: 3.78 (3.92)  Time: 0.602s,   66.48/s  (0.604s,   66.23/s)  LR: 8.200e-05  Data: 0.011 (0.011)
Train: 8 [ 900/3167 ( 28%)]  Loss: 4.13 (3.92)  Time: 0.605s,   66.09/s  (0.604s,   66.23/s)  LR: 8.200e-05  Data: 0.012 (0.011)
Train: 8 [ 950/3167 ( 30%)]  Loss: 3.83 (3.92)  Time: 0.607s,   65.94/s  (0.604s,   66.23/s)  LR: 8.200e-05  Data: 0.012 (0.011)
Train: 8 [1000/3167 ( 32%)]  Loss: 3.69 (3.92)  Time: 0.599s,   66.80/s  (0.604s,   66.24/s)  LR: 8.200e-05  Data: 0.007 (0.011)
Train: 8 [1050/3167 ( 33%)]  Loss: 3.62 (3.92)  Time: 0.606s,   65.97/s  (0.604s,   66.24/s)  LR: 8.200e-05  Data: 0.011 (0.011)
Train: 8 [1100/3167 ( 35%)]  Loss: 4.13 (3.92)  Time: 0.600s,   66.71/s  (0.604s,   66.24/s)  LR: 8.200e-05  Data: 0.007 (0.011)
Train: 8 [1150/3167 ( 36%)]  Loss: 3.38 (3.92)  Time: 0.604s,   66.24/s  (0.604s,   66.25/s)  LR: 8.200e-05  Data: 0.010 (0.011)
Train: 8 [1200/3167 ( 38%)]  Loss: 3.42 (3.91)  Time: 0.602s,   66.48/s  (0.604s,   66.25/s)  LR: 8.200e-05  Data: 0.012 (0.011)
Train: 8 [1250/3167 ( 39%)]  Loss: 4.15 (3.91)  Time: 0.605s,   66.15/s  (0.604s,   66.25/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1300/3167 ( 41%)]  Loss: 3.74 (3.91)  Time: 0.596s,   67.07/s  (0.604s,   66.26/s)  LR: 8.200e-05  Data: 0.006 (0.010)
Train: 8 [1350/3167 ( 43%)]  Loss: 3.68 (3.91)  Time: 0.608s,   65.80/s  (0.604s,   66.26/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1400/3167 ( 44%)]  Loss: 3.96 (3.92)  Time: 0.607s,   65.86/s  (0.604s,   66.26/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [1450/3167 ( 46%)]  Loss: 3.69 (3.91)  Time: 0.597s,   67.04/s  (0.604s,   66.26/s)  LR: 8.200e-05  Data: 0.007 (0.010)
Train: 8 [1500/3167 ( 47%)]  Loss: 3.60 (3.91)  Time: 0.609s,   65.63/s  (0.604s,   66.26/s)  LR: 8.200e-05  Data: 0.014 (0.010)
Train: 8 [1550/3167 ( 49%)]  Loss: 4.12 (3.92)  Time: 0.602s,   66.49/s  (0.604s,   66.27/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1600/3167 ( 51%)]  Loss: 3.62 (3.92)  Time: 0.606s,   66.01/s  (0.604s,   66.27/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1650/3167 ( 52%)]  Loss: 3.61 (3.92)  Time: 0.601s,   66.50/s  (0.604s,   66.27/s)  LR: 8.200e-05  Data: 0.011 (0.010)
Train: 8 [1700/3167 ( 54%)]  Loss: 3.88 (3.92)  Time: 0.602s,   66.40/s  (0.604s,   66.28/s)  LR: 8.200e-05  Data: 0.011 (0.010)
Train: 8 [1750/3167 ( 55%)]  Loss: 4.11 (3.92)  Time: 0.597s,   67.05/s  (0.603s,   66.28/s)  LR: 8.200e-05  Data: 0.004 (0.010)
Train: 8 [1800/3167 ( 57%)]  Loss: 3.67 (3.92)  Time: 0.604s,   66.22/s  (0.603s,   66.29/s)  LR: 8.200e-05  Data: 0.010 (0.010)
Train: 8 [1850/3167 ( 58%)]  Loss: 3.95 (3.92)  Time: 0.604s,   66.22/s  (0.603s,   66.29/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1900/3167 ( 60%)]  Loss: 4.23 (3.92)  Time: 0.596s,   67.06/s  (0.603s,   66.29/s)  LR: 8.200e-05  Data: 0.006 (0.010)
Train: 8 [1950/3167 ( 62%)]  Loss: 3.61 (3.91)  Time: 0.603s,   66.37/s  (0.603s,   66.29/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [2000/3167 ( 63%)]  Loss: 4.05 (3.91)  Time: 0.597s,   66.99/s  (0.603s,   66.30/s)  LR: 8.200e-05  Data: 0.007 (0.010)
Train: 8 [2050/3167 ( 65%)]  Loss: 4.17 (3.91)  Time: 0.598s,   66.93/s  (0.603s,   66.30/s)  LR: 8.200e-05  Data: 0.007 (0.010)
slurmstepd: error: *** JOB 2080294 ON i58 CANCELLED AT 2024-05-19T22:43:40 DUE TO TIME LIMIT ***
