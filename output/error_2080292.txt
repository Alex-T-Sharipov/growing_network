Training with a single process on 1 device (cuda:0).
WARNING: No pretrained configuration specified for MONet_T_16_double model. Using a default. Please add a config to the model pretrained_cfg registry or pass explicitly.
Model MONet_T_16_double created, param count:17509380
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.875
	crop_mode: center
AMP not enabled. Training in float32.
/home/sharipov/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Scheduled epochs: 300. LR stepped per epoch.
Train: 0 [   0/3167 (  0%)]  Loss: 4.61 (4.61)  Time: 4.103s,    9.75/s  (4.103s,    9.75/s)  LR: 1.000e-05  Data: 1.475 (1.475)
Train: 0 [  50/3167 (  2%)]  Loss: 4.58 (4.60)  Time: 0.616s,   64.91/s  (0.681s,   58.72/s)  LR: 1.000e-05  Data: 0.014 (0.040)
Train: 0 [ 100/3167 (  3%)]  Loss: 4.58 (4.59)  Time: 0.594s,   67.40/s  (0.640s,   62.47/s)  LR: 1.000e-05  Data: 0.004 (0.023)
Train: 0 [ 150/3167 (  5%)]  Loss: 4.52 (4.58)  Time: 0.596s,   67.09/s  (0.626s,   63.91/s)  LR: 1.000e-05  Data: 0.006 (0.017)
Train: 0 [ 200/3167 (  6%)]  Loss: 4.54 (4.57)  Time: 0.605s,   66.15/s  (0.619s,   64.66/s)  LR: 1.000e-05  Data: 0.007 (0.014)
Train: 0 [ 250/3167 (  8%)]  Loss: 4.52 (4.56)  Time: 0.593s,   67.40/s  (0.614s,   65.13/s)  LR: 1.000e-05  Data: 0.004 (0.012)
Train: 0 [ 300/3167 (  9%)]  Loss: 4.56 (4.55)  Time: 0.596s,   67.12/s  (0.611s,   65.43/s)  LR: 1.000e-05  Data: 0.004 (0.011)
Train: 0 [ 350/3167 ( 11%)]  Loss: 4.51 (4.55)  Time: 0.600s,   66.63/s  (0.609s,   65.67/s)  LR: 1.000e-05  Data: 0.007 (0.010)
Train: 0 [ 400/3167 ( 13%)]  Loss: 4.44 (4.54)  Time: 0.602s,   66.41/s  (0.608s,   65.84/s)  LR: 1.000e-05  Data: 0.004 (0.009)
Train: 0 [ 450/3167 ( 14%)]  Loss: 4.46 (4.53)  Time: 0.596s,   67.14/s  (0.606s,   65.98/s)  LR: 1.000e-05  Data: 0.004 (0.009)
Train: 0 [ 500/3167 ( 16%)]  Loss: 4.48 (4.53)  Time: 0.594s,   67.37/s  (0.605s,   66.09/s)  LR: 1.000e-05  Data: 0.004 (0.008)
Train: 0 [ 550/3167 ( 17%)]  Loss: 4.52 (4.52)  Time: 0.597s,   67.03/s  (0.604s,   66.18/s)  LR: 1.000e-05  Data: 0.007 (0.008)
Train: 0 [ 600/3167 ( 19%)]  Loss: 4.53 (4.52)  Time: 0.594s,   67.38/s  (0.604s,   66.26/s)  LR: 1.000e-05  Data: 0.004 (0.008)
Train: 0 [ 650/3167 ( 21%)]  Loss: 4.45 (4.52)  Time: 0.599s,   66.83/s  (0.603s,   66.31/s)  LR: 1.000e-05  Data: 0.007 (0.007)
Train: 0 [ 700/3167 ( 22%)]  Loss: 4.25 (4.51)  Time: 0.594s,   67.35/s  (0.603s,   66.37/s)  LR: 1.000e-05  Data: 0.004 (0.007)
Train: 0 [ 750/3167 ( 24%)]  Loss: 4.55 (4.51)  Time: 0.598s,   66.94/s  (0.602s,   66.41/s)  LR: 1.000e-05  Data: 0.007 (0.007)
Train: 0 [ 800/3167 ( 25%)]  Loss: 4.32 (4.51)  Time: 0.596s,   67.10/s  (0.602s,   66.45/s)  LR: 1.000e-05  Data: 0.007 (0.007)
Train: 0 [ 850/3167 ( 27%)]  Loss: 4.38 (4.50)  Time: 0.593s,   67.42/s  (0.602s,   66.48/s)  LR: 1.000e-05  Data: 0.004 (0.007)
Train: 0 [ 900/3167 ( 28%)]  Loss: 4.52 (4.50)  Time: 0.596s,   67.12/s  (0.601s,   66.51/s)  LR: 1.000e-05  Data: 0.006 (0.007)
Train: 0 [ 950/3167 ( 30%)]  Loss: 4.46 (4.50)  Time: 0.595s,   67.18/s  (0.601s,   66.55/s)  LR: 1.000e-05  Data: 0.004 (0.007)
Train: 0 [1000/3167 ( 32%)]  Loss: 4.41 (4.50)  Time: 0.595s,   67.24/s  (0.601s,   66.58/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1050/3167 ( 33%)]  Loss: 4.46 (4.49)  Time: 0.594s,   67.39/s  (0.601s,   66.60/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1100/3167 ( 35%)]  Loss: 4.55 (4.49)  Time: 0.596s,   67.11/s  (0.600s,   66.62/s)  LR: 1.000e-05  Data: 0.006 (0.006)
Train: 0 [1150/3167 ( 36%)]  Loss: 4.61 (4.49)  Time: 0.604s,   66.22/s  (0.600s,   66.64/s)  LR: 1.000e-05  Data: 0.007 (0.006)
Train: 0 [1200/3167 ( 38%)]  Loss: 4.46 (4.49)  Time: 0.594s,   67.30/s  (0.600s,   66.66/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1250/3167 ( 39%)]  Loss: 4.48 (4.48)  Time: 0.603s,   66.38/s  (0.600s,   66.67/s)  LR: 1.000e-05  Data: 0.012 (0.006)
Train: 0 [1300/3167 ( 41%)]  Loss: 4.56 (4.48)  Time: 0.593s,   67.43/s  (0.600s,   66.69/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1350/3167 ( 43%)]  Loss: 4.45 (4.48)  Time: 0.593s,   67.43/s  (0.600s,   66.70/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1400/3167 ( 44%)]  Loss: 4.57 (4.48)  Time: 0.610s,   65.57/s  (0.600s,   66.71/s)  LR: 1.000e-05  Data: 0.007 (0.006)
Train: 0 [1450/3167 ( 46%)]  Loss: 4.47 (4.48)  Time: 0.596s,   67.15/s  (0.599s,   66.73/s)  LR: 1.000e-05  Data: 0.006 (0.006)
Train: 0 [1500/3167 ( 47%)]  Loss: 4.63 (4.48)  Time: 0.596s,   67.08/s  (0.599s,   66.74/s)  LR: 1.000e-05  Data: 0.007 (0.006)
Train: 0 [1550/3167 ( 49%)]  Loss: 4.59 (4.48)  Time: 0.595s,   67.18/s  (0.599s,   66.75/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1600/3167 ( 51%)]  Loss: 4.45 (4.47)  Time: 0.594s,   67.39/s  (0.599s,   66.76/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1650/3167 ( 52%)]  Loss: 4.39 (4.47)  Time: 0.593s,   67.44/s  (0.599s,   66.77/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1700/3167 ( 54%)]  Loss: 4.47 (4.47)  Time: 0.593s,   67.41/s  (0.599s,   66.78/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1750/3167 ( 55%)]  Loss: 4.39 (4.47)  Time: 0.594s,   67.38/s  (0.599s,   66.79/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1800/3167 ( 57%)]  Loss: 4.43 (4.47)  Time: 0.596s,   67.13/s  (0.599s,   66.80/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1850/3167 ( 58%)]  Loss: 4.31 (4.47)  Time: 0.594s,   67.34/s  (0.599s,   66.81/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1900/3167 ( 60%)]  Loss: 4.46 (4.47)  Time: 0.598s,   66.86/s  (0.599s,   66.82/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [1950/3167 ( 62%)]  Loss: 4.41 (4.47)  Time: 0.593s,   67.44/s  (0.599s,   66.82/s)  LR: 1.000e-05  Data: 0.004 (0.006)
Train: 0 [2000/3167 ( 63%)]  Loss: 4.19 (4.47)  Time: 0.601s,   66.54/s  (0.599s,   66.83/s)  LR: 1.000e-05  Data: 0.004 (0.005)
Train: 0 [2050/3167 ( 65%)]  Loss: 4.50 (4.47)  Time: 0.600s,   66.66/s  (0.598s,   66.84/s)  LR: 1.000e-05  Data: 0.007 (0.005)
Train: 0 [2100/3167 ( 66%)]  Loss: 4.39 (4.46)  Time: 0.594s,   67.36/s  (0.598s,   66.84/s)  LR: 1.000e-05  Data: 0.004 (0.005)
Train: 0 [2150/3167 ( 68%)]  Loss: 4.48 (4.46)  Time: 0.597s,   66.98/s  (0.598s,   66.85/s)  LR: 1.000e-05  Data: 0.004 (0.005)
Train: 0 [2200/3167 ( 69%)]  Loss: 4.43 (4.46)  Time: 0.593s,   67.44/s  (0.598s,   66.85/s)  LR: 1.000e-05  Data: 0.004 (0.005)
Train: 0 [2250/3167 ( 71%)]  Loss: 4.29 (4.46)  Time: 0.593s,   67.42/s  (0.598s,   66.86/s)  LR: 1.000e-05  Data: 0.004 (0.005)
Train: 0 [2300/3167 ( 73%)]  Loss: 4.40 (4.46)  Time: 0.597s,   67.01/s  (0.598s,   66.86/s)  LR: 1.000e-05  Data: 0.004 (0.005)
Train: 0 [2350/3167 ( 74%)]  Loss: 4.47 (4.46)  Time: 0.599s,   66.82/s  (0.598s,   66.87/s)  LR: 1.000e-05  Data: 0.009 (0.005)
Train: 0 [2400/3167 ( 76%)]  Loss: 4.53 (4.46)  Time: 0.597s,   67.05/s  (0.598s,   66.87/s)  LR: 1.000e-05  Data: 0.007 (0.005)
Train: 0 [2450/3167 ( 77%)]  Loss: 4.35 (4.46)  Time: 0.598s,   66.85/s  (0.598s,   66.88/s)  LR: 1.000e-05  Data: 0.009 (0.005)
Train: 0 [2500/3167 ( 79%)]  Loss: 4.26 (4.46)  Time: 0.597s,   67.05/s  (0.598s,   66.88/s)  LR: 1.000e-05  Data: 0.007 (0.005)
Train: 0 [2550/3167 ( 81%)]  Loss: 4.30 (4.46)  Time: 0.610s,   65.61/s  (0.598s,   66.89/s)  LR: 1.000e-05  Data: 0.007 (0.005)
Train: 0 [2600/3167 ( 82%)]  Loss: 4.43 (4.45)  Time: 0.602s,   66.43/s  (0.598s,   66.89/s)  LR: 1.000e-05  Data: 0.004 (0.005)
Train: 0 [2650/3167 ( 84%)]  Loss: 4.39 (4.45)  Time: 0.612s,   65.38/s  (0.598s,   66.89/s)  LR: 1.000e-05  Data: 0.006 (0.005)
Train: 0 [2700/3167 ( 85%)]  Loss: 4.40 (4.45)  Time: 0.596s,   67.15/s  (0.598s,   66.90/s)  LR: 1.000e-05  Data: 0.006 (0.005)
Train: 0 [2750/3167 ( 87%)]  Loss: 4.39 (4.45)  Time: 0.594s,   67.39/s  (0.598s,   66.90/s)  LR: 1.000e-05  Data: 0.004 (0.005)
Train: 0 [2800/3167 ( 88%)]  Loss: 4.42 (4.45)  Time: 0.593s,   67.42/s  (0.598s,   66.90/s)  LR: 1.000e-05  Data: 0.004 (0.005)
Train: 0 [2850/3167 ( 90%)]  Loss: 4.14 (4.45)  Time: 0.598s,   66.94/s  (0.598s,   66.91/s)  LR: 1.000e-05  Data: 0.004 (0.005)
Train: 0 [2900/3167 ( 92%)]  Loss: 4.46 (4.45)  Time: 0.595s,   67.26/s  (0.598s,   66.91/s)  LR: 1.000e-05  Data: 0.004 (0.005)
Train: 0 [2950/3167 ( 93%)]  Loss: 4.48 (4.45)  Time: 0.593s,   67.41/s  (0.598s,   66.91/s)  LR: 1.000e-05  Data: 0.004 (0.005)
Train: 0 [3000/3167 ( 95%)]  Loss: 4.32 (4.45)  Time: 0.595s,   67.19/s  (0.598s,   66.91/s)  LR: 1.000e-05  Data: 0.004 (0.005)
Train: 0 [3050/3167 ( 96%)]  Loss: 4.54 (4.45)  Time: 0.596s,   67.13/s  (0.598s,   66.92/s)  LR: 1.000e-05  Data: 0.004 (0.005)
Train: 0 [3100/3167 ( 98%)]  Loss: 4.58 (4.45)  Time: 0.599s,   66.72/s  (0.598s,   66.92/s)  LR: 1.000e-05  Data: 0.010 (0.005)
Train: 0 [3150/3167 ( 99%)]  Loss: 4.54 (4.45)  Time: 0.593s,   67.42/s  (0.598s,   66.92/s)  LR: 1.000e-05  Data: 0.004 (0.005)
Test: [   0/3167]  Time: 2.778 (2.778)  Loss:   4.324 ( 4.324)  Acc@1:   2.500 (  2.500)  Acc@5:  15.000 ( 15.000)
Test: [  50/3167]  Time: 0.190 (0.245)  Loss:   4.111 ( 4.132)  Acc@1:  10.000 (  5.784)  Acc@5:  42.500 ( 30.098)
Test: [ 100/3167]  Time: 0.196 (0.218)  Loss:   4.414 ( 4.159)  Acc@1:   0.000 (  5.520)  Acc@5:   2.500 ( 27.376)
Test: [ 150/3167]  Time: 0.195 (0.209)  Loss:   3.744 ( 4.164)  Acc@1:  17.500 (  5.894)  Acc@5:  70.000 ( 26.970)
Test: [ 200/3167]  Time: 0.191 (0.205)  Loss:   4.490 ( 4.210)  Acc@1:   0.000 (  5.398)  Acc@5:   0.000 ( 23.557)
Test: [ 250/3167]  Time: 0.191 (0.203)  Loss:   4.556 ( 4.263)  Acc@1:   0.000 (  4.462)  Acc@5:  10.000 ( 19.691)
Test: [ 300/3167]  Time: 0.189 (0.201)  Loss:   4.002 ( 4.273)  Acc@1:   0.000 (  3.762)  Acc@5:  52.500 ( 20.025)
Test: [ 350/3167]  Time: 0.198 (0.200)  Loss:   3.989 ( 4.246)  Acc@1:  30.000 (  4.872)  Acc@5:  55.000 ( 23.625)
Test: [ 400/3167]  Time: 0.186 (0.199)  Loss:   4.122 ( 4.127)  Acc@1:   0.000 ( 10.536)  Acc@5:  42.500 ( 29.046)
Test: [ 450/3167]  Time: 0.190 (0.198)  Loss:   4.179 ( 4.134)  Acc@1:   0.000 (  9.468)  Acc@5:  27.500 ( 28.664)
Test: [ 500/3167]  Time: 0.193 (0.198)  Loss:   4.419 ( 4.165)  Acc@1:   2.500 (  8.598)  Acc@5:  15.000 ( 26.577)
Test: [ 550/3167]  Time: 0.190 (0.197)  Loss:   4.608 ( 4.126)  Acc@1:   0.000 (  9.560)  Acc@5:   0.000 ( 28.553)
Test: [ 600/3167]  Time: 0.191 (0.197)  Loss:   3.731 ( 4.142)  Acc@1:   5.000 (  9.014)  Acc@5:  42.500 ( 27.874)
Test: [ 650/3167]  Time: 0.191 (0.197)  Loss:   4.439 ( 4.138)  Acc@1:   0.000 (  8.909)  Acc@5:   2.500 ( 28.237)
Test: [ 700/3167]  Time: 0.194 (0.196)  Loss:   4.347 ( 4.156)  Acc@1:   0.000 (  8.306)  Acc@5:   7.500 ( 26.680)
Test: [ 750/3167]  Time: 0.203 (0.196)  Loss:   3.975 ( 4.155)  Acc@1:   5.000 (  8.063)  Acc@5:  45.000 ( 26.428)
Test: [ 800/3167]  Time: 0.191 (0.196)  Loss:   4.429 ( 4.155)  Acc@1:   0.000 (  7.971)  Acc@5:  10.000 ( 26.414)
Test: [ 850/3167]  Time: 0.201 (0.196)  Loss:   4.448 ( 4.173)  Acc@1:   0.000 (  7.515)  Acc@5:   0.000 ( 25.068)
Test: [ 900/3167]  Time: 0.201 (0.196)  Loss:   4.410 ( 4.188)  Acc@1:   0.000 (  7.100)  Acc@5:   5.000 ( 23.782)
Test: [ 950/3167]  Time: 0.198 (0.196)  Loss:   4.219 ( 4.200)  Acc@1:   0.000 (  6.743)  Acc@5:  10.000 ( 22.805)
Test: [1000/3167]  Time: 0.202 (0.196)  Loss:   4.285 ( 4.210)  Acc@1:   0.000 (  6.411)  Acc@5:  15.000 ( 21.966)
Test: [1050/3167]  Time: 0.192 (0.195)  Loss:   3.954 ( 4.202)  Acc@1:   7.500 (  6.287)  Acc@5:  32.500 ( 22.136)
Test: [1100/3167]  Time: 0.193 (0.195)  Loss:   4.384 ( 4.209)  Acc@1:   0.000 (  6.051)  Acc@5:  10.000 ( 21.417)
Test: [1150/3167]  Time: 0.191 (0.195)  Loss:   3.927 ( 4.206)  Acc@1:  12.500 (  5.967)  Acc@5:  42.500 ( 21.846)
Test: [1200/3167]  Time: 0.201 (0.195)  Loss:   3.090 ( 4.190)  Acc@1:  45.000 (  6.703)  Acc@5:  82.500 ( 23.112)
Test: [1250/3167]  Time: 0.194 (0.195)  Loss:   3.511 ( 4.162)  Acc@1:  62.500 (  8.501)  Acc@5:  80.000 ( 24.988)
Test: [1300/3167]  Time: 0.186 (0.195)  Loss:   4.240 ( 4.169)  Acc@1:   0.000 (  8.236)  Acc@5:   5.000 ( 24.347)
Test: [1350/3167]  Time: 0.186 (0.195)  Loss:   4.410 ( 4.183)  Acc@1:   0.000 (  7.931)  Acc@5:   5.000 ( 23.614)
Test: [1400/3167]  Time: 0.184 (0.195)  Loss:   3.711 ( 4.194)  Acc@1:  22.500 (  7.711)  Acc@5:  62.500 ( 23.112)
Test: [1450/3167]  Time: 0.193 (0.194)  Loss:   4.488 ( 4.189)  Acc@1:   0.000 (  7.936)  Acc@5:   0.000 ( 23.744)
Test: [1500/3167]  Time: 0.186 (0.194)  Loss:   4.262 ( 4.166)  Acc@1:   2.500 (  9.051)  Acc@5:  15.000 ( 24.580)
Test: [1550/3167]  Time: 0.185 (0.194)  Loss:   4.074 ( 4.168)  Acc@1:   2.500 (  8.836)  Acc@5:  27.500 ( 24.600)
Test: [1600/3167]  Time: 0.202 (0.194)  Loss:   2.955 ( 4.160)  Acc@1:  37.500 (  8.927)  Acc@5:  77.500 ( 25.273)
Test: [1650/3167]  Time: 0.198 (0.194)  Loss:   4.029 ( 4.141)  Acc@1:   2.500 (  9.499)  Acc@5:  32.500 ( 26.105)
Test: [1700/3167]  Time: 0.196 (0.194)  Loss:   4.169 ( 4.136)  Acc@1:   2.500 (  9.277)  Acc@5:  20.000 ( 26.549)
Test: [1750/3167]  Time: 0.189 (0.194)  Loss:   4.072 ( 4.137)  Acc@1:   0.000 (  9.076)  Acc@5:  27.500 ( 26.630)
Test: [1800/3167]  Time: 0.185 (0.194)  Loss:   4.303 ( 4.138)  Acc@1:   0.000 (  8.977)  Acc@5:  12.500 ( 26.696)
Test: [1850/3167]  Time: 0.187 (0.194)  Loss:   4.554 ( 4.147)  Acc@1:   0.000 (  8.734)  Acc@5:   5.000 ( 26.045)
Test: [1900/3167]  Time: 0.190 (0.194)  Loss:   4.550 ( 4.156)  Acc@1:   0.000 (  8.509)  Acc@5:   0.000 ( 25.464)
Test: [1950/3167]  Time: 0.189 (0.194)  Loss:   4.542 ( 4.162)  Acc@1:   0.000 (  8.330)  Acc@5:   0.000 ( 25.124)
Test: [2000/3167]  Time: 0.188 (0.194)  Loss:   4.708 ( 4.175)  Acc@1:   0.000 (  8.122)  Acc@5:   0.000 ( 24.553)
Test: [2050/3167]  Time: 0.196 (0.194)  Loss:   4.545 ( 4.185)  Acc@1:   0.000 (  7.924)  Acc@5:   0.000 ( 23.955)
Test: [2100/3167]  Time: 0.195 (0.194)  Loss:   4.327 ( 4.185)  Acc@1:   5.000 (  8.089)  Acc@5:  17.500 ( 24.243)
Test: [2150/3167]  Time: 0.194 (0.193)  Loss:   2.002 ( 4.160)  Acc@1:  77.500 (  8.909)  Acc@5:  90.000 ( 24.905)
Test: [2200/3167]  Time: 0.186 (0.193)  Loss:   4.354 ( 4.157)  Acc@1:   0.000 (  9.019)  Acc@5:  15.000 ( 25.216)
Test: [2250/3167]  Time: 0.187 (0.193)  Loss:   4.018 ( 4.163)  Acc@1:   0.000 (  8.829)  Acc@5:  50.000 ( 25.060)
Test: [2300/3167]  Time: 0.188 (0.193)  Loss:   4.375 ( 4.168)  Acc@1:   0.000 (  8.659)  Acc@5:  12.500 ( 24.963)
Test: [2350/3167]  Time: 0.206 (0.193)  Loss:   4.149 ( 4.170)  Acc@1:  10.000 (  8.573)  Acc@5:  50.000 ( 24.860)
Test: [2400/3167]  Time: 0.184 (0.193)  Loss:   4.458 ( 4.169)  Acc@1:   0.000 (  8.786)  Acc@5:   5.000 ( 25.019)
Test: [2450/3167]  Time: 0.193 (0.193)  Loss:   4.084 ( 4.171)  Acc@1:   5.000 (  8.632)  Acc@5:  22.500 ( 24.768)
Test: [2500/3167]  Time: 0.187 (0.193)  Loss:   4.317 ( 4.171)  Acc@1:   5.000 (  8.620)  Acc@5:  30.000 ( 24.994)
Test: [2550/3167]  Time: 0.200 (0.193)  Loss:   4.140 ( 4.166)  Acc@1:   0.000 (  8.569)  Acc@5:  17.500 ( 25.496)
Test: [2600/3167]  Time: 0.184 (0.193)  Loss:   3.987 ( 4.165)  Acc@1:   5.000 (  8.470)  Acc@5:  32.500 ( 25.461)
Test: [2650/3167]  Time: 0.195 (0.193)  Loss:   4.319 ( 4.168)  Acc@1:   2.500 (  8.342)  Acc@5:  20.000 ( 25.253)
Test: [2700/3167]  Time: 0.184 (0.193)  Loss:   4.189 ( 4.170)  Acc@1:   2.500 (  8.233)  Acc@5:  27.500 ( 25.268)
Test: [2750/3167]  Time: 0.187 (0.193)  Loss:   3.950 ( 4.171)  Acc@1:   2.500 (  8.120)  Acc@5:  45.000 ( 25.246)
Test: [2800/3167]  Time: 0.187 (0.193)  Loss:   4.213 ( 4.171)  Acc@1:   0.000 (  8.036)  Acc@5:  27.500 ( 25.403)
Test: [2850/3167]  Time: 0.189 (0.193)  Loss:   3.957 ( 4.174)  Acc@1:   2.500 (  7.919)  Acc@5:  55.000 ( 25.258)
Test: [2900/3167]  Time: 0.184 (0.193)  Loss:   4.182 ( 4.172)  Acc@1:   2.500 (  7.834)  Acc@5:  20.000 ( 25.367)
Test: [2950/3167]  Time: 0.200 (0.193)  Loss:   4.334 ( 4.175)  Acc@1:   0.000 (  7.702)  Acc@5:  10.000 ( 24.999)
Test: [3000/3167]  Time: 0.187 (0.193)  Loss:   4.329 ( 4.178)  Acc@1:   0.000 (  7.575)  Acc@5:   0.000 ( 24.633)
Test: [3050/3167]  Time: 0.184 (0.193)  Loss:   4.415 ( 4.179)  Acc@1:   0.000 (  7.502)  Acc@5:   0.000 ( 24.477)
Test: [3100/3167]  Time: 0.185 (0.193)  Loss:   4.255 ( 4.182)  Acc@1:   0.000 (  7.385)  Acc@5:  20.000 ( 24.245)
Test: [3150/3167]  Time: 0.184 (0.193)  Loss:   4.464 ( 4.186)  Acc@1:   0.000 (  7.272)  Acc@5:   2.500 ( 23.927)
Test: [3167/3167]  Time: 0.118 (0.193)  Loss:   4.452 ( 4.187)  Acc@1:   0.000 (  7.234)  Acc@5:   0.000 ( 23.818)
Test: [   0/124]  Time: 1.776 (1.776)  Loss:   4.316 ( 4.316)  Acc@1:   0.000 (  0.000)  Acc@5:  10.000 ( 10.000)
Test: [  50/124]  Time: 0.185 (0.222)  Loss:   4.367 ( 4.204)  Acc@1:   0.000 (  7.255)  Acc@5:  12.500 ( 23.725)
Test: [ 100/124]  Time: 0.194 (0.207)  Loss:   3.542 ( 4.205)  Acc@1:   5.000 (  7.450)  Acc@5:  70.000 ( 25.025)
Test: [ 124/124]  Time: 0.180 (0.203)  Loss:   4.449 ( 4.220)  Acc@1:   0.000 (  6.320)  Acc@5:   2.500 ( 23.260)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_0/checkpoint-0.pth.tar', 7.234250803147866)

Train: 1 [   0/3167 (  0%)]  Loss: 4.38 (4.38)  Time: 1.164s,   34.37/s  (1.164s,   34.37/s)  LR: 1.900e-05  Data: 0.544 (0.544)
Train: 1 [  50/3167 (  2%)]  Loss: 4.40 (4.40)  Time: 0.601s,   66.55/s  (0.615s,   65.08/s)  LR: 1.900e-05  Data: 0.010 (0.021)
Train: 1 [ 100/3167 (  3%)]  Loss: 4.22 (4.38)  Time: 0.593s,   67.43/s  (0.609s,   65.67/s)  LR: 1.900e-05  Data: 0.004 (0.016)
Train: 1 [ 150/3167 (  5%)]  Loss: 4.50 (4.39)  Time: 0.596s,   67.12/s  (0.607s,   65.93/s)  LR: 1.900e-05  Data: 0.006 (0.014)
Train: 1 [ 200/3167 (  6%)]  Loss: 4.33 (4.39)  Time: 0.600s,   66.62/s  (0.606s,   66.01/s)  LR: 1.900e-05  Data: 0.009 (0.013)
Train: 1 [ 250/3167 (  8%)]  Loss: 4.29 (4.39)  Time: 0.608s,   65.76/s  (0.605s,   66.07/s)  LR: 1.900e-05  Data: 0.011 (0.012)
Train: 1 [ 300/3167 (  9%)]  Loss: 4.44 (4.39)  Time: 0.601s,   66.59/s  (0.605s,   66.12/s)  LR: 1.900e-05  Data: 0.012 (0.012)
Train: 1 [ 350/3167 ( 11%)]  Loss: 4.23 (4.40)  Time: 0.593s,   67.47/s  (0.605s,   66.16/s)  LR: 1.900e-05  Data: 0.004 (0.012)
Train: 1 [ 400/3167 ( 13%)]  Loss: 4.11 (4.40)  Time: 0.601s,   66.59/s  (0.604s,   66.19/s)  LR: 1.900e-05  Data: 0.009 (0.012)
Train: 1 [ 450/3167 ( 14%)]  Loss: 4.59 (4.39)  Time: 0.601s,   66.61/s  (0.604s,   66.21/s)  LR: 1.900e-05  Data: 0.012 (0.011)
Train: 1 [ 500/3167 ( 16%)]  Loss: 4.33 (4.40)  Time: 0.611s,   65.48/s  (0.604s,   66.23/s)  LR: 1.900e-05  Data: 0.012 (0.011)
Train: 1 [ 550/3167 ( 17%)]  Loss: 4.24 (4.39)  Time: 0.603s,   66.33/s  (0.604s,   66.24/s)  LR: 1.900e-05  Data: 0.009 (0.011)
Train: 1 [ 600/3167 ( 19%)]  Loss: 4.23 (4.39)  Time: 0.600s,   66.63/s  (0.604s,   66.25/s)  LR: 1.900e-05  Data: 0.011 (0.011)
Train: 1 [ 650/3167 ( 21%)]  Loss: 4.39 (4.39)  Time: 0.606s,   66.05/s  (0.604s,   66.27/s)  LR: 1.900e-05  Data: 0.012 (0.011)
Train: 1 [ 700/3167 ( 22%)]  Loss: 4.34 (4.39)  Time: 0.598s,   66.84/s  (0.604s,   66.28/s)  LR: 1.900e-05  Data: 0.009 (0.011)
Train: 1 [ 750/3167 ( 24%)]  Loss: 4.22 (4.39)  Time: 0.603s,   66.36/s  (0.603s,   66.29/s)  LR: 1.900e-05  Data: 0.011 (0.011)
Train: 1 [ 800/3167 ( 25%)]  Loss: 4.28 (4.39)  Time: 0.599s,   66.80/s  (0.603s,   66.30/s)  LR: 1.900e-05  Data: 0.010 (0.011)
Train: 1 [ 850/3167 ( 27%)]  Loss: 4.28 (4.39)  Time: 0.598s,   66.86/s  (0.603s,   66.31/s)  LR: 1.900e-05  Data: 0.007 (0.011)
Train: 1 [ 900/3167 ( 28%)]  Loss: 4.31 (4.39)  Time: 0.608s,   65.77/s  (0.603s,   66.32/s)  LR: 1.900e-05  Data: 0.012 (0.011)
Train: 1 [ 950/3167 ( 30%)]  Loss: 4.33 (4.39)  Time: 0.600s,   66.62/s  (0.603s,   66.32/s)  LR: 1.900e-05  Data: 0.011 (0.011)
Train: 1 [1000/3167 ( 32%)]  Loss: 4.42 (4.39)  Time: 0.604s,   66.18/s  (0.603s,   66.33/s)  LR: 1.900e-05  Data: 0.010 (0.011)
Train: 1 [1050/3167 ( 33%)]  Loss: 4.35 (4.38)  Time: 0.593s,   67.48/s  (0.603s,   66.34/s)  LR: 1.900e-05  Data: 0.004 (0.010)
Train: 1 [1100/3167 ( 35%)]  Loss: 4.42 (4.38)  Time: 0.604s,   66.28/s  (0.603s,   66.35/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [1150/3167 ( 36%)]  Loss: 4.50 (4.38)  Time: 0.602s,   66.46/s  (0.603s,   66.36/s)  LR: 1.900e-05  Data: 0.011 (0.010)
Train: 1 [1200/3167 ( 38%)]  Loss: 4.52 (4.38)  Time: 0.605s,   66.17/s  (0.603s,   66.36/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [1250/3167 ( 39%)]  Loss: 4.30 (4.38)  Time: 0.598s,   66.90/s  (0.603s,   66.36/s)  LR: 1.900e-05  Data: 0.009 (0.010)
Train: 1 [1300/3167 ( 41%)]  Loss: 4.49 (4.38)  Time: 0.603s,   66.30/s  (0.603s,   66.37/s)  LR: 1.900e-05  Data: 0.011 (0.010)
Train: 1 [1350/3167 ( 43%)]  Loss: 4.15 (4.38)  Time: 0.600s,   66.66/s  (0.603s,   66.38/s)  LR: 1.900e-05  Data: 0.011 (0.010)
Train: 1 [1400/3167 ( 44%)]  Loss: 4.41 (4.38)  Time: 0.593s,   67.46/s  (0.603s,   66.39/s)  LR: 1.900e-05  Data: 0.004 (0.010)
Train: 1 [1450/3167 ( 46%)]  Loss: 4.30 (4.38)  Time: 0.600s,   66.70/s  (0.602s,   66.40/s)  LR: 1.900e-05  Data: 0.009 (0.010)
Train: 1 [1500/3167 ( 47%)]  Loss: 4.41 (4.38)  Time: 0.595s,   67.24/s  (0.602s,   66.41/s)  LR: 1.900e-05  Data: 0.004 (0.010)
Train: 1 [1550/3167 ( 49%)]  Loss: 4.52 (4.38)  Time: 0.596s,   67.12/s  (0.602s,   66.41/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [1600/3167 ( 51%)]  Loss: 4.28 (4.38)  Time: 0.598s,   66.90/s  (0.602s,   66.42/s)  LR: 1.900e-05  Data: 0.009 (0.010)
Train: 1 [1650/3167 ( 52%)]  Loss: 4.40 (4.38)  Time: 0.602s,   66.40/s  (0.602s,   66.42/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [1700/3167 ( 54%)]  Loss: 4.32 (4.38)  Time: 0.593s,   67.44/s  (0.602s,   66.43/s)  LR: 1.900e-05  Data: 0.004 (0.010)
Train: 1 [1750/3167 ( 55%)]  Loss: 4.28 (4.38)  Time: 0.605s,   66.15/s  (0.602s,   66.44/s)  LR: 1.900e-05  Data: 0.009 (0.010)
Train: 1 [1800/3167 ( 57%)]  Loss: 4.42 (4.38)  Time: 0.601s,   66.60/s  (0.602s,   66.44/s)  LR: 1.900e-05  Data: 0.011 (0.010)
Train: 1 [1850/3167 ( 58%)]  Loss: 4.25 (4.38)  Time: 0.598s,   66.89/s  (0.602s,   66.45/s)  LR: 1.900e-05  Data: 0.007 (0.010)
Train: 1 [1900/3167 ( 60%)]  Loss: 4.38 (4.38)  Time: 0.593s,   67.42/s  (0.602s,   66.45/s)  LR: 1.900e-05  Data: 0.004 (0.010)
Train: 1 [1950/3167 ( 62%)]  Loss: 4.41 (4.38)  Time: 0.601s,   66.59/s  (0.602s,   66.46/s)  LR: 1.900e-05  Data: 0.006 (0.010)
Train: 1 [2000/3167 ( 63%)]  Loss: 4.28 (4.38)  Time: 0.601s,   66.58/s  (0.602s,   66.46/s)  LR: 1.900e-05  Data: 0.004 (0.010)
Train: 1 [2050/3167 ( 65%)]  Loss: 4.38 (4.38)  Time: 0.596s,   67.08/s  (0.602s,   66.47/s)  LR: 1.900e-05  Data: 0.004 (0.010)
Train: 1 [2100/3167 ( 66%)]  Loss: 4.48 (4.38)  Time: 0.596s,   67.16/s  (0.602s,   66.48/s)  LR: 1.900e-05  Data: 0.006 (0.010)
Train: 1 [2150/3167 ( 68%)]  Loss: 4.27 (4.38)  Time: 0.603s,   66.32/s  (0.602s,   66.48/s)  LR: 1.900e-05  Data: 0.014 (0.010)
Train: 1 [2200/3167 ( 69%)]  Loss: 4.22 (4.38)  Time: 0.601s,   66.59/s  (0.602s,   66.49/s)  LR: 1.900e-05  Data: 0.012 (0.010)
Train: 1 [2250/3167 ( 71%)]  Loss: 4.38 (4.38)  Time: 0.598s,   66.85/s  (0.601s,   66.50/s)  LR: 1.900e-05  Data: 0.009 (0.010)
Train: 1 [2300/3167 ( 73%)]  Loss: 4.42 (4.37)  Time: 0.593s,   67.43/s  (0.601s,   66.51/s)  LR: 1.900e-05  Data: 0.004 (0.010)
Train: 1 [2350/3167 ( 74%)]  Loss: 4.34 (4.37)  Time: 0.601s,   66.60/s  (0.601s,   66.52/s)  LR: 1.900e-05  Data: 0.009 (0.009)
Train: 1 [2400/3167 ( 76%)]  Loss: 4.25 (4.37)  Time: 0.596s,   67.09/s  (0.601s,   66.53/s)  LR: 1.900e-05  Data: 0.007 (0.009)
Train: 1 [2450/3167 ( 77%)]  Loss: 4.54 (4.37)  Time: 0.595s,   67.18/s  (0.601s,   66.54/s)  LR: 1.900e-05  Data: 0.006 (0.009)
Train: 1 [2500/3167 ( 79%)]  Loss: 4.24 (4.37)  Time: 0.596s,   67.14/s  (0.601s,   66.55/s)  LR: 1.900e-05  Data: 0.007 (0.009)
Train: 1 [2550/3167 ( 81%)]  Loss: 4.58 (4.37)  Time: 0.593s,   67.42/s  (0.601s,   66.55/s)  LR: 1.900e-05  Data: 0.004 (0.009)
Train: 1 [2600/3167 ( 82%)]  Loss: 4.44 (4.37)  Time: 0.596s,   67.14/s  (0.601s,   66.56/s)  LR: 1.900e-05  Data: 0.007 (0.009)
Train: 1 [2650/3167 ( 84%)]  Loss: 4.23 (4.37)  Time: 0.601s,   66.53/s  (0.601s,   66.57/s)  LR: 1.900e-05  Data: 0.010 (0.009)
Train: 1 [2700/3167 ( 85%)]  Loss: 4.36 (4.37)  Time: 0.596s,   67.09/s  (0.601s,   66.58/s)  LR: 1.900e-05  Data: 0.007 (0.009)
Train: 1 [2750/3167 ( 87%)]  Loss: 4.63 (4.37)  Time: 0.596s,   67.10/s  (0.601s,   66.59/s)  LR: 1.900e-05  Data: 0.007 (0.009)
Train: 1 [2800/3167 ( 88%)]  Loss: 4.40 (4.37)  Time: 0.598s,   66.89/s  (0.601s,   66.60/s)  LR: 1.900e-05  Data: 0.009 (0.009)
Train: 1 [2850/3167 ( 90%)]  Loss: 4.40 (4.37)  Time: 0.593s,   67.44/s  (0.601s,   66.61/s)  LR: 1.900e-05  Data: 0.004 (0.009)
Train: 1 [2900/3167 ( 92%)]  Loss: 4.59 (4.37)  Time: 0.593s,   67.45/s  (0.600s,   66.62/s)  LR: 1.900e-05  Data: 0.004 (0.009)
Train: 1 [2950/3167 ( 93%)]  Loss: 4.37 (4.37)  Time: 0.593s,   67.41/s  (0.600s,   66.62/s)  LR: 1.900e-05  Data: 0.004 (0.009)
Train: 1 [3000/3167 ( 95%)]  Loss: 4.12 (4.37)  Time: 0.593s,   67.44/s  (0.600s,   66.63/s)  LR: 1.900e-05  Data: 0.004 (0.009)
Train: 1 [3050/3167 ( 96%)]  Loss: 4.40 (4.37)  Time: 0.596s,   67.10/s  (0.600s,   66.63/s)  LR: 1.900e-05  Data: 0.007 (0.009)
Train: 1 [3100/3167 ( 98%)]  Loss: 4.31 (4.36)  Time: 0.598s,   66.86/s  (0.600s,   66.64/s)  LR: 1.900e-05  Data: 0.006 (0.009)
Train: 1 [3150/3167 ( 99%)]  Loss: 4.14 (4.36)  Time: 0.594s,   67.40/s  (0.600s,   66.65/s)  LR: 1.900e-05  Data: 0.004 (0.009)
Test: [   0/3167]  Time: 0.512 (0.512)  Loss:   4.181 ( 4.181)  Acc@1:  10.000 ( 10.000)  Acc@5:  20.000 ( 20.000)
Test: [  50/3167]  Time: 0.189 (0.198)  Loss:   4.144 ( 4.085)  Acc@1:  20.000 (  9.363)  Acc@5:  35.000 ( 33.284)
Test: [ 100/3167]  Time: 0.191 (0.195)  Loss:   4.439 ( 4.173)  Acc@1:   0.000 (  6.683)  Acc@5:   5.000 ( 24.629)
Test: [ 150/3167]  Time: 0.191 (0.193)  Loss:   3.446 ( 4.138)  Acc@1:  10.000 (  6.540)  Acc@5:  65.000 ( 26.540)
Test: [ 200/3167]  Time: 0.191 (0.193)  Loss:   4.282 ( 4.168)  Acc@1:   0.000 (  5.585)  Acc@5:   7.500 ( 23.843)
Test: [ 250/3167]  Time: 0.190 (0.193)  Loss:   4.437 ( 4.194)  Acc@1:   2.500 (  4.612)  Acc@5:   5.000 ( 20.269)
Test: [ 300/3167]  Time: 0.191 (0.193)  Loss:   4.010 ( 4.214)  Acc@1:   0.000 (  4.344)  Acc@5:  40.000 ( 20.523)
Test: [ 350/3167]  Time: 0.191 (0.192)  Loss:   3.274 ( 4.131)  Acc@1:  50.000 (  7.528)  Acc@5:  67.500 ( 24.964)
Test: [ 400/3167]  Time: 0.193 (0.192)  Loss:   3.800 ( 4.013)  Acc@1:  20.000 ( 12.556)  Acc@5:  52.500 ( 30.536)
Test: [ 450/3167]  Time: 0.189 (0.192)  Loss:   3.877 ( 4.002)  Acc@1:   5.000 ( 11.857)  Acc@5:  35.000 ( 30.837)
Test: [ 500/3167]  Time: 0.190 (0.192)  Loss:   4.506 ( 4.051)  Acc@1:   0.000 ( 10.689)  Acc@5:   5.000 ( 28.249)
Test: [ 550/3167]  Time: 0.200 (0.192)  Loss:   4.566 ( 4.014)  Acc@1:   0.000 ( 12.232)  Acc@5:   0.000 ( 29.714)
Test: [ 600/3167]  Time: 0.191 (0.192)  Loss:   3.388 ( 4.026)  Acc@1:   7.500 ( 11.722)  Acc@5:  60.000 ( 29.122)
Test: [ 650/3167]  Time: 0.190 (0.192)  Loss:   4.503 ( 3.990)  Acc@1:   0.000 ( 12.761)  Acc@5:   5.000 ( 30.614)
Test: [ 700/3167]  Time: 0.197 (0.192)  Loss:   3.776 ( 4.001)  Acc@1:  12.500 ( 12.115)  Acc@5:  52.500 ( 30.207)
Test: [ 750/3167]  Time: 0.191 (0.192)  Loss:   3.637 ( 3.993)  Acc@1:  17.500 ( 11.674)  Acc@5:  47.500 ( 30.220)
Test: [ 800/3167]  Time: 0.189 (0.192)  Loss:   4.550 ( 3.997)  Acc@1:   0.000 ( 11.495)  Acc@5:  10.000 ( 30.278)
Test: [ 850/3167]  Time: 0.191 (0.192)  Loss:   4.297 ( 4.018)  Acc@1:   0.000 ( 10.984)  Acc@5:   7.500 ( 29.650)
Test: [ 900/3167]  Time: 0.189 (0.192)  Loss:   4.276 ( 4.034)  Acc@1:   7.500 ( 10.522)  Acc@5:  20.000 ( 28.982)
Test: [ 950/3167]  Time: 0.191 (0.192)  Loss:   3.773 ( 4.044)  Acc@1:   2.500 ( 10.110)  Acc@5:  37.500 ( 28.228)
Test: [1000/3167]  Time: 0.196 (0.192)  Loss:   4.230 ( 4.050)  Acc@1:   0.000 (  9.723)  Acc@5:  12.500 ( 27.413)
Test: [1050/3167]  Time: 0.186 (0.192)  Loss:   3.908 ( 4.048)  Acc@1:   0.000 (  9.460)  Acc@5:  42.500 ( 27.369)
Test: [1100/3167]  Time: 0.190 (0.192)  Loss:   4.314 ( 4.050)  Acc@1:   2.500 (  9.078)  Acc@5:   7.500 ( 26.885)
Test: [1150/3167]  Time: 0.201 (0.192)  Loss:   3.647 ( 4.046)  Acc@1:  30.000 (  9.272)  Acc@5:  62.500 ( 27.389)
Test: [1200/3167]  Time: 0.204 (0.192)  Loss:   3.162 ( 4.030)  Acc@1:  40.000 (  9.536)  Acc@5:  72.500 ( 28.276)
Test: [1250/3167]  Time: 0.194 (0.192)  Loss:   3.159 ( 3.999)  Acc@1:  42.500 ( 10.677)  Acc@5:  82.500 ( 29.966)
Test: [1300/3167]  Time: 0.203 (0.192)  Loss:   3.703 ( 4.005)  Acc@1:   0.000 ( 10.338)  Acc@5:  40.000 ( 29.660)
Test: [1350/3167]  Time: 0.207 (0.192)  Loss:   4.351 ( 4.021)  Acc@1:   2.500 (  9.976)  Acc@5:  20.000 ( 29.123)
Test: [1400/3167]  Time: 0.196 (0.193)  Loss:   3.617 ( 4.039)  Acc@1:  30.000 (  9.713)  Acc@5:  55.000 ( 28.622)
Test: [1450/3167]  Time: 0.192 (0.193)  Loss:   4.436 ( 4.036)  Acc@1:   0.000 (  9.990)  Acc@5:   5.000 ( 28.968)
Test: [1500/3167]  Time: 0.191 (0.193)  Loss:   3.837 ( 4.009)  Acc@1:   7.500 ( 10.996)  Acc@5:  32.500 ( 29.745)
Test: [1550/3167]  Time: 0.198 (0.193)  Loss:   3.030 ( 3.994)  Acc@1:  35.000 ( 11.202)  Acc@5:  82.500 ( 30.540)
Test: [1600/3167]  Time: 0.194 (0.193)  Loss:   2.909 ( 3.975)  Acc@1:  40.000 ( 11.451)  Acc@5:  75.000 ( 31.588)
Test: [1650/3167]  Time: 0.204 (0.193)  Loss:   3.853 ( 3.959)  Acc@1:  17.500 ( 11.988)  Acc@5:  45.000 ( 32.421)
Test: [1700/3167]  Time: 0.190 (0.193)  Loss:   4.308 ( 3.951)  Acc@1:   0.000 ( 12.136)  Acc@5:  12.500 ( 32.888)
Test: [1750/3167]  Time: 0.191 (0.193)  Loss:   3.885 ( 3.955)  Acc@1:   7.500 ( 12.069)  Acc@5:  32.500 ( 32.866)
Test: [1800/3167]  Time: 0.194 (0.193)  Loss:   3.968 ( 3.954)  Acc@1:   5.000 ( 12.066)  Acc@5:  32.500 ( 33.111)
Test: [1850/3167]  Time: 0.186 (0.193)  Loss:   4.724 ( 3.966)  Acc@1:   0.000 ( 11.760)  Acc@5:   0.000 ( 32.504)
Test: [1900/3167]  Time: 0.194 (0.193)  Loss:   4.543 ( 3.983)  Acc@1:   0.000 ( 11.451)  Acc@5:   0.000 ( 31.661)
Test: [1950/3167]  Time: 0.197 (0.193)  Loss:   4.508 ( 3.993)  Acc@1:   5.000 ( 11.174)  Acc@5:  17.500 ( 31.084)
Test: [2000/3167]  Time: 0.196 (0.193)  Loss:   4.599 ( 4.010)  Acc@1:   0.000 ( 10.916)  Acc@5:   0.000 ( 30.491)
Test: [2050/3167]  Time: 0.193 (0.193)  Loss:   4.591 ( 4.023)  Acc@1:   0.000 ( 10.651)  Acc@5:   0.000 ( 29.771)
Test: [2100/3167]  Time: 0.186 (0.193)  Loss:   4.218 ( 4.030)  Acc@1:   7.500 ( 10.564)  Acc@5:  10.000 ( 29.586)
Test: [2150/3167]  Time: 0.195 (0.193)  Loss:   2.065 ( 4.008)  Acc@1:  72.500 ( 11.232)  Acc@5:  80.000 ( 30.045)
Test: [2200/3167]  Time: 0.193 (0.193)  Loss:   3.938 ( 4.005)  Acc@1:   2.500 ( 11.206)  Acc@5:  32.500 ( 30.120)
Test: [2250/3167]  Time: 0.196 (0.193)  Loss:   3.658 ( 4.009)  Acc@1:  27.500 ( 11.103)  Acc@5:  62.500 ( 30.096)
Test: [2300/3167]  Time: 0.200 (0.193)  Loss:   4.399 ( 4.016)  Acc@1:   0.000 ( 11.059)  Acc@5:  12.500 ( 29.936)
Test: [2350/3167]  Time: 0.195 (0.193)  Loss:   4.018 ( 4.020)  Acc@1:  12.500 ( 10.890)  Acc@5:  37.500 ( 29.759)
Test: [2400/3167]  Time: 0.203 (0.193)  Loss:   4.368 ( 4.025)  Acc@1:   0.000 ( 10.828)  Acc@5:  12.500 ( 29.596)
Test: [2450/3167]  Time: 0.196 (0.193)  Loss:   3.681 ( 4.024)  Acc@1:   7.500 ( 10.674)  Acc@5:  42.500 ( 29.550)
Test: [2500/3167]  Time: 0.199 (0.193)  Loss:   4.485 ( 4.027)  Acc@1:  10.000 ( 10.650)  Acc@5:  17.500 ( 29.505)
Test: [2550/3167]  Time: 0.201 (0.193)  Loss:   4.191 ( 4.022)  Acc@1:   0.000 ( 10.589)  Acc@5:   7.500 ( 29.821)
Test: [2600/3167]  Time: 0.209 (0.193)  Loss:   3.891 ( 4.025)  Acc@1:  15.000 ( 10.432)  Acc@5:  40.000 ( 29.546)
Test: [2650/3167]  Time: 0.190 (0.193)  Loss:   3.930 ( 4.029)  Acc@1:  10.000 ( 10.290)  Acc@5:  37.500 ( 29.344)
Test: [2700/3167]  Time: 0.196 (0.193)  Loss:   3.926 ( 4.027)  Acc@1:   2.500 ( 10.221)  Acc@5:  30.000 ( 29.459)
Test: [2750/3167]  Time: 0.185 (0.193)  Loss:   2.959 ( 4.027)  Acc@1:  62.500 ( 10.202)  Acc@5:  85.000 ( 29.405)
Test: [2800/3167]  Time: 0.194 (0.193)  Loss:   4.235 ( 4.019)  Acc@1:  10.000 ( 10.584)  Acc@5:  30.000 ( 29.865)
Test: [2850/3167]  Time: 0.184 (0.193)  Loss:   3.922 ( 4.024)  Acc@1:   7.500 ( 10.444)  Acc@5:  32.500 ( 29.593)
Test: [2900/3167]  Time: 0.185 (0.192)  Loss:   4.043 ( 4.022)  Acc@1:  12.500 ( 10.431)  Acc@5:  32.500 ( 29.738)
Test: [2950/3167]  Time: 0.189 (0.192)  Loss:   3.926 ( 4.024)  Acc@1:   0.000 ( 10.293)  Acc@5:  15.000 ( 29.383)
Test: [3000/3167]  Time: 0.184 (0.192)  Loss:   4.173 ( 4.025)  Acc@1:   0.000 ( 10.127)  Acc@5:   7.500 ( 29.024)
Test: [3050/3167]  Time: 0.184 (0.192)  Loss:   4.539 ( 4.028)  Acc@1:   2.500 (  9.997)  Acc@5:   7.500 ( 28.873)
Test: [3100/3167]  Time: 0.191 (0.192)  Loss:   4.236 ( 4.032)  Acc@1:   0.000 (  9.844)  Acc@5:   5.000 ( 28.575)
Test: [3150/3167]  Time: 0.187 (0.192)  Loss:   4.600 ( 4.038)  Acc@1:   0.000 (  9.689)  Acc@5:   0.000 ( 28.185)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   4.584 ( 4.041)  Acc@1:   0.000 (  9.640)  Acc@5:   0.000 ( 28.047)
Test: [   0/124]  Time: 0.681 (0.681)  Loss:   4.221 ( 4.221)  Acc@1:   5.000 (  5.000)  Acc@5:  30.000 ( 30.000)
Test: [  50/124]  Time: 0.184 (0.201)  Loss:   3.905 ( 4.052)  Acc@1:   0.000 (  8.922)  Acc@5:  35.000 ( 28.578)
Test: [ 100/124]  Time: 0.184 (0.196)  Loss:   3.256 ( 4.072)  Acc@1:  10.000 (  9.109)  Acc@5:  70.000 ( 28.688)
Test: [ 124/124]  Time: 0.180 (0.195)  Loss:   4.582 ( 4.085)  Acc@1:   0.000 (  8.440)  Acc@5:   0.000 ( 26.900)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_0/checkpoint-1.pth.tar', 9.640142395945977)

Train: 2 [   0/3167 (  0%)]  Loss: 4.27 (4.27)  Time: 1.085s,   36.86/s  (1.085s,   36.86/s)  LR: 2.800e-05  Data: 0.473 (0.473)
Train: 2 [  50/3167 (  2%)]  Loss: 4.23 (4.34)  Time: 0.611s,   65.46/s  (0.614s,   65.16/s)  LR: 2.800e-05  Data: 0.012 (0.020)
Train: 2 [ 100/3167 (  3%)]  Loss: 4.28 (4.34)  Time: 0.607s,   65.91/s  (0.609s,   65.69/s)  LR: 2.800e-05  Data: 0.012 (0.016)
Train: 2 [ 150/3167 (  5%)]  Loss: 4.50 (4.33)  Time: 0.604s,   66.18/s  (0.607s,   65.90/s)  LR: 2.800e-05  Data: 0.012 (0.014)
Train: 2 [ 200/3167 (  6%)]  Loss: 4.51 (4.34)  Time: 0.601s,   66.59/s  (0.606s,   66.01/s)  LR: 2.800e-05  Data: 0.009 (0.013)
Train: 2 [ 250/3167 (  8%)]  Loss: 4.31 (4.34)  Time: 0.600s,   66.62/s  (0.605s,   66.08/s)  LR: 2.800e-05  Data: 0.011 (0.013)
Train: 2 [ 300/3167 (  9%)]  Loss: 4.26 (4.34)  Time: 0.598s,   66.86/s  (0.605s,   66.13/s)  LR: 2.800e-05  Data: 0.007 (0.012)
Train: 2 [ 350/3167 ( 11%)]  Loss: 4.26 (4.34)  Time: 0.598s,   66.89/s  (0.604s,   66.18/s)  LR: 2.800e-05  Data: 0.006 (0.012)
Train: 2 [ 400/3167 ( 13%)]  Loss: 4.14 (4.34)  Time: 0.601s,   66.56/s  (0.604s,   66.20/s)  LR: 2.800e-05  Data: 0.012 (0.012)
Train: 2 [ 450/3167 ( 14%)]  Loss: 4.27 (4.33)  Time: 0.600s,   66.67/s  (0.604s,   66.22/s)  LR: 2.800e-05  Data: 0.004 (0.011)
Train: 2 [ 500/3167 ( 16%)]  Loss: 4.41 (4.33)  Time: 0.601s,   66.59/s  (0.604s,   66.25/s)  LR: 2.800e-05  Data: 0.012 (0.011)
Train: 2 [ 550/3167 ( 17%)]  Loss: 4.20 (4.33)  Time: 0.594s,   67.34/s  (0.604s,   66.27/s)  LR: 2.800e-05  Data: 0.004 (0.011)
Train: 2 [ 600/3167 ( 19%)]  Loss: 4.25 (4.33)  Time: 0.606s,   65.98/s  (0.603s,   66.28/s)  LR: 2.800e-05  Data: 0.014 (0.011)
Train: 2 [ 650/3167 ( 21%)]  Loss: 4.26 (4.33)  Time: 0.600s,   66.63/s  (0.603s,   66.30/s)  LR: 2.800e-05  Data: 0.011 (0.011)
Train: 2 [ 700/3167 ( 22%)]  Loss: 4.39 (4.33)  Time: 0.601s,   66.59/s  (0.603s,   66.30/s)  LR: 2.800e-05  Data: 0.012 (0.011)
Train: 2 [ 750/3167 ( 24%)]  Loss: 4.15 (4.33)  Time: 0.599s,   66.83/s  (0.603s,   66.31/s)  LR: 2.800e-05  Data: 0.009 (0.011)
Train: 2 [ 800/3167 ( 25%)]  Loss: 4.30 (4.33)  Time: 0.600s,   66.66/s  (0.603s,   66.32/s)  LR: 2.800e-05  Data: 0.011 (0.011)
Train: 2 [ 850/3167 ( 27%)]  Loss: 4.16 (4.33)  Time: 0.601s,   66.55/s  (0.603s,   66.32/s)  LR: 2.800e-05  Data: 0.009 (0.011)
Train: 2 [ 900/3167 ( 28%)]  Loss: 4.47 (4.33)  Time: 0.603s,   66.37/s  (0.603s,   66.33/s)  LR: 2.800e-05  Data: 0.012 (0.011)
Train: 2 [ 950/3167 ( 30%)]  Loss: 4.14 (4.32)  Time: 0.603s,   66.37/s  (0.603s,   66.33/s)  LR: 2.800e-05  Data: 0.011 (0.011)
Train: 2 [1000/3167 ( 32%)]  Loss: 4.53 (4.32)  Time: 0.595s,   67.18/s  (0.603s,   66.34/s)  LR: 2.800e-05  Data: 0.004 (0.011)
Train: 2 [1050/3167 ( 33%)]  Loss: 4.45 (4.32)  Time: 0.601s,   66.57/s  (0.603s,   66.35/s)  LR: 2.800e-05  Data: 0.009 (0.010)
Train: 2 [1100/3167 ( 35%)]  Loss: 4.27 (4.32)  Time: 0.596s,   67.12/s  (0.603s,   66.36/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1150/3167 ( 36%)]  Loss: 4.40 (4.32)  Time: 0.602s,   66.44/s  (0.603s,   66.37/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1200/3167 ( 38%)]  Loss: 4.41 (4.32)  Time: 0.595s,   67.22/s  (0.603s,   66.37/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1250/3167 ( 39%)]  Loss: 4.21 (4.32)  Time: 0.600s,   66.65/s  (0.603s,   66.38/s)  LR: 2.800e-05  Data: 0.011 (0.010)
Train: 2 [1300/3167 ( 41%)]  Loss: 4.53 (4.32)  Time: 0.601s,   66.57/s  (0.603s,   66.38/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [1350/3167 ( 43%)]  Loss: 4.28 (4.32)  Time: 0.595s,   67.20/s  (0.602s,   66.40/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1400/3167 ( 44%)]  Loss: 4.20 (4.32)  Time: 0.598s,   66.87/s  (0.602s,   66.40/s)  LR: 2.800e-05  Data: 0.007 (0.010)
Train: 2 [1450/3167 ( 46%)]  Loss: 4.44 (4.32)  Time: 0.596s,   67.14/s  (0.602s,   66.40/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1500/3167 ( 47%)]  Loss: 4.34 (4.32)  Time: 0.598s,   66.92/s  (0.602s,   66.41/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1550/3167 ( 49%)]  Loss: 4.29 (4.32)  Time: 0.603s,   66.32/s  (0.602s,   66.42/s)  LR: 2.800e-05  Data: 0.011 (0.010)
Train: 2 [1600/3167 ( 51%)]  Loss: 4.51 (4.32)  Time: 0.593s,   67.45/s  (0.602s,   66.42/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1650/3167 ( 52%)]  Loss: 4.44 (4.32)  Time: 0.603s,   66.36/s  (0.602s,   66.43/s)  LR: 2.800e-05  Data: 0.014 (0.010)
Train: 2 [1700/3167 ( 54%)]  Loss: 4.12 (4.31)  Time: 0.605s,   66.15/s  (0.602s,   66.43/s)  LR: 2.800e-05  Data: 0.009 (0.010)
Train: 2 [1750/3167 ( 55%)]  Loss: 4.41 (4.31)  Time: 0.601s,   66.58/s  (0.602s,   66.44/s)  LR: 2.800e-05  Data: 0.009 (0.010)
Train: 2 [1800/3167 ( 57%)]  Loss: 4.02 (4.31)  Time: 0.593s,   67.45/s  (0.602s,   66.45/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1850/3167 ( 58%)]  Loss: 4.13 (4.31)  Time: 0.599s,   66.76/s  (0.602s,   66.46/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1900/3167 ( 60%)]  Loss: 4.14 (4.31)  Time: 0.593s,   67.44/s  (0.602s,   66.46/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [1950/3167 ( 62%)]  Loss: 4.23 (4.31)  Time: 0.596s,   67.14/s  (0.602s,   66.47/s)  LR: 2.800e-05  Data: 0.007 (0.010)
Train: 2 [2000/3167 ( 63%)]  Loss: 4.24 (4.31)  Time: 0.606s,   66.00/s  (0.602s,   66.47/s)  LR: 2.800e-05  Data: 0.014 (0.010)
Train: 2 [2050/3167 ( 65%)]  Loss: 4.38 (4.31)  Time: 0.601s,   66.55/s  (0.602s,   66.48/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [2100/3167 ( 66%)]  Loss: 4.42 (4.31)  Time: 0.601s,   66.54/s  (0.602s,   66.48/s)  LR: 2.800e-05  Data: 0.012 (0.010)
Train: 2 [2150/3167 ( 68%)]  Loss: 4.31 (4.31)  Time: 0.602s,   66.43/s  (0.602s,   66.49/s)  LR: 2.800e-05  Data: 0.010 (0.010)
Train: 2 [2200/3167 ( 69%)]  Loss: 4.00 (4.31)  Time: 0.606s,   66.05/s  (0.602s,   66.50/s)  LR: 2.800e-05  Data: 0.014 (0.010)
Train: 2 [2250/3167 ( 71%)]  Loss: 4.48 (4.30)  Time: 0.595s,   67.28/s  (0.601s,   66.51/s)  LR: 2.800e-05  Data: 0.004 (0.010)
Train: 2 [2300/3167 ( 73%)]  Loss: 4.45 (4.30)  Time: 0.596s,   67.14/s  (0.601s,   66.51/s)  LR: 2.800e-05  Data: 0.007 (0.009)
Train: 2 [2350/3167 ( 74%)]  Loss: 4.48 (4.30)  Time: 0.601s,   66.57/s  (0.601s,   66.52/s)  LR: 2.800e-05  Data: 0.011 (0.009)
Train: 2 [2400/3167 ( 76%)]  Loss: 4.25 (4.30)  Time: 0.601s,   66.54/s  (0.601s,   66.53/s)  LR: 2.800e-05  Data: 0.012 (0.009)
Train: 2 [2450/3167 ( 77%)]  Loss: 4.23 (4.30)  Time: 0.596s,   67.14/s  (0.601s,   66.54/s)  LR: 2.800e-05  Data: 0.007 (0.009)
Train: 2 [2500/3167 ( 79%)]  Loss: 4.17 (4.30)  Time: 0.593s,   67.42/s  (0.601s,   66.55/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [2550/3167 ( 81%)]  Loss: 4.66 (4.30)  Time: 0.598s,   66.85/s  (0.601s,   66.56/s)  LR: 2.800e-05  Data: 0.009 (0.009)
Train: 2 [2600/3167 ( 82%)]  Loss: 4.41 (4.30)  Time: 0.599s,   66.82/s  (0.601s,   66.57/s)  LR: 2.800e-05  Data: 0.009 (0.009)
Train: 2 [2650/3167 ( 84%)]  Loss: 4.05 (4.30)  Time: 0.596s,   67.15/s  (0.601s,   66.58/s)  LR: 2.800e-05  Data: 0.006 (0.009)
Train: 2 [2700/3167 ( 85%)]  Loss: 4.37 (4.30)  Time: 0.594s,   67.38/s  (0.601s,   66.59/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [2750/3167 ( 87%)]  Loss: 4.30 (4.30)  Time: 0.595s,   67.21/s  (0.601s,   66.59/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [2800/3167 ( 88%)]  Loss: 4.16 (4.30)  Time: 0.596s,   67.13/s  (0.601s,   66.60/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [2850/3167 ( 90%)]  Loss: 4.43 (4.30)  Time: 0.599s,   66.81/s  (0.601s,   66.61/s)  LR: 2.800e-05  Data: 0.009 (0.009)
Train: 2 [2900/3167 ( 92%)]  Loss: 4.32 (4.29)  Time: 0.598s,   66.84/s  (0.600s,   66.61/s)  LR: 2.800e-05  Data: 0.009 (0.009)
Train: 2 [2950/3167 ( 93%)]  Loss: 3.93 (4.29)  Time: 0.593s,   67.43/s  (0.600s,   66.62/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [3000/3167 ( 95%)]  Loss: 4.39 (4.29)  Time: 0.596s,   67.13/s  (0.600s,   66.63/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Train: 2 [3050/3167 ( 96%)]  Loss: 4.31 (4.29)  Time: 0.600s,   66.71/s  (0.600s,   66.63/s)  LR: 2.800e-05  Data: 0.009 (0.009)
Train: 2 [3100/3167 ( 98%)]  Loss: 4.33 (4.29)  Time: 0.599s,   66.80/s  (0.600s,   66.64/s)  LR: 2.800e-05  Data: 0.007 (0.009)
Train: 2 [3150/3167 ( 99%)]  Loss: 4.33 (4.29)  Time: 0.595s,   67.25/s  (0.600s,   66.64/s)  LR: 2.800e-05  Data: 0.004 (0.009)
Test: [   0/3167]  Time: 0.504 (0.504)  Loss:   4.207 ( 4.207)  Acc@1:  10.000 ( 10.000)  Acc@5:  22.500 ( 22.500)
Test: [  50/3167]  Time: 0.190 (0.199)  Loss:   3.915 ( 3.998)  Acc@1:  22.500 ( 12.990)  Acc@5:  45.000 ( 35.441)
Test: [ 100/3167]  Time: 0.189 (0.196)  Loss:   4.159 ( 3.982)  Acc@1:   2.500 (  9.851)  Acc@5:  17.500 ( 33.144)
Test: [ 150/3167]  Time: 0.193 (0.194)  Loss:   3.053 ( 3.919)  Acc@1:  42.500 ( 12.467)  Acc@5:  80.000 ( 34.321)
Test: [ 200/3167]  Time: 0.195 (0.194)  Loss:   4.094 ( 3.952)  Acc@1:   7.500 ( 11.530)  Acc@5:  25.000 ( 31.032)
Test: [ 250/3167]  Time: 0.191 (0.193)  Loss:   3.540 ( 3.913)  Acc@1:  20.000 ( 12.092)  Acc@5:  50.000 ( 32.321)
Test: [ 300/3167]  Time: 0.190 (0.193)  Loss:   3.884 ( 3.904)  Acc@1:   0.000 ( 12.400)  Acc@5:  35.000 ( 33.538)
Test: [ 350/3167]  Time: 0.191 (0.193)  Loss:   3.382 ( 3.863)  Acc@1:  40.000 ( 13.305)  Acc@5:  62.500 ( 35.527)
Test: [ 400/3167]  Time: 0.200 (0.193)  Loss:   3.730 ( 3.746)  Acc@1:  10.000 ( 17.787)  Acc@5:  47.500 ( 39.688)
Test: [ 450/3167]  Time: 0.199 (0.193)  Loss:   3.786 ( 3.758)  Acc@1:   0.000 ( 16.480)  Acc@5:  20.000 ( 38.548)
Test: [ 500/3167]  Time: 0.190 (0.193)  Loss:   3.962 ( 3.786)  Acc@1:   5.000 ( 15.444)  Acc@5:  25.000 ( 37.839)
Test: [ 550/3167]  Time: 0.196 (0.193)  Loss:   4.080 ( 3.764)  Acc@1:   0.000 ( 16.620)  Acc@5:  17.500 ( 38.893)
Test: [ 600/3167]  Time: 0.191 (0.193)  Loss:   3.397 ( 3.780)  Acc@1:   5.000 ( 15.478)  Acc@5:  45.000 ( 37.899)
Test: [ 650/3167]  Time: 0.191 (0.193)  Loss:   4.202 ( 3.764)  Acc@1:   0.000 ( 15.787)  Acc@5:  15.000 ( 38.341)
Test: [ 700/3167]  Time: 0.201 (0.193)  Loss:   3.258 ( 3.761)  Acc@1:  45.000 ( 15.770)  Acc@5:  70.000 ( 38.948)
Test: [ 750/3167]  Time: 0.190 (0.193)  Loss:   3.752 ( 3.754)  Acc@1:  17.500 ( 15.579)  Acc@5:  45.000 ( 39.407)
Test: [ 800/3167]  Time: 0.187 (0.193)  Loss:   4.334 ( 3.768)  Acc@1:   0.000 ( 15.353)  Acc@5:  20.000 ( 38.895)
Test: [ 850/3167]  Time: 0.191 (0.193)  Loss:   4.139 ( 3.793)  Acc@1:   0.000 ( 14.645)  Acc@5:   5.000 ( 37.817)
Test: [ 900/3167]  Time: 0.195 (0.193)  Loss:   4.010 ( 3.813)  Acc@1:  10.000 ( 14.029)  Acc@5:  27.500 ( 36.570)
Test: [ 950/3167]  Time: 0.190 (0.193)  Loss:   3.167 ( 3.817)  Acc@1:  27.500 ( 14.017)  Acc@5:  75.000 ( 36.543)
Test: [1000/3167]  Time: 0.208 (0.193)  Loss:   4.137 ( 3.829)  Acc@1:   0.000 ( 13.831)  Acc@5:  20.000 ( 35.887)
Test: [1050/3167]  Time: 0.200 (0.193)  Loss:   3.621 ( 3.826)  Acc@1:  10.000 ( 13.549)  Acc@5:  45.000 ( 36.108)
Test: [1100/3167]  Time: 0.187 (0.193)  Loss:   4.206 ( 3.832)  Acc@1:   2.500 ( 13.031)  Acc@5:   2.500 ( 35.515)
Test: [1150/3167]  Time: 0.199 (0.193)  Loss:   3.593 ( 3.833)  Acc@1:  22.500 ( 13.189)  Acc@5:  62.500 ( 35.738)
Test: [1200/3167]  Time: 0.190 (0.193)  Loss:   2.876 ( 3.811)  Acc@1:  47.500 ( 13.836)  Acc@5:  75.000 ( 36.799)
Test: [1250/3167]  Time: 0.191 (0.193)  Loss:   3.450 ( 3.792)  Acc@1:  42.500 ( 14.924)  Acc@5:  60.000 ( 37.826)
Test: [1300/3167]  Time: 0.200 (0.193)  Loss:   3.710 ( 3.800)  Acc@1:  17.500 ( 14.520)  Acc@5:  40.000 ( 37.333)
Test: [1350/3167]  Time: 0.195 (0.193)  Loss:   4.031 ( 3.817)  Acc@1:   2.500 ( 14.078)  Acc@5:  32.500 ( 36.532)
Test: [1400/3167]  Time: 0.191 (0.193)  Loss:   3.441 ( 3.832)  Acc@1:  50.000 ( 13.729)  Acc@5:  62.500 ( 35.915)
Test: [1450/3167]  Time: 0.196 (0.193)  Loss:   4.118 ( 3.827)  Acc@1:   0.000 ( 14.166)  Acc@5:  17.500 ( 36.380)
Test: [1500/3167]  Time: 0.190 (0.193)  Loss:   3.789 ( 3.808)  Acc@1:   7.500 ( 14.181)  Acc@5:  35.000 ( 37.000)
Test: [1550/3167]  Time: 0.185 (0.193)  Loss:   2.737 ( 3.792)  Acc@1:  67.500 ( 14.734)  Acc@5:  90.000 ( 37.689)
Test: [1600/3167]  Time: 0.192 (0.193)  Loss:   2.660 ( 3.780)  Acc@1:  45.000 ( 15.112)  Acc@5:  72.500 ( 38.214)
Test: [1650/3167]  Time: 0.202 (0.193)  Loss:   3.636 ( 3.762)  Acc@1:  20.000 ( 15.657)  Acc@5:  52.500 ( 38.919)
Test: [1700/3167]  Time: 0.193 (0.193)  Loss:   4.223 ( 3.755)  Acc@1:   2.500 ( 15.704)  Acc@5:  17.500 ( 39.297)
Test: [1750/3167]  Time: 0.190 (0.193)  Loss:   3.822 ( 3.762)  Acc@1:  10.000 ( 15.557)  Acc@5:  35.000 ( 39.073)
Test: [1800/3167]  Time: 0.192 (0.193)  Loss:   3.522 ( 3.760)  Acc@1:  27.500 ( 15.732)  Acc@5:  55.000 ( 39.411)
Test: [1850/3167]  Time: 0.192 (0.193)  Loss:   4.196 ( 3.767)  Acc@1:   5.000 ( 15.539)  Acc@5:  22.500 ( 38.990)
Test: [1900/3167]  Time: 0.202 (0.193)  Loss:   4.198 ( 3.775)  Acc@1:   0.000 ( 15.389)  Acc@5:  17.500 ( 38.809)
Test: [1950/3167]  Time: 0.205 (0.193)  Loss:   4.528 ( 3.780)  Acc@1:   0.000 ( 15.346)  Acc@5:   7.500 ( 38.643)
Test: [2000/3167]  Time: 0.189 (0.193)  Loss:   4.074 ( 3.796)  Acc@1:  10.000 ( 15.007)  Acc@5:  25.000 ( 37.889)
Test: [2050/3167]  Time: 0.194 (0.193)  Loss:   4.366 ( 3.806)  Acc@1:   0.000 ( 14.805)  Acc@5:   0.000 ( 37.333)
Test: [2100/3167]  Time: 0.192 (0.193)  Loss:   4.017 ( 3.812)  Acc@1:   2.500 ( 14.673)  Acc@5:  15.000 ( 37.118)
Test: [2150/3167]  Time: 0.195 (0.193)  Loss:   2.334 ( 3.797)  Acc@1:  62.500 ( 15.103)  Acc@5:  70.000 ( 37.451)
Test: [2200/3167]  Time: 0.186 (0.193)  Loss:   3.631 ( 3.790)  Acc@1:   5.000 ( 15.112)  Acc@5:  47.500 ( 37.719)
Test: [2250/3167]  Time: 0.189 (0.193)  Loss:   3.702 ( 3.794)  Acc@1:  25.000 ( 14.938)  Acc@5:  55.000 ( 37.633)
Test: [2300/3167]  Time: 0.186 (0.193)  Loss:   4.208 ( 3.801)  Acc@1:   2.500 ( 14.808)  Acc@5:  20.000 ( 37.332)
Test: [2350/3167]  Time: 0.194 (0.193)  Loss:   3.386 ( 3.801)  Acc@1:  52.500 ( 14.815)  Acc@5:  62.500 ( 37.280)
Test: [2400/3167]  Time: 0.189 (0.193)  Loss:   4.353 ( 3.797)  Acc@1:   0.000 ( 15.051)  Acc@5:   5.000 ( 37.464)
Test: [2450/3167]  Time: 0.188 (0.193)  Loss:   3.232 ( 3.795)  Acc@1:  30.000 ( 14.933)  Acc@5:  72.500 ( 37.646)
Test: [2500/3167]  Time: 0.187 (0.193)  Loss:   4.176 ( 3.797)  Acc@1:  10.000 ( 14.912)  Acc@5:  30.000 ( 37.644)
Test: [2550/3167]  Time: 0.194 (0.193)  Loss:   3.993 ( 3.785)  Acc@1:   5.000 ( 15.428)  Acc@5:  17.500 ( 38.099)
Test: [2600/3167]  Time: 0.197 (0.193)  Loss:   3.821 ( 3.790)  Acc@1:  12.500 ( 15.251)  Acc@5:  37.500 ( 37.811)
Test: [2650/3167]  Time: 0.191 (0.193)  Loss:   3.852 ( 3.796)  Acc@1:   2.500 ( 15.068)  Acc@5:  37.500 ( 37.647)
Test: [2700/3167]  Time: 0.191 (0.193)  Loss:   3.498 ( 3.794)  Acc@1:  17.500 ( 14.979)  Acc@5:  47.500 ( 37.692)
Test: [2750/3167]  Time: 0.188 (0.193)  Loss:   2.907 ( 3.796)  Acc@1:  30.000 ( 14.854)  Acc@5:  85.000 ( 37.539)
Test: [2800/3167]  Time: 0.190 (0.193)  Loss:   3.980 ( 3.790)  Acc@1:   2.500 ( 14.837)  Acc@5:  30.000 ( 37.854)
Test: [2850/3167]  Time: 0.202 (0.193)  Loss:   3.988 ( 3.795)  Acc@1:  15.000 ( 14.683)  Acc@5:  37.500 ( 37.675)
Test: [2900/3167]  Time: 0.188 (0.193)  Loss:   3.971 ( 3.797)  Acc@1:  10.000 ( 14.687)  Acc@5:  32.500 ( 37.686)
Test: [2950/3167]  Time: 0.188 (0.193)  Loss:   4.032 ( 3.800)  Acc@1:   0.000 ( 14.481)  Acc@5:   7.500 ( 37.320)
Test: [3000/3167]  Time: 0.184 (0.193)  Loss:   4.185 ( 3.806)  Acc@1:   0.000 ( 14.241)  Acc@5:   2.500 ( 36.802)
Test: [3050/3167]  Time: 0.188 (0.193)  Loss:   4.293 ( 3.809)  Acc@1:   2.500 ( 14.077)  Acc@5:  12.500 ( 36.596)
Test: [3100/3167]  Time: 0.190 (0.193)  Loss:   4.174 ( 3.816)  Acc@1:   0.000 ( 13.880)  Acc@5:   7.500 ( 36.251)
Test: [3150/3167]  Time: 0.183 (0.192)  Loss:   4.186 ( 3.821)  Acc@1:   0.000 ( 13.673)  Acc@5:  20.000 ( 35.908)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   4.018 ( 3.823)  Acc@1:   0.000 ( 13.617)  Acc@5:  11.111 ( 35.838)
Test: [   0/124]  Time: 0.679 (0.679)  Loss:   4.315 ( 4.315)  Acc@1:   2.500 (  2.500)  Acc@5:  20.000 ( 20.000)
Test: [  50/124]  Time: 0.189 (0.200)  Loss:   3.903 ( 3.862)  Acc@1:   7.500 ( 13.480)  Acc@5:  32.500 ( 34.510)
Test: [ 100/124]  Time: 0.190 (0.195)  Loss:   2.584 ( 3.844)  Acc@1:  67.500 ( 13.985)  Acc@5:  80.000 ( 35.842)
Test: [ 124/124]  Time: 0.180 (0.194)  Loss:   4.078 ( 3.874)  Acc@1:   0.000 ( 12.440)  Acc@5:  30.000 ( 34.040)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_0/checkpoint-2.pth.tar', 13.616809667769104)

Train: 3 [   0/3167 (  0%)]  Loss: 4.41 (4.41)  Time: 1.142s,   35.01/s  (1.142s,   35.01/s)  LR: 3.700e-05  Data: 0.538 (0.538)
Train: 3 [  50/3167 (  2%)]  Loss: 4.31 (4.25)  Time: 0.599s,   66.82/s  (0.614s,   65.12/s)  LR: 3.700e-05  Data: 0.007 (0.021)
Train: 3 [ 100/3167 (  3%)]  Loss: 4.20 (4.22)  Time: 0.612s,   65.41/s  (0.609s,   65.68/s)  LR: 3.700e-05  Data: 0.012 (0.016)
Train: 3 [ 150/3167 (  5%)]  Loss: 4.16 (4.24)  Time: 0.608s,   65.82/s  (0.607s,   65.94/s)  LR: 3.700e-05  Data: 0.012 (0.014)
Train: 3 [ 200/3167 (  6%)]  Loss: 4.14 (4.24)  Time: 0.611s,   65.49/s  (0.606s,   66.05/s)  LR: 3.700e-05  Data: 0.012 (0.013)
Train: 3 [ 250/3167 (  8%)]  Loss: 4.37 (4.25)  Time: 0.601s,   66.58/s  (0.605s,   66.11/s)  LR: 3.700e-05  Data: 0.012 (0.013)
Train: 3 [ 300/3167 (  9%)]  Loss: 4.17 (4.24)  Time: 0.603s,   66.29/s  (0.605s,   66.14/s)  LR: 3.700e-05  Data: 0.012 (0.012)
Train: 3 [ 350/3167 ( 11%)]  Loss: 4.13 (4.24)  Time: 0.606s,   66.06/s  (0.604s,   66.18/s)  LR: 3.700e-05  Data: 0.009 (0.012)
Train: 3 [ 400/3167 ( 13%)]  Loss: 4.31 (4.24)  Time: 0.601s,   66.59/s  (0.604s,   66.20/s)  LR: 3.700e-05  Data: 0.012 (0.012)
Train: 3 [ 450/3167 ( 14%)]  Loss: 4.35 (4.24)  Time: 0.601s,   66.53/s  (0.604s,   66.21/s)  LR: 3.700e-05  Data: 0.009 (0.012)
Train: 3 [ 500/3167 ( 16%)]  Loss: 3.99 (4.24)  Time: 0.607s,   65.90/s  (0.604s,   66.24/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [ 550/3167 ( 17%)]  Loss: 4.28 (4.24)  Time: 0.605s,   66.13/s  (0.604s,   66.26/s)  LR: 3.700e-05  Data: 0.009 (0.011)
Train: 3 [ 600/3167 ( 19%)]  Loss: 3.86 (4.24)  Time: 0.607s,   65.93/s  (0.604s,   66.27/s)  LR: 3.700e-05  Data: 0.009 (0.011)
Train: 3 [ 650/3167 ( 21%)]  Loss: 4.04 (4.24)  Time: 0.601s,   66.58/s  (0.604s,   66.27/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [ 700/3167 ( 22%)]  Loss: 4.09 (4.24)  Time: 0.600s,   66.63/s  (0.604s,   66.28/s)  LR: 3.700e-05  Data: 0.011 (0.011)
Train: 3 [ 750/3167 ( 24%)]  Loss: 4.27 (4.24)  Time: 0.595s,   67.21/s  (0.603s,   66.28/s)  LR: 3.700e-05  Data: 0.004 (0.011)
Train: 3 [ 800/3167 ( 25%)]  Loss: 3.91 (4.24)  Time: 0.595s,   67.19/s  (0.603s,   66.30/s)  LR: 3.700e-05  Data: 0.004 (0.011)
Train: 3 [ 850/3167 ( 27%)]  Loss: 4.49 (4.23)  Time: 0.601s,   66.55/s  (0.603s,   66.30/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [ 900/3167 ( 28%)]  Loss: 4.01 (4.23)  Time: 0.604s,   66.18/s  (0.603s,   66.31/s)  LR: 3.700e-05  Data: 0.007 (0.011)
Train: 3 [ 950/3167 ( 30%)]  Loss: 4.23 (4.23)  Time: 0.596s,   67.13/s  (0.603s,   66.32/s)  LR: 3.700e-05  Data: 0.004 (0.011)
Train: 3 [1000/3167 ( 32%)]  Loss: 4.00 (4.23)  Time: 0.603s,   66.34/s  (0.603s,   66.33/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [1050/3167 ( 33%)]  Loss: 4.31 (4.23)  Time: 0.601s,   66.57/s  (0.603s,   66.34/s)  LR: 3.700e-05  Data: 0.012 (0.011)
Train: 3 [1100/3167 ( 35%)]  Loss: 4.32 (4.23)  Time: 0.601s,   66.51/s  (0.603s,   66.35/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1150/3167 ( 36%)]  Loss: 4.25 (4.23)  Time: 0.601s,   66.55/s  (0.603s,   66.36/s)  LR: 3.700e-05  Data: 0.011 (0.010)
Train: 3 [1200/3167 ( 38%)]  Loss: 4.20 (4.23)  Time: 0.600s,   66.69/s  (0.603s,   66.36/s)  LR: 3.700e-05  Data: 0.011 (0.010)
Train: 3 [1250/3167 ( 39%)]  Loss: 4.25 (4.23)  Time: 0.601s,   66.56/s  (0.603s,   66.36/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1300/3167 ( 41%)]  Loss: 4.34 (4.23)  Time: 0.608s,   65.74/s  (0.603s,   66.37/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1350/3167 ( 43%)]  Loss: 4.27 (4.23)  Time: 0.601s,   66.53/s  (0.603s,   66.38/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1400/3167 ( 44%)]  Loss: 4.25 (4.23)  Time: 0.609s,   65.68/s  (0.603s,   66.38/s)  LR: 3.700e-05  Data: 0.014 (0.010)
Train: 3 [1450/3167 ( 46%)]  Loss: 4.40 (4.23)  Time: 0.598s,   66.85/s  (0.602s,   66.39/s)  LR: 3.700e-05  Data: 0.006 (0.010)
Train: 3 [1500/3167 ( 47%)]  Loss: 3.84 (4.22)  Time: 0.601s,   66.60/s  (0.602s,   66.40/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1550/3167 ( 49%)]  Loss: 4.27 (4.22)  Time: 0.593s,   67.48/s  (0.602s,   66.40/s)  LR: 3.700e-05  Data: 0.004 (0.010)
Train: 3 [1600/3167 ( 51%)]  Loss: 3.93 (4.22)  Time: 0.607s,   65.90/s  (0.602s,   66.41/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1650/3167 ( 52%)]  Loss: 4.09 (4.22)  Time: 0.598s,   66.86/s  (0.602s,   66.41/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [1700/3167 ( 54%)]  Loss: 4.28 (4.22)  Time: 0.603s,   66.29/s  (0.602s,   66.42/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1750/3167 ( 55%)]  Loss: 3.97 (4.22)  Time: 0.601s,   66.52/s  (0.602s,   66.42/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [1800/3167 ( 57%)]  Loss: 4.20 (4.22)  Time: 0.604s,   66.27/s  (0.602s,   66.43/s)  LR: 3.700e-05  Data: 0.011 (0.010)
Train: 3 [1850/3167 ( 58%)]  Loss: 3.98 (4.22)  Time: 0.596s,   67.14/s  (0.602s,   66.44/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [1900/3167 ( 60%)]  Loss: 4.45 (4.22)  Time: 0.593s,   67.46/s  (0.602s,   66.45/s)  LR: 3.700e-05  Data: 0.004 (0.010)
Train: 3 [1950/3167 ( 62%)]  Loss: 4.36 (4.22)  Time: 0.600s,   66.64/s  (0.602s,   66.45/s)  LR: 3.700e-05  Data: 0.011 (0.010)
Train: 3 [2000/3167 ( 63%)]  Loss: 4.15 (4.22)  Time: 0.595s,   67.17/s  (0.602s,   66.46/s)  LR: 3.700e-05  Data: 0.006 (0.010)
Train: 3 [2050/3167 ( 65%)]  Loss: 4.25 (4.22)  Time: 0.601s,   66.58/s  (0.602s,   66.46/s)  LR: 3.700e-05  Data: 0.012 (0.010)
Train: 3 [2100/3167 ( 66%)]  Loss: 4.22 (4.21)  Time: 0.596s,   67.12/s  (0.602s,   66.47/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [2150/3167 ( 68%)]  Loss: 4.17 (4.21)  Time: 0.596s,   67.17/s  (0.602s,   66.48/s)  LR: 3.700e-05  Data: 0.006 (0.010)
Train: 3 [2200/3167 ( 69%)]  Loss: 4.37 (4.21)  Time: 0.596s,   67.16/s  (0.602s,   66.49/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [2250/3167 ( 71%)]  Loss: 4.41 (4.21)  Time: 0.598s,   66.85/s  (0.602s,   66.49/s)  LR: 3.700e-05  Data: 0.006 (0.010)
Train: 3 [2300/3167 ( 73%)]  Loss: 3.92 (4.21)  Time: 0.606s,   65.96/s  (0.602s,   66.50/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [2350/3167 ( 74%)]  Loss: 4.45 (4.21)  Time: 0.596s,   67.14/s  (0.601s,   66.51/s)  LR: 3.700e-05  Data: 0.007 (0.010)
Train: 3 [2400/3167 ( 76%)]  Loss: 4.21 (4.21)  Time: 0.602s,   66.46/s  (0.601s,   66.52/s)  LR: 3.700e-05  Data: 0.012 (0.009)
Train: 3 [2450/3167 ( 77%)]  Loss: 4.40 (4.21)  Time: 0.593s,   67.45/s  (0.601s,   66.52/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [2500/3167 ( 79%)]  Loss: 4.26 (4.21)  Time: 0.599s,   66.81/s  (0.601s,   66.53/s)  LR: 3.700e-05  Data: 0.009 (0.009)
Train: 3 [2550/3167 ( 81%)]  Loss: 4.34 (4.21)  Time: 0.596s,   67.13/s  (0.601s,   66.54/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [2600/3167 ( 82%)]  Loss: 3.83 (4.21)  Time: 0.593s,   67.44/s  (0.601s,   66.55/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [2650/3167 ( 84%)]  Loss: 3.93 (4.21)  Time: 0.596s,   67.08/s  (0.601s,   66.56/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [2700/3167 ( 85%)]  Loss: 4.55 (4.21)  Time: 0.599s,   66.76/s  (0.601s,   66.57/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [2750/3167 ( 87%)]  Loss: 4.09 (4.20)  Time: 0.594s,   67.31/s  (0.601s,   66.58/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [2800/3167 ( 88%)]  Loss: 3.83 (4.20)  Time: 0.604s,   66.28/s  (0.601s,   66.59/s)  LR: 3.700e-05  Data: 0.014 (0.009)
Train: 3 [2850/3167 ( 90%)]  Loss: 4.32 (4.20)  Time: 0.593s,   67.43/s  (0.601s,   66.60/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [2900/3167 ( 92%)]  Loss: 3.83 (4.20)  Time: 0.602s,   66.49/s  (0.601s,   66.60/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Train: 3 [2950/3167 ( 93%)]  Loss: 4.08 (4.20)  Time: 0.604s,   66.24/s  (0.601s,   66.61/s)  LR: 3.700e-05  Data: 0.015 (0.009)
Train: 3 [3000/3167 ( 95%)]  Loss: 4.16 (4.20)  Time: 0.593s,   67.43/s  (0.600s,   66.62/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [3050/3167 ( 96%)]  Loss: 3.89 (4.20)  Time: 0.593s,   67.41/s  (0.600s,   66.62/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [3100/3167 ( 98%)]  Loss: 4.16 (4.20)  Time: 0.593s,   67.40/s  (0.600s,   66.63/s)  LR: 3.700e-05  Data: 0.004 (0.009)
Train: 3 [3150/3167 ( 99%)]  Loss: 4.00 (4.20)  Time: 0.596s,   67.11/s  (0.600s,   66.64/s)  LR: 3.700e-05  Data: 0.007 (0.009)
Test: [   0/3167]  Time: 0.470 (0.470)  Loss:   4.065 ( 4.065)  Acc@1:  10.000 ( 10.000)  Acc@5:  32.500 ( 32.500)
Test: [  50/3167]  Time: 0.191 (0.199)  Loss:   3.889 ( 3.899)  Acc@1:  25.000 (  9.902)  Acc@5:  45.000 ( 36.863)
Test: [ 100/3167]  Time: 0.190 (0.195)  Loss:   3.989 ( 3.895)  Acc@1:   2.500 (  7.079)  Acc@5:  22.500 ( 33.317)
Test: [ 150/3167]  Time: 0.190 (0.194)  Loss:   2.531 ( 3.742)  Acc@1:  47.500 ( 12.715)  Acc@5:  82.500 ( 38.675)
Test: [ 200/3167]  Time: 0.191 (0.193)  Loss:   4.259 ( 3.761)  Acc@1:   0.000 ( 12.550)  Acc@5:  10.000 ( 36.331)
Test: [ 250/3167]  Time: 0.189 (0.193)  Loss:   3.039 ( 3.739)  Acc@1:  35.000 ( 14.054)  Acc@5:  52.500 ( 35.279)
Test: [ 300/3167]  Time: 0.198 (0.193)  Loss:   3.759 ( 3.742)  Acc@1:   0.000 ( 13.555)  Acc@5:  37.500 ( 35.806)
Test: [ 350/3167]  Time: 0.194 (0.193)  Loss:   3.041 ( 3.690)  Acc@1:  25.000 ( 13.597)  Acc@5:  70.000 ( 38.291)
Test: [ 400/3167]  Time: 0.191 (0.193)  Loss:   3.135 ( 3.523)  Acc@1:  25.000 ( 18.791)  Acc@5:  65.000 ( 43.211)
Test: [ 450/3167]  Time: 0.187 (0.193)  Loss:   3.933 ( 3.554)  Acc@1:   0.000 ( 17.727)  Acc@5:  17.500 ( 42.206)
Test: [ 500/3167]  Time: 0.201 (0.193)  Loss:   3.795 ( 3.606)  Acc@1:  22.500 ( 16.936)  Acc@5:  32.500 ( 40.619)
Test: [ 550/3167]  Time: 0.190 (0.193)  Loss:   4.004 ( 3.554)  Acc@1:  12.500 ( 19.061)  Acc@5:  22.500 ( 42.328)
Test: [ 600/3167]  Time: 0.185 (0.193)  Loss:   2.890 ( 3.558)  Acc@1:  12.500 ( 18.178)  Acc@5:  67.500 ( 42.230)
Test: [ 650/3167]  Time: 0.199 (0.193)  Loss:   3.831 ( 3.511)  Acc@1:  20.000 ( 19.758)  Acc@5:  45.000 ( 43.902)
Test: [ 700/3167]  Time: 0.199 (0.193)  Loss:   3.326 ( 3.511)  Acc@1:  12.500 ( 19.686)  Acc@5:  62.500 ( 44.911)
Test: [ 750/3167]  Time: 0.191 (0.193)  Loss:   3.588 ( 3.501)  Acc@1:  32.500 ( 19.394)  Acc@5:  45.000 ( 45.360)
Test: [ 800/3167]  Time: 0.199 (0.193)  Loss:   4.403 ( 3.525)  Acc@1:   0.000 ( 18.992)  Acc@5:   7.500 ( 44.438)
Test: [ 850/3167]  Time: 0.191 (0.193)  Loss:   3.735 ( 3.552)  Acc@1:   2.500 ( 18.223)  Acc@5:  22.500 ( 43.508)
Test: [ 900/3167]  Time: 0.190 (0.193)  Loss:   4.244 ( 3.586)  Acc@1:   2.500 ( 17.339)  Acc@5:  17.500 ( 42.156)
Test: [ 950/3167]  Time: 0.190 (0.193)  Loss:   3.070 ( 3.599)  Acc@1:  25.000 ( 16.940)  Acc@5:  65.000 ( 41.785)
Test: [1000/3167]  Time: 0.200 (0.193)  Loss:   3.430 ( 3.605)  Acc@1:  12.500 ( 16.581)  Acc@5:  57.500 ( 41.608)
Test: [1050/3167]  Time: 0.191 (0.193)  Loss:   3.434 ( 3.590)  Acc@1:  15.000 ( 16.658)  Acc@5:  47.500 ( 42.495)
Test: [1100/3167]  Time: 0.196 (0.193)  Loss:   3.874 ( 3.583)  Acc@1:  12.500 ( 16.619)  Acc@5:  35.000 ( 43.136)
Test: [1150/3167]  Time: 0.200 (0.193)  Loss:   3.033 ( 3.574)  Acc@1:  47.500 ( 17.350)  Acc@5:  80.000 ( 43.834)
Test: [1200/3167]  Time: 0.204 (0.193)  Loss:   2.789 ( 3.548)  Acc@1:  52.500 ( 18.197)  Acc@5:  75.000 ( 45.062)
Test: [1250/3167]  Time: 0.196 (0.193)  Loss:   3.209 ( 3.536)  Acc@1:  37.500 ( 18.921)  Acc@5:  62.500 ( 45.735)
Test: [1300/3167]  Time: 0.204 (0.193)  Loss:   3.493 ( 3.547)  Acc@1:  10.000 ( 18.457)  Acc@5:  45.000 ( 45.138)
Test: [1350/3167]  Time: 0.195 (0.193)  Loss:   4.023 ( 3.572)  Acc@1:   7.500 ( 18.042)  Acc@5:  32.500 ( 44.234)
Test: [1400/3167]  Time: 0.190 (0.193)  Loss:   3.645 ( 3.597)  Acc@1:  17.500 ( 17.602)  Acc@5:  50.000 ( 43.394)
Test: [1450/3167]  Time: 0.199 (0.193)  Loss:   3.679 ( 3.597)  Acc@1:  10.000 ( 17.677)  Acc@5:  35.000 ( 43.641)
Test: [1500/3167]  Time: 0.212 (0.193)  Loss:   3.400 ( 3.568)  Acc@1:  20.000 ( 18.654)  Acc@5:  55.000 ( 44.514)
Test: [1550/3167]  Time: 0.202 (0.193)  Loss:   2.516 ( 3.550)  Acc@1:  67.500 ( 19.383)  Acc@5:  85.000 ( 45.303)
Test: [1600/3167]  Time: 0.187 (0.193)  Loss:   2.583 ( 3.538)  Acc@1:  50.000 ( 19.872)  Acc@5:  72.500 ( 45.870)
Test: [1650/3167]  Time: 0.199 (0.193)  Loss:   3.352 ( 3.519)  Acc@1:  20.000 ( 20.469)  Acc@5:  60.000 ( 46.466)
Test: [1700/3167]  Time: 0.202 (0.193)  Loss:   4.199 ( 3.512)  Acc@1:   2.500 ( 20.703)  Acc@5:  17.500 ( 46.893)
Test: [1750/3167]  Time: 0.188 (0.193)  Loss:   3.585 ( 3.521)  Acc@1:  10.000 ( 20.387)  Acc@5:  32.500 ( 46.503)
Test: [1800/3167]  Time: 0.197 (0.193)  Loss:   3.355 ( 3.528)  Acc@1:  12.500 ( 20.110)  Acc@5:  47.500 ( 46.259)
Test: [1850/3167]  Time: 0.193 (0.193)  Loss:   4.194 ( 3.540)  Acc@1:  10.000 ( 19.610)  Acc@5:  17.500 ( 45.481)
Test: [1900/3167]  Time: 0.209 (0.193)  Loss:   3.896 ( 3.550)  Acc@1:   0.000 ( 19.337)  Acc@5:  32.500 ( 45.249)
Test: [1950/3167]  Time: 0.185 (0.193)  Loss:   4.589 ( 3.556)  Acc@1:   0.000 ( 19.227)  Acc@5:  10.000 ( 45.077)
Test: [2000/3167]  Time: 0.204 (0.193)  Loss:   3.889 ( 3.576)  Acc@1:   5.000 ( 18.779)  Acc@5:  35.000 ( 44.289)
Test: [2050/3167]  Time: 0.200 (0.193)  Loss:   4.124 ( 3.584)  Acc@1:   0.000 ( 18.481)  Acc@5:  25.000 ( 43.880)
Test: [2100/3167]  Time: 0.191 (0.193)  Loss:   3.810 ( 3.594)  Acc@1:   7.500 ( 18.296)  Acc@5:  30.000 ( 43.573)
Test: [2150/3167]  Time: 0.186 (0.193)  Loss:   2.021 ( 3.575)  Acc@1:  67.500 ( 18.784)  Acc@5:  75.000 ( 43.948)
Test: [2200/3167]  Time: 0.184 (0.193)  Loss:   3.290 ( 3.565)  Acc@1:   2.500 ( 18.848)  Acc@5:  55.000 ( 44.233)
Test: [2250/3167]  Time: 0.194 (0.193)  Loss:   3.701 ( 3.568)  Acc@1:  20.000 ( 18.568)  Acc@5:  52.500 ( 44.137)
Test: [2300/3167]  Time: 0.196 (0.193)  Loss:   4.149 ( 3.580)  Acc@1:   0.000 ( 18.300)  Acc@5:  15.000 ( 43.654)
Test: [2350/3167]  Time: 0.197 (0.193)  Loss:   3.992 ( 3.590)  Acc@1:   5.000 ( 17.962)  Acc@5:  42.500 ( 43.116)
Test: [2400/3167]  Time: 0.187 (0.193)  Loss:   4.351 ( 3.591)  Acc@1:   0.000 ( 18.056)  Acc@5:   5.000 ( 43.095)
Test: [2450/3167]  Time: 0.196 (0.193)  Loss:   2.760 ( 3.587)  Acc@1:  35.000 ( 18.160)  Acc@5:  85.000 ( 43.321)
Test: [2500/3167]  Time: 0.191 (0.193)  Loss:   4.261 ( 3.590)  Acc@1:  10.000 ( 18.138)  Acc@5:  20.000 ( 43.294)
Test: [2550/3167]  Time: 0.200 (0.193)  Loss:   4.133 ( 3.579)  Acc@1:   2.500 ( 18.629)  Acc@5:  20.000 ( 43.675)
Test: [2600/3167]  Time: 0.188 (0.193)  Loss:   3.296 ( 3.586)  Acc@1:  27.500 ( 18.477)  Acc@5:  55.000 ( 43.352)
Test: [2650/3167]  Time: 0.196 (0.193)  Loss:   4.107 ( 3.594)  Acc@1:   0.000 ( 18.279)  Acc@5:  12.500 ( 43.067)
Test: [2700/3167]  Time: 0.193 (0.193)  Loss:   3.275 ( 3.598)  Acc@1:  25.000 ( 18.140)  Acc@5:  52.500 ( 42.835)
Test: [2750/3167]  Time: 0.191 (0.193)  Loss:   2.844 ( 3.601)  Acc@1:  32.500 ( 18.055)  Acc@5:  75.000 ( 42.714)
Test: [2800/3167]  Time: 0.191 (0.193)  Loss:   4.291 ( 3.601)  Acc@1:   0.000 ( 17.995)  Acc@5:   5.000 ( 42.771)
Test: [2850/3167]  Time: 0.184 (0.193)  Loss:   3.912 ( 3.608)  Acc@1:  15.000 ( 17.803)  Acc@5:  40.000 ( 42.499)
Test: [2900/3167]  Time: 0.211 (0.193)  Loss:   3.806 ( 3.610)  Acc@1:   7.500 ( 17.785)  Acc@5:  45.000 ( 42.534)
Test: [2950/3167]  Time: 0.198 (0.193)  Loss:   3.934 ( 3.615)  Acc@1:   0.000 ( 17.547)  Acc@5:  20.000 ( 42.198)
Test: [3000/3167]  Time: 0.184 (0.193)  Loss:   4.094 ( 3.623)  Acc@1:   0.000 ( 17.263)  Acc@5:  17.500 ( 41.722)
Test: [3050/3167]  Time: 0.196 (0.192)  Loss:   4.302 ( 3.625)  Acc@1:   0.000 ( 17.102)  Acc@5:   5.000 ( 41.554)
Test: [3100/3167]  Time: 0.184 (0.192)  Loss:   4.123 ( 3.635)  Acc@1:   0.000 ( 16.860)  Acc@5:  20.000 ( 41.167)
Test: [3150/3167]  Time: 0.189 (0.192)  Loss:   4.144 ( 3.638)  Acc@1:   0.000 ( 16.706)  Acc@5:  22.500 ( 41.085)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   3.869 ( 3.640)  Acc@1:   0.000 ( 16.637)  Acc@5:  33.333 ( 40.990)
Test: [   0/124]  Time: 0.742 (0.742)  Loss:   4.161 ( 4.161)  Acc@1:   0.000 (  0.000)  Acc@5:  15.000 ( 15.000)
Test: [  50/124]  Time: 0.184 (0.202)  Loss:   3.816 ( 3.599)  Acc@1:  15.000 ( 16.765)  Acc@5:  32.500 ( 43.627)
Test: [ 100/124]  Time: 0.187 (0.196)  Loss:   2.424 ( 3.643)  Acc@1:  62.500 ( 17.054)  Acc@5:  87.500 ( 41.609)
Test: [ 124/124]  Time: 0.180 (0.194)  Loss:   4.071 ( 3.698)  Acc@1:   5.000 ( 15.380)  Acc@5:  35.000 ( 39.200)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_0/checkpoint-3.pth.tar', 16.63680351095991)

Train: 4 [   0/3167 (  0%)]  Loss: 3.98 (3.98)  Time: 1.120s,   35.70/s  (1.120s,   35.70/s)  LR: 4.600e-05  Data: 0.496 (0.496)
Train: 4 [  50/3167 (  2%)]  Loss: 3.83 (4.16)  Time: 0.597s,   67.03/s  (0.614s,   65.14/s)  LR: 4.600e-05  Data: 0.004 (0.020)
Train: 4 [ 100/3167 (  3%)]  Loss: 4.45 (4.20)  Time: 0.604s,   66.24/s  (0.608s,   65.78/s)  LR: 4.600e-05  Data: 0.012 (0.015)
Train: 4 [ 150/3167 (  5%)]  Loss: 4.21 (4.18)  Time: 0.603s,   66.29/s  (0.606s,   65.98/s)  LR: 4.600e-05  Data: 0.010 (0.013)
Train: 4 [ 200/3167 (  6%)]  Loss: 4.05 (4.19)  Time: 0.600s,   66.63/s  (0.605s,   66.09/s)  LR: 4.600e-05  Data: 0.011 (0.012)
Train: 4 [ 250/3167 (  8%)]  Loss: 4.28 (4.18)  Time: 0.593s,   67.46/s  (0.605s,   66.14/s)  LR: 4.600e-05  Data: 0.004 (0.012)
Train: 4 [ 300/3167 (  9%)]  Loss: 4.30 (4.17)  Time: 0.602s,   66.39/s  (0.605s,   66.16/s)  LR: 4.600e-05  Data: 0.011 (0.012)
Train: 4 [ 350/3167 ( 11%)]  Loss: 4.02 (4.17)  Time: 0.593s,   67.48/s  (0.604s,   66.19/s)  LR: 4.600e-05  Data: 0.004 (0.011)
Train: 4 [ 400/3167 ( 13%)]  Loss: 4.11 (4.17)  Time: 0.606s,   65.98/s  (0.604s,   66.21/s)  LR: 4.600e-05  Data: 0.014 (0.011)
Train: 4 [ 450/3167 ( 14%)]  Loss: 4.23 (4.17)  Time: 0.603s,   66.33/s  (0.604s,   66.24/s)  LR: 4.600e-05  Data: 0.012 (0.011)
Train: 4 [ 500/3167 ( 16%)]  Loss: 4.33 (4.16)  Time: 0.604s,   66.27/s  (0.604s,   66.25/s)  LR: 4.600e-05  Data: 0.015 (0.011)
Train: 4 [ 550/3167 ( 17%)]  Loss: 4.34 (4.17)  Time: 0.598s,   66.92/s  (0.604s,   66.25/s)  LR: 4.600e-05  Data: 0.009 (0.011)
Train: 4 [ 600/3167 ( 19%)]  Loss: 4.18 (4.16)  Time: 0.596s,   67.10/s  (0.604s,   66.26/s)  LR: 4.600e-05  Data: 0.007 (0.011)
Train: 4 [ 650/3167 ( 21%)]  Loss: 4.06 (4.16)  Time: 0.595s,   67.18/s  (0.604s,   66.26/s)  LR: 4.600e-05  Data: 0.004 (0.011)
Train: 4 [ 700/3167 ( 22%)]  Loss: 4.21 (4.17)  Time: 0.603s,   66.30/s  (0.604s,   66.27/s)  LR: 4.600e-05  Data: 0.012 (0.011)
Train: 4 [ 750/3167 ( 24%)]  Loss: 4.13 (4.16)  Time: 0.603s,   66.34/s  (0.604s,   66.27/s)  LR: 4.600e-05  Data: 0.012 (0.011)
Train: 4 [ 800/3167 ( 25%)]  Loss: 4.05 (4.16)  Time: 0.601s,   66.57/s  (0.603s,   66.29/s)  LR: 4.600e-05  Data: 0.012 (0.011)
Train: 4 [ 850/3167 ( 27%)]  Loss: 4.35 (4.16)  Time: 0.603s,   66.33/s  (0.603s,   66.30/s)  LR: 4.600e-05  Data: 0.011 (0.011)
Train: 4 [ 900/3167 ( 28%)]  Loss: 3.87 (4.16)  Time: 0.601s,   66.58/s  (0.603s,   66.31/s)  LR: 4.600e-05  Data: 0.012 (0.011)
Train: 4 [ 950/3167 ( 30%)]  Loss: 4.34 (4.15)  Time: 0.604s,   66.22/s  (0.603s,   66.32/s)  LR: 4.600e-05  Data: 0.011 (0.011)
Train: 4 [1000/3167 ( 32%)]  Loss: 3.99 (4.15)  Time: 0.604s,   66.25/s  (0.603s,   66.33/s)  LR: 4.600e-05  Data: 0.011 (0.011)
Train: 4 [1050/3167 ( 33%)]  Loss: 4.25 (4.15)  Time: 0.602s,   66.49/s  (0.603s,   66.33/s)  LR: 4.600e-05  Data: 0.012 (0.011)
Train: 4 [1100/3167 ( 35%)]  Loss: 4.23 (4.15)  Time: 0.601s,   66.57/s  (0.603s,   66.35/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1150/3167 ( 36%)]  Loss: 3.67 (4.15)  Time: 0.601s,   66.58/s  (0.603s,   66.35/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1200/3167 ( 38%)]  Loss: 3.94 (4.15)  Time: 0.601s,   66.58/s  (0.603s,   66.36/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1250/3167 ( 39%)]  Loss: 3.86 (4.14)  Time: 0.604s,   66.25/s  (0.603s,   66.36/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1300/3167 ( 41%)]  Loss: 4.46 (4.14)  Time: 0.606s,   66.04/s  (0.603s,   66.36/s)  LR: 4.600e-05  Data: 0.006 (0.010)
Train: 4 [1350/3167 ( 43%)]  Loss: 4.00 (4.14)  Time: 0.606s,   66.03/s  (0.603s,   66.37/s)  LR: 4.600e-05  Data: 0.011 (0.010)
Train: 4 [1400/3167 ( 44%)]  Loss: 4.28 (4.14)  Time: 0.606s,   66.05/s  (0.603s,   66.38/s)  LR: 4.600e-05  Data: 0.006 (0.010)
Train: 4 [1450/3167 ( 46%)]  Loss: 4.23 (4.14)  Time: 0.596s,   67.16/s  (0.603s,   66.39/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [1500/3167 ( 47%)]  Loss: 4.15 (4.14)  Time: 0.602s,   66.42/s  (0.603s,   66.39/s)  LR: 4.600e-05  Data: 0.006 (0.010)
Train: 4 [1550/3167 ( 49%)]  Loss: 4.30 (4.14)  Time: 0.607s,   65.94/s  (0.602s,   66.40/s)  LR: 4.600e-05  Data: 0.011 (0.010)
Train: 4 [1600/3167 ( 51%)]  Loss: 3.89 (4.14)  Time: 0.597s,   66.95/s  (0.602s,   66.41/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [1650/3167 ( 52%)]  Loss: 4.32 (4.14)  Time: 0.597s,   66.98/s  (0.602s,   66.41/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [1700/3167 ( 54%)]  Loss: 4.12 (4.14)  Time: 0.601s,   66.54/s  (0.602s,   66.42/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [1750/3167 ( 55%)]  Loss: 4.13 (4.14)  Time: 0.593s,   67.45/s  (0.602s,   66.42/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [1800/3167 ( 57%)]  Loss: 4.16 (4.14)  Time: 0.593s,   67.47/s  (0.602s,   66.43/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [1850/3167 ( 58%)]  Loss: 4.20 (4.14)  Time: 0.598s,   66.94/s  (0.602s,   66.44/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [1900/3167 ( 60%)]  Loss: 4.22 (4.14)  Time: 0.593s,   67.45/s  (0.602s,   66.44/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [1950/3167 ( 62%)]  Loss: 3.87 (4.14)  Time: 0.596s,   67.12/s  (0.602s,   66.45/s)  LR: 4.600e-05  Data: 0.007 (0.010)
Train: 4 [2000/3167 ( 63%)]  Loss: 4.16 (4.14)  Time: 0.593s,   67.41/s  (0.602s,   66.46/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [2050/3167 ( 65%)]  Loss: 3.99 (4.14)  Time: 0.593s,   67.48/s  (0.602s,   66.46/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [2100/3167 ( 66%)]  Loss: 3.94 (4.14)  Time: 0.606s,   66.06/s  (0.602s,   66.47/s)  LR: 4.600e-05  Data: 0.014 (0.010)
Train: 4 [2150/3167 ( 68%)]  Loss: 4.03 (4.14)  Time: 0.600s,   66.68/s  (0.602s,   66.47/s)  LR: 4.600e-05  Data: 0.010 (0.010)
Train: 4 [2200/3167 ( 69%)]  Loss: 4.02 (4.14)  Time: 0.593s,   67.47/s  (0.602s,   66.48/s)  LR: 4.600e-05  Data: 0.004 (0.010)
Train: 4 [2250/3167 ( 71%)]  Loss: 4.27 (4.14)  Time: 0.599s,   66.80/s  (0.602s,   66.49/s)  LR: 4.600e-05  Data: 0.009 (0.010)
Train: 4 [2300/3167 ( 73%)]  Loss: 4.19 (4.14)  Time: 0.601s,   66.59/s  (0.602s,   66.50/s)  LR: 4.600e-05  Data: 0.011 (0.010)
Train: 4 [2350/3167 ( 74%)]  Loss: 4.51 (4.14)  Time: 0.604s,   66.27/s  (0.601s,   66.51/s)  LR: 4.600e-05  Data: 0.012 (0.010)
Train: 4 [2400/3167 ( 76%)]  Loss: 4.18 (4.14)  Time: 0.594s,   67.33/s  (0.601s,   66.51/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2450/3167 ( 77%)]  Loss: 3.57 (4.13)  Time: 0.598s,   66.89/s  (0.601s,   66.52/s)  LR: 4.600e-05  Data: 0.009 (0.009)
Train: 4 [2500/3167 ( 79%)]  Loss: 4.14 (4.13)  Time: 0.594s,   67.30/s  (0.601s,   66.53/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2550/3167 ( 81%)]  Loss: 4.22 (4.13)  Time: 0.601s,   66.56/s  (0.601s,   66.54/s)  LR: 4.600e-05  Data: 0.009 (0.009)
Train: 4 [2600/3167 ( 82%)]  Loss: 3.89 (4.13)  Time: 0.603s,   66.30/s  (0.601s,   66.55/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Train: 4 [2650/3167 ( 84%)]  Loss: 4.42 (4.13)  Time: 0.595s,   67.26/s  (0.601s,   66.56/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2700/3167 ( 85%)]  Loss: 4.31 (4.13)  Time: 0.596s,   67.15/s  (0.601s,   66.57/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Train: 4 [2750/3167 ( 87%)]  Loss: 4.40 (4.13)  Time: 0.596s,   67.10/s  (0.601s,   66.58/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2800/3167 ( 88%)]  Loss: 4.08 (4.13)  Time: 0.598s,   66.84/s  (0.601s,   66.59/s)  LR: 4.600e-05  Data: 0.009 (0.009)
Train: 4 [2850/3167 ( 90%)]  Loss: 4.30 (4.13)  Time: 0.596s,   67.14/s  (0.601s,   66.59/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [2900/3167 ( 92%)]  Loss: 3.93 (4.13)  Time: 0.597s,   67.02/s  (0.601s,   66.60/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Train: 4 [2950/3167 ( 93%)]  Loss: 4.43 (4.13)  Time: 0.596s,   67.10/s  (0.601s,   66.61/s)  LR: 4.600e-05  Data: 0.007 (0.009)
Train: 4 [3000/3167 ( 95%)]  Loss: 4.04 (4.13)  Time: 0.593s,   67.46/s  (0.600s,   66.62/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [3050/3167 ( 96%)]  Loss: 4.28 (4.13)  Time: 0.613s,   65.26/s  (0.600s,   66.62/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [3100/3167 ( 98%)]  Loss: 3.88 (4.13)  Time: 0.596s,   67.14/s  (0.600s,   66.63/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Train: 4 [3150/3167 ( 99%)]  Loss: 4.16 (4.13)  Time: 0.593s,   67.43/s  (0.600s,   66.63/s)  LR: 4.600e-05  Data: 0.004 (0.009)
Test: [   0/3167]  Time: 0.505 (0.505)  Loss:   4.166 ( 4.166)  Acc@1:   7.500 (  7.500)  Acc@5:  20.000 ( 20.000)
Test: [  50/3167]  Time: 0.191 (0.198)  Loss:   3.760 ( 3.874)  Acc@1:  32.500 ( 11.324)  Acc@5:  50.000 ( 35.147)
Test: [ 100/3167]  Time: 0.198 (0.195)  Loss:   3.627 ( 3.646)  Acc@1:   7.500 ( 12.673)  Acc@5:  42.500 ( 44.604)
Test: [ 150/3167]  Time: 0.186 (0.194)  Loss:   2.254 ( 3.470)  Acc@1:  62.500 ( 19.404)  Acc@5:  82.500 ( 50.232)
Test: [ 200/3167]  Time: 0.210 (0.194)  Loss:   4.059 ( 3.533)  Acc@1:   2.500 ( 17.998)  Acc@5:  12.500 ( 44.279)
Test: [ 250/3167]  Time: 0.207 (0.194)  Loss:   2.635 ( 3.514)  Acc@1:  45.000 ( 18.894)  Acc@5:  67.500 ( 42.859)
Test: [ 300/3167]  Time: 0.186 (0.193)  Loss:   3.748 ( 3.518)  Acc@1:   5.000 ( 18.904)  Acc@5:  32.500 ( 43.339)
Test: [ 350/3167]  Time: 0.203 (0.193)  Loss:   2.986 ( 3.501)  Acc@1:  42.500 ( 19.167)  Acc@5:  70.000 ( 44.573)
Test: [ 400/3167]  Time: 0.192 (0.193)  Loss:   3.292 ( 3.395)  Acc@1:  22.500 ( 22.668)  Acc@5:  57.500 ( 48.042)
Test: [ 450/3167]  Time: 0.190 (0.193)  Loss:   3.720 ( 3.433)  Acc@1:   2.500 ( 21.014)  Acc@5:  35.000 ( 46.491)
Test: [ 500/3167]  Time: 0.203 (0.193)  Loss:   3.187 ( 3.454)  Acc@1:  37.500 ( 21.228)  Acc@5:  52.500 ( 46.267)
Test: [ 550/3167]  Time: 0.192 (0.193)  Loss:   3.957 ( 3.410)  Acc@1:   7.500 ( 22.981)  Acc@5:  27.500 ( 47.532)
Test: [ 600/3167]  Time: 0.187 (0.193)  Loss:   3.139 ( 3.434)  Acc@1:  12.500 ( 21.926)  Acc@5:  60.000 ( 46.647)
Test: [ 650/3167]  Time: 0.191 (0.193)  Loss:   3.520 ( 3.406)  Acc@1:  17.500 ( 22.853)  Acc@5:  47.500 ( 47.535)
Test: [ 700/3167]  Time: 0.191 (0.193)  Loss:   3.257 ( 3.403)  Acc@1:  15.000 ( 22.340)  Acc@5:  67.500 ( 48.438)
Test: [ 750/3167]  Time: 0.198 (0.193)  Loss:   3.412 ( 3.392)  Acc@1:  37.500 ( 22.250)  Acc@5:  50.000 ( 49.174)
Test: [ 800/3167]  Time: 0.192 (0.193)  Loss:   4.223 ( 3.408)  Acc@1:   0.000 ( 22.113)  Acc@5:  20.000 ( 48.452)
Test: [ 850/3167]  Time: 0.199 (0.193)  Loss:   4.000 ( 3.436)  Acc@1:   0.000 ( 21.290)  Acc@5:  15.000 ( 47.374)
Test: [ 900/3167]  Time: 0.190 (0.193)  Loss:   3.952 ( 3.473)  Acc@1:   7.500 ( 20.297)  Acc@5:  30.000 ( 45.794)
Test: [ 950/3167]  Time: 0.190 (0.193)  Loss:   3.319 ( 3.484)  Acc@1:  15.000 ( 19.858)  Acc@5:  50.000 ( 45.463)
Test: [1000/3167]  Time: 0.208 (0.193)  Loss:   3.428 ( 3.509)  Acc@1:  17.500 ( 19.216)  Acc@5:  57.500 ( 44.500)
Test: [1050/3167]  Time: 0.197 (0.193)  Loss:   2.905 ( 3.482)  Acc@1:  35.000 ( 19.945)  Acc@5:  77.500 ( 45.785)
Test: [1100/3167]  Time: 0.185 (0.193)  Loss:   3.415 ( 3.483)  Acc@1:  30.000 ( 19.600)  Acc@5:  65.000 ( 45.543)
Test: [1150/3167]  Time: 0.187 (0.193)  Loss:   2.949 ( 3.468)  Acc@1:  52.500 ( 20.506)  Acc@5:  72.500 ( 46.425)
Test: [1200/3167]  Time: 0.191 (0.193)  Loss:   3.215 ( 3.453)  Acc@1:  22.500 ( 20.897)  Acc@5:  57.500 ( 47.179)
Test: [1250/3167]  Time: 0.203 (0.193)  Loss:   2.850 ( 3.437)  Acc@1:  47.500 ( 21.725)  Acc@5:  65.000 ( 47.926)
Test: [1300/3167]  Time: 0.194 (0.193)  Loss:   3.220 ( 3.437)  Acc@1:  27.500 ( 21.451)  Acc@5:  67.500 ( 48.071)
Test: [1350/3167]  Time: 0.198 (0.193)  Loss:   3.824 ( 3.454)  Acc@1:  10.000 ( 21.153)  Acc@5:  47.500 ( 47.546)
Test: [1400/3167]  Time: 0.194 (0.193)  Loss:   3.063 ( 3.475)  Acc@1:  40.000 ( 20.787)  Acc@5:  62.500 ( 46.827)
Test: [1450/3167]  Time: 0.193 (0.193)  Loss:   3.568 ( 3.469)  Acc@1:  12.500 ( 21.160)  Acc@5:  42.500 ( 47.205)
Test: [1500/3167]  Time: 0.191 (0.193)  Loss:   3.376 ( 3.449)  Acc@1:  17.500 ( 21.762)  Acc@5:  55.000 ( 47.861)
Test: [1550/3167]  Time: 0.184 (0.193)  Loss:   2.351 ( 3.434)  Acc@1:  75.000 ( 22.257)  Acc@5:  87.500 ( 48.503)
Test: [1600/3167]  Time: 0.192 (0.193)  Loss:   2.654 ( 3.424)  Acc@1:  52.500 ( 22.541)  Acc@5:  65.000 ( 48.930)
Test: [1650/3167]  Time: 0.194 (0.193)  Loss:   3.211 ( 3.406)  Acc@1:  22.500 ( 23.113)  Acc@5:  52.500 ( 49.456)
Test: [1700/3167]  Time: 0.200 (0.193)  Loss:   4.205 ( 3.405)  Acc@1:   5.000 ( 23.110)  Acc@5:  15.000 ( 49.672)
Test: [1750/3167]  Time: 0.203 (0.193)  Loss:   3.425 ( 3.414)  Acc@1:  22.500 ( 22.823)  Acc@5:  42.500 ( 49.325)
Test: [1800/3167]  Time: 0.192 (0.193)  Loss:   3.382 ( 3.423)  Acc@1:  12.500 ( 22.529)  Acc@5:  50.000 ( 48.991)
Test: [1850/3167]  Time: 0.198 (0.193)  Loss:   3.764 ( 3.433)  Acc@1:  17.500 ( 22.022)  Acc@5:  32.500 ( 48.291)
Test: [1900/3167]  Time: 0.186 (0.193)  Loss:   3.630 ( 3.438)  Acc@1:  10.000 ( 21.820)  Acc@5:  45.000 ( 48.309)
Test: [1950/3167]  Time: 0.203 (0.193)  Loss:   4.606 ( 3.439)  Acc@1:   5.000 ( 21.826)  Acc@5:  17.500 ( 48.329)
Test: [2000/3167]  Time: 0.189 (0.193)  Loss:   4.047 ( 3.461)  Acc@1:   2.500 ( 21.396)  Acc@5:  22.500 ( 47.499)
Test: [2050/3167]  Time: 0.197 (0.193)  Loss:   3.969 ( 3.472)  Acc@1:   0.000 ( 21.003)  Acc@5:  10.000 ( 46.855)
Test: [2100/3167]  Time: 0.183 (0.193)  Loss:   3.214 ( 3.478)  Acc@1:  17.500 ( 20.908)  Acc@5:  62.500 ( 46.742)
Test: [2150/3167]  Time: 0.195 (0.193)  Loss:   1.792 ( 3.453)  Acc@1:  67.500 ( 21.573)  Acc@5:  82.500 ( 47.416)
Test: [2200/3167]  Time: 0.196 (0.193)  Loss:   3.455 ( 3.447)  Acc@1:   7.500 ( 21.463)  Acc@5:  52.500 ( 47.706)
Test: [2250/3167]  Time: 0.192 (0.193)  Loss:   3.561 ( 3.452)  Acc@1:  20.000 ( 21.202)  Acc@5:  52.500 ( 47.536)
Test: [2300/3167]  Time: 0.189 (0.193)  Loss:   3.895 ( 3.461)  Acc@1:   0.000 ( 20.941)  Acc@5:  17.500 ( 47.034)
Test: [2350/3167]  Time: 0.190 (0.193)  Loss:   3.980 ( 3.469)  Acc@1:  12.500 ( 20.590)  Acc@5:  37.500 ( 46.557)
Test: [2400/3167]  Time: 0.185 (0.193)  Loss:   4.102 ( 3.467)  Acc@1:   2.500 ( 20.699)  Acc@5:  27.500 ( 46.649)
Test: [2450/3167]  Time: 0.184 (0.193)  Loss:   2.756 ( 3.464)  Acc@1:  40.000 ( 20.777)  Acc@5:  87.500 ( 46.866)
Test: [2500/3167]  Time: 0.184 (0.193)  Loss:   3.732 ( 3.462)  Acc@1:  25.000 ( 20.836)  Acc@5:  47.500 ( 47.035)
Test: [2550/3167]  Time: 0.188 (0.193)  Loss:   4.135 ( 3.451)  Acc@1:   2.500 ( 21.388)  Acc@5:  10.000 ( 47.466)
Test: [2600/3167]  Time: 0.184 (0.193)  Loss:   3.385 ( 3.460)  Acc@1:  30.000 ( 21.160)  Acc@5:  50.000 ( 47.033)
Test: [2650/3167]  Time: 0.189 (0.193)  Loss:   3.768 ( 3.470)  Acc@1:   5.000 ( 20.982)  Acc@5:  30.000 ( 46.768)
Test: [2700/3167]  Time: 0.185 (0.193)  Loss:   2.987 ( 3.469)  Acc@1:  32.500 ( 20.977)  Acc@5:  67.500 ( 46.765)
Test: [2750/3167]  Time: 0.183 (0.193)  Loss:   2.674 ( 3.474)  Acc@1:  42.500 ( 20.893)  Acc@5:  87.500 ( 46.611)
Test: [2800/3167]  Time: 0.189 (0.193)  Loss:   4.165 ( 3.473)  Acc@1:   0.000 ( 20.926)  Acc@5:  27.500 ( 46.740)
Test: [2850/3167]  Time: 0.189 (0.193)  Loss:   3.939 ( 3.482)  Acc@1:  10.000 ( 20.623)  Acc@5:  35.000 ( 46.337)
Test: [2900/3167]  Time: 0.189 (0.193)  Loss:   3.551 ( 3.485)  Acc@1:   7.500 ( 20.562)  Acc@5:  50.000 ( 46.323)
Test: [2950/3167]  Time: 0.186 (0.193)  Loss:   3.941 ( 3.491)  Acc@1:   0.000 ( 20.305)  Acc@5:  20.000 ( 45.998)
Test: [3000/3167]  Time: 0.184 (0.193)  Loss:   3.885 ( 3.499)  Acc@1:   7.500 ( 20.017)  Acc@5:  35.000 ( 45.610)
Test: [3050/3167]  Time: 0.184 (0.192)  Loss:   4.002 ( 3.496)  Acc@1:   5.000 ( 20.169)  Acc@5:  17.500 ( 45.828)
Test: [3100/3167]  Time: 0.192 (0.192)  Loss:   3.978 ( 3.505)  Acc@1:   2.500 ( 19.906)  Acc@5:  25.000 ( 45.504)
Test: [3150/3167]  Time: 0.185 (0.192)  Loss:   3.600 ( 3.505)  Acc@1:   0.000 ( 19.698)  Acc@5:  45.000 ( 45.551)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   3.338 ( 3.506)  Acc@1:  22.222 ( 19.648)  Acc@5:  55.556 ( 45.541)
Test: [   0/124]  Time: 0.585 (0.585)  Loss:   4.250 ( 4.250)  Acc@1:   0.000 (  0.000)  Acc@5:  12.500 ( 12.500)
Test: [  50/124]  Time: 0.198 (0.199)  Loss:   3.487 ( 3.507)  Acc@1:  27.500 ( 19.020)  Acc@5:  55.000 ( 45.245)
Test: [ 100/124]  Time: 0.198 (0.195)  Loss:   2.603 ( 3.523)  Acc@1:  65.000 ( 18.911)  Acc@5:  75.000 ( 44.307)
Test: [ 124/124]  Time: 0.180 (0.193)  Loss:   3.532 ( 3.570)  Acc@1:  12.500 ( 17.480)  Acc@5:  47.500 ( 42.880)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_0/checkpoint-4.pth.tar', 19.64811467459319)

Train: 5 [   0/3167 (  0%)]  Loss: 4.29 (4.29)  Time: 1.090s,   36.70/s  (1.090s,   36.70/s)  LR: 5.500e-05  Data: 0.480 (0.480)
Train: 5 [  50/3167 (  2%)]  Loss: 4.14 (4.20)  Time: 0.607s,   65.93/s  (0.613s,   65.26/s)  LR: 5.500e-05  Data: 0.011 (0.019)
Train: 5 [ 100/3167 (  3%)]  Loss: 4.50 (4.15)  Time: 0.601s,   66.53/s  (0.608s,   65.80/s)  LR: 5.500e-05  Data: 0.012 (0.014)
Train: 5 [ 150/3167 (  5%)]  Loss: 4.18 (4.13)  Time: 0.593s,   67.46/s  (0.606s,   65.97/s)  LR: 5.500e-05  Data: 0.004 (0.013)
Train: 5 [ 200/3167 (  6%)]  Loss: 4.22 (4.12)  Time: 0.605s,   66.14/s  (0.605s,   66.07/s)  LR: 5.500e-05  Data: 0.007 (0.012)
Train: 5 [ 250/3167 (  8%)]  Loss: 4.50 (4.11)  Time: 0.611s,   65.51/s  (0.605s,   66.13/s)  LR: 5.500e-05  Data: 0.012 (0.012)
Train: 5 [ 300/3167 (  9%)]  Loss: 3.93 (4.11)  Time: 0.596s,   67.17/s  (0.605s,   66.15/s)  LR: 5.500e-05  Data: 0.004 (0.012)
Train: 5 [ 350/3167 ( 11%)]  Loss: 3.94 (4.11)  Time: 0.603s,   66.34/s  (0.604s,   66.19/s)  LR: 5.500e-05  Data: 0.011 (0.012)
Train: 5 [ 400/3167 ( 13%)]  Loss: 4.27 (4.10)  Time: 0.609s,   65.66/s  (0.604s,   66.18/s)  LR: 5.500e-05  Data: 0.011 (0.011)
Train: 5 [ 450/3167 ( 14%)]  Loss: 4.25 (4.10)  Time: 0.608s,   65.83/s  (0.604s,   66.20/s)  LR: 5.500e-05  Data: 0.012 (0.011)
Train: 5 [ 500/3167 ( 16%)]  Loss: 3.34 (4.09)  Time: 0.609s,   65.67/s  (0.604s,   66.22/s)  LR: 5.500e-05  Data: 0.012 (0.011)
Train: 5 [ 550/3167 ( 17%)]  Loss: 4.48 (4.09)  Time: 0.607s,   65.91/s  (0.604s,   66.23/s)  LR: 5.500e-05  Data: 0.011 (0.011)
Train: 5 [ 600/3167 ( 19%)]  Loss: 4.52 (4.10)  Time: 0.603s,   66.36/s  (0.604s,   66.25/s)  LR: 5.500e-05  Data: 0.012 (0.011)
Train: 5 [ 650/3167 ( 21%)]  Loss: 4.01 (4.10)  Time: 0.601s,   66.58/s  (0.604s,   66.26/s)  LR: 5.500e-05  Data: 0.012 (0.011)
Train: 5 [ 700/3167 ( 22%)]  Loss: 4.36 (4.10)  Time: 0.593s,   67.46/s  (0.604s,   66.27/s)  LR: 5.500e-05  Data: 0.004 (0.011)
Train: 5 [ 750/3167 ( 24%)]  Loss: 4.24 (4.10)  Time: 0.601s,   66.61/s  (0.603s,   66.28/s)  LR: 5.500e-05  Data: 0.012 (0.011)
Train: 5 [ 800/3167 ( 25%)]  Loss: 3.66 (4.09)  Time: 0.601s,   66.60/s  (0.603s,   66.28/s)  LR: 5.500e-05  Data: 0.012 (0.011)
Train: 5 [ 850/3167 ( 27%)]  Loss: 4.08 (4.09)  Time: 0.608s,   65.76/s  (0.603s,   66.29/s)  LR: 5.500e-05  Data: 0.012 (0.011)
Train: 5 [ 900/3167 ( 28%)]  Loss: 3.92 (4.09)  Time: 0.605s,   66.17/s  (0.603s,   66.30/s)  LR: 5.500e-05  Data: 0.009 (0.011)
Train: 5 [ 950/3167 ( 30%)]  Loss: 4.12 (4.09)  Time: 0.601s,   66.56/s  (0.603s,   66.30/s)  LR: 5.500e-05  Data: 0.012 (0.011)
Train: 5 [1000/3167 ( 32%)]  Loss: 4.00 (4.09)  Time: 0.601s,   66.59/s  (0.603s,   66.30/s)  LR: 5.500e-05  Data: 0.011 (0.011)
Train: 5 [1050/3167 ( 33%)]  Loss: 4.38 (4.09)  Time: 0.604s,   66.23/s  (0.603s,   66.31/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [1100/3167 ( 35%)]  Loss: 4.38 (4.09)  Time: 0.601s,   66.56/s  (0.603s,   66.32/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1150/3167 ( 36%)]  Loss: 4.46 (4.09)  Time: 0.611s,   65.51/s  (0.603s,   66.32/s)  LR: 5.500e-05  Data: 0.014 (0.010)
Train: 5 [1200/3167 ( 38%)]  Loss: 4.28 (4.09)  Time: 0.598s,   66.86/s  (0.603s,   66.34/s)  LR: 5.500e-05  Data: 0.009 (0.010)
Train: 5 [1250/3167 ( 39%)]  Loss: 3.94 (4.09)  Time: 0.603s,   66.30/s  (0.603s,   66.35/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [1300/3167 ( 41%)]  Loss: 3.91 (4.09)  Time: 0.605s,   66.09/s  (0.603s,   66.36/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [1350/3167 ( 43%)]  Loss: 3.61 (4.09)  Time: 0.600s,   66.67/s  (0.603s,   66.36/s)  LR: 5.500e-05  Data: 0.006 (0.010)
Train: 5 [1400/3167 ( 44%)]  Loss: 4.28 (4.09)  Time: 0.610s,   65.53/s  (0.603s,   66.37/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [1450/3167 ( 46%)]  Loss: 4.04 (4.09)  Time: 0.600s,   66.62/s  (0.603s,   66.37/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1500/3167 ( 47%)]  Loss: 4.06 (4.09)  Time: 0.601s,   66.56/s  (0.603s,   66.37/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1550/3167 ( 49%)]  Loss: 4.25 (4.09)  Time: 0.603s,   66.29/s  (0.603s,   66.38/s)  LR: 5.500e-05  Data: 0.009 (0.010)
Train: 5 [1600/3167 ( 51%)]  Loss: 4.17 (4.09)  Time: 0.601s,   66.57/s  (0.603s,   66.38/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1650/3167 ( 52%)]  Loss: 3.74 (4.08)  Time: 0.600s,   66.66/s  (0.602s,   66.39/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [1700/3167 ( 54%)]  Loss: 3.97 (4.08)  Time: 0.596s,   67.15/s  (0.602s,   66.40/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [1750/3167 ( 55%)]  Loss: 4.17 (4.08)  Time: 0.610s,   65.54/s  (0.602s,   66.40/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1800/3167 ( 57%)]  Loss: 4.21 (4.08)  Time: 0.601s,   66.54/s  (0.602s,   66.41/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [1850/3167 ( 58%)]  Loss: 3.64 (4.08)  Time: 0.600s,   66.63/s  (0.602s,   66.41/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [1900/3167 ( 60%)]  Loss: 4.31 (4.08)  Time: 0.595s,   67.19/s  (0.602s,   66.42/s)  LR: 5.500e-05  Data: 0.006 (0.010)
Train: 5 [1950/3167 ( 62%)]  Loss: 4.43 (4.08)  Time: 0.598s,   66.88/s  (0.602s,   66.42/s)  LR: 5.500e-05  Data: 0.009 (0.010)
Train: 5 [2000/3167 ( 63%)]  Loss: 3.98 (4.08)  Time: 0.607s,   65.86/s  (0.602s,   66.43/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [2050/3167 ( 65%)]  Loss: 4.20 (4.08)  Time: 0.601s,   66.54/s  (0.602s,   66.44/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [2100/3167 ( 66%)]  Loss: 4.37 (4.08)  Time: 0.596s,   67.13/s  (0.602s,   66.44/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [2150/3167 ( 68%)]  Loss: 3.67 (4.08)  Time: 0.600s,   66.62/s  (0.602s,   66.45/s)  LR: 5.500e-05  Data: 0.011 (0.010)
Train: 5 [2200/3167 ( 69%)]  Loss: 4.15 (4.08)  Time: 0.595s,   67.26/s  (0.602s,   66.46/s)  LR: 5.500e-05  Data: 0.004 (0.010)
Train: 5 [2250/3167 ( 71%)]  Loss: 4.22 (4.08)  Time: 0.601s,   66.54/s  (0.602s,   66.47/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [2300/3167 ( 73%)]  Loss: 4.22 (4.08)  Time: 0.604s,   66.22/s  (0.602s,   66.47/s)  LR: 5.500e-05  Data: 0.012 (0.010)
Train: 5 [2350/3167 ( 74%)]  Loss: 3.94 (4.08)  Time: 0.596s,   67.15/s  (0.602s,   66.48/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [2400/3167 ( 76%)]  Loss: 4.39 (4.08)  Time: 0.596s,   67.09/s  (0.602s,   66.49/s)  LR: 5.500e-05  Data: 0.007 (0.010)
Train: 5 [2450/3167 ( 77%)]  Loss: 4.31 (4.08)  Time: 0.596s,   67.14/s  (0.602s,   66.50/s)  LR: 5.500e-05  Data: 0.007 (0.009)
Train: 5 [2500/3167 ( 79%)]  Loss: 3.81 (4.08)  Time: 0.593s,   67.47/s  (0.601s,   66.51/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2550/3167 ( 81%)]  Loss: 3.64 (4.08)  Time: 0.593s,   67.45/s  (0.601s,   66.52/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2600/3167 ( 82%)]  Loss: 4.28 (4.08)  Time: 0.593s,   67.45/s  (0.601s,   66.53/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2650/3167 ( 84%)]  Loss: 3.80 (4.08)  Time: 0.598s,   66.90/s  (0.601s,   66.54/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2700/3167 ( 85%)]  Loss: 4.05 (4.08)  Time: 0.593s,   67.42/s  (0.601s,   66.55/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2750/3167 ( 87%)]  Loss: 4.20 (4.08)  Time: 0.593s,   67.46/s  (0.601s,   66.56/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2800/3167 ( 88%)]  Loss: 4.05 (4.07)  Time: 0.598s,   66.84/s  (0.601s,   66.57/s)  LR: 5.500e-05  Data: 0.009 (0.009)
Train: 5 [2850/3167 ( 90%)]  Loss: 3.93 (4.07)  Time: 0.597s,   66.98/s  (0.601s,   66.57/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2900/3167 ( 92%)]  Loss: 3.89 (4.07)  Time: 0.593s,   67.43/s  (0.601s,   66.58/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [2950/3167 ( 93%)]  Loss: 4.28 (4.07)  Time: 0.598s,   66.93/s  (0.601s,   66.59/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [3000/3167 ( 95%)]  Loss: 4.00 (4.07)  Time: 0.593s,   67.42/s  (0.601s,   66.60/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [3050/3167 ( 96%)]  Loss: 4.18 (4.07)  Time: 0.600s,   66.67/s  (0.601s,   66.60/s)  LR: 5.500e-05  Data: 0.010 (0.009)
Train: 5 [3100/3167 ( 98%)]  Loss: 4.10 (4.07)  Time: 0.595s,   67.26/s  (0.600s,   66.61/s)  LR: 5.500e-05  Data: 0.004 (0.009)
Train: 5 [3150/3167 ( 99%)]  Loss: 3.69 (4.07)  Time: 0.601s,   66.54/s  (0.600s,   66.62/s)  LR: 5.500e-05  Data: 0.009 (0.009)
Test: [   0/3167]  Time: 0.536 (0.536)  Loss:   3.965 ( 3.965)  Acc@1:   2.500 (  2.500)  Acc@5:  30.000 ( 30.000)
Test: [  50/3167]  Time: 0.195 (0.199)  Loss:   3.562 ( 3.684)  Acc@1:  30.000 ( 13.382)  Acc@5:  47.500 ( 40.343)
Test: [ 100/3167]  Time: 0.191 (0.196)  Loss:   3.678 ( 3.698)  Acc@1:  17.500 ( 13.119)  Acc@5:  50.000 ( 39.010)
Test: [ 150/3167]  Time: 0.190 (0.194)  Loss:   2.170 ( 3.515)  Acc@1:  62.500 ( 19.520)  Acc@5:  92.500 ( 46.457)
Test: [ 200/3167]  Time: 0.187 (0.194)  Loss:   3.616 ( 3.530)  Acc@1:  12.500 ( 19.378)  Acc@5:  45.000 ( 45.920)
Test: [ 250/3167]  Time: 0.183 (0.193)  Loss:   2.790 ( 3.476)  Acc@1:  30.000 ( 20.657)  Acc@5:  57.500 ( 46.574)
Test: [ 300/3167]  Time: 0.191 (0.193)  Loss:   3.199 ( 3.452)  Acc@1:  22.500 ( 21.653)  Acc@5:  65.000 ( 47.882)
Test: [ 350/3167]  Time: 0.197 (0.193)  Loss:   2.490 ( 3.369)  Acc@1:  65.000 ( 24.003)  Acc@5:  77.500 ( 50.776)
Test: [ 400/3167]  Time: 0.191 (0.193)  Loss:   2.700 ( 3.204)  Acc@1:  30.000 ( 28.541)  Acc@5:  72.500 ( 54.913)
Test: [ 450/3167]  Time: 0.193 (0.193)  Loss:   3.348 ( 3.216)  Acc@1:   2.500 ( 27.023)  Acc@5:  47.500 ( 54.257)
Test: [ 500/3167]  Time: 0.189 (0.193)  Loss:   2.706 ( 3.228)  Acc@1:  52.500 ( 27.061)  Acc@5:  67.500 ( 53.668)
Test: [ 550/3167]  Time: 0.189 (0.193)  Loss:   3.725 ( 3.165)  Acc@1:   2.500 ( 29.279)  Acc@5:  32.500 ( 55.113)
Test: [ 600/3167]  Time: 0.191 (0.192)  Loss:   2.602 ( 3.183)  Acc@1:  27.500 ( 28.066)  Acc@5:  77.500 ( 54.434)
Test: [ 650/3167]  Time: 0.191 (0.193)  Loss:   3.514 ( 3.170)  Acc@1:  30.000 ( 28.475)  Acc@5:  52.500 ( 54.969)
Test: [ 700/3167]  Time: 0.189 (0.193)  Loss:   3.023 ( 3.178)  Acc@1:  35.000 ( 28.627)  Acc@5:  75.000 ( 55.685)
Test: [ 750/3167]  Time: 0.185 (0.193)  Loss:   3.269 ( 3.175)  Acc@1:  42.500 ( 28.033)  Acc@5:  50.000 ( 56.095)
Test: [ 800/3167]  Time: 0.207 (0.193)  Loss:   4.375 ( 3.208)  Acc@1:   0.000 ( 27.453)  Acc@5:  20.000 ( 54.778)
Test: [ 850/3167]  Time: 0.191 (0.193)  Loss:   3.620 ( 3.258)  Acc@1:   2.500 ( 25.981)  Acc@5:  37.500 ( 52.838)
Test: [ 900/3167]  Time: 0.190 (0.193)  Loss:   3.699 ( 3.289)  Acc@1:  10.000 ( 24.761)  Acc@5:  40.000 ( 51.598)
Test: [ 950/3167]  Time: 0.190 (0.193)  Loss:   3.045 ( 3.319)  Acc@1:  25.000 ( 23.885)  Acc@5:  60.000 ( 50.360)
Test: [1000/3167]  Time: 0.207 (0.193)  Loss:   2.937 ( 3.326)  Acc@1:  45.000 ( 23.469)  Acc@5:  75.000 ( 50.237)
Test: [1050/3167]  Time: 0.197 (0.193)  Loss:   3.526 ( 3.317)  Acc@1:  20.000 ( 23.666)  Acc@5:  40.000 ( 50.802)
Test: [1100/3167]  Time: 0.202 (0.193)  Loss:   3.620 ( 3.317)  Acc@1:  22.500 ( 23.417)  Acc@5:  42.500 ( 51.056)
Test: [1150/3167]  Time: 0.200 (0.193)  Loss:   2.383 ( 3.301)  Acc@1:  62.500 ( 24.264)  Acc@5:  82.500 ( 51.709)
Test: [1200/3167]  Time: 0.196 (0.193)  Loss:   3.050 ( 3.283)  Acc@1:  35.000 ( 24.519)  Acc@5:  70.000 ( 52.592)
Test: [1250/3167]  Time: 0.188 (0.193)  Loss:   2.735 ( 3.269)  Acc@1:  50.000 ( 25.236)  Acc@5:  67.500 ( 53.157)
Test: [1300/3167]  Time: 0.191 (0.193)  Loss:   3.278 ( 3.287)  Acc@1:  20.000 ( 24.600)  Acc@5:  62.500 ( 52.291)
Test: [1350/3167]  Time: 0.184 (0.193)  Loss:   3.278 ( 3.313)  Acc@1:  17.500 ( 24.054)  Acc@5:  67.500 ( 51.345)
Test: [1400/3167]  Time: 0.191 (0.193)  Loss:   2.693 ( 3.332)  Acc@1:  47.500 ( 23.721)  Acc@5:  80.000 ( 50.785)
Test: [1450/3167]  Time: 0.202 (0.193)  Loss:   3.172 ( 3.315)  Acc@1:  17.500 ( 24.414)  Acc@5:  65.000 ( 51.489)
Test: [1500/3167]  Time: 0.205 (0.193)  Loss:   3.687 ( 3.298)  Acc@1:  10.000 ( 24.943)  Acc@5:  45.000 ( 52.064)
Test: [1550/3167]  Time: 0.204 (0.193)  Loss:   2.066 ( 3.288)  Acc@1:  82.500 ( 25.285)  Acc@5:  90.000 ( 52.444)
Test: [1600/3167]  Time: 0.198 (0.193)  Loss:   2.720 ( 3.276)  Acc@1:  42.500 ( 25.681)  Acc@5:  57.500 ( 52.954)
Test: [1650/3167]  Time: 0.190 (0.193)  Loss:   3.108 ( 3.263)  Acc@1:  15.000 ( 25.996)  Acc@5:  62.500 ( 53.363)
Test: [1700/3167]  Time: 0.190 (0.193)  Loss:   3.954 ( 3.259)  Acc@1:   2.500 ( 26.141)  Acc@5:  17.500 ( 53.595)
Test: [1750/3167]  Time: 0.191 (0.193)  Loss:   3.625 ( 3.272)  Acc@1:  20.000 ( 25.834)  Acc@5:  37.500 ( 53.091)
Test: [1800/3167]  Time: 0.194 (0.193)  Loss:   3.016 ( 3.272)  Acc@1:  20.000 ( 25.854)  Acc@5:  67.500 ( 53.200)
Test: [1850/3167]  Time: 0.186 (0.193)  Loss:   3.896 ( 3.289)  Acc@1:  15.000 ( 25.370)  Acc@5:  32.500 ( 52.496)
Test: [1900/3167]  Time: 0.189 (0.193)  Loss:   3.859 ( 3.301)  Acc@1:   0.000 ( 25.009)  Acc@5:  32.500 ( 52.173)
Test: [1950/3167]  Time: 0.187 (0.193)  Loss:   4.417 ( 3.316)  Acc@1:   0.000 ( 24.621)  Acc@5:  10.000 ( 51.629)
Test: [2000/3167]  Time: 0.192 (0.193)  Loss:   3.796 ( 3.337)  Acc@1:  10.000 ( 24.103)  Acc@5:  37.500 ( 50.820)
Test: [2050/3167]  Time: 0.187 (0.193)  Loss:   4.298 ( 3.352)  Acc@1:   0.000 ( 23.707)  Acc@5:   7.500 ( 50.091)
Test: [2100/3167]  Time: 0.202 (0.193)  Loss:   3.783 ( 3.358)  Acc@1:  12.500 ( 23.671)  Acc@5:  32.500 ( 49.983)
Test: [2150/3167]  Time: 0.194 (0.193)  Loss:   1.478 ( 3.339)  Acc@1:  80.000 ( 24.133)  Acc@5:  85.000 ( 50.255)
Test: [2200/3167]  Time: 0.193 (0.193)  Loss:   3.055 ( 3.329)  Acc@1:  12.500 ( 24.154)  Acc@5:  70.000 ( 50.593)
Test: [2250/3167]  Time: 0.202 (0.193)  Loss:   3.199 ( 3.335)  Acc@1:  42.500 ( 23.985)  Acc@5:  67.500 ( 50.436)
Test: [2300/3167]  Time: 0.191 (0.193)  Loss:   4.203 ( 3.344)  Acc@1:   0.000 ( 23.835)  Acc@5:  12.500 ( 50.176)
Test: [2350/3167]  Time: 0.189 (0.193)  Loss:   3.448 ( 3.352)  Acc@1:  27.500 ( 23.520)  Acc@5:  55.000 ( 49.872)
Test: [2400/3167]  Time: 0.187 (0.193)  Loss:   3.954 ( 3.342)  Acc@1:   0.000 ( 23.887)  Acc@5:  22.500 ( 50.091)
Test: [2450/3167]  Time: 0.191 (0.193)  Loss:   2.801 ( 3.341)  Acc@1:  37.500 ( 23.851)  Acc@5:  77.500 ( 50.219)
Test: [2500/3167]  Time: 0.185 (0.193)  Loss:   3.889 ( 3.344)  Acc@1:  12.500 ( 23.756)  Acc@5:  45.000 ( 50.231)
Test: [2550/3167]  Time: 0.192 (0.193)  Loss:   3.687 ( 3.336)  Acc@1:   2.500 ( 24.093)  Acc@5:  27.500 ( 50.566)
Test: [2600/3167]  Time: 0.185 (0.193)  Loss:   3.062 ( 3.340)  Acc@1:  32.500 ( 23.892)  Acc@5:  55.000 ( 50.287)
Test: [2650/3167]  Time: 0.186 (0.193)  Loss:   3.018 ( 3.343)  Acc@1:  35.000 ( 23.782)  Acc@5:  75.000 ( 50.257)
Test: [2700/3167]  Time: 0.198 (0.193)  Loss:   2.978 ( 3.339)  Acc@1:  32.500 ( 24.025)  Acc@5:  65.000 ( 50.517)
Test: [2750/3167]  Time: 0.191 (0.193)  Loss:   2.374 ( 3.344)  Acc@1:  47.500 ( 23.905)  Acc@5:  85.000 ( 50.255)
Test: [2800/3167]  Time: 0.187 (0.193)  Loss:   3.713 ( 3.338)  Acc@1:   0.000 ( 24.030)  Acc@5:  42.500 ( 50.453)
Test: [2850/3167]  Time: 0.184 (0.193)  Loss:   3.687 ( 3.349)  Acc@1:  12.500 ( 23.720)  Acc@5:  42.500 ( 50.069)
Test: [2900/3167]  Time: 0.185 (0.192)  Loss:   3.399 ( 3.350)  Acc@1:  27.500 ( 23.711)  Acc@5:  62.500 ( 50.127)
Test: [2950/3167]  Time: 0.188 (0.192)  Loss:   3.708 ( 3.353)  Acc@1:   0.000 ( 23.539)  Acc@5:  37.500 ( 50.097)
Test: [3000/3167]  Time: 0.187 (0.192)  Loss:   3.865 ( 3.361)  Acc@1:   7.500 ( 23.204)  Acc@5:  27.500 ( 49.715)
Test: [3050/3167]  Time: 0.186 (0.192)  Loss:   4.156 ( 3.367)  Acc@1:   0.000 ( 23.001)  Acc@5:  22.500 ( 49.452)
Test: [3100/3167]  Time: 0.196 (0.192)  Loss:   3.720 ( 3.376)  Acc@1:   5.000 ( 22.694)  Acc@5:  40.000 ( 49.117)
Test: [3150/3167]  Time: 0.187 (0.192)  Loss:   3.741 ( 3.384)  Acc@1:   0.000 ( 22.381)  Acc@5:  42.500 ( 48.857)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   3.389 ( 3.386)  Acc@1:  11.111 ( 22.330)  Acc@5:  55.556 ( 48.833)
Test: [   0/124]  Time: 0.695 (0.695)  Loss:   4.183 ( 4.183)  Acc@1:   2.500 (  2.500)  Acc@5:  12.500 ( 12.500)
Test: [  50/124]  Time: 0.184 (0.200)  Loss:   3.436 ( 3.372)  Acc@1:  17.500 ( 22.157)  Acc@5:  57.500 ( 49.510)
Test: [ 100/124]  Time: 0.184 (0.195)  Loss:   2.583 ( 3.415)  Acc@1:  57.500 ( 21.931)  Acc@5:  77.500 ( 47.475)
Test: [ 124/124]  Time: 0.180 (0.193)  Loss:   3.633 ( 3.453)  Acc@1:  17.500 ( 20.920)  Acc@5:  45.000 ( 46.520)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_0/checkpoint-5.pth.tar', 22.33027334657917)

Train: 6 [   0/3167 (  0%)]  Loss: 4.11 (4.11)  Time: 1.085s,   36.85/s  (1.085s,   36.85/s)  LR: 6.400e-05  Data: 0.476 (0.476)
Train: 6 [  50/3167 (  2%)]  Loss: 4.28 (4.05)  Time: 0.600s,   66.62/s  (0.613s,   65.21/s)  LR: 6.400e-05  Data: 0.011 (0.019)
Train: 6 [ 100/3167 (  3%)]  Loss: 4.01 (4.05)  Time: 0.599s,   66.78/s  (0.609s,   65.73/s)  LR: 6.400e-05  Data: 0.007 (0.015)
Train: 6 [ 150/3167 (  5%)]  Loss: 3.72 (4.04)  Time: 0.598s,   66.85/s  (0.606s,   65.99/s)  LR: 6.400e-05  Data: 0.004 (0.013)
Train: 6 [ 200/3167 (  6%)]  Loss: 4.05 (4.03)  Time: 0.598s,   66.85/s  (0.605s,   66.06/s)  LR: 6.400e-05  Data: 0.007 (0.012)
Train: 6 [ 250/3167 (  8%)]  Loss: 3.78 (4.02)  Time: 0.604s,   66.27/s  (0.605s,   66.14/s)  LR: 6.400e-05  Data: 0.012 (0.012)
Train: 6 [ 300/3167 (  9%)]  Loss: 3.48 (4.02)  Time: 0.604s,   66.27/s  (0.605s,   66.16/s)  LR: 6.400e-05  Data: 0.012 (0.012)
Train: 6 [ 350/3167 ( 11%)]  Loss: 4.05 (4.03)  Time: 0.603s,   66.33/s  (0.604s,   66.19/s)  LR: 6.400e-05  Data: 0.011 (0.011)
Train: 6 [ 400/3167 ( 13%)]  Loss: 3.91 (4.03)  Time: 0.603s,   66.28/s  (0.604s,   66.22/s)  LR: 6.400e-05  Data: 0.011 (0.011)
Train: 6 [ 450/3167 ( 14%)]  Loss: 3.98 (4.03)  Time: 0.606s,   65.99/s  (0.604s,   66.23/s)  LR: 6.400e-05  Data: 0.011 (0.011)
Train: 6 [ 500/3167 ( 16%)]  Loss: 3.99 (4.02)  Time: 0.599s,   66.74/s  (0.604s,   66.28/s)  LR: 6.400e-05  Data: 0.004 (0.011)
Train: 6 [ 550/3167 ( 17%)]  Loss: 4.13 (4.03)  Time: 0.603s,   66.35/s  (0.603s,   66.28/s)  LR: 6.400e-05  Data: 0.011 (0.011)
Train: 6 [ 600/3167 ( 19%)]  Loss: 4.27 (4.03)  Time: 0.600s,   66.62/s  (0.603s,   66.29/s)  LR: 6.400e-05  Data: 0.011 (0.011)
Train: 6 [ 650/3167 ( 21%)]  Loss: 3.80 (4.03)  Time: 0.600s,   66.65/s  (0.603s,   66.31/s)  LR: 6.400e-05  Data: 0.011 (0.011)
Train: 6 [ 700/3167 ( 22%)]  Loss: 4.40 (4.03)  Time: 0.601s,   66.58/s  (0.603s,   66.32/s)  LR: 6.400e-05  Data: 0.012 (0.011)
Train: 6 [ 750/3167 ( 24%)]  Loss: 4.22 (4.03)  Time: 0.600s,   66.66/s  (0.603s,   66.34/s)  LR: 6.400e-05  Data: 0.009 (0.011)
Train: 6 [ 800/3167 ( 25%)]  Loss: 4.24 (4.03)  Time: 0.593s,   67.48/s  (0.603s,   66.34/s)  LR: 6.400e-05  Data: 0.004 (0.011)
Train: 6 [ 850/3167 ( 27%)]  Loss: 4.38 (4.02)  Time: 0.606s,   66.04/s  (0.603s,   66.34/s)  LR: 6.400e-05  Data: 0.011 (0.010)
Train: 6 [ 900/3167 ( 28%)]  Loss: 3.67 (4.02)  Time: 0.609s,   65.67/s  (0.603s,   66.35/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [ 950/3167 ( 30%)]  Loss: 3.74 (4.02)  Time: 0.603s,   66.37/s  (0.603s,   66.36/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1000/3167 ( 32%)]  Loss: 3.92 (4.02)  Time: 0.603s,   66.30/s  (0.603s,   66.37/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [1050/3167 ( 33%)]  Loss: 3.89 (4.03)  Time: 0.604s,   66.18/s  (0.603s,   66.38/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1100/3167 ( 35%)]  Loss: 3.89 (4.03)  Time: 0.610s,   65.61/s  (0.603s,   66.38/s)  LR: 6.400e-05  Data: 0.011 (0.010)
Train: 6 [1150/3167 ( 36%)]  Loss: 3.85 (4.02)  Time: 0.595s,   67.18/s  (0.603s,   66.39/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [1200/3167 ( 38%)]  Loss: 4.00 (4.02)  Time: 0.593s,   67.48/s  (0.602s,   66.39/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [1250/3167 ( 39%)]  Loss: 4.21 (4.02)  Time: 0.593s,   67.47/s  (0.602s,   66.40/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [1300/3167 ( 41%)]  Loss: 4.66 (4.02)  Time: 0.607s,   65.90/s  (0.602s,   66.41/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1350/3167 ( 43%)]  Loss: 4.22 (4.02)  Time: 0.595s,   67.19/s  (0.602s,   66.41/s)  LR: 6.400e-05  Data: 0.006 (0.010)
Train: 6 [1400/3167 ( 44%)]  Loss: 4.15 (4.02)  Time: 0.603s,   66.32/s  (0.602s,   66.42/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1450/3167 ( 46%)]  Loss: 3.59 (4.02)  Time: 0.608s,   65.74/s  (0.602s,   66.43/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1500/3167 ( 47%)]  Loss: 4.37 (4.02)  Time: 0.593s,   67.47/s  (0.602s,   66.43/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [1550/3167 ( 49%)]  Loss: 4.00 (4.02)  Time: 0.601s,   66.61/s  (0.602s,   66.44/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1600/3167 ( 51%)]  Loss: 3.68 (4.02)  Time: 0.600s,   66.72/s  (0.602s,   66.45/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [1650/3167 ( 52%)]  Loss: 4.06 (4.02)  Time: 0.601s,   66.59/s  (0.602s,   66.45/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1700/3167 ( 54%)]  Loss: 4.33 (4.02)  Time: 0.610s,   65.57/s  (0.602s,   66.45/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1750/3167 ( 55%)]  Loss: 3.57 (4.02)  Time: 0.609s,   65.67/s  (0.602s,   66.46/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [1800/3167 ( 57%)]  Loss: 3.83 (4.02)  Time: 0.603s,   66.38/s  (0.602s,   66.46/s)  LR: 6.400e-05  Data: 0.010 (0.010)
Train: 6 [1850/3167 ( 58%)]  Loss: 3.97 (4.02)  Time: 0.610s,   65.53/s  (0.602s,   66.47/s)  LR: 6.400e-05  Data: 0.011 (0.010)
Train: 6 [1900/3167 ( 60%)]  Loss: 3.95 (4.02)  Time: 0.595s,   67.18/s  (0.602s,   66.48/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [1950/3167 ( 62%)]  Loss: 4.10 (4.02)  Time: 0.601s,   66.57/s  (0.602s,   66.48/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [2000/3167 ( 63%)]  Loss: 4.26 (4.02)  Time: 0.598s,   66.88/s  (0.602s,   66.48/s)  LR: 6.400e-05  Data: 0.006 (0.010)
Train: 6 [2050/3167 ( 65%)]  Loss: 3.44 (4.02)  Time: 0.593s,   67.49/s  (0.602s,   66.49/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [2100/3167 ( 66%)]  Loss: 3.68 (4.02)  Time: 0.610s,   65.57/s  (0.602s,   66.49/s)  LR: 6.400e-05  Data: 0.012 (0.010)
Train: 6 [2150/3167 ( 68%)]  Loss: 4.01 (4.02)  Time: 0.595s,   67.19/s  (0.602s,   66.50/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [2200/3167 ( 69%)]  Loss: 3.80 (4.02)  Time: 0.593s,   67.45/s  (0.601s,   66.51/s)  LR: 6.400e-05  Data: 0.004 (0.010)
Train: 6 [2250/3167 ( 71%)]  Loss: 3.88 (4.02)  Time: 0.596s,   67.14/s  (0.601s,   66.52/s)  LR: 6.400e-05  Data: 0.007 (0.009)
Train: 6 [2300/3167 ( 73%)]  Loss: 3.66 (4.01)  Time: 0.593s,   67.46/s  (0.601s,   66.52/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [2350/3167 ( 74%)]  Loss: 3.63 (4.01)  Time: 0.598s,   66.86/s  (0.601s,   66.53/s)  LR: 6.400e-05  Data: 0.009 (0.009)
Train: 6 [2400/3167 ( 76%)]  Loss: 4.10 (4.01)  Time: 0.596s,   67.11/s  (0.601s,   66.54/s)  LR: 6.400e-05  Data: 0.007 (0.009)
Train: 6 [2450/3167 ( 77%)]  Loss: 4.08 (4.01)  Time: 0.596s,   67.14/s  (0.601s,   66.54/s)  LR: 6.400e-05  Data: 0.006 (0.009)
Train: 6 [2500/3167 ( 79%)]  Loss: 3.93 (4.01)  Time: 0.611s,   65.41/s  (0.601s,   66.55/s)  LR: 6.400e-05  Data: 0.012 (0.009)
Train: 6 [2550/3167 ( 81%)]  Loss: 4.23 (4.01)  Time: 0.595s,   67.24/s  (0.601s,   66.56/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [2600/3167 ( 82%)]  Loss: 4.25 (4.01)  Time: 0.596s,   67.13/s  (0.601s,   66.57/s)  LR: 6.400e-05  Data: 0.007 (0.009)
Train: 6 [2650/3167 ( 84%)]  Loss: 3.71 (4.01)  Time: 0.593s,   67.46/s  (0.601s,   66.58/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [2700/3167 ( 85%)]  Loss: 3.55 (4.01)  Time: 0.601s,   66.59/s  (0.601s,   66.59/s)  LR: 6.400e-05  Data: 0.008 (0.009)
Train: 6 [2750/3167 ( 87%)]  Loss: 3.67 (4.01)  Time: 0.593s,   67.48/s  (0.601s,   66.60/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [2800/3167 ( 88%)]  Loss: 4.28 (4.01)  Time: 0.593s,   67.45/s  (0.601s,   66.60/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [2850/3167 ( 90%)]  Loss: 4.08 (4.01)  Time: 0.593s,   67.48/s  (0.600s,   66.61/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [2900/3167 ( 92%)]  Loss: 3.93 (4.01)  Time: 0.594s,   67.31/s  (0.600s,   66.62/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [2950/3167 ( 93%)]  Loss: 3.62 (4.01)  Time: 0.615s,   65.05/s  (0.600s,   66.62/s)  LR: 6.400e-05  Data: 0.026 (0.009)
Train: 6 [3000/3167 ( 95%)]  Loss: 4.08 (4.01)  Time: 0.606s,   65.99/s  (0.600s,   66.63/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Train: 6 [3050/3167 ( 96%)]  Loss: 4.00 (4.01)  Time: 0.596s,   67.14/s  (0.600s,   66.64/s)  LR: 6.400e-05  Data: 0.006 (0.009)
Train: 6 [3100/3167 ( 98%)]  Loss: 4.24 (4.00)  Time: 0.608s,   65.75/s  (0.600s,   66.64/s)  LR: 6.400e-05  Data: 0.007 (0.009)
Train: 6 [3150/3167 ( 99%)]  Loss: 4.09 (4.01)  Time: 0.593s,   67.42/s  (0.600s,   66.65/s)  LR: 6.400e-05  Data: 0.004 (0.009)
Test: [   0/3167]  Time: 0.508 (0.508)  Loss:   3.390 ( 3.390)  Acc@1:  17.500 ( 17.500)  Acc@5:  52.500 ( 52.500)
Test: [  50/3167]  Time: 0.208 (0.198)  Loss:   3.348 ( 3.299)  Acc@1:  32.500 ( 21.569)  Acc@5:  42.500 ( 54.412)
Test: [ 100/3167]  Time: 0.190 (0.195)  Loss:   3.342 ( 3.318)  Acc@1:  22.500 ( 19.059)  Acc@5:  60.000 ( 53.342)
Test: [ 150/3167]  Time: 0.190 (0.194)  Loss:   2.006 ( 3.187)  Acc@1:  47.500 ( 23.311)  Acc@5:  92.500 ( 58.013)
Test: [ 200/3167]  Time: 0.187 (0.193)  Loss:   3.454 ( 3.235)  Acc@1:  17.500 ( 22.027)  Acc@5:  55.000 ( 54.988)
Test: [ 250/3167]  Time: 0.186 (0.193)  Loss:   3.032 ( 3.238)  Acc@1:  27.500 ( 22.371)  Acc@5:  50.000 ( 54.363)
Test: [ 300/3167]  Time: 0.185 (0.193)  Loss:   3.034 ( 3.269)  Acc@1:  20.000 ( 22.126)  Acc@5:  65.000 ( 53.472)
Test: [ 350/3167]  Time: 0.191 (0.192)  Loss:   2.726 ( 3.222)  Acc@1:  52.500 ( 23.162)  Acc@5:  75.000 ( 55.157)
Test: [ 400/3167]  Time: 0.191 (0.192)  Loss:   2.551 ( 3.087)  Acc@1:  42.500 ( 27.413)  Acc@5:  80.000 ( 58.678)
Test: [ 450/3167]  Time: 0.190 (0.192)  Loss:   3.457 ( 3.112)  Acc@1:   0.000 ( 26.292)  Acc@5:  45.000 ( 57.777)
Test: [ 500/3167]  Time: 0.190 (0.193)  Loss:   2.599 ( 3.114)  Acc@1:  47.500 ( 26.786)  Acc@5:  67.500 ( 57.545)
Test: [ 550/3167]  Time: 0.201 (0.193)  Loss:   3.787 ( 3.056)  Acc@1:   5.000 ( 28.884)  Acc@5:  35.000 ( 58.671)
Test: [ 600/3167]  Time: 0.191 (0.193)  Loss:   2.745 ( 3.091)  Acc@1:  35.000 ( 27.928)  Acc@5:  60.000 ( 57.438)
Test: [ 650/3167]  Time: 0.189 (0.193)  Loss:   2.851 ( 3.072)  Acc@1:  37.500 ( 28.641)  Acc@5:  72.500 ( 57.857)
Test: [ 700/3167]  Time: 0.190 (0.193)  Loss:   2.651 ( 3.052)  Acc@1:  47.500 ( 29.479)  Acc@5:  85.000 ( 59.198)
Test: [ 750/3167]  Time: 0.191 (0.193)  Loss:   3.245 ( 3.028)  Acc@1:  40.000 ( 30.513)  Acc@5:  47.500 ( 60.439)
Test: [ 800/3167]  Time: 0.190 (0.193)  Loss:   3.836 ( 3.049)  Acc@1:   2.500 ( 29.953)  Acc@5:  35.000 ( 59.560)
Test: [ 850/3167]  Time: 0.191 (0.193)  Loss:   3.391 ( 3.092)  Acc@1:   7.500 ( 28.422)  Acc@5:  55.000 ( 58.035)
Test: [ 900/3167]  Time: 0.189 (0.193)  Loss:   3.697 ( 3.126)  Acc@1:  12.500 ( 27.350)  Acc@5:  40.000 ( 57.103)
Test: [ 950/3167]  Time: 0.202 (0.193)  Loss:   3.261 ( 3.156)  Acc@1:  25.000 ( 26.427)  Acc@5:  57.500 ( 55.920)
Test: [1000/3167]  Time: 0.204 (0.193)  Loss:   3.228 ( 3.178)  Acc@1:  20.000 ( 25.652)  Acc@5:  55.000 ( 55.157)
Test: [1050/3167]  Time: 0.190 (0.193)  Loss:   3.017 ( 3.171)  Acc@1:  30.000 ( 25.928)  Acc@5:  72.500 ( 55.716)
Test: [1100/3167]  Time: 0.190 (0.193)  Loss:   3.237 ( 3.168)  Acc@1:  37.500 ( 25.752)  Acc@5:  65.000 ( 56.092)
Test: [1150/3167]  Time: 0.199 (0.193)  Loss:   1.913 ( 3.140)  Acc@1:  75.000 ( 27.035)  Acc@5:  90.000 ( 56.979)
Test: [1200/3167]  Time: 0.198 (0.193)  Loss:   2.516 ( 3.118)  Acc@1:  55.000 ( 27.679)  Acc@5:  82.500 ( 57.783)
Test: [1250/3167]  Time: 0.196 (0.193)  Loss:   2.091 ( 3.088)  Acc@1:  65.000 ( 28.817)  Acc@5:  87.500 ( 58.555)
Test: [1300/3167]  Time: 0.189 (0.193)  Loss:   2.680 ( 3.103)  Acc@1:  50.000 ( 28.461)  Acc@5:  80.000 ( 57.988)
Test: [1350/3167]  Time: 0.190 (0.193)  Loss:   3.417 ( 3.129)  Acc@1:  22.500 ( 28.111)  Acc@5:  57.500 ( 57.150)
Test: [1400/3167]  Time: 0.192 (0.193)  Loss:   3.220 ( 3.149)  Acc@1:  30.000 ( 27.646)  Acc@5:  57.500 ( 56.499)
Test: [1450/3167]  Time: 0.194 (0.193)  Loss:   3.216 ( 3.150)  Acc@1:  20.000 ( 27.817)  Acc@5:  55.000 ( 56.549)
Test: [1500/3167]  Time: 0.184 (0.193)  Loss:   3.337 ( 3.132)  Acc@1:  17.500 ( 28.394)  Acc@5:  57.500 ( 57.005)
Test: [1550/3167]  Time: 0.186 (0.193)  Loss:   1.615 ( 3.118)  Acc@1:  82.500 ( 28.810)  Acc@5:  92.500 ( 57.456)
Test: [1600/3167]  Time: 0.192 (0.193)  Loss:   2.873 ( 3.104)  Acc@1:  37.500 ( 29.158)  Acc@5:  57.500 ( 58.017)
Test: [1650/3167]  Time: 0.189 (0.193)  Loss:   2.729 ( 3.092)  Acc@1:  32.500 ( 29.487)  Acc@5:  75.000 ( 58.377)
Test: [1700/3167]  Time: 0.192 (0.193)  Loss:   3.796 ( 3.080)  Acc@1:   7.500 ( 29.900)  Acc@5:  32.500 ( 58.676)
Test: [1750/3167]  Time: 0.207 (0.193)  Loss:   3.569 ( 3.096)  Acc@1:  15.000 ( 29.477)  Acc@5:  37.500 ( 58.077)
Test: [1800/3167]  Time: 0.193 (0.193)  Loss:   3.278 ( 3.105)  Acc@1:   7.500 ( 29.313)  Acc@5:  45.000 ( 57.873)
Test: [1850/3167]  Time: 0.199 (0.193)  Loss:   3.374 ( 3.122)  Acc@1:  17.500 ( 28.652)  Acc@5:  42.500 ( 57.042)
Test: [1900/3167]  Time: 0.190 (0.193)  Loss:   3.803 ( 3.131)  Acc@1:   7.500 ( 28.210)  Acc@5:  32.500 ( 56.845)
Test: [1950/3167]  Time: 0.198 (0.193)  Loss:   4.335 ( 3.141)  Acc@1:   0.000 ( 27.865)  Acc@5:  10.000 ( 56.534)
Test: [2000/3167]  Time: 0.189 (0.193)  Loss:   3.977 ( 3.163)  Acc@1:   5.000 ( 27.285)  Acc@5:  25.000 ( 55.620)
Test: [2050/3167]  Time: 0.189 (0.193)  Loss:   3.754 ( 3.178)  Acc@1:   2.500 ( 26.786)  Acc@5:  27.500 ( 54.980)
Test: [2100/3167]  Time: 0.193 (0.193)  Loss:   3.476 ( 3.180)  Acc@1:  17.500 ( 26.785)  Acc@5:  50.000 ( 55.008)
Test: [2150/3167]  Time: 0.198 (0.193)  Loss:   1.754 ( 3.164)  Acc@1:  70.000 ( 27.209)  Acc@5:  77.500 ( 55.307)
Test: [2200/3167]  Time: 0.199 (0.193)  Loss:   3.242 ( 3.160)  Acc@1:  12.500 ( 27.205)  Acc@5:  55.000 ( 55.446)
Test: [2250/3167]  Time: 0.196 (0.193)  Loss:   3.361 ( 3.170)  Acc@1:  30.000 ( 26.845)  Acc@5:  50.000 ( 55.101)
Test: [2300/3167]  Time: 0.186 (0.193)  Loss:   3.930 ( 3.181)  Acc@1:   0.000 ( 26.435)  Acc@5:  20.000 ( 54.635)
Test: [2350/3167]  Time: 0.197 (0.193)  Loss:   3.797 ( 3.194)  Acc@1:   5.000 ( 25.972)  Acc@5:  37.500 ( 54.085)
Test: [2400/3167]  Time: 0.194 (0.193)  Loss:   3.741 ( 3.189)  Acc@1:   0.000 ( 26.155)  Acc@5:  25.000 ( 54.120)
Test: [2450/3167]  Time: 0.183 (0.193)  Loss:   2.573 ( 3.186)  Acc@1:  45.000 ( 26.167)  Acc@5:  82.500 ( 54.317)
Test: [2500/3167]  Time: 0.184 (0.193)  Loss:   2.926 ( 3.184)  Acc@1:  37.500 ( 26.279)  Acc@5:  72.500 ( 54.478)
Test: [2550/3167]  Time: 0.190 (0.193)  Loss:   3.935 ( 3.166)  Acc@1:   0.000 ( 26.923)  Acc@5:  22.500 ( 54.992)
Test: [2600/3167]  Time: 0.190 (0.193)  Loss:   2.644 ( 3.175)  Acc@1:  47.500 ( 26.769)  Acc@5:  70.000 ( 54.651)
Test: [2650/3167]  Time: 0.191 (0.193)  Loss:   3.325 ( 3.181)  Acc@1:  15.000 ( 26.698)  Acc@5:  52.500 ( 54.492)
Test: [2700/3167]  Time: 0.184 (0.193)  Loss:   2.743 ( 3.181)  Acc@1:  40.000 ( 26.690)  Acc@5:  70.000 ( 54.551)
Test: [2750/3167]  Time: 0.184 (0.193)  Loss:   2.447 ( 3.187)  Acc@1:  40.000 ( 26.526)  Acc@5:  87.500 ( 54.305)
Test: [2800/3167]  Time: 0.203 (0.193)  Loss:   3.746 ( 3.185)  Acc@1:  15.000 ( 26.481)  Acc@5:  47.500 ( 54.495)
Test: [2850/3167]  Time: 0.205 (0.193)  Loss:   3.680 ( 3.200)  Acc@1:  10.000 ( 26.082)  Acc@5:  27.500 ( 53.851)
Test: [2900/3167]  Time: 0.187 (0.193)  Loss:   2.946 ( 3.202)  Acc@1:  40.000 ( 26.106)  Acc@5:  70.000 ( 53.844)
Test: [2950/3167]  Time: 0.193 (0.193)  Loss:   3.613 ( 3.212)  Acc@1:   0.000 ( 25.772)  Acc@5:  35.000 ( 53.424)
Test: [3000/3167]  Time: 0.186 (0.192)  Loss:   4.066 ( 3.223)  Acc@1:   2.500 ( 25.372)  Acc@5:  27.500 ( 52.970)
Test: [3050/3167]  Time: 0.196 (0.192)  Loss:   3.885 ( 3.227)  Acc@1:   7.500 ( 25.231)  Acc@5:  20.000 ( 52.880)
Test: [3100/3167]  Time: 0.186 (0.192)  Loss:   3.800 ( 3.237)  Acc@1:   0.000 ( 24.864)  Acc@5:  35.000 ( 52.450)
Test: [3150/3167]  Time: 0.187 (0.192)  Loss:   3.105 ( 3.240)  Acc@1:  12.500 ( 24.666)  Acc@5:  65.000 ( 52.444)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   2.673 ( 3.240)  Acc@1:  33.333 ( 24.636)  Acc@5:  77.778 ( 52.495)
Test: [   0/124]  Time: 0.717 (0.717)  Loss:   3.593 ( 3.593)  Acc@1:   7.500 (  7.500)  Acc@5:  45.000 ( 45.000)
Test: [  50/124]  Time: 0.198 (0.199)  Loss:   2.928 ( 3.199)  Acc@1:  50.000 ( 26.618)  Acc@5:  75.000 ( 55.098)
Test: [ 100/124]  Time: 0.184 (0.195)  Loss:   2.199 ( 3.260)  Acc@1:  65.000 ( 24.653)  Acc@5:  82.500 ( 51.163)
Test: [ 124/124]  Time: 0.180 (0.193)  Loss:   2.921 ( 3.321)  Acc@1:  22.500 ( 22.680)  Acc@5:  67.500 ( 49.180)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_0/checkpoint-6.pth.tar', 24.635919456216055)

Train: 7 [   0/3167 (  0%)]  Loss: 4.21 (4.21)  Time: 1.079s,   37.06/s  (1.079s,   37.06/s)  LR: 7.300e-05  Data: 0.479 (0.479)
Train: 7 [  50/3167 (  2%)]  Loss: 4.19 (3.99)  Time: 0.610s,   65.62/s  (0.612s,   65.32/s)  LR: 7.300e-05  Data: 0.012 (0.020)
Train: 7 [ 100/3167 (  3%)]  Loss: 4.15 (3.97)  Time: 0.596s,   67.09/s  (0.608s,   65.84/s)  LR: 7.300e-05  Data: 0.004 (0.015)
Train: 7 [ 150/3167 (  5%)]  Loss: 4.04 (3.99)  Time: 0.600s,   66.61/s  (0.606s,   66.00/s)  LR: 7.300e-05  Data: 0.011 (0.013)
Train: 7 [ 200/3167 (  6%)]  Loss: 4.17 (3.98)  Time: 0.603s,   66.36/s  (0.605s,   66.09/s)  LR: 7.300e-05  Data: 0.011 (0.013)
Train: 7 [ 250/3167 (  8%)]  Loss: 3.96 (3.98)  Time: 0.599s,   66.80/s  (0.605s,   66.14/s)  LR: 7.300e-05  Data: 0.007 (0.012)
Train: 7 [ 300/3167 (  9%)]  Loss: 4.17 (3.98)  Time: 0.604s,   66.22/s  (0.605s,   66.16/s)  LR: 7.300e-05  Data: 0.009 (0.012)
Train: 7 [ 350/3167 ( 11%)]  Loss: 4.24 (3.98)  Time: 0.598s,   66.90/s  (0.604s,   66.19/s)  LR: 7.300e-05  Data: 0.006 (0.012)
Train: 7 [ 400/3167 ( 13%)]  Loss: 4.64 (3.99)  Time: 0.596s,   67.17/s  (0.604s,   66.21/s)  LR: 7.300e-05  Data: 0.004 (0.011)
Train: 7 [ 450/3167 ( 14%)]  Loss: 4.09 (3.99)  Time: 0.604s,   66.21/s  (0.604s,   66.23/s)  LR: 7.300e-05  Data: 0.012 (0.011)
Train: 7 [ 500/3167 ( 16%)]  Loss: 3.57 (3.98)  Time: 0.605s,   66.16/s  (0.604s,   66.25/s)  LR: 7.300e-05  Data: 0.006 (0.011)
Train: 7 [ 550/3167 ( 17%)]  Loss: 3.51 (3.98)  Time: 0.606s,   66.02/s  (0.604s,   66.25/s)  LR: 7.300e-05  Data: 0.009 (0.011)
Train: 7 [ 600/3167 ( 19%)]  Loss: 3.43 (3.98)  Time: 0.607s,   65.86/s  (0.604s,   66.28/s)  LR: 7.300e-05  Data: 0.011 (0.011)
Train: 7 [ 650/3167 ( 21%)]  Loss: 4.14 (3.98)  Time: 0.600s,   66.61/s  (0.603s,   66.28/s)  LR: 7.300e-05  Data: 0.011 (0.011)
Train: 7 [ 700/3167 ( 22%)]  Loss: 4.64 (3.99)  Time: 0.609s,   65.65/s  (0.604s,   66.28/s)  LR: 7.300e-05  Data: 0.012 (0.011)
Train: 7 [ 750/3167 ( 24%)]  Loss: 3.88 (3.99)  Time: 0.601s,   66.60/s  (0.603s,   66.30/s)  LR: 7.300e-05  Data: 0.009 (0.011)
Train: 7 [ 800/3167 ( 25%)]  Loss: 3.87 (3.98)  Time: 0.600s,   66.64/s  (0.603s,   66.30/s)  LR: 7.300e-05  Data: 0.011 (0.011)
Train: 7 [ 850/3167 ( 27%)]  Loss: 3.75 (3.99)  Time: 0.603s,   66.30/s  (0.603s,   66.31/s)  LR: 7.300e-05  Data: 0.012 (0.011)
Train: 7 [ 900/3167 ( 28%)]  Loss: 3.86 (3.98)  Time: 0.613s,   65.29/s  (0.603s,   66.32/s)  LR: 7.300e-05  Data: 0.009 (0.011)
Train: 7 [ 950/3167 ( 30%)]  Loss: 3.92 (3.98)  Time: 0.600s,   66.63/s  (0.603s,   66.33/s)  LR: 7.300e-05  Data: 0.011 (0.011)
Train: 7 [1000/3167 ( 32%)]  Loss: 4.18 (3.98)  Time: 0.600s,   66.61/s  (0.603s,   66.34/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [1050/3167 ( 33%)]  Loss: 3.71 (3.98)  Time: 0.600s,   66.62/s  (0.603s,   66.35/s)  LR: 7.300e-05  Data: 0.011 (0.010)
Train: 7 [1100/3167 ( 35%)]  Loss: 4.33 (3.98)  Time: 0.614s,   65.19/s  (0.603s,   66.35/s)  LR: 7.300e-05  Data: 0.015 (0.010)
Train: 7 [1150/3167 ( 36%)]  Loss: 4.31 (3.98)  Time: 0.596s,   67.14/s  (0.603s,   66.36/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [1200/3167 ( 38%)]  Loss: 4.19 (3.98)  Time: 0.598s,   66.90/s  (0.603s,   66.37/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [1250/3167 ( 39%)]  Loss: 3.59 (3.98)  Time: 0.600s,   66.65/s  (0.603s,   66.37/s)  LR: 7.300e-05  Data: 0.011 (0.010)
Train: 7 [1300/3167 ( 41%)]  Loss: 4.22 (3.98)  Time: 0.595s,   67.17/s  (0.603s,   66.38/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [1350/3167 ( 43%)]  Loss: 4.09 (3.98)  Time: 0.600s,   66.63/s  (0.603s,   66.38/s)  LR: 7.300e-05  Data: 0.011 (0.010)
Train: 7 [1400/3167 ( 44%)]  Loss: 4.16 (3.98)  Time: 0.600s,   66.65/s  (0.603s,   66.38/s)  LR: 7.300e-05  Data: 0.011 (0.010)
Train: 7 [1450/3167 ( 46%)]  Loss: 4.04 (3.98)  Time: 0.596s,   67.16/s  (0.602s,   66.39/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [1500/3167 ( 47%)]  Loss: 4.63 (3.97)  Time: 0.595s,   67.18/s  (0.602s,   66.40/s)  LR: 7.300e-05  Data: 0.006 (0.010)
Train: 7 [1550/3167 ( 49%)]  Loss: 4.12 (3.97)  Time: 0.601s,   66.57/s  (0.602s,   66.40/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [1600/3167 ( 51%)]  Loss: 3.74 (3.97)  Time: 0.593s,   67.48/s  (0.602s,   66.41/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [1650/3167 ( 52%)]  Loss: 4.24 (3.97)  Time: 0.598s,   66.89/s  (0.602s,   66.42/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [1700/3167 ( 54%)]  Loss: 3.92 (3.97)  Time: 0.596s,   67.16/s  (0.602s,   66.42/s)  LR: 7.300e-05  Data: 0.006 (0.010)
Train: 7 [1750/3167 ( 55%)]  Loss: 3.92 (3.97)  Time: 0.601s,   66.59/s  (0.602s,   66.43/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [1800/3167 ( 57%)]  Loss: 3.87 (3.97)  Time: 0.601s,   66.61/s  (0.602s,   66.43/s)  LR: 7.300e-05  Data: 0.011 (0.010)
Train: 7 [1850/3167 ( 58%)]  Loss: 3.94 (3.97)  Time: 0.603s,   66.29/s  (0.602s,   66.44/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [1900/3167 ( 60%)]  Loss: 4.04 (3.97)  Time: 0.603s,   66.36/s  (0.602s,   66.45/s)  LR: 7.300e-05  Data: 0.007 (0.010)
Train: 7 [1950/3167 ( 62%)]  Loss: 3.98 (3.97)  Time: 0.598s,   66.90/s  (0.602s,   66.46/s)  LR: 7.300e-05  Data: 0.006 (0.010)
Train: 7 [2000/3167 ( 63%)]  Loss: 4.23 (3.97)  Time: 0.603s,   66.38/s  (0.602s,   66.46/s)  LR: 7.300e-05  Data: 0.010 (0.010)
Train: 7 [2050/3167 ( 65%)]  Loss: 4.08 (3.97)  Time: 0.601s,   66.53/s  (0.602s,   66.47/s)  LR: 7.300e-05  Data: 0.012 (0.010)
Train: 7 [2100/3167 ( 66%)]  Loss: 4.14 (3.97)  Time: 0.600s,   66.70/s  (0.602s,   66.48/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [2150/3167 ( 68%)]  Loss: 4.24 (3.97)  Time: 0.595s,   67.19/s  (0.602s,   66.49/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [2200/3167 ( 69%)]  Loss: 4.30 (3.97)  Time: 0.593s,   67.45/s  (0.602s,   66.49/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [2250/3167 ( 71%)]  Loss: 3.75 (3.97)  Time: 0.601s,   66.61/s  (0.602s,   66.50/s)  LR: 7.300e-05  Data: 0.011 (0.010)
Train: 7 [2300/3167 ( 73%)]  Loss: 4.11 (3.97)  Time: 0.597s,   67.04/s  (0.601s,   66.50/s)  LR: 7.300e-05  Data: 0.004 (0.010)
Train: 7 [2350/3167 ( 74%)]  Loss: 3.49 (3.97)  Time: 0.598s,   66.86/s  (0.601s,   66.51/s)  LR: 7.300e-05  Data: 0.009 (0.010)
Train: 7 [2400/3167 ( 76%)]  Loss: 4.15 (3.97)  Time: 0.596s,   67.13/s  (0.601s,   66.52/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2450/3167 ( 77%)]  Loss: 4.19 (3.97)  Time: 0.593s,   67.46/s  (0.601s,   66.53/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2500/3167 ( 79%)]  Loss: 3.36 (3.96)  Time: 0.601s,   66.61/s  (0.601s,   66.54/s)  LR: 7.300e-05  Data: 0.011 (0.009)
Train: 7 [2550/3167 ( 81%)]  Loss: 3.80 (3.96)  Time: 0.593s,   67.44/s  (0.601s,   66.54/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2600/3167 ( 82%)]  Loss: 3.75 (3.96)  Time: 0.601s,   66.55/s  (0.601s,   66.55/s)  LR: 7.300e-05  Data: 0.011 (0.009)
Train: 7 [2650/3167 ( 84%)]  Loss: 3.91 (3.96)  Time: 0.593s,   67.45/s  (0.601s,   66.56/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2700/3167 ( 85%)]  Loss: 4.23 (3.96)  Time: 0.596s,   67.14/s  (0.601s,   66.57/s)  LR: 7.300e-05  Data: 0.006 (0.009)
Train: 7 [2750/3167 ( 87%)]  Loss: 4.19 (3.96)  Time: 0.598s,   66.84/s  (0.601s,   66.58/s)  LR: 7.300e-05  Data: 0.009 (0.009)
Train: 7 [2800/3167 ( 88%)]  Loss: 4.14 (3.96)  Time: 0.600s,   66.71/s  (0.601s,   66.59/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2850/3167 ( 90%)]  Loss: 3.92 (3.96)  Time: 0.602s,   66.39/s  (0.601s,   66.59/s)  LR: 7.300e-05  Data: 0.008 (0.009)
Train: 7 [2900/3167 ( 92%)]  Loss: 3.96 (3.96)  Time: 0.593s,   67.42/s  (0.601s,   66.60/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [2950/3167 ( 93%)]  Loss: 4.40 (3.96)  Time: 0.596s,   67.07/s  (0.600s,   66.61/s)  LR: 7.300e-05  Data: 0.007 (0.009)
Train: 7 [3000/3167 ( 95%)]  Loss: 3.92 (3.96)  Time: 0.593s,   67.45/s  (0.600s,   66.62/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [3050/3167 ( 96%)]  Loss: 3.90 (3.96)  Time: 0.596s,   67.14/s  (0.600s,   66.63/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [3100/3167 ( 98%)]  Loss: 3.60 (3.96)  Time: 0.593s,   67.43/s  (0.600s,   66.63/s)  LR: 7.300e-05  Data: 0.004 (0.009)
Train: 7 [3150/3167 ( 99%)]  Loss: 4.08 (3.95)  Time: 0.599s,   66.83/s  (0.600s,   66.64/s)  LR: 7.300e-05  Data: 0.009 (0.009)
Test: [   0/3167]  Time: 0.482 (0.482)  Loss:   3.290 ( 3.290)  Acc@1:  30.000 ( 30.000)  Acc@5:  62.500 ( 62.500)
Test: [  50/3167]  Time: 0.190 (0.198)  Loss:   2.972 ( 3.132)  Acc@1:  32.500 ( 31.863)  Acc@5:  55.000 ( 61.618)
Test: [ 100/3167]  Time: 0.191 (0.195)  Loss:   3.487 ( 3.147)  Acc@1:  10.000 ( 23.020)  Acc@5:  50.000 ( 57.327)
Test: [ 150/3167]  Time: 0.195 (0.193)  Loss:   1.858 ( 3.077)  Acc@1:  77.500 ( 26.722)  Acc@5:  95.000 ( 59.983)
Test: [ 200/3167]  Time: 0.191 (0.193)  Loss:   4.033 ( 3.139)  Acc@1:   0.000 ( 24.540)  Acc@5:  17.500 ( 56.219)
Test: [ 250/3167]  Time: 0.191 (0.193)  Loss:   2.302 ( 3.166)  Acc@1:  45.000 ( 24.422)  Acc@5:  72.500 ( 53.257)
Test: [ 300/3167]  Time: 0.189 (0.193)  Loss:   2.687 ( 3.141)  Acc@1:  30.000 ( 25.872)  Acc@5:  70.000 ( 54.659)
Test: [ 350/3167]  Time: 0.189 (0.193)  Loss:   2.688 ( 3.092)  Acc@1:  40.000 ( 27.051)  Acc@5:  70.000 ( 56.567)
Test: [ 400/3167]  Time: 0.187 (0.193)  Loss:   3.082 ( 2.990)  Acc@1:  25.000 ( 30.162)  Acc@5:  60.000 ( 59.202)
Test: [ 450/3167]  Time: 0.189 (0.192)  Loss:   3.201 ( 3.036)  Acc@1:  10.000 ( 28.320)  Acc@5:  62.500 ( 58.304)
Test: [ 500/3167]  Time: 0.191 (0.192)  Loss:   2.348 ( 3.061)  Acc@1:  47.500 ( 28.493)  Acc@5:  75.000 ( 57.340)
Test: [ 550/3167]  Time: 0.189 (0.192)  Loss:   3.907 ( 3.028)  Acc@1:   2.500 ( 29.701)  Acc@5:  32.500 ( 58.158)
Test: [ 600/3167]  Time: 0.189 (0.192)  Loss:   2.899 ( 3.067)  Acc@1:  32.500 ( 28.336)  Acc@5:  62.500 ( 56.997)
Test: [ 650/3167]  Time: 0.191 (0.192)  Loss:   2.219 ( 3.030)  Acc@1:  62.500 ( 29.581)  Acc@5:  90.000 ( 57.884)
Test: [ 700/3167]  Time: 0.194 (0.192)  Loss:   2.393 ( 2.977)  Acc@1:  60.000 ( 31.794)  Acc@5:  90.000 ( 59.900)
Test: [ 750/3167]  Time: 0.203 (0.193)  Loss:   3.287 ( 2.962)  Acc@1:  45.000 ( 32.527)  Acc@5:  45.000 ( 60.706)
Test: [ 800/3167]  Time: 0.195 (0.192)  Loss:   3.864 ( 2.989)  Acc@1:   0.000 ( 31.823)  Acc@5:  27.500 ( 59.654)
Test: [ 850/3167]  Time: 0.185 (0.192)  Loss:   3.283 ( 3.026)  Acc@1:   7.500 ( 30.464)  Acc@5:  50.000 ( 58.490)
Test: [ 900/3167]  Time: 0.189 (0.192)  Loss:   3.527 ( 3.058)  Acc@1:  15.000 ( 29.495)  Acc@5:  50.000 ( 57.708)
Test: [ 950/3167]  Time: 0.193 (0.192)  Loss:   2.448 ( 3.073)  Acc@1:  55.000 ( 29.130)  Acc@5:  72.500 ( 57.079)
Test: [1000/3167]  Time: 0.187 (0.192)  Loss:   3.130 ( 3.094)  Acc@1:  27.500 ( 28.789)  Acc@5:  70.000 ( 56.489)
Test: [1050/3167]  Time: 0.191 (0.192)  Loss:   2.994 ( 3.086)  Acc@1:  27.500 ( 28.656)  Acc@5:  70.000 ( 57.112)
Test: [1100/3167]  Time: 0.195 (0.192)  Loss:   3.218 ( 3.083)  Acc@1:  35.000 ( 28.547)  Acc@5:  55.000 ( 57.425)
Test: [1150/3167]  Time: 0.183 (0.192)  Loss:   2.101 ( 3.065)  Acc@1:  62.500 ( 29.453)  Acc@5:  87.500 ( 58.023)
Test: [1200/3167]  Time: 0.191 (0.193)  Loss:   2.741 ( 3.046)  Acc@1:  37.500 ( 29.886)  Acc@5:  65.000 ( 58.739)
Test: [1250/3167]  Time: 0.186 (0.193)  Loss:   2.746 ( 3.037)  Acc@1:  42.500 ( 30.418)  Acc@5:  67.500 ( 59.079)
Test: [1300/3167]  Time: 0.209 (0.193)  Loss:   3.314 ( 3.047)  Acc@1:  35.000 ( 29.839)  Acc@5:  62.500 ( 58.866)
Test: [1350/3167]  Time: 0.187 (0.193)  Loss:   3.396 ( 3.074)  Acc@1:  22.500 ( 29.191)  Acc@5:  57.500 ( 58.013)
Test: [1400/3167]  Time: 0.198 (0.193)  Loss:   3.347 ( 3.099)  Acc@1:  32.500 ( 28.633)  Acc@5:  60.000 ( 57.175)
Test: [1450/3167]  Time: 0.205 (0.193)  Loss:   3.370 ( 3.104)  Acc@1:  27.500 ( 28.699)  Acc@5:  47.500 ( 57.157)
Test: [1500/3167]  Time: 0.187 (0.193)  Loss:   3.351 ( 3.083)  Acc@1:  10.000 ( 29.424)  Acc@5:  55.000 ( 57.632)
Test: [1550/3167]  Time: 0.195 (0.193)  Loss:   2.088 ( 3.078)  Acc@1:  65.000 ( 29.371)  Acc@5:  82.500 ( 57.829)
Test: [1600/3167]  Time: 0.190 (0.193)  Loss:   2.254 ( 3.078)  Acc@1:  47.500 ( 29.435)  Acc@5:  80.000 ( 57.931)
Test: [1650/3167]  Time: 0.192 (0.193)  Loss:   2.563 ( 3.056)  Acc@1:  35.000 ( 29.989)  Acc@5:  70.000 ( 58.431)
Test: [1700/3167]  Time: 0.203 (0.193)  Loss:   4.013 ( 3.044)  Acc@1:  10.000 ( 30.479)  Acc@5:  27.500 ( 58.705)
Test: [1750/3167]  Time: 0.191 (0.193)  Loss:   2.975 ( 3.052)  Acc@1:  37.500 ( 30.330)  Acc@5:  55.000 ( 58.342)
Test: [1800/3167]  Time: 0.190 (0.193)  Loss:   2.890 ( 3.060)  Acc@1:  25.000 ( 30.203)  Acc@5:  60.000 ( 58.201)
Test: [1850/3167]  Time: 0.191 (0.193)  Loss:   3.010 ( 3.073)  Acc@1:  17.500 ( 29.639)  Acc@5:  65.000 ( 57.536)
Test: [1900/3167]  Time: 0.191 (0.193)  Loss:   3.514 ( 3.073)  Acc@1:  10.000 ( 29.296)  Acc@5:  50.000 ( 57.675)
Test: [1950/3167]  Time: 0.185 (0.193)  Loss:   4.191 ( 3.074)  Acc@1:   2.500 ( 29.254)  Acc@5:  17.500 ( 57.737)
Test: [2000/3167]  Time: 0.196 (0.193)  Loss:   3.875 ( 3.095)  Acc@1:   2.500 ( 28.687)  Acc@5:  30.000 ( 57.035)
Test: [2050/3167]  Time: 0.190 (0.193)  Loss:   3.877 ( 3.112)  Acc@1:   0.000 ( 28.133)  Acc@5:   7.500 ( 56.171)
Test: [2100/3167]  Time: 0.188 (0.193)  Loss:   2.663 ( 3.113)  Acc@1:  40.000 ( 28.160)  Acc@5:  80.000 ( 56.267)
Test: [2150/3167]  Time: 0.185 (0.193)  Loss:   1.292 ( 3.085)  Acc@1:  75.000 ( 28.947)  Acc@5:  90.000 ( 56.985)
Test: [2200/3167]  Time: 0.186 (0.193)  Loss:   3.148 ( 3.078)  Acc@1:   7.500 ( 28.986)  Acc@5:  55.000 ( 57.202)
Test: [2250/3167]  Time: 0.201 (0.193)  Loss:   3.359 ( 3.086)  Acc@1:  42.500 ( 28.684)  Acc@5:  55.000 ( 56.960)
Test: [2300/3167]  Time: 0.191 (0.193)  Loss:   3.384 ( 3.096)  Acc@1:   5.000 ( 28.352)  Acc@5:  50.000 ( 56.595)
Test: [2350/3167]  Time: 0.195 (0.193)  Loss:   3.618 ( 3.102)  Acc@1:  22.500 ( 27.994)  Acc@5:  50.000 ( 56.484)
Test: [2400/3167]  Time: 0.190 (0.193)  Loss:   3.669 ( 3.095)  Acc@1:   7.500 ( 28.225)  Acc@5:  32.500 ( 56.630)
Test: [2450/3167]  Time: 0.193 (0.193)  Loss:   2.383 ( 3.091)  Acc@1:  35.000 ( 28.311)  Acc@5:  82.500 ( 56.883)
Test: [2500/3167]  Time: 0.194 (0.193)  Loss:   2.803 ( 3.081)  Acc@1:  32.500 ( 28.624)  Acc@5:  65.000 ( 57.269)
Test: [2550/3167]  Time: 0.187 (0.193)  Loss:   4.004 ( 3.069)  Acc@1:   2.500 ( 28.958)  Acc@5:  22.500 ( 57.692)
Test: [2600/3167]  Time: 0.197 (0.193)  Loss:   2.836 ( 3.082)  Acc@1:  37.500 ( 28.688)  Acc@5:  70.000 ( 57.202)
Test: [2650/3167]  Time: 0.198 (0.193)  Loss:   3.501 ( 3.094)  Acc@1:  17.500 ( 28.439)  Acc@5:  45.000 ( 56.847)
Test: [2700/3167]  Time: 0.186 (0.193)  Loss:   2.446 ( 3.094)  Acc@1:  50.000 ( 28.529)  Acc@5:  75.000 ( 56.910)
Test: [2750/3167]  Time: 0.195 (0.193)  Loss:   2.306 ( 3.104)  Acc@1:  50.000 ( 28.370)  Acc@5:  85.000 ( 56.554)
Test: [2800/3167]  Time: 0.191 (0.192)  Loss:   3.879 ( 3.103)  Acc@1:  12.500 ( 28.459)  Acc@5:  40.000 ( 56.645)
Test: [2850/3167]  Time: 0.187 (0.192)  Loss:   3.833 ( 3.117)  Acc@1:  12.500 ( 28.023)  Acc@5:  37.500 ( 56.058)
Test: [2900/3167]  Time: 0.185 (0.192)  Loss:   2.904 ( 3.120)  Acc@1:  42.500 ( 28.023)  Acc@5:  67.500 ( 56.044)
Test: [2950/3167]  Time: 0.192 (0.192)  Loss:   3.951 ( 3.132)  Acc@1:   5.000 ( 27.661)  Acc@5:  20.000 ( 55.547)
Test: [3000/3167]  Time: 0.184 (0.192)  Loss:   3.986 ( 3.147)  Acc@1:  12.500 ( 27.285)  Acc@5:  27.500 ( 55.047)
Test: [3050/3167]  Time: 0.184 (0.192)  Loss:   3.778 ( 3.143)  Acc@1:  12.500 ( 27.452)  Acc@5:  30.000 ( 55.275)
Test: [3100/3167]  Time: 0.209 (0.192)  Loss:   4.094 ( 3.155)  Acc@1:   0.000 ( 27.092)  Acc@5:  22.500 ( 54.856)
Test: [3150/3167]  Time: 0.209 (0.192)  Loss:   3.093 ( 3.155)  Acc@1:   2.500 ( 26.907)  Acc@5:  75.000 ( 54.980)
Test: [3167/3167]  Time: 0.043 (0.192)  Loss:   2.717 ( 3.155)  Acc@1:  11.111 ( 26.809)  Acc@5:  77.778 ( 55.016)
Test: [   0/124]  Time: 0.611 (0.611)  Loss:   3.581 ( 3.581)  Acc@1:  17.500 ( 17.500)  Acc@5:  52.500 ( 52.500)
Test: [  50/124]  Time: 0.184 (0.199)  Loss:   3.654 ( 3.171)  Acc@1:  17.500 ( 25.784)  Acc@5:  40.000 ( 53.971)
Test: [ 100/124]  Time: 0.184 (0.195)  Loss:   2.498 ( 3.178)  Acc@1:  50.000 ( 25.371)  Acc@5:  75.000 ( 53.144)
Test: [ 124/124]  Time: 0.180 (0.194)  Loss:   2.888 ( 3.252)  Acc@1:  12.500 ( 23.840)  Acc@5:  65.000 ( 50.980)
Current checkpoints:
 ('./output/train/Upd_Exp40_imagenet_monet_16_double_depth_init_0/checkpoint-7.pth.tar', 26.80895736808064)

Train: 8 [   0/3167 (  0%)]  Loss: 4.22 (4.22)  Time: 1.155s,   34.62/s  (1.155s,   34.62/s)  LR: 8.200e-05  Data: 0.540 (0.540)
Train: 8 [  50/3167 (  2%)]  Loss: 4.19 (4.02)  Time: 0.599s,   66.81/s  (0.614s,   65.18/s)  LR: 8.200e-05  Data: 0.010 (0.021)
Train: 8 [ 100/3167 (  3%)]  Loss: 4.04 (4.00)  Time: 0.604s,   66.26/s  (0.608s,   65.82/s)  LR: 8.200e-05  Data: 0.012 (0.015)
Train: 8 [ 150/3167 (  5%)]  Loss: 3.41 (3.97)  Time: 0.603s,   66.33/s  (0.606s,   65.98/s)  LR: 8.200e-05  Data: 0.014 (0.013)
Train: 8 [ 200/3167 (  6%)]  Loss: 3.93 (3.96)  Time: 0.599s,   66.83/s  (0.606s,   66.05/s)  LR: 8.200e-05  Data: 0.010 (0.013)
Train: 8 [ 250/3167 (  8%)]  Loss: 4.14 (3.94)  Time: 0.603s,   66.28/s  (0.605s,   66.11/s)  LR: 8.200e-05  Data: 0.007 (0.012)
Train: 8 [ 300/3167 (  9%)]  Loss: 3.97 (3.94)  Time: 0.611s,   65.52/s  (0.605s,   66.15/s)  LR: 8.200e-05  Data: 0.011 (0.012)
Train: 8 [ 350/3167 ( 11%)]  Loss: 3.65 (3.94)  Time: 0.606s,   66.02/s  (0.604s,   66.17/s)  LR: 8.200e-05  Data: 0.012 (0.012)
Train: 8 [ 400/3167 ( 13%)]  Loss: 4.07 (3.93)  Time: 0.603s,   66.32/s  (0.604s,   66.20/s)  LR: 8.200e-05  Data: 0.012 (0.011)
Train: 8 [ 450/3167 ( 14%)]  Loss: 4.06 (3.94)  Time: 0.600s,   66.65/s  (0.604s,   66.23/s)  LR: 8.200e-05  Data: 0.011 (0.011)
Train: 8 [ 500/3167 ( 16%)]  Loss: 3.32 (3.93)  Time: 0.601s,   66.60/s  (0.604s,   66.25/s)  LR: 8.200e-05  Data: 0.012 (0.011)
Train: 8 [ 550/3167 ( 17%)]  Loss: 4.06 (3.93)  Time: 0.595s,   67.17/s  (0.604s,   66.26/s)  LR: 8.200e-05  Data: 0.007 (0.011)
Train: 8 [ 600/3167 ( 19%)]  Loss: 3.99 (3.93)  Time: 0.602s,   66.47/s  (0.604s,   66.27/s)  LR: 8.200e-05  Data: 0.013 (0.011)
Train: 8 [ 650/3167 ( 21%)]  Loss: 3.49 (3.93)  Time: 0.600s,   66.66/s  (0.603s,   66.29/s)  LR: 8.200e-05  Data: 0.011 (0.011)
Train: 8 [ 700/3167 ( 22%)]  Loss: 3.22 (3.93)  Time: 0.598s,   66.84/s  (0.603s,   66.30/s)  LR: 8.200e-05  Data: 0.007 (0.011)
Train: 8 [ 750/3167 ( 24%)]  Loss: 3.69 (3.93)  Time: 0.595s,   67.21/s  (0.603s,   66.31/s)  LR: 8.200e-05  Data: 0.004 (0.011)
Train: 8 [ 800/3167 ( 25%)]  Loss: 3.48 (3.93)  Time: 0.597s,   66.95/s  (0.603s,   66.32/s)  LR: 8.200e-05  Data: 0.006 (0.011)
Train: 8 [ 850/3167 ( 27%)]  Loss: 3.77 (3.92)  Time: 0.602s,   66.41/s  (0.603s,   66.33/s)  LR: 8.200e-05  Data: 0.011 (0.011)
Train: 8 [ 900/3167 ( 28%)]  Loss: 4.12 (3.92)  Time: 0.593s,   67.46/s  (0.603s,   66.34/s)  LR: 8.200e-05  Data: 0.004 (0.011)
Train: 8 [ 950/3167 ( 30%)]  Loss: 3.83 (3.92)  Time: 0.598s,   66.89/s  (0.603s,   66.33/s)  LR: 8.200e-05  Data: 0.006 (0.011)
Train: 8 [1000/3167 ( 32%)]  Loss: 3.68 (3.92)  Time: 0.603s,   66.34/s  (0.603s,   66.34/s)  LR: 8.200e-05  Data: 0.011 (0.011)
Train: 8 [1050/3167 ( 33%)]  Loss: 3.62 (3.92)  Time: 0.603s,   66.36/s  (0.603s,   66.35/s)  LR: 8.200e-05  Data: 0.011 (0.010)
Train: 8 [1100/3167 ( 35%)]  Loss: 4.14 (3.92)  Time: 0.600s,   66.62/s  (0.603s,   66.35/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1150/3167 ( 36%)]  Loss: 3.38 (3.92)  Time: 0.604s,   66.19/s  (0.603s,   66.36/s)  LR: 8.200e-05  Data: 0.010 (0.010)
Train: 8 [1200/3167 ( 38%)]  Loss: 3.42 (3.91)  Time: 0.601s,   66.61/s  (0.603s,   66.36/s)  LR: 8.200e-05  Data: 0.011 (0.010)
Train: 8 [1250/3167 ( 39%)]  Loss: 4.16 (3.91)  Time: 0.603s,   66.36/s  (0.603s,   66.37/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1300/3167 ( 41%)]  Loss: 3.74 (3.91)  Time: 0.595s,   67.21/s  (0.603s,   66.38/s)  LR: 8.200e-05  Data: 0.006 (0.010)
Train: 8 [1350/3167 ( 43%)]  Loss: 3.69 (3.91)  Time: 0.598s,   66.85/s  (0.603s,   66.38/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [1400/3167 ( 44%)]  Loss: 3.97 (3.92)  Time: 0.601s,   66.58/s  (0.603s,   66.39/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [1450/3167 ( 46%)]  Loss: 3.68 (3.91)  Time: 0.606s,   65.98/s  (0.602s,   66.39/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [1500/3167 ( 47%)]  Loss: 3.61 (3.91)  Time: 0.610s,   65.53/s  (0.602s,   66.40/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1550/3167 ( 49%)]  Loss: 4.12 (3.92)  Time: 0.593s,   67.48/s  (0.602s,   66.41/s)  LR: 8.200e-05  Data: 0.004 (0.010)
Train: 8 [1600/3167 ( 51%)]  Loss: 3.64 (3.92)  Time: 0.603s,   66.36/s  (0.602s,   66.41/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1650/3167 ( 52%)]  Loss: 3.61 (3.92)  Time: 0.604s,   66.18/s  (0.602s,   66.42/s)  LR: 8.200e-05  Data: 0.009 (0.010)
Train: 8 [1700/3167 ( 54%)]  Loss: 3.89 (3.92)  Time: 0.598s,   66.84/s  (0.602s,   66.43/s)  LR: 8.200e-05  Data: 0.007 (0.010)
Train: 8 [1750/3167 ( 55%)]  Loss: 4.10 (3.92)  Time: 0.605s,   66.09/s  (0.602s,   66.44/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [1800/3167 ( 57%)]  Loss: 3.68 (3.92)  Time: 0.596s,   67.16/s  (0.602s,   66.44/s)  LR: 8.200e-05  Data: 0.007 (0.010)
Train: 8 [1850/3167 ( 58%)]  Loss: 3.94 (3.92)  Time: 0.596s,   67.16/s  (0.602s,   66.45/s)  LR: 8.200e-05  Data: 0.006 (0.010)
Train: 8 [1900/3167 ( 60%)]  Loss: 4.22 (3.91)  Time: 0.596s,   67.07/s  (0.602s,   66.45/s)  LR: 8.200e-05  Data: 0.004 (0.010)
Train: 8 [1950/3167 ( 62%)]  Loss: 3.63 (3.91)  Time: 0.593s,   67.48/s  (0.602s,   66.46/s)  LR: 8.200e-05  Data: 0.004 (0.010)
Train: 8 [2000/3167 ( 63%)]  Loss: 4.06 (3.91)  Time: 0.601s,   66.58/s  (0.602s,   66.47/s)  LR: 8.200e-05  Data: 0.012 (0.010)
Train: 8 [2050/3167 ( 65%)]  Loss: 4.15 (3.91)  Time: 0.593s,   67.48/s  (0.602s,   66.47/s)  LR: 8.200e-05  Data: 0.004 (0.010)
Train: 8 [2100/3167 ( 66%)]  Loss: 3.64 (3.91)  Time: 0.603s,   66.29/s  (0.602s,   66.48/s)  LR: 8.200e-05  Data: 0.012 (0.010)
slurmstepd: error: *** JOB 2080292 ON i51 CANCELLED AT 2024-05-19T22:41:40 DUE TO TIME LIMIT ***
